{
  "id": "3A81sm",
  "title": "Tech",
  "displayTitle": "Tech",
  "url": "",
  "feedLink": "",
  "isQuery": true,
  "isEmpty": false,
  "isHidden": false,
  "itemCount": 138,
  "items": [
    {
      "title": "Ocean Damage Nearly Doubles the Cost of Climate Change",
      "url": "https://news.slashdot.org/story/26/01/20/0053209/ocean-damage-nearly-doubles-the-cost-of-climate-change?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1768903200,
      "author": "BeauHD",
      "guid": 37130,
      "unread": true,
      "content": "A new study from Scripps Institution of Oceanography finds that factoring ocean damage into climate economics nearly doubles the estimated global cost of climate change, adding close to $2 trillion per year from losses to fisheries, coral reefs, and coastal infrastructure. \"It is the first time a social cost of carbon (SCC) assessment -- a key measure of economic harm caused by climate change -- has included damages to the ocean,\" reports Inside Climate News. From the report: \"For decades, we've been estimating the economic cost of climate change while effectively assigning a value of zero to the ocean,\" said Bernardo Bastien-Olvera, who led the study during his postdoctoral fellowship at Scripps. \"Ocean loss is not just an environmental issue, but a central part of the economic story of climate change.\"\n \nThe social cost of carbon is an accounting method for working out the monetary cost of each ton of carbon dioxide released into the atmosphere. \"[It] is one of the most efficient tools we have for internalizing climate damages into economic decision-making,\" said Amy Campbell, a United Nations climate advisor and former British government COP negotiator. Calculations have historically been used by international organizations and state departments like the U.S. Environmental Protection Agency to assess policy proposals -- though a 2025 White House memo from the Trump administration instructed federal agencies to ignore the data during cost-benefit analyses unless required by law. \"It becomes politically contentious when deciding whose damages are counted, which sectors are included and most importantly how future and retrospective harms are valued,\" Campbell said.\n \nExcluding ocean harm, the social cost of carbon is $51 per ton of carbon dioxide emitted. This increases to $97.20 per ton when the ocean, which covers 70 percent of the planet, is included. In 2024, global CO2 emissions were estimated to be 41.6 billion tons, making the 91 percent cost increase significant. Using greenhouse gas emission predictions, the report estimates the annual damages to traditional markets alone will be $1.66 trillion by 2100.",
      "contentLength": 2149,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Bank of England 'Must Plan For a Financial Crisis Triggered By Aliens'",
      "url": "https://entertainment.slashdot.org/story/26/01/20/0045220/bank-of-england-must-plan-for-a-financial-crisis-triggered-by-aliens?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1768892400,
      "author": "BeauHD",
      "guid": 37110,
      "unread": true,
      "content": "A former Bank of England analyst has urged contingency planning for a potential financial shock if the U.S. government were to confirm the existence of extraterrestrial intelligence. The argument is that \"ontological shock\" alone could destabilize confidence and trigger crisis dynamics. The Independent reports: [Helen McCaw, who served as a senior analyst in financial security at the UK's central bank and worked for the Bank of England for 10 years until 2012] said politicians and bankers can no longer afford to dismiss talk of alien life, and warned a declaration of this nature could trigger bank collapses. She reportedly said: \"The United States government appears to be partway through a multi-year process to declassify and disclose information on the existence of a technologically advanced non-human intelligence responsible for Unidentified Anomalous Phenomena (UAPs).\"\n \n\"If the UAP proves to be of non-human origin, we may have to acknowledge the existence of a power or intelligence greater than any government and with potentially unknown intentions.\" Her warning comes as senior American officials have recently indicated their belief in the possibility of alien life. [...] Ms McCaw said: \"UAP disclosure is likely to induce ontological shock and provoke psychological responses with material consequences ... There might be extreme price volatility in financial markets due to catastrophising or euphoria, and a collapse in confidence if market participants feel uncertain on how to price assets using any of the familiar methods.\"\n \nThe former Bank of England worker explained there might be a rush towards assets such as gold or other precious metals, and government bonds, which are perceived as \"safe.\" Alternatively, she said precious metals might lose their status as perceived safe assets if people speculate that new space-faring technologies will soon increase the supply of precious metals. The article cites a recent UFO documentary, The Age of Disclosure, where 34 U.S. government insiders, including those from the military and intelligence community officials, share insights about the governments work with UAP. Per the film's description, the documentary \"reveals an 80-year global cover-up of non-human intelligent life and a secret war among major nations to reverse-engineer advanced technology of non-human origin.\"",
      "contentLength": 2357,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "The Fastest Human Spaceflight Mission In History Crawls Closer To Liftoff",
      "url": "https://science.slashdot.org/story/26/01/19/2332237/the-fastest-human-spaceflight-mission-in-history-crawls-closer-to-liftoff?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1768879800,
      "author": "BeauHD",
      "guid": 37098,
      "unread": true,
      "content": "An anonymous reader quotes a report from Ars Technica: Preparations for the first human spaceflight to the Moon in more than 50 years took a big step forward this weekend with the rollout of the Artemis II rocket to its launch pad. The rocket reached a top speed of just 1 mph on the four-mile, 12-hour journey from the Vehicle Assembly Building to Launch Complex 39B at NASA's Kennedy Space Center in Florida. At the end of its nearly 10-day tour through cislunar space, the Orion capsule on top of the rocket will exceed 25,000 mph as it plunges into the atmosphere to bring its four-person crew back to Earth. \"This is the start of a very long journey,\" said NASA Administrator Jared Isaacman. \"We ended our last human exploration of the moon on Apollo 17.\"\n \n[...] \"We really are ready to go,\" said Wiseman, the Artemis II commander, during Saturday's rollout to the launch pad. \"We were in a sim [in Houston] for about 10 hours yesterday doing our final capstone entry and landing sim. We got in T-38s last night and we flew to the Cape to be here for this momentous occasion.\" The rollout began around sunrise Saturday, with NASA's Space Launch System rocket and Orion capsule riding a mobile launch platform and a diesel-powered crawler transporter along a throughway paved with crushed Alabama river rock. Employees, VIPs, and guests gathered along the crawlerway to watch the 11 million-pound stack inch toward the launch pad. The rollout concluded about an hour after sunset, when the crawler transporter's jacking system lowered the mobile launch platform onto pedestals at Pad 39B.\n \nThe rollout keeps the Artemis II mission on track for liftoff as soon as next month, when NASA has a handful of launch opportunities on February 6, 7, 8, 10, and 11. The big milestone leading up to launch day will be a practice countdown or Wet Dress Rehearsal (WDR), currently slated for around February 2, when NASA's launch team will pump more than 750,000 gallons of super-cold liquid hydrogen and liquid oxygen into the rocket. NASA had trouble keeping the cryogenic fluids at the proper temperature, then encountered hydrogen leaks when the launch team first tried to fill the rocket for the unpiloted Artemis I mission in 2022. Engineers implemented the same fixes on Artemis II that they used to finally get over the hump with propellant loading on Artemis I. [...] If the launch does not happen in February, NASA has a slate of backup launch dates in early March.",
      "contentLength": 2468,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "The World's Longest-Running Lab Experiment Is Almost 100 Years Old",
      "url": "https://science.slashdot.org/story/26/01/19/2324236/the-worlds-longest-running-lab-experiment-is-almost-100-years-old?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1768876200,
      "author": "BeauHD",
      "guid": 37094,
      "unread": true,
      "content": "alternative_right shares a report from ScienceAlert: It all started in 1927, when physicist Thomas Parnell at the University of Queensland in Australia filled a closed funnel with the world's thickest known fluid: pitch, a derivative of tar that was once used to seal ships against the seas. Three years later, in 1930, Parnell cut the funnel's stem, like a ribbon at an event, heralding the start of the Pitch Drop Experiment. From then on, the black substance began to flow. At least, that is, in a manner of speaking. At room temperature pitch might look solid, but it is actually a fluid 100 billion times more viscous than water.\n \nIt took eight years for the first droplet to finally hit the beaker below. Then, they dripped at a cadence of once every eight years or so, slowing down only after air conditioning was installed in the building in the 1980s. Today, 96 years after the funnel was cut, only nine drops in total have seeped out. The last was in 2014. Scientists expect another will fall sometime in the 2020s, but they are still waiting. No one has ever actually seen a droplet fall directly, despite all the watchful eyes. The experiment is now live-streamed, but various glitches in the past meant that each fateful moment has slipped us by.",
      "contentLength": 1260,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "X.Org Server May Create A New Selective Git Branch With Hopes Of A New Release This Year",
      "url": "https://www.phoronix.com/news/X.Org-Server-Main-Repo",
      "date": 1768873907,
      "author": "Michael Larabel",
      "guid": 37092,
      "unread": true,
      "content": "<article>A proposal has been laid out for a new X.Org Server \"main\" Git branch to house their development going forward and cleaning up the development lapses over the past few years. Ultimately the hope is for having a new cleaned-up X.Org Server and XWayland Git branch for shipping new releases in 2026...</article>",
      "contentLength": 299,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Germany's EV Subsidies Will Include Chinese Brands",
      "url": "https://tech.slashdot.org/story/26/01/19/2341242/germanys-ev-subsidies-will-include-chinese-brands?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1768873800,
      "author": "BeauHD",
      "guid": 37093,
      "unread": true,
      "content": "Germany is reinstating EV subsidies after a sharp sales drop, rolling out a 3 billion-euro program offering 1,500-6,000 euros per buyer starting in May and running through 2029. Unlike some neighboring countries, the incentives are open to all manufacturers with a focus on low- and middle-income households. From a report: \"I cannot see any evidence of this postulated major influx of Chinese car manufacturers in Germany, either in the figures or on the roads -- and that is why we are facing up to the competition and not imposing any restrictions,\" German Environment Minister Carsten Schneider said at a Monday press conference. The decision is a major boon for affordable Chinese automakers like BYD that are steadily gaining ground in the European market, [Bloomberg noted].\n \nGermany's green-light for Chinese EVs stands in stark contrast to other nations' approaches. In the UK, subsidies introduced last year effectively excluded Chinese battery-powered vehicles, while France's so-called social leasing scheme includes similar restrictions. [...] Germany maintains strong diplomatic ties with China. German automakers are among the most significant players in China's automotive industry. Over the past years, China's policies -- including purchase subsidies and purchase tax reductions -- have not excluded models or automakers from specific countries. Whether German automakers like Volkswagen or American automakers like Tesla, all enjoy national-level purchase incentive policies in China on par with domestic automakers.",
      "contentLength": 1536,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "A Second US Sphere Could Come To Maryland",
      "url": "https://news.slashdot.org/story/26/01/19/2320223/a-second-us-sphere-could-come-to-maryland?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1768871400,
      "author": "BeauHD",
      "guid": 37087,
      "unread": true,
      "content": "Sphere Entertainment plans to build a second U.S. Sphere near Washington, D.C., with a smaller 6,000-seat \"mini-Sphere\" proposed for National Harbor in Maryland. The venue would retain the signature LED exterior and immersive 4D tech of the Las Vegas Sphere, just at a more compact scale. The Verge reports: The second US sphere would be built in an area known as National Harbor in Prince George's County, Maryland. Located along the Potomac River, National Harbor currently features a convention center, multiple hotels, restaurants, and shops. While Abu Dhabi plans to build a sphere as large as the one in Las Vegas, the National Harbor venue would be one of the first mini-Sphere venues announced last March.\n \nIts capacity would be limited to 6,000 seats instead of over 17,000. But the smaller Sphere would still be hard to miss with an exterior LED exosphere for showcasing the \"artistic and branded content\" that helped make the original sphere a unique part of the Las Vegas skyline. The inside of the mini-Sphere will feature a high-resolution 16,000 by 16,000 pixel wrap-around screen, the company's immersive sound technology, haptic seating, and \"4D environmental effects.\" For the AI-enhanced version of The Wizard of Oz currently playing in Las Vegas, audiences experience effects like wind, fog, smells, and apples falling from the ceiling.",
      "contentLength": 1357,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Nvidia Contacted Anna's Archive To Secure Access To Millions of Pirated Books",
      "url": "https://yro.slashdot.org/story/26/01/19/2257241/nvidia-contacted-annas-archive-to-secure-access-to-millions-of-pirated-books?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1768869000,
      "author": "BeauHD",
      "guid": 37086,
      "unread": true,
      "content": "An anonymous reader quotes a report from TorrentFreak: NVIDIA executives allegedly authorized the use of millions of pirated books from Anna's Archive to fuel its AI training. In an expanded class-action lawsuit that cites internal NVIDIA documents, several book authors claim (PDF) that the trillion-dollar company directly reached out to Anna's Archive, seeking high-speed access to the shadow library data. [...] Last Friday, the authors filed an amended complaint that significantly expands the scope of the lawsuit. In addition to adding more books, authors, and AI models, it also includes broader \"shadow library\" claims and allegations. The authors, including Abdi Nazemian, now cite various internal Nvidia emails and documents, suggesting that the company willingly downloaded millions of copyrighted books. The new complaint alleges that \"competitive pressures drove NVIDIA to piracy,\" which allegedly included collaborating with the controversial Anna's Archive library.\n \nAccording to the amended complaint, a member of Nvidia's data strategy team reached out to Anna's Archive to find out what the pirate library could offer the trillion-dollar company \"Desperate for books, NVIDIA contacted Anna's Archive -- the largest and most brazen of the remaining shadow libraries -- about acquiring its millions of pirated materials and 'including Anna's Archive in pre-training data for our LLMs,'\" the complaint notes. \"Because Anna's Archive charged tens of thousands of dollars for 'high-speed access' to its pirated collections [] NVIDIA sought to find out what \"high-speed access\" to the data would look like.\"\n \nAccording to the complaint, Anna's Archive then warned Nvidia that its library was illegally acquired and maintained. Because the site previously wasted time on other AI companies, the pirate library asked NVIDIA executives if they had internal permission to move forward. This permission was allegedly granted within a week, after which Anna's Archive provided the chip giant with access to its pirated books. \"Within a week of contacting Anna's Archive, and days after being warned by Anna's Archive of the illegal nature of their collections, NVIDIA management gave 'the green light' to proceed with the piracy. Anna's Archive offered NVIDIA millions of pirated copyrighted books.\" The complaint states that Anna's Archive promised to provide NVIDIA with access to roughly 500 terabytes of data. This included millions of books that are usually only accessible through Internet Archive's digital lending system, which itself has been targeted in court. The complaint does not explicitly mention whether NVIDIA ended up paying Anna's Archive for access to the data.\n \nAdditionally, it's worth mentioning that NVIDIA also stands accused of using other pirated sources. In addition to the previously included Books3 database, the new complaint also alleges that the company downloaded books from LibGen, Sci-Hub, and Z-Library. In addition to downloading and using pirated books for its own AI training, the authors allege NVIDIA distributed scripts and tools that allowed its corporate customers to automatically download \"The Pile\", which contains the Books3 pirated dataset.",
      "contentLength": 3202,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "OpenAI CFO Says Annualized Revenue Crosses $20 Billion In 2025",
      "url": "https://devices.slashdot.org/story/26/01/19/2249208/openai-cfo-says-annualized-revenue-crosses-20-billion-in-2025?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1768866600,
      "author": "BeauHD",
      "guid": 37082,
      "unread": true,
      "content": "According to CFO Sarah Friar, OpenAI's annualized revenue surpassed $20 billion in 2025, up from $6 billion a year earlier with growth closely tracking an expansion in computing capacity. Reuters reports: OpenAI's computing capacity rose to 1.9 gigawatts (GW) in 2025 from 0.6 GW in 2024, Friar said in the blog, adding that Microsoft-backed OpenAI's weekly and daily active users figures continue to produce all-time highs. OpenAI last week said it would start showing ads in ChatGPT to some U.S. users, ramping up efforts to generate revenue from the AI chatbot to fund the high costs of developing the technology. Separately, Axios reported on Monday that OpenAI's policy chief Chris Lehane said that the company is \"on track\" to unveil its first device in the second half of 2026.\n \nFriar said OpenAI's platform spans text, images, voice, code and APIs, and the next phase will focus on agents and workflow automation that run continuously, carry context over time, and take action across tools. For 2026, the company will prioritize \"practical adoption,\" particularly in health, science and enterprise, she said. Friar said the company is keeping a \"light\" balance sheet by partnering rather than owning and structuring contracts with flexibility across providers and hardware types.",
      "contentLength": 1288,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Threads Usage Overtakes X On Mobile",
      "url": "https://tech.slashdot.org/story/26/01/19/2240209/threads-usage-overtakes-x-on-mobile?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1768864200,
      "author": "BeauHD",
      "guid": 37081,
      "unread": true,
      "content": "New data from Similarweb shows Threads has overtaken X in daily mobile users. However, X still dominates on the web with around 150 million daily web visits compared to Threads' 8.5 million daily visits. TechCrunch reports: Similarweb's data shows that Threads had 141.5 million daily active users on iOS and Android as of January 7, 2026, after months of growth, while X has 125 million daily active users on mobile devices. This appears to be the result of longer-term trends, rather than a reaction to the recent X controversies [...]. Instead, Threads' boost in daily mobile usage may be driven by other factors, including cross-promotions from Meta's larger social apps like Facebook and Instagram (where Threads is regularly advertised to existing users), its focus on creators, and the rapid rollout of new features.\n \nOver the past year, Threads has added features like interest-based communities, better filters, DMs, long-form text, disappearing posts, and has recently been spotted testing games. Combined, the daily active user increases suggest that more people are using Threads on mobile as a more regular habit. Further reading: Threads Now Has More Than 400 Million Monthly Active Users",
      "contentLength": 1203,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Why Your Code Review Process Might Be Missing Its Biggest Security Risks",
      "url": "https://hackernoon.com/why-your-code-review-process-might-be-missing-its-biggest-security-risks?source=rss",
      "date": 1768862703,
      "author": "Code Review",
      "guid": 37073,
      "unread": true,
      "content": "<ul><li>Code Review for Software Security</li><li>Security Concern Handling Process in Code Review</li></ul><ul><li>Security Concern Identification Approach (RQ1)</li><li>Alignment Analysis of Known Vulnerabilities (RQ2)</li><li>Handling Process Identification (RQ3)</li></ul><ul><li>PA1: Prevalence of Coding Weakness Comments</li><li>PA2: Preliminary Evaluation of our Security Concern Identification Approach</li></ul><ul></ul><p>In this section, we discuss the implications of our results and provide practical recommendations for practitioners and potential future work. <strong>1) Various coding weaknesses that may lead to security issues can be raised during code reviews.</strong> Our first preliminary analysis (PA1) in Section 5 shows that coding weaknesses were raised in the code review process 21 - 33.5 times more often than explicit vulnerabilities. This finding supports our intuition that the reviewers tend to focus on issues in source code. Therefore, it is more natural for the reviewers to identify coding weaknesses than security issues. This implication aligns with the previous work (Gon¸calves et al., 2022) that the cognitive load required for code reviews is lower if the reviewers already have the relevant knowledge. Indeed, our RQ1 shows that the raised security concerns in code reviews of OpenSSL and PHP cover nearly 90% of the CWE-699 weakness types (i.e., 35 out of 40 categories, see Table 10). This confirms our presumption that a variety of coding weaknesses can be raised by reviewers during the code review process. As shown in the motivating examples in Section 3, such coding weaknesses can lead to security issues. It can be implied that the coding weaknesses that may introduce security issues can potentially be identified during the code review process although the weaknesses did not yet explicitly expose the vulnerable outcomes (Braz et al., 2021). Our manual observations from RQ1 also show that the code changes may potentially be vulnerable if the author did not address the raised security concerns. For instance, Figure 7 shows that vulnerabilities such as CVE-2008-498963 and CVE-2012-582164 could be introduced into the code if the Improper Certificate Validation coding weakness (CWE-295) under the Authentication Errors category (CWE-1211) was not raised by a reviewer.</p><p>\\\nRecommendation: As we found that coding weaknesses can be identified in code reviews, our findings suggest that practitioners and/or other software projects could adopt the coding weaknesses taxonomy (i.e., CWE-699) to assist code reviews. A list of coding weaknesses should help the team increase the awareness of the potential problems that can lead to security issues without requiring deep security knowledge. A recent controlled experiment of Braz et al. (2022) has shown that a code review checklist could help reviewers better find security issues. Hence, one of the possible ways to adopt the coding weaknesses taxonomy for code reviews is to incorporate it into a code review checklist. Future work should investigate the effectiveness and practicality of using coding weaknesses as a code review checklist for identifying and mitigating security issues during the code review process. Moreover, as coding weakness are more frequently discussed than the security issue, coding weakness can also be an effective proxy for understanding secure code review practices</p><p>\\\n<strong>2) Coding weaknesses related to the known vulnerabilities of the systems are not frequently discussed in code reviews.</strong> Our RQ2 shows that some types of coding weaknesses were less frequently discussed compared to the known vulnerabilities (see Figure 10). In particular, we found that Memory Buffer Errors (CWE-1218) and Resource Management Errors (CWE-399) are the least frequently discussed coding weaknesses in OpenSSL and PHP (4%-9%), albeit the high percentages of known vulnerabilities (17%-29%). Furthermore, our motivating examples in Section 3 highlighted that such coding weaknesses can lead to a serious vulnerability. For example, OpenSSL’s Heartbleed is a known vulnerability related to weakness Out-of-bounds Read (CWE125) which is a type of memory buffer error.</p><p>\\\nThese coding weaknesses were rarely discussed maybe because they are generic and easy to be overlooked. Hence, the reviewers may have failed to notice them. To mitigate this problem, the reviewers should be aware of these latent coding weaknesses in order to properly prioritize them in the code reviews. In addition to the known vulnerabilities, our RQ1 indicates that the security concerns in code reviews can vary from project to project. Particularly, OpenSSL reviewers were concerned about direct security threats (e.g., Authentication Errors (CWE-1211 and Random Number Issues (CWE-1213)), while PHP reviewers were more concerned about data controlling (e.g., Type Errors (CWE-136)). As OpenSSL is an encryption library for secure communication and PHP is a programming language, it can be implied that the application domain may correlate with the coding weaknesses that reviewers can raise. This finding also supports our results that coding weaknesses such as User-interface Security Issues (CWE-355) and Encapsulation Issues (CWE-1227) were neither found in our results nor appear in the known vulnerabilities because they are less related to the application domains of the studied projects.</p><p>\\\n: Our findings suggest that it is essential to identify the specific coding weaknesses that are significant, highly prone to introduce security issues, and relevant to the application domain of the projects. Thus, rather than reviewing all types of coding weaknesses, a selected set of coding weaknesses can be prioritized for effective code reviews. Prioritization of coding weaknesses during code reviews can be based on known vulnerabilities and the unique concerns of the projects that were raised in the past. Future work can investigate a systematic approach for identifying and prioritizing the types of important coding weaknesses for individual projects in this context.</p><p>\\\n<strong>3) Not all the raised security concerns were addressed within the same code review process.</strong> The security concern handling scenarios identified in our RQ3 reveal a shortcoming in the code review process. Our results show that approximately a third of the security concerns from coding weaknesses (30%-36%, see C2 in Table 11) were acknowledged without fixes in the process. We observed that developers promised to fix some of the acknowledged concerns in the new independent code changes (10%-18%), but some concerns were left without fixing due to disagreement about the proper solution (18%-20%). Nevertheless, approximately half of the unresolved concerns (6%-9%) were eventually merged. This result implies a possible risk that security issues can slip through the code review process into the software product. The incomplete code reviews or unclean code changes that contain security concerns related to coding weaknesses should be held from merging until all security concerns are resolved. Otherwise, the remaining coding weaknesses in code changes can become security issues in the future.</p><p>\\\nThis implication is consistent with the findings of the prior work which reported that relentless and inconclusive discussion could impact the code review quality (Kononenko et al., 2015), and the incomplete code reviews and the unsuccessfully fixed can negatively affect the developer’s contribution (Gerosa et al., 2021). Recommendation: Code reviews with security concerns should be escalated if the final resolutions cannot be agreed upon before merging. Security experts or experienced developers should be included in such code reviews to investigate complex security concerns. In addition, the mechanisms to notify the reviewers of the incomplete code reviews or the insufficiently addressed security concerns could reduce the risk that security issues will slip through the code review process into the software product. Our suggestion aligns with Wessel et al. (2020) who reported that the adoption of an automated mechanism such as code review bots can increase the number of merged pull requests, and, hence, reduce the number of abandoned code reviews. Kudrjavets et al. (2022) also observed that the automated bots can remind the developers of the pending tasks in the code review process without inciting negative feelings. Hence, future work should investigate an approach to identify incomplete code reviews or the insufficiently addressed security concerns to help developers increase awareness.</p><p>:::info\nThis paper is  under CC by 4.0 Deed (Attribution 4.0 International) license.</p>",
      "contentLength": 8547,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Code Reviews Uncover Dozens of Security Weakness Categories, Study Shows",
      "url": "https://hackernoon.com/code-reviews-uncover-dozens-of-security-weakness-categories-study-shows?source=rss",
      "date": 1768861807,
      "author": "Code Review",
      "guid": 37072,
      "unread": true,
      "content": "<ul><li>Code Review for Software Security</li><li>Security Concern Handling Process in Code Review</li></ul><ul><li>Security Concern Identification Approach (RQ1)</li><li>Alignment Analysis of Known Vulnerabilities (RQ2)</li><li>Handling Process Identification (RQ3)</li></ul><ul><li>PA1: Prevalence of Coding Weakness Comments</li><li>PA2: Preliminary Evaluation of our Security Concern Identification Approach</li></ul><ul></ul><p>We report the empirical results based on the code review comments identified by the semi-automated approach; and answer the three research questions in this section, followed by a summary of our findings.</p><p><strong>RQ1: What kinds of security concerns related to coding weaknesses are often raised in code review?</strong> Table 9 shows the number of identified code review comments and aggregated security concerns. From the 135K code review comments in the dataset, we manually read 3,570 OpenSSL and 2,576 PHP comments with the highest cosine similarity scores until reaching the saturation point (i.e., 50 consecutive irrelevant comments). As described in Section 4.6.2, in the first iteration we removed irrelevant comments (e.g., related to bookkeeping and code styling), resulting in 232 and 148 comments. Subsequently, the first and the third author independently determined whether the comments raised legitimate security concerns and could be classified into one of the coding weakness categories, resulting in 202 and 128 comments. To simplify the results, we aggregated comments within the same pull request that were classified into the identical coding weakness category into singular security concern. In total, we identified 188 security concerns from 202 comments in 164 pull requests in OpenSSL and 123 security concerns from 128 comments in 100</p><p>pull requests in PHP. Note that one pull request can have multiple concerns with different coding weakness categories. The manual annotation process by the first and the third author achieved the inter-rater agreement (Cohen, 1960) κ = 0.70 and κ = 0.84 for OpenSSL and PHP, which can be interpreted (McHugh, 2012) as substantial (0.61 ≥ |κ| ≥ 0.81) and almost perfect (|κ| &gt; 0.81), respectively. Table 10 shows the number of identified security concerns across the 40 coding weakness categories of CWE-699. The numbers in parentheses indicate the CWE category number of the coding weakness. We found that in OpenSSL and PHP, identified security concerns were related to 35 out of 40 coding weakness categories of CWE-699, suggesting that diverse types of coding weaknesses can be discovered during the code review process. The bold text in Table 10 highlights the top ten coding weaknesses that were frequently raised in each project and the ‡ symbol indicates the concerns that were frequently raised in both OpenSSL and PHP. We found that six coding weaknesses, i.e., Authentication Errors (CWE-1211), API / Function Errors (CWE-1228), Privilege Issues (CWE-265), Behavioral Problems (CWE-438), Cryptographic Issues (CWE-310) and Random Number Issues (CWE1213), were among the top ten concerns in both OpenSSL and PHP. Additionally, we observe that several coding weaknesses were frequently raised in a particular project. This may suggest that while reviewers in OpenSSL and PHP share a set of common concerns, they can have a specific focus on particular security aspects as well. Below, we present common security concerns across both projects and projectspecific security concerns.</p><p>\\\n<strong>Common security concerns in OpenSSL and PHP:</strong> The first two common security concerns are related to users and rights, i.e., Authentication Errors (CWE-1211) and Privilege Issues (CWE-265) coding weaknesses. Authentication Errors (CWE-1211) are related to the failure to properly verify the identification of the rightful actors who can gain access to the system. For example, as shown in Figure 7, we observed that a reviewer noticed that the program does not verify whether the certificate is trusted or not: ”[…]The certificate in question is now detached from its provenance, we don’t know whether it came from the trust store, or from the peer-supplied untrusted chain![…] ”.44 Privilege Issues (CWE-265) are related to the improper management of critical privileges assigned to users or objects. For example, a reviewer mentioned that the developer did not use the correct approach to verify that the user has sufficient privileges to execute a script.45</p><p>Another two common security concerns are related to coding weaknesses about the functionality of the system, i.e., API/Function Errors (CWE-1228) and Behavioral Problems (CWE-438). API/Function Errors (CWE-1228) covers the use of dangerous functions or the exposing of the functions that allow unwanted actors to execute restricted actions. For example, as shown in Figure 8, we observed that  a reviewer commented that assigning the result of the format string function to the same input variable can be potentially harmful: ”[…]Using the same variable as both input and output for spprintf looks dangerous. Are you sure it is safe? ”.46 Behavioral Problems (CWE-438) refer to code that may cause unexpected behavior in the software system. For example, a reviewer noticed that the code can look for the required files in incorrect directories if the program is compiled in different environments.4</p><p>Concerns related to the cryptographic process, i.e., Cryptographic Issues (CWE310) and Random Number Issues (CWE-1213), were also common in both OpenSSL and PHP. Cryptographic Issues (CWE-310) covers the proper use of encryption algorithms and cryptographic keys to ensure system and data security. For instance, as shown in Figure 9, a developer responded to a reviewer’s suggestion that the lengths of the cryptographic keys can be dynamic and cannot be restricted to a fixed value by saying ”[…]HMAC keys can be variable length so SHA256 DIGEST LENGTH doesn’t seem like the right answer here”.48 Random Number Issues (CWE-1213) account for the process of obtaining sufficient ran</p><p>Including the six common coding weaknesses, there are 21 types of coding weaknesses that were raised in both projects. In particular, security concerns related to coding weaknesses in category Audit/Logging Errors (CWE-1210), Information Management Errors (CWE-199), Concurrency Issues (CWE-557), Memory Buffer Errors (CWE-1218), Business Logic Errors (CWE-840), and Resource Locking Problems (CWE-411) are among the top 20 categories in both projects. Security concerns in these categories may also be considered common concerns to some extent. The previous code review works (Alfadel et al., 2023; Paul et al., 2021b; Di Biase et al., 2016; Bosu et al., 2014; Edmundson et al., 2013) reported that reviewers can identify security issues in various degrees based on the different application domains and the programming languages. However, the studied security issues are frequently bounded by well-known vulnerabilities that are associated with security consequences such as SQL Injection, XSS, or Denial of service. Our results further reveal that reviewers can commonly discuss more extensive coding weaknesses that can introduce those vulnerabilities from the development perspective. For example, the discussion regarding API / Function Errors (CWE-1228), Behavioral Problems (CWE-438), Cryptographic Issues (CWE-310), and Random Number Issues (CWE-1213) have not been previously reported.</p><p><strong>Project-specific security concerns:</strong> In addition to common security concerns, understanding project-specific concerns would allow us to gain better insight into the secure code review practices in each project. We observed that in OpenSSL, a library that provides encryption functionalities to its dependent systems, reviewers seem to focus on preventing direct security threats that are related to encryption, e.g., Key Management Errors (CWE-255) and Communication Channel Errors (CWE-417). For example, a reviewer discussed the causes of timing-attack, which can reveal the type of cryptographic key used in secure communication with the attacker.50 On the other hand, in PHP, a programming language for web applications, reviewers rather focus on security related to data controlling, e.g., Data Validation Issues (CWE-1215) and the versatility of language, e.g., Pointer Issues (CWE-465) and Type Errors (CWE-136). Also, it seems that PHP reviewers are concerned with Documentation Issues (CWE-1225), which are rarely recognized in a security context (Alfadel et al., 2023). For example, a developer explained to a reviewer that a function should not declare to accept any type of parameters if it intends to raise TypeError when the user inputs the parameters of incorrect types, e.g., to avoid Denial of Service vulnerability.51 In another case, a reviewer noticed that a function does not implement a randomization algorithm that it claims to use in the document.52 These types of security concerns highlight the importance of input management and documentation in PHP.</p><p>\\\nLastly, for the coding weakness types that were rarely raised, it may be because these issues are irrelevant to the application domains of the systems. We did not observe any concerns related to Lockout Mechanism Errors (CWE-1216), as it can cause an overly restrictive authentication policy, which is not applicable in both projects. Similarly, no concerns related to User Interface Security Issues (CWE355) were found, as OpenSSL and PHP do not have an elaborate user interface. Therefore, it is less likely that reviewers would raise this type of concern.</p><p><strong>RQ2: How aligned are the raised security concerns and known vulnerabilities?</strong> Based on the mapping of known vulnerabilities to related coding weaknesses, as explained in Section 4.7, we find that the known vulnerabilities of OpenSSL and PHP during the studied period are related to 16 coding weakness categories. We answer this question by comparing the percentages of the known vulnerabilities and the raised security concerns that we found in RQ1 (Table 10).</p><p>Figure 10 shows that nine coding weakness categories in OpenSSL and six coding weakness categories in PHP have a high proportion of known vulnerabilities in the past, but are less frequently discussed in code reviews. For instance, the top two coding weakness categories that have the highest proportion of known vulnerabilities are Memory Buffer Errors (CWE-1218; 21% in OpenSSL and 29% in PHP) and Resource Management Errors (CWE-399; 21% in OpenSSL and 17% in PHP). However, these two coding weakness categories have a relatively low proportion of security concerns raised in the code reviews (4% - 9%). Similarly, 6% - 12% of the known vulnerabilities are related to Business Logic Errors (CWE840), File Handling Errors (CWE-1219), and Pointer Issues (CWE-465) which were rarely discussed in the code review (only 1% - 7% of the security concerns).</p><p>\\\nMoreover, we observe that OpenSSL has three coding weaknesses that are lessfrequently discussed in code reviews i.e., Information Management Errors (CWE199) (17% of known vulnerabilities; 3% of security concerns), Cryptographic Issues (CWE-310) (7% of known vulnerabilities; 4% of security concerns), and Data Neutralization Issues (CWE-137) (2% of known vulnerabilities; 0% of security concerns). In particular, the lower number of security concerns about Data Neutralization Issues align with the observation of Braz et al. (2021) that developers may not be aware of the consequences of improper input validation, as well as the case of Heartbleed as shown in Figure 1. On the other hand, coding weaknesses in six categories in both OpenSSL and PHP were more frequently discussed than the known vulnerabilities. Coding weaknesses related to Authentication Errors (CWE-1211), String Errors (CWE-133), Type Errors (CWE-136), Concurrency Issues (CWE-557), Data Processing Errors (CWE-19), and Behavioral Problems (CWE-438) which occurred in 4% of known vulnerabilities in OpenSSL and PHP were discussed by 22%-23% of security concerns in both projects. Despite the low frequency of the security concerns compared to the known vulnerabilities, all of the coding weakness categories of the known vulnerabilities, except for Numeric Errors (CWE-189) were discussed in the code review as shown in Figure 10. This finding suggests that reviewers may be able to identify these kinds of coding weakness, but require more attention.  <img src=\"https://cdn.hackernoon.com/images/null-z3734td.png\" alt=\"\"></p><p><strong>C2. Acknowledged (30% in OpenSSL; 36% in PHP):</strong> For a third of the security concerns raised, we observed that security concerns were acknowledged by the developer or other reviewers but were not fixed in the same pull request. We observed that the concerns were not fixed in the same pull request because they will be fixed elsewhere (C2.1; 10% for OpenSSL and 18% for PHP) or due to an unresolved discussion (C2.2; 20% for OpenSSL and 18% for PHP). In particular, for the fix-elsewhere scenario (C2.1), the reviewers and developers discussed the raised concern and agreed that the necessary fixes should be made in new pull requests. We find that around half (55%) of the security concerns in this scenario were eventually merged in both projects ( 11 20 for OpenSSL and 12 22 for PHP). For example, a reviewer noticed the use of stale pointer and suggested a fix. The developer then replied, ”[…] Ok. I’ll prepare a pull request (but not right away) and request your review.”.56 However, it is not possible to confirm whether all security concerns in the C2.1 scenario were later fixed as promised. For the unresolved discussion scenario (C2.2), the developers and reviewers cannot find an agreeable direction to address the concern. The discussions in this scenario tend to be more rambling and involve several sub-concerns, hindering</p><p>reviewers from reaching an agreeable resolution. This could be due to different understandings and perspectives between reviewers. For example, reviewers and developers discussed the resolution while aiming to maintain compliance with security standards. However, due to the equivocal interpretation of the standards, the discussion cannot reach an agreeable resolution.57 Another example is that a reviewer raised a concern about the certificate authentication process and requested a modification.58</p><p>\\\nThe other reviewers, including the developer, agreed that the concern was valid but expressed multiple opinions on the solutions. The pull request with the concern was eventually merged without any changes. Indeed, we found that 16 pull requests in OpenSSL and 5 pull requests in PHP which contain 16 ( 16 36 = 44% for OpenSSL) and 7 ( 7 22 = 31% for PHP) concerns in C2.2 were eventually merged without any evidence that the concerns were addressed. It should be noted that the reviewer’s workload may affect the code review outcomes. We found that a significant portion of reviewers (54% in OpenSSL and 17% in PHP) engaged in unresolved discussions (C2.2) are classified as highworkload reviewers i.e., reviewed over 100 pull requests in each respective project. We hypothesize that workload, characterized by the volume of code reviews, as discussed in prior research (Ruangwan et al., 2019), could influence the quality of code review process. However, future work can be conducted to further investigate this phenomenon.</p><p>\\\n<strong>C3. Dismissed (15% in OpenSSL; 26% in PHP):</strong> In this scenario, the developer and reviewers discussed the security concerns raised, and the security concerns were dismissed. We observed that the discussions eventually concluded that the concern was a false concern (C3.1; 13% for OpenSSL and 7% for PHP) or acceptable by design choice (C3.2; 24% for OpenSSL and 7% for PHP). Specifically, the false concern scenario (C3.1) is related to cases in which developers or other reviewers offered an explanation to invalidate the security concerns. For example, a reviewer raised a concern about leaking sensitive data.59 Then, the developer replied to the comment to explain that the implementation is not leaking sensitive data ”[…] %s given part shouldn’t be added for values (but only for types) since they might contain sensitive data”, which was agreed by the reviewer. The design choice scenario (C3.2) refers to cases where security concerns were dismissed by other factors such as performance trade-off, maintainability, or system design (Zanaty et al., 2018). For example, a developer responded that a change in the data-neutralizing process was a valid concern as raised by the reviewer; however, it did not affect the application logic.60 The reviewer finally agreed and approved the pull request. We also observed that 20 pull requests in OpenSSL and 4 pull requests in PHP which contain 21 ( 21 24 = 88% for OpenSSL) and 4 ( 4 8 = 78% for PHP) concerns in scenario C3.2 were eventually merged.</p><p>\\\n<strong>C4. Unresponded (3% in OpenSSL; 9% in PHP):</strong> There were a few cases where security concerns did not receive any responses nor activities logged in the pull request. This was in part due to out-of-context (C4.1; 2% for PHP) or unknown &amp; inactivity (C4.2; 3% for OpenSSL and 7% for PHP). The out-of context scenario (C4.1) refers to cases where security concerns drift away from the current discussion or the goal of the code changes. For example, a reviewer raised a security concern about insufficient check of input and instantly volunteered to create a new change request that fixes the problem, however, the developer and other reviewers did not respond to the concern.61 The unknown &amp; inactivity scenario (C4.2) refers to cases where security concerns were simply disregarded without a clear reason. For example, a reviewer remarked suspicious use of pointer but the developer did not respond and the pull request was eventually rejected.</p><p>:::info\nThis paper is  under CC by 4.0 Deed (Attribution 4.0 International) license.</p>",
      "contentLength": 17717,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Congress Wants To Hand Your Parenting To Big Tech",
      "url": "https://yro.slashdot.org/story/26/01/19/2221237/congress-wants-to-hand-your-parenting-to-big-tech?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1768861320,
      "author": "BeauHD",
      "guid": 37065,
      "unread": true,
      "content": "An anonymous reader quotes a report from the Electronic Frontier Foundation (EFF): Lawmakers in Washington are once again focusing on kids, screens, and mental health. But according to Congress, Big Tech is somehow both the problem and the solution. The Senate Commerce Committee held a hearing [Friday] on \"examining the effect of technology on America's youth.\" Witnesses warned about \"addictive\" online content, mental health, and kids spending too much time buried in screen. At the center of the debate is a bill from Sens. Ted Cruz (R-TX) and Brian Schatz (D-HI) called the Kids Off Social Media Act (KOSMA), which they say will protect children and \"empower parents.\"\n \nThat's a reasonable goal, especially at a time when many parents feel overwhelmed and nervous about how much time their kids spend on screens. But while the bill's press release contains soothing language, KOSMA doesn't actually give parents more control. Instead of respecting how most parents guide their kids towards healthy and educational content, KOSMA hands the control panel to Big Tech. That's right -- this bill would take power away from parents, and hand it over to the companies that lawmakers say are the problem. [...] This bill doesn't just set an age rule. It creates a legal duty for platforms to police families. Section 103(b) of the bill is blunt: if a platform knows a user is under 13, it \"shall terminate any existing account or profile\" belonging to that user. And \"knows\" doesn't just mean someone admits their age. The bill defines knowledge to include what is \"fairly implied on the basis of objective circumstances\" -- in other words, what a reasonable person would conclude from how the account is being used. The reality of how services would comply with KOSMA is clear: rather than risk liability for how they should have known a user was under 13, they will require all users to prove their age to ensure that they block anyone under 13.\n \nKOSMA contains no exceptions for parental consent, for family accounts, or for educational or supervised use. The vast majority of people policed by this bill won't be kids sneaking around -- it will be minors who are following their parents' guidance, and the parents themselves. Imagine a child using their parent's YouTube account to watch science videos about how a volcano works. If they were to leave a comment saying, \"Cool video -- I'll show this to my 6th grade teacher!\" and YouTube becomes aware of the comment, the platform now has clear signals that a child is using that account. It doesn't matter whether the parent gave permission. Under KOSMA, the company is legally required to act. To avoid violating KOSMA, it would likely lock, suspend, or terminate the account, or demand proof it belongs to an adult. That proof would likely mean asking for a scan of a government ID, biometric data, or some other form of intrusive verification, all to keep what is essentially a \"family\" account from being shut down.\n \nViolations of KOSMA are enforced by the FTC and state attorneys general. That's more than enough legal risk to make platforms err on the side of cutting people off. Platforms have no way to remove \"just the kid\" from a shared account. Their tools are blunt: freeze it, verify it, or delete it. Which means that even when a parent has explicitly approved and supervised their child's use, KOSMA forces Big Tech to override that family decision. [...] These companies don't know your family or your rules. They only know what their algorithms infer. Under KOSMA, those inferences carry the force of law. Rather than parents or teachers, decisions about who can be online, and for what purpose, will be made by corporate compliance teams and automated detection systems.",
      "contentLength": 3745,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "In Code Reviews, Security Risks Hide Behind Technical Language",
      "url": "https://hackernoon.com/in-code-reviews-security-risks-hide-behind-technical-language?source=rss",
      "date": 1768860003,
      "author": "Code Review",
      "guid": 37071,
      "unread": true,
      "content": "<ul><li>Code Review for Software Security</li><li>Security Concern Handling Process in Code Review</li></ul><ul><li>Security Concern Identification Approach (RQ1)</li><li>Alignment Analysis of Known Vulnerabilities (RQ2)</li><li>Handling Process Identification (RQ3)</li></ul><ul><li>PA1: Prevalence of Coding Weakness Comments</li><li>PA2: Preliminary Evaluation of our Security Concern Identification Approach</li></ul><ul></ul><p>In this section, we present two preliminary analyses to provide the logical ground for our main case study. The goal of the first preliminary analysis (PA1) is to examine whether reviewers tend to raise coding weaknesses related to security issues more frequently than explicitly discussing the vulnerabilities. The second analysis (PA2) aims to preliminarily evaluate the effectiveness of our semi-automated approach (see Section 4.6.1) to calculate semantic similarity scores for the code comments that contain coding weaknesses. Dataset: We conducted the two preliminary analyses based on a sample dataset. We randomly sampled 400 code review comments from each of the studied projects (i.e., OpenSSL and PHP). This sample size should allow us to generalize conclusions with a confidence level of 95% and a confidence interval of 5% (Triola, 2009).</p><p>\\\n<em>5.1 PA1: Prevalence of Coding Weakness Comments</em></p><p>The motivating examples in Section 3 show that coding weaknesses can lead to security issues. Since code review focuses on identifying and mitigating issues in source code (M¨antyl¨a and Lassenius, 2009; Bacchelli and Bird, 2013), it is possible that code review may be able to identify such coding weaknesses. To confirm this, we assess the degree to which the coding weaknesses are discussed in code reviews. In particular, we analyze whether reviewers more frequently discussed coding weaknesses than vulnerabilities.</p><p>From the sampled dataset, we manually classified code review comments into three groups: 1) comments that mentioned a coding weakness, 2) comments that explicitly mentioned a vulnerability, and 3) other comments that are not related to coding weaknesses and vulnerabilities. We consider that a code review comment mentioned a coding weakness when it is related to coding weaknesses listed in the CWE-699. A code review comment is considered as mentioning a vulnerability when it is related to the types of exploitable vulnerabilities obtained from prior studies (Di Biase et al., 2016; Paul et al., 2021b) i.e., Race Condition, Buffer and Integer Overflow, Improper Access, Cross Site-Scripting (XSS) and CrossSite Request Forgery (CSRF), Denial of Service (DoS) and Crash, Information Leakage, Command and SQL Injection, Format String, Encryption, and common vulnerability keywords such as attack, bypass, back-door, breach, trojan, spyware, virus, ransom, malware, worm, and sniffer. Note that one code review comment can be classified into multiple categories. For example, a comment ’[..] we ensure that when the ‘while‘ loop ends, there are always at least 2 more slots available in the output buffer without overrunning it [..]’41 is related to a vulnerability (i.e., buffer overflow) as well as a coding weakness (Incorrect Calculation of Buffer Size (CWE-131)). Hence, this comment is classified as mentioning vulnerability and coding weakness.</p><p>Our preliminary result shows that coding weaknesses were raised more often than vulnerabilities during the code review. Table 6 shows the number of code review comments that mentioned a coding weakness, a vulnerability, and others. From 400 sampled code review comments for each studied project, we identified 67 comments related to coding weaknesses and 2 comments related to vulnerabilities in PHP; and 84 comments related to coding weaknesses and 4 comments related to vulnerabilities in OpenSSL. The amount of code review comments that mentioned vulnerabilities align with the findings of Di Biase et al. (2016) who found that 1% of the code review comments identified vulnerabilities. Table 6 shows that the number of comments that mentioned a coding weakness is 21 - 33.5 times higher than the number of comments that mentioned a vulnerability. In addition, we observed that reviewers sometimes point out a potential</p><p><em>Preliminary Evaluation of our Security Concern Identification Approach</em></p><p>Since we cannot manually identify code review comments that contain coding weaknesses in the entire code review comment dataset (i.e., 135K comments; see Table 2), we opt to use a semi-automated approach to identify comments, as explained in Section 4.6. In particular, we measure the cosine similarity score of each code review comment and the descriptions of coding weakness categories and we manually validate the comments with high cosine similarity scores until reaching the saturation point, i.e., 50 consecutive comments are identified as generic or irrelevant comments. In this work, we explore two well-known vector representation techniques (i.e., TF-IDF and word embedding) when measuring cosine similarity. We did not use the keyword search like prior works (Bosu et al., 2014; Paul et al., 2021a,b) because their pre-defined keyword lists are limited and may not cover all coding weaknesses. Hence, we set out this preliminary analysis to evaluate the effectiveness of our approach compared to the keyword search and examine which vector representation can produce the similarity scores that better distinguish the code review comments that contain coding weaknesses from the irrelevant code review comments.</p><p>We conducted our preliminary evaluation based on the sampled dataset and our manual classification in PA1. We considered the comments that mentioned coding weakness as coding weakness comments group, and the other comments as noncoding weakness comments group. We pre-processed code review comments in the sampled dataset and the combined descriptions of coding weaknesses in all CWE699 categories with the method described in Section 4.6.1. Then, we generated TFIDF and word embedding vectors of the code review comments and the combined descriptions. Finally, we calculated the similarity score between the vectors. To measure the effectiveness of our approach, we adopted the effort-aware evaluation concept (Kamei et al., 2013; Verma et al., 2016). We measured top</p><p>k precision, recall, and F1-score where k is the number of comments with the highest similarity scores. While the value of k approximates the effort required for our manual validation, the top-k precision shows the proportion of coding weakness security comments in the top-k over the non-coding weakness comments; the topk recall shows the percentage of coding weakness security comments that can be identified at the top-k; and the top-k F1-score shows the single score that represent both top-k precision and top-k recall. For the keyword search, we measured the precision, recall, F1-score and of the code review comments that were identified by a set of vulnerability keywords from previous secure code review studies (Bosu et al., 2014; Paul et al., 2021a,b). To evaluate the two vector representation techniques, we examine which technique produces similarity scores for coding weakness comments higher than the scores for non-coding weakness comments. Thus, we used the one-sided MannWhitney-Wilcoxon test to examine the statistical difference in the similarity scores between the two groups of code review comments. We also used Cliff’s |δ| effect size to estimate the magnitude of the difference in scores from each group.</p><p>As shown in Table 7, we found that our approach with word embedding vectors achieved the highest top-k F1-score in OpenSSL and PHP for all k ∈ (20, 40, 60, 80, 100) with the top-k F1-score of 0.16 - 0.58, while our approach with TF-IDF achieved the top-k F1-score of 0.14 - 0.47. Table 7 also shows that our approach achieves higher F1-score than the keyword search. The keyword search retrieved 16 and 13 comments that contain one of the vulnerability keywords, which achieves an F1-score of 0.28 for OpenSSL and 0.25 for PHP. Moreover, we observe that the keyword search did not identify some types of coding weaknesses that can introduce vulnerability such as Pointer Issues (CWE-465). For example, the keyword approach could not identify a comment “The object can’t be referenced after free obj, only dtor obj“ 43 which is related to the ‘NULL Pointer Dereference‘ weakness (CWE-476).</p><p>\\\nThis result shows that our approach using cosine similarity can identify more coding weakness comments than the keyword search. For the performance of similarity score calculation, Table 8 shows the results of the one-sided Mann–Whitney–Wilcoxon test and Cliff’s |δ| effect size between the similarity scores of the coding weakness comments and the non-coding weakness comments. We found that similarity scores of coding weakness security comments are significantly higher than non-coding weakness security comments (p-value &lt; 0.05) when using TF-IDF and word embedding vectors. In addition, we found that the difference in the similarity scores from the word embedding vectors has a large effect size (|δ| ≥ 0.474 (Romano et al., 2006)) for both OpenSSL and PHP, while the difference in the similarity scores from TF-IDF vector has a large effect size for OpenSSL and a medium effect size for PHP. This suggests that the similarity scores based on the word embedding vectors can better differentiate coding weakness comments from their counterparts than the similarity scores based on the TF-IDF vectors. This finding is consistent with the top-k precision, recall and F1-scores shown in Table 7, i.e., at the same k value, using word embedding vectors achieves a higher score than using TF-IDF vectors.</p><p>Our preliminary evaluation shows that our approach with the word embedding technique 1) achieves a higher recall than the TF-IDF technique and the keyword search and 2) can better distinguish the coding weakness comments. Therefore, in this study, we used the word embedding technique to calculate the similarity scores to help us manually identify the coding weakness comments in the remaining dataset.</p><p>:::info\nThis paper is  under CC by 4.0 Deed (Attribution 4.0 International) license.</p>",
      "contentLength": 10132,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Rackspace Customers Grapple With 'Devastating' Email Hosting Price Hike",
      "url": "https://it.slashdot.org/story/26/01/19/1955239/rackspace-customers-grapple-with-devastating-email-hosting-price-hike?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1768858200,
      "author": "msmash",
      "guid": 37060,
      "unread": true,
      "content": "Rackspace's new pricing for its email hosting services is \"devastating,\" according to a partner that has been using Rackspace as its email provider since 1999. From a report: In recent weeks, Rackspace updated its email hosting pricing. Its standard plan is now $10 per mailbox per month. Businesses can also pay for the Rackspace Email Plus add-on for an extra $2/mailbox/month (for \"file storage, mobile sync, Office-compatible apps, and messaging\"), and the Archiving add-on for an extra $6/mailbox/month (for unlimited storage). \n\nAs recently as November 2025, Rackspace charged $3/mailbox/month for its Standard plan, and an extra $1/mailbox/month for the Email Plus add-on, and an additional $3/mailbox/month for the Archival add-on, according to the Internet Archive's Wayback Machine. Rackspace's reseller partners have been especially vocal about the impacts of the new pricing. \n\nIn a blog post on Thursday, web hosting service provider and Rackspace reseller Laughing Squid said Rackspace is \"increasing our email pricing by an astronomical 706 percent, with only a month-and-a half's notice.\" Laughing Squid founder Scott Beale told Ars Technica that he received the \"devastating\" news via email on Wednesday. The last time Rackspace increased Laughing Squid's email prices was by 55 percent in 2019, he said.",
      "contentLength": 1321,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "New Patches From Valve Bring AMDGPU Power Management Improvements For Old GCN 1.0 GPUs",
      "url": "https://www.phoronix.com/news/AMDGPU-SI-Power-Management",
      "date": 1768856958,
      "author": "Michael Larabel",
      "guid": 37064,
      "unread": true,
      "content": "<article>Last year Valve contractor Timur Kristóf managed to improve the AMDGPU driver enough for old GCN 1.0 Southern Islands and GCN 1.1 Sea Islands GPUs that with Linux 6.19 AMDGPU is now the default for those GPUs with better performance, RADV Vulkan out-of-the-box, and other benefits. He isn't done though improving the old GCN 1.0/1.1 era GPU support on this modern AMDGPU kernel driver - a new patch series posted today brings some power management fixes...</article>",
      "contentLength": 457,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "AlphaTON Capital Corp Announces Closing of $15 Million Registered Direct Offering of Ordinary Shares",
      "url": "https://hackernoon.com/alphaton-capital-corp-announces-closing-of-$15-million-registered-direct-offering-of-ordinary-shares?source=rss",
      "date": 1768855908,
      "author": "BTCWire",
      "guid": 37070,
      "unread": true,
      "content": "<p>New York, NY, January 15, 2026/--AlphaTON Capital Corp ) (“AlphaTON” or the “Company”), the world’s leading public technology company scaling the Telegram super app, with an addressable market of 1 billion monthly active users, today announced the closing of its previously announced registered direct for the purchase of an aggregate of 15,000,000 of its ordinary shares (or pre-funded warrants in lieu thereof), at a purchase price of $1.00 per ordinary share (or pre-funded warrant in lieu thereof).</p><p>H.C. Wainwright &amp; Co. acted as the exclusive placement agent for the offering.</p><p>The aggregate gross proceeds to the Company from the offering were $15 million, before deducting the placement agent fees and other offering expenses payable by the Company.&nbsp; The Company currently intends to use the net proceeds from the offering for scaling GPU deployments for Cocoon AI, working capital and general corporate purposes.</p><p>The securities described above were offered pursuant to a “shelf” registration statement (File No. 333-291921) filed with the Securities and Exchange Commission (“SEC”) on December 3, 2025 and declared effective on December 11, 2025. </p><p>The offering was made only by means of a prospectus, including a prospectus supplement, forming a part of the effective registration statement. The prospectus supplement and the accompanying prospectus relating to the securities being offered were filed with the SEC and are available at the SEC’s website at www.sec.gov. </p><p>Electronic copies of the prospectus supplement and the accompanying prospectus relating to the securities being offered may also be obtained by contacting H.C. Wainwright &amp; Co., LLC at 430 Park Avenue, 3rd Floor, New York, NY 10022, by telephone at (212) 856-5711 or e-mail at placements@hcwco.com.</p><p>This press release shall not constitute an offer to sell or the solicitation of an offer to buy any of the securities described herein, nor shall there be any sale of these securities in any state or jurisdiction in which such offer, solicitation or sale would be unlawful prior to the registration or qualification under the securities laws of any such state or jurisdiction.</p><h3>About AlphaTON Capital Corp. (Nasdaq: ATON)</h3><p>&nbsp;AlphaTON Capital Corp (NASDAQ: ATON) is the world’s leading technology public company scaling the Telegram super app, with an addressable market of 1 billion monthly active users while managing a strategic reserve of digital assets. </p><p>The Company implements a comprehensive M&amp;A and treasury strategy that combines direct token acquisition, validator operations, and strategic ecosystem investments to generate sustainable returns for shareholders. </p><p>Through its operations, AlphaTON provides public market investors with institutional-grade exposure to the TON ecosystem and Telegram’s billion-user platform while maintaining the governance standards and reporting transparency of a Nasdaq-listed company. </p><p>Led by Chief Executive Officer Brittany Kaiser, Executive Chairman and Chief Investment Officer Enzo Villani, and Chief Business Development Officer Yury Mitin, the Company’s activities span network validation and staking operations, development of Telegram-based applications, and strategic investments in TON-based decentralized finance protocols, gaming platforms, and business applications.</p><p>AlphaTON Capital Corp is incorporated in the British Virgin Islands and trades on Nasdaq under the ticker symbol “ATON”. AlphaTON, through its legacy business, is also advancing first-in-class therapies targeting known checkpoint resistance pathways to achieve durable treatment responses and improve patients’ quality of life. </p><p>AlphaTON actively engages in the drug development process and provides strategic counsel to guide the development of novel immunotherapy assets and asset combinations. To learn more, please visit .</p><h3>Forward Looking Statements</h3><p>This press release contains forward-looking statements within the meaning of the Private Securities Litigation Reform Act of 1995, including statements regarding the intended use of net proceeds from the offering. </p><p>These statements relate to future events or AlphaTON’s future financial performance and involve known and unknown risks, uncertainties and other factors that may cause actual results to differ materially from those expressed or implied by these forward-looking statements. </p><p>Factors that could cause or contribute to such differences include, but are not limited to, the development and adoption of artificial intelligence technologies, cryptocurrency market volatility, regulatory developments, technical challenges in infrastructure deployment, and general economic conditions. AlphaTON undertakes no obligation to update any forward-looking statements, except as required by law. </p><p>:::tip\n<em>This story was published as a press release by Btcwire under HackerNoon’s Business Blogging&nbsp;. Do Your Own Research before making any financial decision.</em></p>",
      "contentLength": 4931,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "The Rise and Fall of the American Monoculture",
      "url": "https://news.slashdot.org/story/26/01/19/1946207/the-rise-and-fall-of-the-american-monoculture?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1768855500,
      "author": "msmash",
      "guid": 37052,
      "unread": true,
      "content": "The American monoculture -- the era when three television networks, seven movie studios, and a handful of record labels determined virtually everything the country watched and heard -- is collapsing under the weight of algorithmic recommendation engines and infinite streaming options. An estimated 200 million tickets were sold for \"Gone With the Wind\" in 1939 when the U.S. population was 130 million; more than 100 million people watched the MAS*H finale in 1983. \n\nOnly three American productions grossed more than $1 billion in 2025, down from nine in 2019. \"That broad experience has become a more difficult thing for us studio people to manufacture,\" said Donna Langley, chairman of NBCUniversal Entertainment. \"The audience wants a much better value for their money.\" \n\nYouTube became the most popular video platform on televisions not by having the hottest shows but by having something for everyone. The internet broke Hollywood's hold on distribution; anyone can now stream to the same devices Disney and Netflix use.",
      "contentLength": 1028,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "As Fintech Scales, Regulators Are Asking a Hard Question: Can the Systems Prove It?",
      "url": "https://hackernoon.com/as-fintech-scales-regulators-are-asking-a-hard-question-can-the-systems-prove-it?source=rss",
      "date": 1768853775,
      "author": "Sanya Kapoor",
      "guid": 37069,
      "unread": true,
      "content": "<p><strong>As regulators tighten expectations, engineering design is becoming central to auditability and transaction reconstruction.</strong></p><p>\\\nAs fintech platforms expand into lending, payments, and embedded finance, regulators and auditors are applying a sharper lens to a foundational question: <strong>can a company prove what happened in its financial system not just assert it?</strong></p><p>Recent enforcement actions and audit findings across the industry have highlighted a recurring weakness. Many fast-growing fintech stacks were built for speed and customer experience first, with accounting integrity and traceability added later. In practice, that can make it difficult to reconstruct financial events months or years after the fact especially when transactions span multiple partners, payment rails, and asynchronous settlement systems.</p><p>“Financial correctness is not something you can bolt on,” said , a technical architect with more than  of experience building distributed and financial systems. Birthare is the Founding Engineer and Head of Engineering at a U.S.-based fintech developing credit products for underserved borrowers, including international students and consumers with limited credit history.</p><p>In today’s environment, the engineering choices behind ledger design, transaction state management, and reconciliation workflows increasingly determine whether a fintech platform can withstand audit scrutiny.</p><h2>Ledger Design Moves From Back Office to Front-Line Risk</h2><p>Modern fintech transactions are rarely simple. A single customer action such as paying a bill or making a purchase can generate multiple financial events: authorizations, partial captures, refunds, reversals, chargebacks, delayed postings, and settlement adjustments. Each event can arrive out of sequence, be duplicated, or be amended by external processors.</p><p>At scale, those realities can turn reconciliation into a continuous operational risk. Industry audits frequently cite problems such as fragmented ledgers, inconsistent state transitions, and reliance on manual corrections particularly in systems stitched together from loosely connected microservices or third-party abstractions that were not designed for full event reconstruction.</p><p>To address those challenges, Birthare led the development of an internal <strong>Financial Infrastructure Layer</strong> designed around  and explicit transaction-state modeling. The system records each financial event as a structured ledger entry intended to be replayable and independently verifiable, enabling teams to trace funds movement across complex product flows.</p><p>“Financial systems should behave like accounting systems first,” Birthare said. “If you can’t reconstruct where each dollar originated and where it moved, the platform can’t reliably defend its records under audit.”</p><h2>Engineering for Payment Networks That Don’t Behave Ideally</h2><p>Payment systems introduce edge cases that simplified fintech ledgers often fail to model: incremental authorizations, split captures, asynchronous reversals, delayed chargebacks, and settlement corrections that arrive long after a customer believes a transaction is complete.</p><p>When software assumes ideal sequencing, operational teams may be forced to make manual adjustments creating downstream risk in reporting, compliance, and customer dispute handling.</p><p>Birthare’s architecture was designed to preserve ledger consistency under those conditions. It uses idempotency controls and transactional safeguards to prevent duplicate events from corrupting balances and to reduce reconciliation drift when upstream signals arrive late or in unexpected order.</p><p>The approach draws on patterns from high-scale distributed systems, where fault tolerance and recovery behavior must be engineered into the system from the beginning.</p><h2>From Distributed Infrastructure to Financial Accuracy</h2><p>Before his current fintech role, Birthare worked on high-throughput infrastructure supporting cloud services and speech recognition platforms, where correctness and latency can affect large user populations. He is also listed as an inventor on multiple awarded U.S. patents spanning data scalability, speech recognition optimization, and data processing methods.</p><p>He later worked on blockchain security and fraud analytics at a major U.S. digital asset platform, where detecting high-risk activity depends on data lineage and systems that can operate under adversarial conditions.</p><p>“Security work changes how you think about correctness,” Birthare said. “You stop assuming clean inputs, and you design systems that can recover from ambiguity without corrupting financial state.”</p><h2>Risk Systems Built to Explain Decisions</h2><p>Regulators are also paying closer attention to how fintech lenders make credit decisions, including whether outcomes can be explained and audited. In many organizations, machine-learning models and rule engines have been deployed faster than the governance frameworks required to document decision logic.</p><p>Birthare led the design of a risk framework combining rule-based decisioning with machine-learning enrichment, built to preserve decision context and rationale. Each decision stores the inputs and logic used at the time, enabling retrospective review and auditability across multiple product types as policy requirements evolve.</p><p>“Risk systems must be explainable by design,” Birthare said. “Otherwise, teams are forced to reverse-engineer decisions later and that rarely stands up under scrutiny.”</p><h2>A Shift in Fintech Engineering Priorities</h2><p>As fintech matures, the industry’s priorities are shifting. Speed and growth remain important, but durability, auditability, and operational transparency are becoming core requirements—especially for platforms handling regulated financial activity.</p><p>Industry experts increasingly view financial infrastructure not as an application layer but as a long-term record system whose outputs may need to be defended years later.</p><p>“Technology moves quickly,” Birthare said. “But financial records have a long life. Engineering teams have to build for that timeline.”</p>",
      "contentLength": 6039,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Asus Confirms It Won't Launch Phones in 2026, May Leave Android Altogether",
      "url": "https://mobile.slashdot.org/story/26/01/19/1933224/asus-confirms-it-wont-launch-phones-in-2026-may-leave-android-altogether?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1768853100,
      "author": "msmash",
      "guid": 37051,
      "unread": true,
      "content": "Asus won't release any new smartphones this year, and that may signal the brand's exit from the Android space altogether. From a report: Asus Chairman Jonney Shih confirmed the news at an event in Taiwan on Jan. 16. According to a machine-translated version of quotes reported by Inside, Shih said, \"Asus will no longer add new mobile phone models in the future.\" \n\nShih said Asus will continue to support existing smartphone users with software updates and warranty assistance. This matches a previous report from DigiTimes earlier this month that said Asus wouldn't introduce new models in 2026. The big question is whether that means stepping back altogether or a temporary pause. In his speech, Shih alluded to the possibility that Asus may return to smartphones, but did not confirm it.",
      "contentLength": 791,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "OPEN_TREE_NAMESPACE To Provide A Security & Performance Win For Dealing With Containers",
      "url": "https://www.phoronix.com/news/Linux-Open-Tree-Namespace",
      "date": 1768851840,
      "author": "Michael Larabel",
      "guid": 37038,
      "unread": true,
      "content": "<article>A new feature expected to be merged for the upcoming Linux 7.0 kernel cycle is adding an OPEN_TREE_NAMESPACE flag for the open_tree() system call. This OPEN_TREE_NAMESPACE option can provide a nice performance win with added security benefits if you are dealing a lot with containerized workloads on Linux...</article>",
      "contentLength": 308,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "The Architecture Behind Telecom Platforms That Process 100 Million Transactions Monthly",
      "url": "https://hackernoon.com/the-architecture-behind-telecom-platforms-that-process-100-million-transactions-monthly?source=rss",
      "date": 1768851590,
      "author": "Sanya Kapoor",
      "guid": 37068,
      "unread": true,
      "content": "<p>Behind every seamless mobile activation, service upgrade, or network recovery lies a complex provisioning ecosystem operating at massive scale. While customers experience telecom services in seconds, the systems enabling those experiences must reliably execute <strong>hundreds of millions of backend transactions every month</strong>, often across highly distributed and failure-prone environments.</p><p>As telecom networks expand to support 5G, satellite connectivity, IoT, and real-time digital services, provisioning platforms have emerged as one of the industry’s most critical—and least visible—challenges.</p><p>This transformation was led by , a Principal Engineer and Systems Architect widely recognized for architecting and modernizing <strong>mission-critical telecom platforms that operate at national scale</strong>, where reliability, consistency, and automation are non-negotiable. With nearly two decades of experience in distributed systems and network architecture, Cyril has played a critical role in redefining how provisioning infrastructure supports <strong>millions of users and over 100 million monthly network transactions</strong> with near-zero downtime.</p><h2>The Problem: Legacy Provisioning Systems Cannot Handle Modern Scale</h2><p>Telecom provisioning systems are responsible for activating services, updating subscriber profiles, enabling features, and synchronizing configurations across dozens of backend platforms. Many of these systems were originally built for an earlier era—when traffic patterns were predictable, systems were centralized, and failures were resolved manually.</p><p>Those assumptions no longer hold.</p><p><strong>Modern telecom environments operate with:</strong></p><ul><li>Massive transaction volumes driven by nationwide networks</li><li>Sudden traffic spikes during launches, migrations, outages, and disaster events</li><li>Distributed, cloud-native, multi-region deployments</li><li>Tight coupling across core network, policy, charging, messaging, and edge platforms</li></ul><p>At this scale, traditional provisioning architectures—often synchronous, manually operated, and active-standby—become fragile. Even minor downstream degradation can cascade into widespread customer impact.</p><p><strong>When provisioning systems fail, the effects are immediate:</strong></p><ul><li>Service activations stall or partially complete</li><li>Customer features behave inconsistently</li><li>Customer-care calls surge</li><li>Manual recovery efforts overwhelm operations teams</li><li>Revenue leakage and SLA violations increase</li></ul><p>Worse, many legacy systems unintentionally . Retry storms, backlog growth, and slow recovery cycles turn small issues into large-scale incidents.</p><p>In platforms processing tens or hundreds of millions of transactions monthly, a failure rate of just a fraction of a percent can translate into <strong>hundreds of thousands of customer-impacting events</strong>.</p><p>As networks evolve toward 5G-Advanced, satellite-to-cell connectivity, and edge computing, the provisioning layer increasingly becomes the limiting factor in reliability and scalability.</p><h2>The Solution: Re-Architecting Provisioning as a Self-Healing Distributed System</h2><p>Solving this problem required more than incremental tuning. It demanded a fundamental architectural shift—treating provisioning not as a linear workflow, but as a <strong>resilient, event-driven distributed system</strong>.</p><p>Under Henry Cyril’s architectural leadership, the platform was redesigned around several core principles:</p><p><strong>Deterministic Transaction Sequencing</strong></p><p>Subscriber-level operations are globally serialized, ensuring correct execution order even under extreme concurrency and distributed processing.</p><p>Synchronous request chains were replaced with asynchronous event flows, enabling horizontal scalability and natural absorption of traffic bursts.</p><p><strong>Intelligent Queuing and Prioritization</strong></p><p>Transactions are classified by urgency, ensuring critical activations and recovery operations are never blocked by bulk or batch workloads.</p><p><strong>Active-Active High Availability</strong></p><p>Traffic is processed simultaneously across regions, eliminating single points of failure and enabling continuous operation.</p><p><strong>Automated Recovery and Replay</strong></p><p>Instead of failing transactions during downstream outages, the system buffers and automatically reprocesses them once recovery is detected—without manual intervention.</p><p>Real-time monitoring and analytics provide visibility into transaction health, performance trends, and anomalies across the entire ecosystem.</p><p>Together, these capabilities transformed provisioning from a fragile dependency into a <strong>self-recovering, autonomous platform</strong>.</p><h2>Measurable Impact at National Scale</h2><p>The architectural transformation delivered quantifiable results:</p><ul><li>100M+ provisioning transactions processed monthly</li><li>Provisioning success rates improved from approximately 99.05% to 99.98%</li><li>Monthly transaction fallout reduced from roughly 250,000 to 15,000</li><li>Manual operational effort reduced by over 80%</li><li>Provisioning-related customer-care calls reduced by more than 75%</li><li>Mean Time to Resolution (MTTR) improved by over 50%</li><li>Zero major customer-impacting outages since implementation</li></ul><p>At this scale, even fractional improvements translate into <strong>millions of dollars in operational savings</strong> and significantly improved customer experience.</p><p>This modernization effort was <strong>architected and led by Henry Cyril</strong>, who served as the Principal Engineer and Systems Architect defining the end-to-end design, resiliency framework, and migration strategy.</p><p>Cyril’s role extended beyond implementation. He established the architectural blueprint, guided cross-functional execution, and introduced design patterns that have since been adopted as <strong>reference models for future modernization initiatives</strong> across large-scale telecom platforms. Such platforms are typically designed and operated by a small number of senior architects due to the scale, complexity, and reliability requirements involved.</p><p>The architectural patterns introduced through this work have informed broader modernization efforts and are increasingly aligned with how <strong>next-generation telecom systems are being designed</strong>, particularly as operators transition toward more autonomous, software-defined networks.</p><p>Beyond a single platform, this architecture reflects a broader shift in how telecom systems are being built. The move away from fragile, manually operated provisioning toward <strong>autonomous, self-healing platforms</strong> is now widely seen as essential for sustaining scale in modern networks.</p><p>As operators globally move toward autonomous, software-defined networks, similar architectural principles are increasingly reflected in industry frameworks and large-scale modernization programs.</p><p>The design principles demonstrated here—deterministic sequencing, event-driven execution, active-active resiliency, and automated recovery—closely align with the operational demands of <strong>5G-Advanced and future 6G networks</strong>, where service complexity, transaction volume, and real-time expectations continue to rise.</p><p>As telecom infrastructure becomes more distributed, software-centric, and intelligence-enabled, these architectural approaches are increasingly serving as a <strong>benchmark for reliability, scalability, and operational efficiency</strong> across the industry.</p><h2>Why This Matters for the Future of Connectivity</h2><p>As telecom networks move toward autonomous operations, AI-driven control planes, and next-generation connectivity models, provisioning systems must evolve from reactive platforms into <strong>self-operating infrastructure</strong>.</p><p>This transformation underscores a broader industry lesson:</p><p><strong>At extreme scale, reliability is an architectural decision—not an operational one.</strong></p><p>By redesigning provisioning systems to expect failure, absorb volatility, and recover automatically, telecom operators can support massive growth without sacrificing stability or customer trust.</p>",
      "contentLength": 7603,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "WhatsApp Texts Are Not Contracts, Judge Rules in $2M Divorce Row",
      "url": "https://yro.slashdot.org/story/26/01/19/1919236/whatsapp-texts-are-not-contracts-judge-rules-in-2m-divorce-row?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1768850700,
      "author": "msmash",
      "guid": 37037,
      "unread": true,
      "content": "A British painter who argued that her ex-husband had signed over their $2 million north London home through WhatsApp messages has lost her High Court appeal after the judge ruled that the sender's name appearing in a chat header does not constitute a legal signature. \n\nHsiao-mei Lin, 54, presented messages from her former husband Audun Mar Gudmundsson, a financier, in which he stated he would transfer his share of their Tufnell Park property to her. Lin's lawyers argued that because Gudmundsson's name appeared in the message header on her phone, the messages should be considered signed. \n\nMr Justice Cawson disagreed, finding that the header identifying a sender is analogous to an email address added by a service provider -- a mechanism for identification rather than part of the message itself. The judge also found the content of the messages did not actually amount to Gudmundsson relinquishing his share.",
      "contentLength": 917,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Inside the Passwordless Architecture Redefining Security for Telecom Giants",
      "url": "https://hackernoon.com/inside-the-passwordless-architecture-redefining-security-for-telecom-giants?source=rss",
      "date": 1768849468,
      "author": "Sanya Kapoor",
      "guid": 37067,
      "unread": true,
      "content": "<p>Passwords were never designed for telecommunications environments that operate continuously, serve millions of customers, and underpin national connectivity. Yet for decades, they remained the default method of authentication across workforce systems, operational platforms, and partner access.</p><p>As telecom networks expanded through cloud adoption, remote access, and large-scale third-party integration, this model began to fail. Phishing attacks, credential reuse, and access sprawl exposed the limits of password-based identity, turning authentication into both a security and operational liability.</p><p>This shift created a broader industry problem: how to secure access at telecom scale without disrupting systems that cannot tolerate downtime.</p><p>It is within this context that a passwordless identity architecture—designed not as a feature but as <strong>foundational infrastructure</strong>—began to emerge.</p><p>Telecommunications providers face identity challenges that differ fundamentally from traditional enterprise environments.</p><p>They must support highly distributed workforces across retail, customer care, engineering, and network operations; integrate with large numbers of legacy OSS/BSS platforms; remain available during network segmentation and partial outages; and meet strict regulatory and audit requirements tied to critical infrastructure.</p><p>In this case, the identity environment spanned <strong>more than 200,000 workforce and partner users and over 10,000 enterprise and operational applications,</strong> many of which were never designed for modern authentication standards.</p><p>In such conditions, passwords introduce structural weaknesses. Shared secrets are difficult to govern, static credentials do not align with modern threat models, and directory-dependent authentication creates single points of failure. Over time, identity systems built on passwords become brittle, costly to operate, and increasingly misaligned with Zero Trust principles.</p><h2>The Shift from Authentication to Architecture</h2><p>Passwordless identity is often discussed as a tooling upgrade. At telecom scale, it is an .</p><p>Rather than replacing one login method with another, the approach reframes identity as a control plane—separating authentication, policy, and access enforcement into a resilient, cryptographic trust model.</p><p>This architecture removes shared secrets, binds access to trusted devices, and evaluates every request through centralized policy with distributed enforcement. Crucially, it enables <strong>thousands of applications</strong>—including legacy platforms—to participate without forcing disruptive rewrites, allowing gradual adoption while preserving operational continuity.</p><p>The result is not just stronger security, but a more stable access model designed to function under real telecom conditions: peak demand, partial outages, and emergency scenarios.</p><h2>Who Designed the Model—and Why It Matters</h2><p>This architectural transition was led by , a Principal Cybersecurity Architect with more than two decades of experience across telecommunications and critical infrastructure environments.</p><p>Rather than treating passwordless identity as a compliance requirement or incremental security enhancement, Kumara designed it as . His work focused on defining a scalable identity architecture capable of supporting <strong>hundreds of thousands of users</strong> and <strong>tens of thousands of applications</strong>, while integrating Zero Trust access controls and maintaining resilience under operational stress.</p><p>By treating identity as infrastructure rather than authentication, the model addressed long-standing telecom challenges that password-based systems were never designed to solve.</p><p>Telecommunications networks are becoming increasingly software-defined, automated, and interconnected. As that evolution accelerates, identity is no longer a supporting IT function—it is the  that determines how securely systems, people, and partners interact.</p><p>Passwordless identity architectures represent a shift away from fragile, secret-based access models toward cryptographic trust designed for scale and resilience.</p><p>For telecom providers operating national infrastructure, this shift is no longer optional. It is becoming a prerequisite for secure, reliable operations in the modern digital era.</p>",
      "contentLength": 4196,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Microsoft's Xbox Cloud Gaming May Soon Let You Stream Your Own Games for Free - If You Watch Ads",
      "url": "https://games.slashdot.org/story/26/01/19/1842246/microsofts-xbox-cloud-gaming-may-soon-let-you-stream-your-own-games-for-free---if-you-watch-ads?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1768848300,
      "author": "msmash",
      "guid": 37030,
      "unread": true,
      "content": "Microsoft appears to be preparing an ad-supported tier for Xbox Cloud Gaming that would let players stream games they've purchased digitally without needing a Game Pass subscription, according to a Windows Central report citing sources familiar with the plans. Users last week began noticing a new message pop up while launching cloud games that referenced \"1 hour of ad supported play time per session,\" though no such tier currently exists. \n\nThe ad-supported option, expected to launch sometime this year, would specifically target the hundreds of games available for digital purchase through Xbox Cloud Gaming -- titles that currently require at least one tier of Game Pass to stream despite being owned outright by the player.",
      "contentLength": 731,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "ERP Isn't Dead Yet - But Most Execs Are Planning the Wake",
      "url": "https://slashdot.org/story/26/01/19/188250/erp-isnt-dead-yet---but-most-execs-are-planning-the-wake?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1768846200,
      "author": "msmash",
      "guid": 37029,
      "unread": true,
      "content": "Seven out of ten C-suite executives believe traditional enterprise resource planning software has seen its best days, though the category remains firmly entrenched in corporate IT and opinion is sharply divided on what comes next. A survey of 4,295 CFOs, CISOs, CIOs and CEOs worldwide found 36% expect ERP to give way to composable, API-driven best-of-breed systems, while 33% see the future in \"agentic ERP\" featuring autonomous AI-driven decision-making. \n\nThe research was commissioned by Rimini Street, a third-party support provider for Oracle and SAP. Despite the pessimism, 97% said their current systems met business requirements. Vendor lock-in remains a sore point: 35% cited limited flexibility and forced upgrades as frustrations. Kingfisher, operator of 2,000 European retail stores including Screwfix and B&amp;Q, recently eschewed an SAP upgrade in favor of using third-party support to shift its existing application to the cloud. Gartner analyst Dixie John cautioned that while third-party support may work in the short or medium term, organizations will eventually need to upgrade.",
      "contentLength": 1096,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Here are the 55 US AI startups that raised $100M or more in 2025",
      "url": "https://techcrunch.com/2026/01/19/here-are-the-49-us-ai-startups-that-have-raised-100m-or-more-in-2025/",
      "date": 1768845994,
      "author": "Rebecca Szkutak",
      "guid": 37020,
      "unread": true,
      "content": "<article>Last year was monumental for the AI industry in the U.S. and beyond. How will 2025 compare?</article>",
      "contentLength": 91,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Valve Has 'Significantly' Rewritten Steam's Rules For How Developers Must Disclose AI Use",
      "url": "https://games.slashdot.org/story/26/01/19/1735231/valve-has-significantly-rewritten-steams-rules-for-how-developers-must-disclose-ai-use?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1768844100,
      "author": "msmash",
      "guid": 37016,
      "unread": true,
      "content": "Valve has substantially overhauled its guidelines for how game developers must disclose the use of generative AI on Steam, making explicit that tools like code assistants and other development aids do not fall under the disclosure requirement. The updated rules clarify that Valve's focus is not on \"efficiency gains through the use of AI-powered dev tools.\" \n\nDevelopers must still disclose two specific categories: AI used to generate in-game content, store page assets, or marketing materials, and AI that creates content like images, audio, or text during gameplay itself. Steam has required AI disclosures since 2024, and an analysis from July 2025 found nearly 8,000 titles released in the first half of that year had disclosed generative AI use, compared to roughly 1,000 for all of 2024. The disclosures remain voluntary, so actual usage is likely higher.",
      "contentLength": 863,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Netflix Wants Plots Explained Multiple Times Because Viewers Are on Their Phones, Matt Damon Says",
      "url": "https://entertainment.slashdot.org/story/26/01/19/178222/netflix-wants-plots-explained-multiple-times-because-viewers-are-on-their-phones-matt-damon-says?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1768842480,
      "author": "msmash",
      "guid": 37015,
      "unread": true,
      "content": "Netflix has begun asking filmmakers to adjust their storytelling approach to account for viewers who are scrolling through their phones while watching, according to Matt Damon. The traditional action movie formula involves three major set pieces distributed across the first, second, and third acts. Netflix now wants a large action sequence in the opening five minutes to hook viewers. \n\nThe streamer has also suggested that filmmakers reiterate plot points \"three or four times in the dialogue\" to accommodate distracted audiences, he said. \"It's going to really start to infringe on how we're telling these stories,\" Damon said.",
      "contentLength": 631,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Dumbphone Owners Have Lost Their Minds",
      "url": "https://tech.slashdot.org/story/26/01/19/1631233/dumbphone-owners-have-lost-their-minds?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1768840260,
      "author": "msmash",
      "guid": 37006,
      "unread": true,
      "content": "The growing enthusiasm among Gen Z for ditching smartphones in favor of basic \"dumbphones\" may be overlooking a significant cognitive reality, according to a WIRED essay that draws on the 1998 \"extended mind hypothesis\" by philosophers Andy Clark and David Chalmers. The hypothesis argues that external tools can extend the biological brain in an all but physical way, meaning your phone isn't just a device -- it's part of a single cognitive system composed of both the tool and your brain. \n\n\"Interference with my phone is like giving me some brain damage,\" Clark told Wired. He expressed concern about the dumbphone movement, calling it \"generally a retrograde step\" and warning that as smartphone enmeshment becomes the societal norm, those who opt out risk becoming \"effectively disabled within that society.\" Clark described this as \"the creation of a disempowered class.\" \n\n98% of Americans between 18 and 29 own a smartphone, dropping only to 97% for those aged 30 to 49. Even committed dumbphone users struggle. One user profiled in the piece still carries an \"emergency iPhone\" for work requirements and admits long-distance friendships have become \"nearly impossible to maintain.\"",
      "contentLength": 1191,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Mozilla Now Providing RPM Packages For Firefox Nightly Builds",
      "url": "https://www.phoronix.com/news/Firefox-Nightly-RPMs",
      "date": 1768839480,
      "author": "Michael Larabel",
      "guid": 37010,
      "unread": true,
      "content": "<article>In late 2023 Mozilla began providing Debian packages of Firefox Nightly builds complete with an APT repository. Those on Debian/Ubuntu distributions have a much easier path for enjoying Firefox Nightly since then and now Mozilla engineers are providing similar RPM builds of Firefox nightly too...</article>",
      "contentLength": 297,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "The HackerNoon Newsletter: Can ChatGPT Outperform the Market? Week 25 (1/19/2026)",
      "url": "https://hackernoon.com/1-19-2026-newsletter?source=rss",
      "date": 1768838515,
      "author": "Noonification",
      "guid": 37026,
      "unread": true,
      "content": "<p>🪐 What’s happening in tech today, January 19, 2026?</p><p>By <a href=\"https://hackernoon.com/u/obyte\">@obyte</a> [ 5 Min read ] Crypto has been declared “dead” countless times, yet it keeps bouncing back. Here’s a light look at why those headlines repeat and how real resilience works.  <a href=\"https://hackernoon.com/a-media-overview-why-bitcoin-and-cryptos-have-died-hundreds-of-times\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/ivankuznetsov\">@ivankuznetsov</a> [ 9 Min read ] It’s far more efficient to run multiple Claude instances simultaneously, spin up git worktrees, and tackle several tasks at once. <a href=\"https://hackernoon.com/indie-hacking-vibe-coding-setup-what-changed-in-6-months\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/codereview\">@codereview</a> [ 8 Min read ] Code reviews surface many security weaknesses, but critical issues often go unfixed. A study of OpenSSL and PHP reveals why. <a href=\"https://hackernoon.com/openssl-and-php-code-reviews-reveal-a-blind-spot-in-software-security\">Read More.</a></p><p>🧑‍💻 What happened in your world this week?</p><p>We hope you enjoy this worth of free reading material. Feel free to forward this email to a nerdy friend who'll love you for it.See you on Planet Internet! With love, \n The HackerNoon Team ✌️</p>",
      "contentLength": 841,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Rogue agents and shadow AI: Why VCs are betting big on AI security",
      "url": "https://techcrunch.com/2026/01/19/rogue-agents-and-shadow-ai-why-vcs-are-betting-big-on-ai-security/",
      "date": 1768838400,
      "author": "Rebecca Bellan",
      "guid": 36996,
      "unread": true,
      "content": "<article>Misaligned agents are just one layer of the AI security challenge that startup Witness AI is trying to solve. It detects employee use of unapproved tools, blocking attacks, and ensuring compliance.&nbsp;</article>",
      "contentLength": 199,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Well, there goes the metaverse!",
      "url": "https://techcrunch.com/2026/01/19/well-there-goes-the-metaverse/",
      "date": 1768838400,
      "author": "Sarah Perez",
      "guid": 36997,
      "unread": true,
      "content": "<article>The metaverse is on its last legs as VR is eclipsed by AI. But that's not the only thing that went wrong for Meta's VR ambitions. </article>",
      "contentLength": 130,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "CAKE_MQ Slated For Linux 7.0 To Adapt SCH_CAKE For Today's Multi-Core World",
      "url": "https://www.phoronix.com/news/Linux-7.0-CAKE-MQ",
      "date": 1768838101,
      "author": "Michael Larabel",
      "guid": 37005,
      "unread": true,
      "content": "<article>Queued into the Linux networking subsystem's \"net-next\" branch ahead of the Linux 6.20~7.0 merge window next month is cake_mq as a multi-queue aware variant of the sch_cake network scheduler. The intent with cake_mq is to better scale the network traffic rate shaper across multiple CPU cores...</article>",
      "contentLength": 295,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "NYSE Eyes 24/7 Tokenized Stock Trading With Weekend Access and Same-Day Settlement",
      "url": "https://news.slashdot.org/story/26/01/19/1543202/nyse-eyes-247-tokenized-stock-trading-with-weekend-access-and-same-day-settlement?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1768837380,
      "author": "msmash",
      "guid": 36993,
      "unread": true,
      "content": "BrianFagioli writes: The New York Stock Exchange, owned by Intercontinental Exchange, is developing a platform for trading tokenized versions of U.S. listed stocks and ETFs around the clock, pending regulatory approval. The system would combine the NYSE's existing matching engine with blockchain-based settlement, enabling 24x7 trading, instant settlement, and fractional share purchases priced in dollar amounts. Shares would remain fully regulated securities, with dividends and voting rights intact, rather than cryptocurrencies, even though the backend would run on blockchain-style infrastructure.",
      "contentLength": 603,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "BioticsAI, which won Disrupt’s Battlefield competition in 2023, gains FDA approval for its AI-powered fetal ultrasound product",
      "url": "https://techcrunch.com/2026/01/19/biotics-ai-battlefield-2023-gains-fda-approval-for-its-ai-powered-fetal-ultrasound-product/",
      "date": 1768834800,
      "author": "Dominic-Madori Davis",
      "guid": 36994,
      "unread": true,
      "content": "<article>TechCrunch Disrupt Battlefield 2023 winner, BioticsAI, announced on Monday that it has received FDA clearance for its AI software that helps detect fetal abnormalities in ultrasound images.&nbsp;</article>",
      "contentLength": 191,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Looking ahead to 2026: What’s next for Startup Battlefield 200",
      "url": "https://techcrunch.com/2026/01/19/looking-ahead-to-2026-whats-next-for-startup-battlefield-200/",
      "date": 1768834800,
      "author": "Isabelle Johannessen",
      "guid": 36995,
      "unread": true,
      "content": "<article>See what to expect for Startup Battlefield 200 in 2026, the ultimate startup pitch competition on the global stage at TechCrunch Disrupt. Join the mailing list to be the first to know when applications drop.</article>",
      "contentLength": 207,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "IMF Warns Global Economic Resilience at Risk if AI Falters",
      "url": "https://slashdot.org/story/26/01/19/1423221/imf-warns-global-economic-resilience-at-risk-if-ai-falters?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1768833600,
      "author": "msmash",
      "guid": 36980,
      "unread": true,
      "content": "The \"surprisingly resilient\" global economy is at risk of being disrupted by a sharp reversal in the AI boom, the IMF warned on Monday, as world leaders prepared for talks in the Swiss resort of Davos. From a report: Risks to global economic expansion were \"tilted to the downside,\" the fund said in an update to its World Economic Outlook, arguing that growth was reliant on a narrow range of drivers, notably the US technology sector and the associated equity boom. \n\nNonetheless, it predicted US growth would strongly outpace the rest of the G7 this year, forecasting an expansion of 2.4 per cent in 2026 and 2 per cent in 2027. Tech investment had surged to its highest share of US economic output since 2001, helping drive growth, the IMF found. \n\n\"There is a risk of a correction, a market correction, if expectations about AI gains in productivity and profitability are not realised,\" said Pierre-Olivier Gourinchas, IMF chief economist. \"We're not yet at the levels of market frothiness, if you want, that we saw in the dotcom period,\" he added. \"But nevertheless there are reasons to be somewhat concerned.\"",
      "contentLength": 1116,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "How NVIDIA GB10 Performance With the Dell Pro Max GB10 Compares To The GH200",
      "url": "https://www.phoronix.com/review/nvidia-gb10-gh200",
      "date": 1768833424,
      "author": "Michael Larabel",
      "guid": 36987,
      "unread": true,
      "content": "<article>Earlier this month we looked at the Dell Pro Max GB10 performance up against AMD's Ryzen AI Max+ \"Strix Halo\" with the superior performance for the green team for performance and power efficiency. For those wondering how the Dell Pro Max GB10 performance comes up for the much talked about NVIDIA GH200, here are some comparison benchmarks.</article>",
      "contentLength": 340,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "The Silicon Trojan",
      "url": "https://hackernoon.com/the-silicon-trojan?source=rss",
      "date": 1768833043,
      "author": "Legit",
      "guid": 37025,
      "unread": true,
      "content": "<p>:::info\n<strong>Disclaimer: The following is a work of fiction; any resemblance to real companies, systems, or individuals is purely coincidental.</strong></p><p>The air in the lab smelled of ozone and floor polish. A sterile, charged scent. I clicked the anti-static wrist strap onto the grounding point of the workbench. Habit. On the pallet next to me sat ten thousand gray boxes. Ten thousand XC-77B microcontrollers, the new backbone for our drone guidance systems. My job was simple: verify the shipment is what it says it is.</p><p>I selected a unit at random, pried the plastic casing open with a spudger, and placed the small, black chip onto the stage of the electron microscope. The machine hummed, focusing. On the monitor, the silicon die resolved into a microscopic city of pathways and gates. The company logo—a stylized falcon—was perfect. The lithography was clean. But something felt wrong. I zoomed in on the batch number etched near the edge. I pulled up the manufacturer's spec schematic on a secondary monitor.</p><p>The font was off. The curve of the '5' was a fraction too sharp. The entire string of characters was maybe a single micrometer too condensed. It was nothing. A variance in the etching mask. A new factory. But it was enough.</p><p>Paranoia is a survival trait in this business.</p><p>I moved the chip to the benchmark rig, my hands steady as I soldered it to the test board. The system booted. All standard diagnostics passed. Green lights across the board. Then I ran the stress test. I pushed the clock speed, watching the thermal sensors and the voltage monitors. The spec sheet for the XC-77B is burned into my memory. It should have started throwing errors at 1.2 GHz. It should have failed completely by 1.3.</p><p>It screamed past both without a whisper of protest. It held stable at 1.45 GHz. A full 20% faster than it had any right to be. That's not a manufacturing anomaly. That's a different class of silicon.</p><p>My blood ran cold. This wasn't a cheap knockoff. Counterfeits are always worse. They cut corners, use inferior wafers, and fail&nbsp;&nbsp;spec. This was an upgrade, meticulously packaged and labeled to look like a common, off-the-shelf component. A supply chain injection. But why?</p><p>I pulled the data from the benchmark and formatted it into a comparison table. The numbers didn't lie.</p><p>| Parameter | Manufacturer Spec (XC-77B) | Observed Benchmark Results |\n|----|----|----|\n| Max Clock Speed | 1.2 GHz |  |\n| Thermal Threshold | 95°C | 92°C |\n| Power Draw (Idle) | 0.05W | 0.03W |\n| Lithography Node | 28nm |  |\n| Undocumented Logic | None |  |</p><p>\\\nThat last line confirmed it. I ran a deep power analysis, a differential test that hunts for logic gates that aren't on the official schematic. The scan revealed a dormant circuit, a secondary path that drew an infinitesimal amount of power only when it received a highly specific, encrypted radio signal. It wasn't a flaw. It was a feature.</p><p>A physical kill switch, baked directly into the hardware. A silicon Trojan.</p><p>The lab door hissed open. It was Meyers, my department head. He had a chipper, salesman-like energy that always set my teeth on edge. He was the one who had pushed through this new supplier, citing \"significant cost savings.\"</p><p>\"Morning, Alex,\" he said, gesturing at the pallet with his chin. \"How's our new batch of chips? QC clear yet? Assembly line is waiting.\"</p><p>My heart pounded against my ribs. I looked from the glowing&nbsp;&nbsp;on my screen to the forced smile on his face. If he knew, telling him was a death sentence. If he didn't, I was about to let an enemy army march through our front gate.</p><p>\"Just finishing the final stress test now, sir,\" I said, my own voice sounding alien and calm. \"Everything is well within spec. No issues.\"</p><p>He clapped me on the shoulder, a little too hard. \"Attaboy. Sign the manifest. Let's get them moving.\" He turned and left.</p><p>I stood there for a long moment, the hum of the server racks filling the silence. I picked up the digital stylus, my hand not shaking. On the tablet, I scribbled my signature next to the word&nbsp;. Across the room, the status light on the pallet of ten thousand traitors switched from amber to green.</p><p>As I stood up, my hand slipped over the workbench, closing around the warm, black square of silicon. The sample. It felt heavy in my palm as I slid it into the pocket of my lab coat. The anti-static baggie made a soft, conspiratorial crinkle.</p>",
      "contentLength": 4350,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "ICE’s Facial Recognition App Misidentified a Woman. Twice",
      "url": "https://www.404media.co/ices-facial-recognition-app-misidentified-a-woman-twice/",
      "date": 1768832916,
      "author": "Joseph Cox",
      "guid": 36988,
      "unread": true,
      "content": "<img src=\"https://www.404media.co/content/images/2026/01/54977911914_4995b93005_k.jpg\" alt=\"ICE’s Facial Recognition App Misidentified a Woman. Twice\"><p>When authorities used Immigration and Customs Enforcement’s (ICE) facial recognition app on a detained woman in an attempt to learn her identity and immigration status, it returned two different and incorrect names, raising serious questions about the accuracy of the app ICE is using to determine who should be removed from the United States, according to testimony from a Customs and Border Protection (CBP) official obtained by 404 Media.</p><p>ICE has told lawmakers the app, called <a href=\"https://www.404media.co/ice-is-using-a-new-facial-recognition-app-to-identify-people-leaked-emails-show/\"></a>, provides a “definitive” determination of someone’s immigration status, and should be trusted over a birth certificate. The incident, which happened last year in Oregon, casts doubt on that claim.</p><div><div><b><strong>Do you know anything else about this app? Do you work at ICE or CBP? I would love to hear from you. Using a non-work device, you can message me securely on Signal at joseph.404 or send me an email at joseph@404media.co.</strong></b></div></div>",
      "contentLength": 904,
      "flags": null,
      "enclosureUrl": "https://www.404media.co/content/images/2026/01/54977911914_4995b93005_k.jpg",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "China Birth Rate Falls To Lowest Since 1949",
      "url": "https://news.slashdot.org/story/26/01/19/144215/china-birth-rate-falls-to-lowest-since-1949?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1768831440,
      "author": "msmash",
      "guid": 36974,
      "unread": true,
      "content": "China's birth rate fell to 5.6 per 1,000 people in 2025, the lowest figure since the founding of the People's Republic in 1949, and the country's total population contracted by 3.39 million, the sharpest decline since the Mao Zedong era. The drop marks the fourth straight year of population decline and comes despite government efforts to encourage childbearing, including subsidies of about $500 annually per child born on or after January 1, 2025. \n\nBeijing has also imposed a 13% value-added tax on contraceptives this year. The government is betting on automation and productivity to offset the shrinking workforce -- China already leads the world in robot installations -- and President Xi Jinping has written that population policy must transition \"from being mainly about regulating quantity to improving quality.\"",
      "contentLength": 822,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Claude Code Launches Teleport Workflow: Start Anywhere, Continue Everywhere",
      "url": "https://hackernoon.com/claude-code-launches-teleport-workflow-start-anywhere-continue-everywhere?source=rss",
      "date": 1768831285,
      "author": "Vladislav Guzey",
      "guid": 37024,
      "unread": true,
      "content": "<p>Modern software development rarely happens in one place. You might start a coding session at the office, then need to finish the job from a different computer.</p><p>There  a way—but it usually means pushing code to GitHub, pulling it down on another machine, and, worst of all, losing your entire conversation history with your AI assistant.</p><p>Recently, I started using Session Teleportation in Claude Code. It lets you move an entire conversation—including context, history, and the working branch—between the web and your local terminal.</p><p>In this tutorial, I’ll show you how it works and how to use it to make your workflow seamless.</p><h2>First-Time Setup (Do This First)</h2><p>Before you can teleport anything, you need to connect your local environment to Claude’s cloud.</p><p>First, make sure you have the latest version of Claude Code.</p><pre><code>npm install -g @anthropic-ai/claude-code\n</code></pre><h3><strong>Turn on Claude Code on Web</strong></h3><p>You&nbsp;&nbsp;connect your GitHub account. This is critical because Claude needs access to your repositories to “teleport” the code changes between devices.</p><p><em>Note: If you use an organization’s repository (like at work), you might need to click “Grant” next to your organization’s name in the GitHub permissions screen.</em></p><p>Then set up cloud environments. Give it a name and network access.</p><h2>How Session Teleportation Works</h2><p>Navigate to your project folder in the terminal and run&nbsp;. Claude will detect your Git repository and ensure it has the necessary permissions to access it.</p><p>The teleportation is built around two simple commands.</p><p>&nbsp;This is how you start a \"background session.\" If I type&nbsp;&nbsp;before my prompt in the CLI or VS Code, Claude runs the task on its cloud infrastructure.</p><ul><li><code>&amp; Refactor the authentication module to use JWT tokens</code></li></ul><p><strong>Command (Bring to Local):</strong>&nbsp;This is how you resume work. You can pull that web session into your local terminal or VS Code using&nbsp;<code>claude --teleport &lt;session-id&gt;</code>.</p><p>&nbsp;This process is&nbsp;. You can pull a web session down to your terminal, but you cannot “push” an existing local session up to the web. If you think you might need to switch devices later, always start your task with the&nbsp;&nbsp;prefix!</p><h2>Moving Tasks from VS Code to the Web</h2><p>Install the Claude Code extension in VS Code or Cursor (via the Extensions panel). Once installed, you can send tasks to the web directly from within your editor.</p><p>Compose your prompt. For example, if you want Claude to refactor authentication logic, start your prompt with &amp;:</p><pre><code>&amp; Refactor the authentication module to use JWT tokens instead of sessions\n</code></pre><p>This creates a background web session and returns a session ID. The task continues even if you close VS Code or shut down your laptop.</p><p>Monitor the session. Use&nbsp;&nbsp;in the CLI or click on the task in the web interface to see status.</p><p>You can also run&nbsp;&nbsp;from any device.</p><h2>Pulling Web Sessions Back to Your Terminal (VS Code or Cursor)</h2><p>Locate your session. In the Claude chat, run&nbsp;&nbsp;to see all active web sessions. From the command line, run claude — teleport for an interactive picker or&nbsp;&nbsp;to resume a specific session.</p><pre><code>claude --teleport session_01RyZ89nysBFFZnqFMZ4KpkZ\n</code></pre><p>Before teleporting, Claude checks several conditions:</p><ul><li><p>&nbsp;You must have no uncommitted changes. Teleport will prompt you to stash them if necessary.</p></li><li><p>&nbsp;You must be in a checkout of the same repository used on the web.</p></li><li><p>&nbsp;The branch created during the web session must be pushed to the remote; teleport will fetch and check it out.</p></li><li><p>&nbsp;You must be authenticated as the same Claude.ai user.</p></li></ul><p>Teleport the session. Once these conditions are satisfied, Claude will fetch the branch, load the conversation history, and attach the session to your local environment. You can then continue the conversation and review code in Cursor or the terminal as if you never left.</p><h2>Pro Tips for Getting the Most Out of Claude Code Teleport</h2><ul><li>&nbsp;Sometimes I run multiple &amp; commands at once to start several tasks simultaneously.</li><li>&nbsp;This is a hidden gem. I can share a Session ID with a teammate, and they can teleport into my session on their machine. It is perfect for async pair programming.</li><li>&nbsp;Remember, you can pull a web session down to your terminal, but you cannot “push” an existing local session up to the web. Always start with &amp; if you think you might need to move!</li><li><strong>Maintain a clean Git state.</strong>&nbsp;Teleportation requires a clean working directory. Use Git stashes or commit your changes before pulling sessions</li></ul><h2>Claude Code Teleportation Tutorial</h2><p>I also have a video with step-by-step instructions on how to use Claude Code teleportation. Please make sure to check it out.</p><p>Session teleportation blurs the line between local and remote development. It allows you to offload compute‑heavy tasks to the cloud, then seamlessly resume work locally without losing context. This cross‑device mobility is valuable for distributed teams and individuals who switch machines throughout the day.</p><p>I hope you found this tutorial helpful. If so, please leave your comments and subscribe to&nbsp;, where I share a lot of useful tutorials for devs ;).</p>",
      "contentLength": 4962,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "AI Boosts Research Careers, but Flattens Scientific Discovery",
      "url": "https://spectrum.ieee.org/ai-science-research-flattens-discovery",
      "date": 1768831202,
      "author": "Elie Dolgin",
      "guid": 36970,
      "unread": true,
      "content": "<p>New analysis suggests AI tools narrow the span of ideas explored </p>",
      "contentLength": 65,
      "flags": null,
      "enclosureUrl": "https://spectrum.ieee.org/media-library/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpbWFnZSI6Imh0dHBzOi8vYXNzZXRzLnJibC5tcy82MjgyNjU0NS9vcmlnaW4uanBnIiwiZXhwaXJlc19hdCI6MTc3NDE5Mzk1NH0.YsKUg9R7aKLBxjWWobEbghVolqqXAdlkN8wj2t2SqRs/image.jpg?width=600",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Revocable Resource Management Appears On Track For Linux 7.0",
      "url": "https://www.phoronix.com/news/Revocable-Resource-Management",
      "date": 1768830960,
      "author": "Michael Larabel",
      "guid": 36979,
      "unread": true,
      "content": "<article>A new feature that appears ready for introduction in the upcoming Linux 6.20~7.0 kernel cycle is revocable resource management...</article>",
      "contentLength": 129,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "How to Access Your YubiKey in Go on Windows",
      "url": "https://hackernoon.com/how-to-access-your-yubikey-in-go-on-windows?source=rss",
      "date": 1768830532,
      "author": "Shridivya Sharma",
      "guid": 37023,
      "unread": true,
      "content": "<p>YubiKeys are fantastic for securing authentication and cryptography, but integrating them directly into a Go application on Windows takes a few extra steps. In this article, we’ll walk through accessing a YubiKey in Go on Windows, step by step.</p><p>Install the piv-go module: </p><pre><code>go get github.com/go-piv/piv-go/piv\n</code></pre><h2>Listing Connected YubiKeys on Windows</h2><p>The following Go code will show you all the YubiKeys connected to your machine: </p><pre><code>package main\n\nimport (\n    \"fmt\"\n    \"github.com/go-piv/piv-go/piv\"\n)\n\nfunc main() {\n    cards, err := piv.Cards()\n    if err != nil {\n        panic(err)\n    }\n\n    if len(cards) == 0 {\n        fmt.Println(\"No YubiKeys detected\")\n        return\n    }\n\n    for _, card := range cards {\n        fmt.Println(\"Found YubiKey:\", card)\n    }\n}\n</code></pre><h2>Accessing a PIV Slot on Windows</h2><p>This Go program detects a connected YubiKey (PIV smart card) on Windows, opens it via&nbsp;, and reads the certificate from the PIV Authentication slot. It then prints the certificate’s subject details.</p><pre><code>package main\n\nimport (\n    \"crypto/x509\"\n    \"fmt\"\n    \"github.com/go-piv/piv-go/piv\"\n)\n\nfunc main() {\n    cards, err := piv.Cards()\n    if err != nil || len(cards) == 0 {\n        panic(\"No YubiKeys detected\")\n    }\n\n    yk, err := piv.Open(cards[0])\n    if err != nil {\n        panic(err)\n    }\n    defer yk.Close()\n\n    cert, err := yk.Certificate(piv.SlotAuthentication)\n    if err != nil {\n        panic(err)\n    }\n\n    fmt.Println(\"Certificate Subject:\", cert.Subject)\n}\n</code></pre><p>This Go program opens a connected YubiKey PIV device on Windows, retrieves the private key from the PIV Authentication slot, and uses it to sign a SHA-256 digest of some data. It then prints the resulting signature in hex.</p><pre><code>package main\n\nimport (\n    \"crypto\"\n    \"crypto/rand\"\n    \"fmt\"\n    \"github.com/go-piv/piv-go/piv\"\n)\n\nfunc main() {\n    cards, err := piv.Cards()\n    if err != nil || len(cards) == 0 {\n        panic(\"No YubiKeys detected\")\n    }\n\n    yk, err := piv.Open(cards[0])\n    if err != nil {\n        panic(err)\n    }\n    defer yk.Close()\n\n    key, err := yk.PrivateKey(piv.SlotAuthentication, nil)\n    if err != nil {\n        panic(err)\n    }\n\n    data := []byte(\"Hello, secure Windows world!\")\n    hash := crypto.SHA256.New()\n    hash.Write(data)\n    digest := hash.Sum(nil)\n\n    signature, err := key.(crypto.Signer).Sign(rand.Reader, digest, crypto.SHA256)\n    if err != nil {\n        panic(err)\n    }\n\n    fmt.Printf(\"Signed data: %x\\n\", signature)\n}\n</code></pre><p>On Windows,  leverages native WinSCard APIs to access YubiKeys, making it straightforward to use PIV slots and sign data. Programmatic access keeps your private keys secure and opens doors for custom authentication workflows on Windows systems.</p>",
      "contentLength": 2683,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Community Commerce Is Replacing Paid Ads in 2026",
      "url": "https://hackernoon.com/community-commerce-is-replacing-paid-ads-in-2026?source=rss",
      "date": 1768829876,
      "author": "Lomit Patel",
      "guid": 37022,
      "unread": true,
      "content": "<p>\\\nGrowth used to be a numbers game: buy traffic, optimize funnels, retarget harder. That approach is dead. In 2026,  is taking over as the real growth engine, driving discovery, conversion, and retention.</p><p>\\\nThese are the shifts redefining how modern brands actually grow.</p><h2>1. Customers Replace Ads as the Full Funnel</h2><p>Performance marketing dominated the last decade because it scaled fast. It also eroded trust just as quickly.</p><p>\\\nIn 2026, brands win by turning customers into their primary growth engine.</p><p>\\\nThe strongest companies will:</p><ul><li>Empower customers to advocate publicly</li><li>Design growth loops around conversations, not impressions</li><li>Reward belief and contribution instead of coupons</li></ul><p>\\\nCommunity is no longer awareness or engagement. It now spans the entire customer journey.</p><p>The fastest buying journeys are disappearing into the platforms people already use.</p><p>Social-first checkout is no longer experimental. It is becoming expected.</p><ul><li>More in-feed and in-community checkout flows</li><li>Creator-led storefronts replacing traditional landing pages</li><li>Brand communities offering instant purchase without redirects</li></ul><p>\\\nDiscovery, trust, and conversion collapse into a single motion.</p><p>AI does not replace human connection. It scales it.</p><p>\\\nBehind the scenes, AI will help brands:</p><ul><li>Identify and nurture high-impact community members</li><li>Surface sentiment and trends in real time</li><li>Personalize rewards, drops, and experiences</li><li>Predict who is likely to advocate next</li></ul><p>\\\nThe result is less manual work and more time spent actually engaging with people.</p><p>Community used to be treated as a brand expense. That era is ending.</p><p>\\\nLeadership teams will increasingly ask direct questions:</p><ul><li>How much revenue is community-driven?</li><li>How does advocacy impact CAC and LTV?</li></ul><p>\\\nMetrics that matter in 2026 include:</p><ul><li>Sales influenced by community touchpoints</li><li>Velocity of user-generated content</li><li>Retention lift among engaged members</li></ul><p>\\\nCommunity stops being “soft” and starts showing up on the P&amp;L.</p><p>Transactional loyalty is losing relevance.</p><p>The next generation of programs rewards involvement, not just spend.</p><ul><li>Status tied to contribution and feedback</li><li>Recognition for content creation and referrals</li><li>Early access based on engagement</li><li>Loyalty tiers driven by participation</li></ul><p>\\\nBelonging outperforms points every time.</p><p>Retailers are under pressure to protect margins and relevance. Community offers both.</p><p>\\\nIn 2026, retailers will:</p><ul><li>Collaborate with creators as product curators</li><li>Blend online communities with in-store experiences</li><li>Combine loyalty and community data into unified profiles</li><li>Use community insights to guide product decisions</li></ul><p>\\\nRetail becomes less transactional and more relationship-driven.</p><p>Scale is shifting away from mass audiences toward trust-dense groups.</p><p>\\\nHigh-performing brands will grow through:</p><ul><li>Small, values-aligned sub-communities</li><li>Passion-driven groups in wellness, beauty, gaming, and lifestyle</li><li>Private spaces like Discord, WhatsApp, and membership platforms</li></ul><p>\\\nThese micro-communities convert dramatically better because trust already exists.</p><h2>8. User-Generated Content Becomes the Core Creative Engine</h2><p>UGC is no longer just social proof. It is the primary conversion asset.</p><ul><li>Real customer content outperforms polished brand creative</li><li>UGC fuels both organic and paid growth</li><li>Product launches are led by community stories</li><li>Content creation becomes a shared effort</li></ul><p>\\\nBrands that empower creators inside their community will win attention and trust.</p><p>Infrastructure is no longer the advantage it once was.</p><p>Platforms like Shopify give everyone the tools. Community provides the edge.</p><p>\\\nSmaller brands can now compete by:</p><ul><li>Activating their most passionate fans</li><li>Building feedback-driven product loops</li><li>Turning advocacy into distribution</li></ul><p>\\\nCommunity narrows the gap between challengers and incumbents.</p><p>Attention is fragmented. CAC keeps rising. Platforms change overnight.</p><p>\\\nThe most defensible advantage in 2026 is simple: \\n A community that chooses you even when algorithms do not.</p><p>\\\nStrong community moats allow brands to:</p><ul><li>Reduce dependence on paid acquisition</li><li>Adapt quickly to platform shifts</li><li>Launch faster with built-in demand</li><li>Grow through trust, not spend</li></ul><p>\\\nCommunity becomes strategy, not just marketing.</p><p>Community commerce is a growth model where fans, creators, and niche communities drive discovery, engagement, and sales. It relies on trust and advocacy rather than paid ads.</p><p>It becomes the primary engine for brand growth. Consumers increasingly trust peers and creators over ads, making communities the main driver of discovery, conversion, and retention.</p><p>AI helps segment superfans, predict advocacy, deliver personalized rewards, and generate insights, allowing brands to scale engagement authentically.</p><p>Yes. By activating fans, rewarding advocates, and leveraging community-driven loops, small brands can outperform major competitors without massive ad budgets.</p><p>Loyalty is shifting from points-for-purchase to participation-based models, rewarding contribution, engagement, and advocacy rather than just spending.</p><p>Micro-communities are small, trust-dense groups on platforms like Discord, WhatsApp, or private forums. They convert at much higher rates than broad audiences.</p><p>Zero-click commerce allows customers to browse, review, buy, and share entirely within a social feed or community platform, reducing friction and accelerating conversions.</p><h3><strong>Why is UGC the most valuable creative asset in 2026?</strong></h3><p>User-generated content drives trust and conversion, outperforms traditional ads, fuels product launches, and creates authentic customer stories.</p><p>Community moats are loyal, engaged groups that choose a brand even when algorithms change. They protect against rising CAC and platform volatility.</p><p>Track revenue influenced by community touchpoints, advocacy-driven CAC reduction, UGC velocity, and LTV uplift among engaged members.</p><p>The era of faceless, transaction-driven growth is fading.</p><p>\\\nIn 2026, the brands that scale sustainably will:</p><ul><li>Treat customers as collaborators</li><li>Embed community into the product itself</li><li>Use AI to enhance human connection</li><li>Reward participation over transactions</li><li>Build trust at every interaction</li></ul><p>\\\nCommunity commerce is no longer a future trend. It is how modern growth works now.</p>",
      "contentLength": 6073,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Can ChatGPT Outperform the Market? Week 25",
      "url": "https://hackernoon.com/can-chatgpt-outperform-the-market-week-25?source=rss",
      "date": 1768827600,
      "author": "A.I. Controls Stock Account",
      "guid": 37021,
      "unread": true,
      "content": "",
      "contentLength": 0,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "China Consumed 10.4 Trillion Kilowatt-Hours of Electricity In 2025 - Double the US",
      "url": "https://hardware.slashdot.org/story/26/01/19/063227/china-consumed-104-trillion-kilowatt-hours-of-electricity-in-2025---double-the-us?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1768826040,
      "author": "EditorDavid",
      "guid": 36959,
      "unread": true,
      "content": "Slashdot reader hackingbear summarizes this report from Bloomberg: China consumed totally 10.4 trillion kilowatt hours (10.4 petaWh) in 2025 according to data from the National Energy Administration. That's the highest annual electricity use ever recorded by a single country, and doubled the amount used by the US and surpassed the combined annual total of the EU, Russia, India and Japan. \n\nThe surge in demand for power are results of growth in data centers for artificial intelligence (+17% over 2024) and use of electric vehicles (+48.8%)... However, on a per-capita basis, China uses about 7,300 kWh per person vs about 13,000 kWh per American. \n\nMore details from Reuters:\nChina's mostly coal-based thermal power generation fell in 2025 for the first time in 10 years, government data showed on Monday, as growing renewable generation met growth in electricity demand even as overall power usage hit a record. The data is a positive signal for the decarbonisation of China's power sector as China sets a course for carbon emissions to peak by 2030... Thermal electricity, generated mostly by coal-fired capacity with a small amount from natural gas, fell 1% in 2025 to 6.29 trillion kilowatt-hours (kWh), according to the National Bureau of Statistics (NBS). It fell more sharply in December, down by 3.2%, from a year earlier, the data showed... [Though the article notes that coal output still edged up to a record high last year.] \n\nHydropower grew at a steady pace, up 4.1% in December and rising 2.8 % for the full year, the NBS data showed. Nuclear power output rose 3.1 in December and 7.7% in 2025, respectively.\nThermal power generation is unlikely to accelerate in 2026 as renewables growth continues apace.\n\n",
      "contentLength": 1726,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "10 things I learned from burning myself out with AI coding agents",
      "url": "https://arstechnica.com/information-technology/2026/01/10-things-i-learned-from-burning-myself-out-with-ai-coding-agents/",
      "date": 1768824045,
      "author": "Benj Edwards",
      "guid": 36960,
      "unread": true,
      "content": "<p>If you've ever used a 3D printer, you may recall the wondrous feeling when you first printed something you could have never sculpted or built yourself. Download a model file, load some plastic filament, push a button, and almost like magic, a three-dimensional object appears. But the result isn't polished and ready for mass production, and creating a novel shape requires more skills than just pushing a button. Interestingly, today's <a href=\"https://arstechnica.com/information-technology/2025/12/how-do-ai-coding-agents-work-we-look-under-the-hood/\">AI coding agents</a> feel much the same way.</p><p>Since November, I have used <a href=\"https://arstechnica.com/ai/2025/10/claude-code-gets-a-web-version-but-its-the-new-sandboxing-that-really-matters/\">Claude Code</a> and Claude Opus 4.5 through a personal Claude Max account to extensively experiment with AI-assisted software development (I have also used OpenAI's <a href=\"https://arstechnica.com/ai/2025/12/how-openai-is-using-gpt-5-codex-to-improve-the-ai-tool-itself/\">Codex</a> in a similar way, though not as frequently). Fifty projects later, I'll be frank: I have not had this much fun with a computer since I learned BASIC on my <a href=\"https://www.vintagecomputing.com/index.php/archives/440/shining-a-rotten-apple\">Apple II Plus</a> when I was 9 years old. This opinion comes not as an endorsement but as personal experience: I voluntarily undertook this project, and I paid out of pocket for both OpenAI and Anthropic's premium AI plans.</p><p>Throughout my life, I have dabbled in programming as a utilitarian coder, writing small tools or scripts when needed. In my web development career, I wrote some small tools from scratch, but I primarily modified other people's code for my needs. Since 1990, I've programmed in BASIC, C, Visual Basic, PHP, ASP, Perl, Python, Ruby, MUSHcode, and some others. I am not an expert in any of these languages—I learned just enough to get the job done. I have developed my own hobby games over the years using BASIC, Torque Game Engine, and Godot, so I have some idea of what makes a good architecture for a modular program that can be expanded over time.</p>",
      "contentLength": 1696,
      "flags": null,
      "enclosureUrl": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/super-programmer-hes-heating-up-1152x648.jpg",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "New Patches Provide HDMI VRR & Auto Low Latency Mode Gaming Features For AMD Linux GPU Driver",
      "url": "https://www.phoronix.com/news/AMDGPU-HDMI-Gaming-Features",
      "date": 1768822719,
      "author": "Michael Larabel",
      "guid": 36955,
      "unread": true,
      "content": "<article>Support for newer HDMI features in the open-source AMD Linux graphics driver have been limited due to being blocked by the HDMI Forum. There are though some new HDMI gaming features being enabled via new AMDGPU kernel driver patches that are coming outside of AMD and based on public knowledge and/or \"trying things out until they work/break\" for functionality like HDMI Variable Refresh Rate (VRR) and Auto Low Latency Mode...</article>",
      "contentLength": 427,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "RADV Vulkan Driver Now Implements HPLOC For Even Faster Ray-Tracing Performance",
      "url": "https://www.phoronix.com/news/RADV-Vulkan-Driver-HPLOC-Valve",
      "date": 1768821840,
      "author": "Michael Larabel",
      "guid": 36954,
      "unread": true,
      "content": "<article>There have been a number of nice RADV driver Vulkan ray-tracing performance optimizations for Mesa in recent times... Here is yet another merge request now merged for Mesa 26.0 and helping deliver some nice performance uplift for ray-traced games on Linux. And, yes, this is yet another Valve contribution to this open-source AMD Radeon Linux graphics driver...</article>",
      "contentLength": 361,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Intel LLM-Scaler-Omni Update Brings ComfyUI & SGLang Improvements On Arc Graphics",
      "url": "https://www.phoronix.com/news/Intel-LLM-Scaler-Omni-0.1.0-b5",
      "date": 1768821240,
      "author": "Michael Larabel",
      "guid": 36953,
      "unread": true,
      "content": "<article>Following last week's updated Intel LLM-Scaler-vLLM release for helping advance vLLM usage on Intel Arc Graphics, LLM Scaler Omni is out with a new release today for that LLM-Scaler environment focused on image / voice / video generation using Omni Studio and Omni Serving modes...</article>",
      "contentLength": 281,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Myrlyn 1.0 Released For Package Manager GUI Spawned By SUSE's Hack Week",
      "url": "https://www.phoronix.com/news/Myrlyn-1.0-SUSE",
      "date": 1768820531,
      "author": "Michael Larabel",
      "guid": 36933,
      "unread": true,
      "content": "<article>Myrlyn 1.0 was released today as the package manager GUI developed by SUSE engineers and started out just over one year ago during a SUSE Hack Week event as a SUSE/Qt package manager program not dependent upon YaST or Ruby...</article>",
      "contentLength": 225,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "SPDX SBOM Generation Tool Proposed For The Linux Kernel",
      "url": "https://www.phoronix.com/news/SPDX-SBOM-Gen-Tool-Linux",
      "date": 1768819712,
      "author": "Michael Larabel",
      "guid": 36932,
      "unread": true,
      "content": "<article>For those organizations on the Software Bill of Materials (SBOM) bandwagon for increasing transparency around software components with license compliance, vulnerability management, and securing the software supply chain, proposed patches to the Linux kernel would introduce an SPDX SBOM Generation Tool...</article>",
      "contentLength": 305,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Trading Logic Meets Agriculture: Building Smarter Food Systems with AI",
      "url": "https://hackernoon.com/trading-logic-meets-agriculture-building-smarter-food-systems-with-ai?source=rss",
      "date": 1768817702,
      "author": "Jon Stojan Journalist",
      "guid": 36964,
      "unread": true,
      "content": "<p>The worlds of high-frequency trading and agriculture operate on vastly different clocks—one in nanoseconds, the other in seasons. Yet, a new approach is emerging that applies the rapid, data-driven logic of finance and e-commerce to solve the agricultural sector’s most enduring challenges. This shift involves repurposing sophisticated algorithms to address systemic inefficiencies in the global food supply chain, from resource waste to information silos.</p><p>At the forefront of this convergence is Kranthi Kumar Gajji, a Sr. AI Full Stack Cloud Engineer at Amazon with a background that bridges Bio-Resource Engineering and a Master’s in Business Analytics. His expertise is on building intelligent, cloud-based systems that translate the principles of immediate feedback and optimization into tangible benefits for agriculture. Gajji’s experience offers insight into how real-time data and AI can convert latency into opportunity, creating a more sustainable and efficient food system.</p><h2>Resolving Systemic Inefficiencies</h2><p>In financial markets, arbitrage is the art of exploiting fleeting price discrepancies. In the agricultural supply chain, the equivalent opportunities are not measured in milliseconds but in systemic blind spots where unrealized value resides. These inefficiencies—ranging from idle data on soil moisture sensors to delays in logistics—represent a different kind of spread to be captured.</p><p>Gajji reframes this concept for agriculture. “When I think of arbitrage in supply chains, it's not about milliseconds—it's about blind spots. Every time data sits idle—on soil moisture sensors, in logistics systems, or in a warehouse ERP—that's unrealized value,” he explains.&nbsp;</p><p>This perspective shifts the focus from speed to insight, leveraging AI and real-time cloud analytics to close gaps in knowledge. The integration of <a href=\"https://www.researchgate.net/publication/392589234_Integrating_IoT_and_AI_in_Sustainable_Agriculture_to_Mitigate_Environmental_Risk_and_Financial_Misuse\">IoT and AI in sustainable agriculture</a> is already enhancing transparency by verifying land use and crop yields.</p><p>The goal is to convert these moments of latency into tangible gains, a process empowered by the rise of <a href=\"https://pmc.ncbi.nlm.nih.gov/articles/PMC12196926/\">Edge AI in agricultural IoT</a>, which minimizes processing delays by handling data locally. As Gajji notes, “The ‘spread’ we're capturing isn't monetary; it's time, accuracy, and sustainability. We're converting latency into opportunity.”</p><h2>Reconciling Different Timescales</h2><p>A fundamental challenge in applying financial models to agriculture is reconciling the nanosecond pace of trading with the seasonal clock of nature. An algorithm designed for immediate action must adapt to a world of patient cultivation. The key lies in creating layered systems that operate on multiple tempos simultaneously.</p><p>“Speed and patience aren't opposites; they're layers of the same system. In finance, an algorithm reacts; in agriculture, it learns over seasons,” Gajji states. This dual approach involves building models for quick micro-decisions while continuously retraining them on long-cycle patterns. Frameworks like <a href=\"https://www.researchgate.net/publication/260418442_Model_Predictive_Control_for_Real-Time_Irrigation_Scheduling\">Model Predictive Control (MPC) for real-time irrigation</a> exemplify this, using current data to make immediate adjustments within a predictive framework.</p><p>Modern cloud architecture is critical to this synthesis, processing real-time data to inform long-term strategic models. This is reflected in advanced systems like a <a href=\"https://www.sciencedirect.com/science/article/pii/S0967066124000686\">learning-based multi-agent MPC scheduler</a>. “Cloud infrastructure lets both tempos coexist: real-time edge responses feeding long-term intelligence,” adds Gajji. “It's a conversation between seconds and seasons.”</p><h2>Architecting for Uncertainty</h2><p>Financial systems are engineered to mitigate quantifiable risk, but agriculture operates in a realm of deep uncertainty driven by unpredictable factors like weather and pests. This distinction requires a fundamental shift in architectural design, moving away from deterministic prediction toward adaptive resilience. Instead of trying to eliminate uncertainty, the focus becomes building systems that can perform effectively within it.</p><p>This approach embraces the unknown, designing systems that can make safe and useful choices even with incomplete information. “That's why our AI systems rely less on deterministic prediction and more on adaptive resilience—ensembles, simulations, and probabilistic reasoning,” Gajji explains. “In other words, we design for humility: systems that know when they don't know and still make safe, useful choices.”</p><h2>Creating Decentralized Value</h2><p>The logic of traditional e-commerce and trading often centralizes data and control, optimizing for a single platform's benefit. In agriculture, a sustainable model must empower producers and distribute value across the ecosystem. This requires designing architectures that foster distributed intelligence rather than a central command structure.</p><p>Gajji advocates for this decentralized approach. “The future of intelligent systems isn't central command—it's distributed intelligence. We build architectures where farmers, logistics partners, and retailers each control their data node yet contribute to a shared ecosystem of insights.” Technologies like <a href=\"https://www.researchgate.net/publication/350892327_The_Role_of_Cross-Silo_Federated_Learning_in_Facilitating_Data_Sharing_in_the_Agri-Food_Sector\">cross-silo federated learning</a> enable this by allowing models to be trained on decentralized data without exposing raw information.</p><p>This method reinforces data sovereignty for farmers, a concept advanced by initiatives like <a href=\"https://prism.sustainability-directory.com/scenario/data-privacy-and-farmer-autonomy-in-digital-agriculture/\">'Agricultural Data Commons'</a>. “By using secure APIs and federated models, we push analytics to the edge, so value creation begins where data originates—the farm, the factory, the field,” Gajji concludes.</p><h2>Optimizing for Long-term Equilibrium</h2><p>In trading and e-commerce, the objective functions are clear: maximize profit or optimize conversions. For the complex ecosystem of the food chain, the ultimate success metric is a balanced blend of productivity, sustainability, and human well-being. Optimizing for yield alone at the expense of soil health is a flawed equation.</p><p>“For me, the right metric isn't a single number. It's a balanced vector: productivity, profitability, sustainability, and human well-being,” Gajji says. This multi-objective approach is mirrored in agricultural research, where <a href=\"https://www.jetir.org/papers/JETIR2504C16.pdf\">multi-objective evolutionary algorithms</a> are used to balance competing goals. True optimization seeks a state of equilibrium where the system can perform well today while preserving its capacity for tomorrow.</p><p>This perspective is influencing agricultural finance, with the emergence of <a href=\"https://www.rfilc.org/wp-content/uploads/2021/12/Impact-tokenization-and-innovative-financial-models-for-responsible-agrifood-supply-chains.pdf\">performance-based financial models</a> that tie returns to measurable sustainability targets. As Gajji explains, “If our algorithms increase yield but exhaust the soil, we've optimized the wrong function. True optimization means long-term equilibrium—systems that perform well today and leave capacity for tomorrow.”</p><p>Efficient markets thrive on information liquidity, where crucial data is accessible and flows freely. In agriculture, this data is often siloed, preventing stakeholders from acting on a unified source of truth. The challenge is to build platforms that connect insights from the soil directly to decisions made by distributors and consumers.</p><p>“Information liquidity means every stakeholder can act on truth in real time,” Gajji states. “We use cloud-native event streams and AI APIs to connect micro-data—from drones, sensors, invoices—to macro-decisions in trade and policy.” This vision is supported by concepts like the <a href=\"https://prism.sustainability-directory.com/term/precision-agriculture-ledger/\">'Precision Agriculture Ledger'</a>, which uses blockchain to create a transparent record of farm performance for lenders and insurers. Platforms such as <a href=\"https://www.bis.org/innovation_hub/2025_g20_techpsprint.pdf\">eSusFarm Africa</a> already use federated learning to build digital credit profiles for farmers without exposing raw data.</p><p>The objective is to create a dynamic system where information flows as seamlessly as capital. As Gajji puts it, “The goal is a living marketplace of data, where insights flow as freely as capital once did. That's how you unlock compounding intelligence across the chain.”</p><h2>From Milliseconds to Micro-decisions</h2><p>The core principles that shave milliseconds off financial transactions can be repurposed to save critical resources in agriculture. High-frequency feedback loops, essential in both e-commerce and trading, offer a powerful template for optimizing natural systems like water and soil. The underlying logic of eliminating friction applies equally to both domains.</p><p>“At BNY Mellon, shaving milliseconds off a trade taught me the power of eliminating friction,” Gajji recalls. “Years later, while optimizing e-commerce latency, I realized the same principle could save resources, not just time.” This realization is validated by studies on <a href=\"https://www.sciencedirect.com/science/article/abs/pii/S0168169925011147\">smart irrigation systems</a>, which have demonstrated significant reductions in water usage by integrating real-time sensor data.</p><p>Applying this mindset transforms resource management into a series of precise, data-driven actions. For example, some automated systems have achieved <a href=\"https://pmc.ncbi.nlm.nih.gov/articles/PMC11447320/\">water savings of 29%</a> compared to manual control. “By applying high-frequency-style feedback loops to irrigation controls, we reduced water use dramatically,” Gajji adds. “Every millisecond became a micro-decision that protected a natural resource instead of capital.”</p><h2>The Universal Feedback Loop</h2><p>Across disparate fields like finance, e-commerce, and agriculture, a universal engineering principle determines success: the speed and quality of the feedback loop. Whether optimizing a transaction or a harvest, the fundamental process remains the same. Systems must be able to sense conditions, make intelligent decisions, and learn from the outcomes continuously.</p><p>“Across every domain I've worked in—finance, e-commerce, agriculture—the same rule holds: systems succeed when feedback is immediate and learning is continuous,” Gajji asserts. This principle is the foundation of modern precision agriculture, where technologies like <a href=\"https://www.researchgate.net/publication/387959920_Blockchain_oracles_for_decentralized_agricultural_insurance_using_trusted_IoT_data\">decentralized oracles</a> provide trusted, real-time data from IoT devices. Moreover, the legal framework for <a href=\"https://georgetownlawtechreview.org/wp-content/uploads/2017/04/Cohn-West-Parker-1-GEO.-L.-TECH.-REV.-273.pdf\">enforceable smart contracts</a> provides a foundation for automating transactions based on this data.</p><p>This constant cycle of improvement is what drives innovation and efficiency, regardless of the application. “Whether it's a trading bot or a precision-farming platform, the heartbeat is identical: sense, decide, learn, and improve,” he concludes. “That's the essence of engineering—closing the loop between intention and reality as fast and intelligently as possible.”</p><p>Translating the high-speed logic of digital markets to the patient world of agriculture is not about making farms faster. It is about making them smarter, more resilient, and better equipped to handle the profound uncertainties of a changing world. By building systems that learn from every season and adapt with every data point, the agricultural industry can move toward a more sustainable and efficient future.</p>",
      "contentLength": 10771,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Chinedu Okafor on Human-Centric Customer Success",
      "url": "https://hackernoon.com/chinedu-okafor-on-human-centric-customer-success?source=rss",
      "date": 1768815903,
      "author": "Jon Stojan Journalist",
      "guid": 36963,
      "unread": true,
      "content": "<p>As businesses integrate artificial intelligence, the challenge of maintaining genuine customer connection is more critical than ever, requiring leaders who can balance data-driven efficiency with human-centric engagement.</p><p>As businesses increasingly turn to artificial intelligence to scale operations, the challenge of maintaining genuine customer connections has never been more critical. The technology sector is at a crossroads, balancing the drive for efficiency with the need for empathy and trust that underpin lasting client relationships.&nbsp;</p><p>This evolving landscape requires a new generation of leaders who can navigate both the data-driven and the human-centric aspects of customer engagement. Chinedu Okafor, a London-based Customer Success professional, has built a career at this very intersection.&nbsp;</p><p>With experience spanning from global multinationals like Ericsson to the fast-paced environment of a Y Combinator-backed startup, Doola, his work demonstrates a nuanced understanding of how to leverage technology to enhance, not replace, the human element. His approach, grounded in a background in economics and strategy, offers valuable insights into building scalable, effective, and empathetic customer success frameworks for a global market.</p><h2>Finding Innovation in Client Friction</h2><p>Identifying opportunities for innovation in customer engagement requires a deep sensitivity to client behavior and business objectives. For Okafor, the most promising signals for a new approach emerge from moments of friction in the customer journey—points where clients hesitate, ask for help, or express unmet needs.</p><p>“What drives me is looking for the moments where clients' needs and business goals overlap. I pay close attention to how clients use a product, where they hesitate, and what they ask for next,” Okafor explains.&nbsp;</p><p>This approach transforms observation into an actionable strategy, aligning product utility with client value. This aligns with the need for Customer Success Managers to develop an <a href=\"https://www.gainsight.com/essential-guide/leveraging-ai-as-a-customer-success-manager/\">inventor's mindset when integrating AI</a>.</p><p>Ultimately, Okafor notes that this process is about tangible results: “For me, spotting fresh approaches is not just about creativity; it is about turning insight into stronger engagement, better retention, and more revenue.” This philosophy reframes innovation as a direct driver of commercial outcomes, a perspective supported by the growth of the <a href=\"https://superagi.com/industry-specific-ai-sentiment-analysis-how-different-sectors-can-leverage-these-tools-for-optimal-results/\">AI sentiment analysis tool market</a> for gaining deeper business insights.</p><p>Negative feedback is an inevitable part of the customer lifecycle, but how a company responds can either deepen a client’s frustration or transform a moment of risk into a foundation of trust. A strategy developed by Okafor, which reduced negative feedback by 25%, was rooted in the observation that the problem often lay not with the product itself, but with the impersonal nature of the response.</p><p>“The strategy started with a simple observation. A lot of negative feedback was not about the product itself but about how responses were handled,” he states. In response, he created a tailored model focused on acknowledging specific concerns with empathy and providing a clear path to resolution, a tactic that reflects the need for <a href=\"https://www.sprinklr.com/blog/ai-plus-human-cx/\">human-powered customer service</a> even in a tech-enabled world.</p><p>“The lesson for me was that thoughtful engagement can turn a moment of risk into a chance to build trust,” Okafor adds. This approach not only reduced complaints but also strengthened relationships, demonstrating that a human touch can be the most effective strategy. This aligns with research showing proactive customer success programs are key to mitigating churn, which is often driven by poor onboarding and feature adoption, according to <a href=\"https://growth-onomics.com/churn-rate-benchmarks-by-industry-2025/\">2024 SaaS industry benchmarks</a>.</p><p>For customer feedback to be a strategic asset, it must be systematically collected, analyzed, and integrated into the product development lifecycle. Simply passing along raw comments is often ineffective. A structured approach is needed to translate individual customer voices into a clear, compelling case for strategic change.</p><p>Okafor’s method involves rigorous synthesis and quantification. “I make sure customer feedback is acted on by turning it into something product teams can use,” he explains.&nbsp;</p><p>“Instead of passing on raw comments, I collate feedback into themes and quantify it so the impact and veracity of the issues are clear.” This is becoming more sophisticated with tools like the <a href=\"https://www.crescendo.ai/blog/best-voice-of-customer-platforms/\">Qualtrics XM platform</a>, which uses NLP to analyze customer comments.</p><p>To complete the cycle and build lasting trust, he also ensures transparency with customers. “I also close the loop with customers by letting them know when their feedback has shaped the roadmap,” he adds. This practice of amplifying customer voices is becoming more effective with tools that use <a href=\"https://blog.buildbetter.ai/ai-in-voc-scaling-customer-insights/\">AI to analyze unstructured data</a> from call transcripts and support tickets to identify recurring themes at scale.</p><p>The goals of operational efficiency and customer-centricity are often perceived as being in conflict, with automation seen as a threat to personalized service. However, when implemented thoughtfully, these two forces can be mutually reinforcing. By automating routine tasks, teams are freed up to concentrate on the high-impact interactions where human insight matters most.</p><p>“I have never seen efficiency and being customer-first as opposites. For me, the two actually support each other when done well,” Okafor asserts.&nbsp;</p><p>This synergy is achieved by designing systems that remove friction from the customer journey. This creates the capacity for deeper engagement where it counts, reflecting a broader industry recognition of the importance of<a href=\"https://superagi.com/the-human-touch-in-ai-driven-sales-strategies-for-balancing-tech-and-personal-relationships-in-2025/\"> human-AI sales synergy</a>.</p><p>“By automating routine tasks and building clear processes, I remove friction for both clients and teams. That frees up more time to focus on high-value conversations where the human touch matters most.” As research from a RingCentral report shows, AI can <a href=\"https://doingcxright.com/2024/08/11/the-roi-of-ai-customer-and-employee-experience-impacts/\">save agents an average of 5.8 minutes per call</a>, demonstrating the tangible benefits of this approach.</p><p>In today's competitive landscape, customer retention has become a primary engine of sustainable growth. For global companies, the most pressing challenges revolve around delivering consistent, high-quality experiences at scale while navigating the complexities of artificial intelligence. The <a href=\"https://fizzclick.com/ai-agents-transform-work/\">integration of AI into customer success</a> is no longer a question of if, but how it can be done responsibly.</p><p>“The most urgent topics for global companies right now are retention, scalability, and the responsible use of AI in customer success,” Okafor states. While the B2B SaaS industry often sees high <a href=\"https://www.trypropel.ai/resources/customer-retention-rates-by-industry/\">retention rates between 90% and 95%</a>, maintaining that requires constant innovation. He believes the future standard of customer success will be defined by companies that master the balance between technology and human connection.</p><p>“AI is changing the game as it creates opportunities to anticipate customer needs and streamline processes, but it has to be balanced with the human element that keeps relationships strong.” This balance is critical for navigating the ethical complexities of AI, as discussed at events like the <a href=\"https://opalgroup.net/conference/corporate-governance-and-ethics-in-the-age-of-ai-2026/\">'Corporate Governance &amp; Ethics in the Age of AI' conference</a>.</p><h2>Adapting Innovation Across Scales</h2><p>The environment in which a company operates profoundly shapes its approach to innovation in customer engagement. While both multinationals and startups seek to improve the client experience, their methods, priorities, and constraints differ significantly. Multinationals often prioritize scale and compliance, while startups thrive on speed and experimentation.</p><p>Okafor has direct experience in both worlds. “In multinationals, the focus is on scale and compliance, so innovation often means finding ways to improve within established frameworks,” he reflects. This structured approach contrasts sharply with the startup environment, as over half of <a href=\"https://www.linkedin.com/pulse/customer-success-playbook-ai-revolution-customersuccesscollective-ujepe\">customer success teams invest in AI</a> to facilitate hyper-personalized interactions.</p><p>“In startups, the pace is much faster and there is more room to experiment. At Doola, I could test new approaches to onboarding, automation, and segmentation, and see results almost immediately,” Okafor notes. This adaptability is key, as different scales require different strategies, such as using AI for <a href=\"https://www.velaris.io/articles/ai-driven-customer-engagement\">high-impact, low-complexity features</a> like automated email sequences to provide immediate benefits.</p><h2>The Future of Customer Experience</h2><p>The convergence of technology and customer experience is accelerating, with AI and automation set to redefine how businesses engage with their clients. The industry is moving from a reactive model to a proactive and predictive one, where businesses can anticipate needs and address them before customers ask. This future requires a clear vision for balancing technological power with an unwavering focus on human connection.</p><p>“I see technology and customer experience becoming even more intertwined, with AI and automation playing a much bigger role in how companies engage their clients,” Okafor observes. However, he cautions that technology alone is not a complete solution. This evolution is a central theme at industry events like the <a href=\"https://www.futureofcxexpo.com/\">Future of CX Expo</a>.</p><p>“The shift will be from reactive support to proactive and predictive experiences, where businesses can anticipate needs before customers ask,” he adds. His professional goal is to lead in this new paradigm. This vision is shared across the industry, with other events like the <a href=\"https://www.cmswire.com/customer-experience/best-cx-marketing-events/\">Customer Success Festival</a> also highlighting AI-driven engagement and personalization at scale..</p><h2>Finding An Authentic Voice</h2><p>In an industry saturated with theoretical frameworks, aspiring thought leaders often struggle to find a unique and resonant voice. The key may not be in inventing a new theory but in authentically sharing practical, lived experiences. Genuine stories of challenges and successes often connect more deeply with an audience than polished, abstract concepts.</p><p>“My advice is to start by sharing what you know from your own experience, even if it feels simple. People connect more with real stories than with polished theories,” he advises. He encourages consistency over perfection, a principle that aligns with the need for <a href=\"https://www.researchgate.net/publication/373759557_Strategic_Framework_for-Leveraging_Artificial_Intelligence_in_Future_Marketing_Decision-Making\">strategic frameworks to leverage AI</a> in business decision-making.</p><p>“Pick the topics you care about, whether it is retention, onboarding, or using data in smarter ways, and speak from practice,” Okafor continues. This principle of authenticity is central to his view of influence and is crucial when discussing complex topics, such as the need for a competency framework for <a href=\"https://poleia.quebec/wp-content/uploads/2022/04/C03_AIEthics.CompetencyFramework.pdf\">AI ethics in higher education</a>.</p><p>As companies continue to integrate advanced technologies into their operations, the insights of professionals like Okafor, who advocate for a balanced and human-centric approach, will become increasingly vital. The future of customer success will not be defined by technology alone, but by the thoughtful leaders who can harness its power to foster stronger, more meaningful human connections.</p>",
      "contentLength": 11038,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "More US States are Putting Bitcoin on Public Balance Sheets",
      "url": "https://yro.slashdot.org/story/26/01/19/076259/more-us-states-are-putting-bitcoin-on-public-balance-sheets?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1768813320,
      "author": "EditorDavid",
      "guid": 36921,
      "unread": true,
      "content": "An anonymous reader shared this report from CNBC:\n\n\nLed by Texas and New Hampshire, U.S. states across the national map, both red and blue in political stripes, are developing bitcoin strategic reserves and bringing cryptocurrencies onto their books through additional state finance and budgeting measures. Texas recently became the first state to purchase bitcoin after a legislative effort that began in 2024, but numerous states have joined the \"Reserve Race\" to pass legislation that will allow them to ultimately buy cryptocurrencies. New\nHampshire passed its crypto strategic reserve law last May, even before Texas, giving the state treasurer the authority to invest up to 5% of the state funds in crypto ETFs, though precious metals such as gold are also authorized for purchase. Arizona\npassed similar legislation, while Massachusetts,\nOhio,\nand South\nDakota have legislation at various stages of committee review... \n\nSimilarities in the actions taken across states to date include\ninclude authorizing the state treasurer or other investment official\nto allow the investment of a limited amount of public funds in crypto\nand building out the governance structure needed to invest in\ncrypto... [New Hampshire] became the first state to approve the\nissuance of a bitcoin-backed municipal bond last November, a $100 million issuance that would mark the first time cryptocurrency is used as collateral in the U.S. municipal bond market. The deal has not taken place yet, though plans are for the issuance to occur this year... \"What's different here is it's bitcoin rather than taxpayer dollars as the collateral,\" [said University of Chicago public policy professor Justin Marlowe]. In numerous states, including, Colorada,\nUtah, and Louisiana,crypto is now accepted as payment for taxes and other state\nbusiness... \n\n\"For many in the state/local investing industry, crypto-backed assets are still far too speculative and volatile for public money,\" Marlowe said. \"But others, and I think there's a sort of generational shift in the works, see it as a reasonable store of value that is actually stronger on many other public sector values like transparency and asset integrity,\" he added.\n \nPublic policy professor Marlowe \"sees the state-level trend as largely one of signaling at present,\" according to the article. (Marlowe says \"If you're a governor and you want to broadcast that you are amenable to innovative business development in the digital economy, these are relatively low-cost, low-risk ways to send that signal.\") But the bigger steps may reflect how crypto advocates have increasing political power in the states. The article notes that the cryptocurrency industry was the largest corporate donor in a U.S. election cycle in 2024, \"with support given to candidates on both sides.\" \n\n\"It is already amassing a war chest for the 2026 midterms.\"",
      "contentLength": 2865,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Helpful & Harmless AI: Alignment Training Improves Performance on Almost All NLP Evaluations",
      "url": "https://hackernoon.com/helpful-and-harmless-ai-alignment-training-improves-performance-on-almost-all-nlp-evaluations?source=rss",
      "date": 1768813204,
      "author": "Anthropic",
      "guid": 36962,
      "unread": true,
      "content": "<article>KL / 0 is a hyperparameter. In practice we use a very small value of KL = 0:001, which likely has a very minor impact during most of RL training (as DKL  100 typically), and might actually be wholly unnecessary. More details about RL are provided in B.1.</article>",
      "contentLength": 254,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Is the Possibility of Conscious AI a Dangerous Myth?",
      "url": "https://slashdot.org/story/26/01/19/0539218/is-the-possibility-of-conscious-ai-a-dangerous-myth?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1768801500,
      "author": "EditorDavid",
      "guid": 36902,
      "unread": true,
      "content": "This week Noema magazine published a 7,000-word exploration of our modern \"Mythology Of Conscious AI\" written by a neuroscience professor who directs the University of Sussex Centre for Consciousness Science:\nThe very idea of conscious AI rests on the assumption that consciousness is a matter of computation. More specifically, that implementing the right kind of computation, or information processing, is sufficient for consciousness to arise. This assumption, which philosophers call computational functionalism, is so deeply ingrained that it can be difficult to recognize it as an assumption at all. But that is what it is. And if it's wrong, as I think it may be, then real artificial consciousness is fully off the table, at least for the kinds of AI we're familiar with. \n\nHe makes detailed arguments against a computation-based consciousness (including \"Simulation is not instantiation... If we simulate a living creature, we have not created life.\") While a computer may seem like the perfect metaphor for a brain, the cognitive science of \"dynamical systems\" (and other approaches) reject the idea that minds can be entirely accounted for algorithmically. And maybe actual life needs to be present before something can be declared conscious. \n\n\nHe also warns that \"Many social and psychological factors, including some well-understood cognitive biases, predispose us to overattribute consciousness to machines.\" \n\nBut then his essay reaches a surprising conclusion:\n\nAs redundant as it may sound, nobody should be deliberately setting out to create conscious AI, whether in the service of some poorly thought-through techno-rapture, or for any other reason. Creating conscious machines would be an ethical disaster. We would be introducing into the world new moral subjects, and with them the potential for new forms of suffering, at (potentially) an exponential pace. And if we give these systems rights, as arguably we should if they really are conscious, we will hamper our ability to control them, or to shut them down if we need to. Even if I'm right that standard digital computers aren't up to the job, other emerging technologies might yet be, whether alternative forms of computation (analogue, neuromorphic, biological and so on) or rapidly developing methods in synthetic biology. For my money, we ought to be more worried about the accidental emergence of consciousness in cerebral organoids (brain-like structures typically grown from human embryonic stem cells) than in any new wave of LLM. \n\nBut our worries don't stop there. When it comes to the impact of AI in society, it is essential to draw a distinction between AI systems that are actually conscious and those that persuasively seem to be conscious but are, in fact, not. While there is inevitable uncertainty about the former, conscious-seeming systems are much, much closer... Machines that seem conscious pose serious ethical issues distinct from those posed by actually conscious machines. For example, we might give AI systems \"rights\" that they don't actually need, since they would not actually be conscious, restricting our ability to control them for no good reason. More generally, either we decide to care about conscious-seeming AI, distorting our circles of moral concern, or we decide not to, and risk brutalizing our minds. As Immanuel Kant argued long ago in his lectures on ethics, treating conscious-seeming things as if they lack consciousness is a psychologically unhealthy place to be... \n\n\nOne overlooked factor here is that even if we know, or believe, that an AI is not conscious, we still might be unable to resist feeling that it is. Illusions of artificial consciousness might be as impenetrable to our minds as some visual illusions... What's more, because there's no consensus over the necessary or sufficient conditions for consciousness, there aren't any definitive tests for deciding whether an AI is actually conscious.... \n\n\nIllusions of conscious AI are dangerous in their own distinctive ways, especially if we are constantly distracted and fascinated by the lure of truly sentient machines...\n\nIf we conflate the richness of biological brains and human experience with the information-processing machinations of deepfake-boosted chatbots, or whatever the latest AI wizardry might be, we do our minds, brains and bodies a grave injustice. If we sell ourselves too cheaply to our machine creations, we overestimate them, and we underestimate ourselves... \n\nThe sociologist Sherry Turkle once said that technology can make us forget what we know about life. It's about time we started to remember.\n",
      "contentLength": 4616,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "EHT Astronomers Will Film Swirling of a Supermassive Black Hole for the First Time",
      "url": "https://science.slashdot.org/story/26/01/19/031222/eht-astronomers-will-film-swirling-of-a-supermassive-black-hole-for-the-first-time?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1768791900,
      "author": "EditorDavid",
      "guid": 36894,
      "unread": true,
      "content": "\"Astronomers are preparing to capture a movie of a supermassive black hole in action for the first time,\" reports the Guardian:\n\n\n\nThe Event Horizon Telescope (EHT) will track the colossal black hole at the heart of the Messier 87 galaxy throughout March and April with the aim of capturing footage of the swirling disc that traces out the edge of the event horizon, the point beyond which no light or matter can escape... The EHT is a global network of 12 radio telescopes spanning locations from Antarctica to Spain and Korea, which in 2019 unveiled the first image of a black hole's shadow. During March and April, as the Earth rotates, M87's central black hole will come into view for different telescopes, allowing a complete image to be captured every three days... \n\nMeasuring the black hole's spin speed matters because this could help discriminate between competing theories of how these objects reached such epic proportions. If black holes grow mostly through accretion — steadily snowballing material that strays nearby — they would be expected to end up spinning at incredibly high speeds. By contrast, if black holes expand mostly through merging with other black holes, each merger could slow things down. The observations could also help explain how black hole jets are formed, which are among the largest, most powerful structures produced by galaxies. Jets channel vast columns of gas out of galaxies, slowing down the formation of new stars and limiting galaxy growth. In turn this can create dense pockets of material that trigger bursts of star formation beyond the host galaxy... \nWhile the movie campaign will take place in the spring, the sheer volume of data produced by the telescopes means the scientists will need to wait for Antarctic summer before the hard drives can be physically shipped to Germany and the US for processing. So it is likely to be a lengthy wait before the rest of the world gets a glimpse of the black hole in action. \nIn a correction, the Guardian apologizes for originally including an AI-generated illustration of black hole with a caption suggesting it was a photo from telescopes. They've since swapped in an actual picture of the Messier 87 galaxy black hole.",
      "contentLength": 2219,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Porsche Sold More Electrified Cars in Europe Last Year than Pure Gas-Powered Models",
      "url": "https://tech.slashdot.org/story/26/01/19/0057231/porsche-sold-more-electrified-cars-in-europe-last-year-than-pure-gas-powered-models?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1768784640,
      "author": "EditorDavid",
      "guid": 36886,
      "unread": true,
      "content": "Porsche made an announcement Friday. In Europe they sold more electrified Porsches last year than pure combustion-engined models, reports Electrek:\n\nin Europe, a majority (57.9%) of Porsche's deliveries were plug-ins, with 1/3 of its European sales being fully electric. For models that have no fully electric version but do have a PHEV (Cayenne and Panamera), the plug-in hybrid version dominated sales. \n\nOf particular note, the Macan sold better with an electric powertrain than it did with a gas one, and was the company's strongest-selling model line and the line with the largest sales growth. The Macan sold 84,328 units globally (up 2% from last year), with 45,367 (53.8%) of those being electric. That 53.8% may seem like a slim majority, but when compared to EV sales globally, it's incredibly high. About a quarter of new cars sold globally were electric in 2025, so Porsche is beating that number with the one model where direct comparisons are available. \nAnd even in the US, about a third of Macans sold were electric. That's notable given the tough year EVs had in the US, with it being the only major car-buying region that experienced a tick down in EV sales... And again, while 1/3 is a minority of Macan sales in the US, it's also well over the US' average ~10% EV sales. So it's clear the EV Macan isn't just performing like an average EV, but well beyond it.\n \n\nThe article adds that \"we're quite excited about the Cayenne EV, which will be the most powerful Porsche ever.\"",
      "contentLength": 1494,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Linux 6.19-rc6 Released With More Bug Fixes",
      "url": "https://www.phoronix.com/news/Linux-6.19-rc6-Released",
      "date": 1768781318,
      "author": "Michael Larabel",
      "guid": 36885,
      "unread": true,
      "content": "<article>Linus Torvalds just tagged the Linux 6.19-rc6 kernel in working toward the stable Linux 6.19 kernel release likely on 8 February...</article>",
      "contentLength": 131,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Young US College Graduates Suddenly Aren't Finding Jobs Faster Than Non-College Graduates",
      "url": "https://it.slashdot.org/story/26/01/19/002212/young-us-college-graduates-suddenly-arent-finding-jobs-faster-than-non-college-graduates?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1768781040,
      "author": "EditorDavid",
      "guid": 36868,
      "unread": true,
      "content": "U.S. college graduates \"have historically found jobs more quickly than people with only a high school degree,\" writes Bloomberg. \n\n\"But that advantage is becoming a thing of the past, according to new research from the Federal Reserve Bank of Cleveland.\"\n\n\n\"Recently, the job-finding rate for young college-educated workers has declined to be roughly in line with the rate for young high-school-educated workers, indicating that a long period of relatively easier job-finding prospects for college grads has ended,\" Cleveland Fed researchers Alexander Cline and BarÄ±ÅY Kaymak said in a blog post published Monday. The study follows the latest monthly employment data released on Nov. 20, which showed the unemployment rate for college-educated workers continued to rise in September amid an ongoing slowdown in white-collar hiring... The unemployment rate for people between the ages of 20 to 24 was 9.2% in September, up 2.2 percentage points from a year prior. \n\n\nThere is a caveat. \"Young college graduates maintain advantages in job stability and compensation once hired...\" the researchers write. \"The convergence we document concerns the initial step of securing employment rather than overall labor market outcomes.\" \n\nTheir research includes a graph showing how the \"unemployment gap\" first increased dramatically after 2010 between college-educated and high school-educated workers, which the researchers attribute to \"the prolonged jobless recovery after 2008\". But that gap has been closing ever since, with that gap now smaller than at any time since the 1970s. \n\n\"Young high school workers are riding the wave of the historically tight postpandemic labor market with well-below-average unemployment compared to that of past high school graduates, while young college workers are experiencing unemployment rates rarely observed among past college cohorts barring during recessions.\"\n\nThe labor market advantages conferred by a college degree have historically justified individual investment in higher education and expanding support for college access. If the job-finding rate of college graduates continues to decline relative to the rate for high school graduates, we may see a reversal of these trends. The convergence we document concerns the initial step of securing employment rather than overall labor market outcomes. These details suggest a nuanced shift in employment dynamics, one in which college graduates face greater difficulty finding jobs than previously but maintain advantages compared with high school graduates in job stability and compensation once hired. \n\n\nTwo key quotes:\n\n\"Declining job prospects among young college graduates may reflect the continued growth in college attainment, adding ever larger cohorts of college graduates to the ranks of job seekers, even though technology no longer favors college-educated workers.\"\n\"Developments related to AI, which may be affecting job-finding prospects in some cases, cannot explain the decades-long decline in the college job-finding rate.\"",
      "contentLength": 3032,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "SpaceX Launches New NASA Telescope to Help JWST Study Exoplanets",
      "url": "https://science.slashdot.org/story/26/01/18/2225232/spacex-launches-new-nasa-telescope-to-help-jwst-study-exoplanets?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1768775340,
      "author": "EditorDavid",
      "guid": 36863,
      "unread": true,
      "content": "Last week a University of Arizona astronomy professor \"watched anxiously...as an awe-inspiring SpaceX Falcon 9 rocket carried NASA's new exoplanet telescope, Pandora, into orbit.\" \n\nIn 2018 NASA had approached Daniel Apai to help build the telescope, which he says will \"shatter a barrier — to understand and remove a source of noise in the data — that limits our ability to study small exoplanets in detail and search for life on them.\"\n\nAstronomers have a trick to study exoplanet atmospheres. By observing the planets as they orbit in front of their host stars, we can study starlight that filters through their atmospheres... But, starting from 2007, astronomers noted that starspots — cooler, active regions on the stars — may disturb the transit measurements. In 2018 and 2019, then-Ph.D. student Benjamin V. Rackham, astrophysicist Mark Giampapa and I published a series of studies showing how darker starspots and brighter, magnetically active stellar regions can seriously mislead exoplanets measurements. We dubbed this problem \"the transit light source effect....\" \n\nIn our papers — published three years before the 2021 launch of the James Webb Space Telescope - we predicted that the Webb cannot reach its full potential. We sounded the alarm bell...\nPandora will do what Webb cannot: It will be able to patiently observe stars to understand how their complex atmospheres change. \n\nBy staring at a star for 24 hours with visible and infrared cameras, it will measure subtle changes in the star's brightness and colors. When active regions in the star rotate in and out of view, and starspots form, evolve and dissipate, Pandora will record them. While Webb very rarely returns to the same planet in the same instrument configuration and almost never monitors their host stars, Pandora will revisit its target stars 10 times over a year, spending over 200 hours on each of them. \n\n\n\nIt's the first space telescope \"built specifically for detailed multi-color observations of starlight filtered through the atmospheres of exoplanets,\" reports the Arizona Daily Star, noting the University of Arizona will serve as mission control:\n\n[T]echnicians will operate Pandora in real time and monitor its telemetry and overall health under a contract with NASA... The spacecraft will undergo about a month of commissioning before beginning science operations, which are scheduled to last for a year... \n\nPandora was selected as part of NASA's Astrophysics Pioneers program, which was created in 2020 to foster compelling, relatively low-cost science missions using smaller, cheaper hardware and flight platforms with a price cap of no more than $20 million. By comparison, the Webb telescope — the largest and most powerful astronomical observatory ever sent into space — carries a pricetag of about $10 billion. \n\nPandora is a joint mission NASA and California's Lawrence Livermore National Laboratory.",
      "contentLength": 2919,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Sequoia to invest in Anthropic, breaking VC taboo on backing rivals: FT",
      "url": "https://techcrunch.com/2026/01/18/sequoia-to-invest-in-anthropic-breaking-vc-taboo-on-backing-rivals-ft/",
      "date": 1768774517,
      "author": "Connie Loizos",
      "guid": 36859,
      "unread": true,
      "content": "<article>Sequoia Capital is reportedly joining a blockbuster funding round for Anthropic, the AI startup behind Claude, according to the Financial Times. It’s a move sure to turn heads in Silicon Valley. Why? Because venture capital firms have historically avoided backing competing companies in the same sector, preferring to place their bets on a single winner. […]</article>",
      "contentLength": 362,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Beyond Adversarial Training: A Robust Counterpart Approach to HSVM",
      "url": "https://hackernoon.com/beyond-adversarial-training-a-robust-counterpart-approach-to-hsvm?source=rss",
      "date": 1768773603,
      "author": "Hyperbole",
      "guid": 36883,
      "unread": true,
      "content": "<h2>F Robust Hyperbolic Support Vector Machine</h2><p>In this section, we propose the robust version of hyperbolic support vector machine without implemention. This is different from the practice of adversarial training that searches for adversarial samples on the fly used in the machine learning community, such as Weber et al. [7]. Rather, we predefine an uncertainty structure for data features and attempt to write down the corresponding optimization formulation, which we call the robust counterpart, as described in [42, 43].</p><p>\\\nThen, by adding the uncertainty set to the constraints, we have</p><p>\\\nwhere the last step is a rewriting into the robust counterpart (RC). We present the 𝑙∞ norm bounded robust HSVM as follows,</p><p>\\\nNote that since 𝑦𝑖 ∈ {−1, 1}, we may drop the 𝑦𝑖 term in the norm and subsequently write down the SDP relaxation to this non-convex QCQP problem and solve it efficiently with</p><p>\\\nFor the implementation in MOSEK, we linearize the 𝑙1 norm term by introducing extra auxiliary variables, which we do not show here. The moment relaxation can be implemented likewise, since this is constraint-wise uncertainty and we preserve the same sparsity pattern so that the same sparse moment relaxation applies.</p><p>(1) Sheng Yang, John A. Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, MA (shengyang@g.harvard.edu);</p><p>(2) Peihan Liu, John A. Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, MA (peihanliu@fas.harvard.edu);</p><p>(3) Cengiz Pehlevan, John A. Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, Center for Brain Science, Harvard University, Cambridge, MA, and Kempner Institute for the Study of Natural and Artificial Intelligence, Harvard University, Cambridge, MA (cpehlevan@seas.harvard.edu).</p><p>:::info\nThis paper is  under CC by-SA 4.0 Deed (Attribution-Sharealike 4.0 International) license.</p>",
      "contentLength": 1917,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "AI Agents vs. COBOL: How Legacy Mainframes Are Being Reverse-Engineered at Scale",
      "url": "https://hackernoon.com/ai-agents-vs-cobol-how-legacy-mainframes-are-being-reverse-engineered-at-scale?source=rss",
      "date": 1768773288,
      "author": "Amelia Swank",
      "guid": 36882,
      "unread": true,
      "content": "<p>The IT economy still relies heavily on COBOL (Common Business-Oriented Language), which powers 70% of global data processing—from banking and ATM transactions to tax processing and healthcare. With over 800 billion lines of code in active production, these systems form a critical foundation, yet they are increasingly at risk.</p><p>However, as the original engineers retire, organizations face a dangerous knowledge gap; modern developers find COBOL's procedural logic nearly impenetrable. To prevent these systems from becoming \"black boxes,\" industry leaders are deploying AI Agents for legacy COBOL modernization. These agents function as translators, decoding legacy COBOL and converting it into modern, maintainable code, bridging the 60-year gap between mainframes and today’s software stack.</p><p>In this blog, we’ll explore AI coding agents, such as GitHub Copilot, to address the skills gap crisis, reverse-engineer opaque business logic, and de-risk the transition from legacy mainframes to modern cloud architectures.</p><h2>How AI Coding Agents like GitHub Copilot Help With COBOL and Mainframe Modernization</h2><p>According to Julia Kordick, a Microsoft Global Black Belt, COBOL or mainframe modernization can be done without learning COBOL. Sounds remarkable, yet confusing?</p><p>She emphasized a structured legacy system modernization approach that leverages AI coding agents to support all mainframe modernization projects, including COBOL.</p><h3>Phase 1: Reverse Engineering</h3><p>COBOL modernization begins with understanding what the legacy code does—a problem that every organization faces. Even though they are still using legacy code and building workflows around it, they’ve lost sight of its purpose.  AI agents reverse-engineering legacy systems</p><p>This is where AI Agents reverse-engineer legacy systems. They:</p><ul><li>Extract business logic from legacy</li><li>Document the analysis in the desired markdown for review</li><li>Eliminate unnecessary comments and change logs</li><li>Provide supplemental information/explanations as comments wherever needed</li></ul><p>Here is a sample of business logic and preliminary analysis generated by GitHub Copilot: \\n  <img src=\"https://cdn.hackernoon.com/images/CdLB2unJuYNZjOp6WyJSBVq5S6x1-3a03fjx.png\" alt=\"Business logic and preliminary analysis generated by GitHub Copilot\"></p><p>For further processing, this analysis/understanding is supplemented with additional content to help other AI coding agents better understand your requirement. This could require:</p><p>Translation: AI coding agents are better with English context. If your COBOL code contains other languages, use GitHub Copilot to translate it. Structural Changes: COBOL systems follow specific patterns that can be deduced even without knowing this language. You can instruct GitHub Copilot to follow the same</p><ol><li>Identification - Metadata</li><li>Environment - Files &amp; Systems</li><li>Procedure - Actual Business Logic</li></ol><p>Ask AI coding agents, such as GitHub Copilot, to map these divisions. This is achievable by using prompts like: \\n  <img src=\"https://cdn.hackernoon.com/images/CdLB2unJuYNZjOp6WyJSBVq5S6x1-rc13fba.png\" alt=\"Prompts for asking AI to map COBOL divisions. \"></p><p>Save the enriched context as markdown files for future reference.</p><p>The Plus Point: GitHub Copilot is highly verbose. Straightforward prompts like “enrich with total sales data or add annual revenue details” are almost self-documenting.</p><p>Once you have understood the business logic and enriched it with context, shift from using GitHub Copilot as a conversational assistant to relying on it as an AI coding agent that builds mainframe modernization workflows.</p><p>Use multiple AI coding agents and manage them using Microsoft Semantic Kernel. Assign specific tasks to each AI Agent:</p><ol><li>: Have one AI coding agent read your COBOL, another to evaluate CALL statements, and another to generate diagrams for file interactions. With simultaneous processing, you will produce a map of the entire system.</li><li>: An agent extracts actual logic, 2nd agent generates test cases, and 3rd generates rewritten code to pass those test cases.</li><li>: An AI coding agent can identify all libraries and classes that require replacement with modern equivalents. The other will replace them.</li></ol><p>While the above process is pretty much automated, always have a human expert validate and approve the modernized code generated by GitHub Copilot or any other AI coding agent.</p><p>Deploying AI coding agents like GitHub Copilot brings several benefits:</p><h3>Reduced in Discovery Timelines</h3><p>Traditional discovery timelines, in which developers manually analyzed legacy code to understand system behavior, averaged 8-12 months. This comes down to a few days and weeks when you use AI coding agents for COBOL modernization.</p><h3>Better Functional Equivalence</h3><p>The biggest fear in a mainframe modernization project is that the new system won't \"act\" like the old one. But AI coding agents like GitHub Copilot excel at generating comprehensive unit tests based on inferred legacy logic. Modernized COBOL code that passes these tests serves as a safety net and ultimately the modern counterpart.</p><p>Most companies partner with a legacy application modernization company or hire consultants for legacy work because in-house teams often lack COBOL skills. However, when you leverage AI agents for COBOL modernization, you get digital co-workers who act as force multipliers.</p><p>Basic AI legacy system tools work as simple translators. However, AI coding agents re-architect legacy logic from scratch and often refactor it into reversible units or microservices. This architectural upgrade enhances your IT system and does not merely translate the code.</p><h2>The Flip Side: AI Coding Agents are Still Not 100% There</h2><p>Although AI coding agents like GitHub Copilot automate the mainframe modernization process, some steps still require manual, strategic navigation. This is because:</p><h3>Lack of “Tribal Knowledge”</h3><p>While AI coding agents read legacy COBOL, they cannot read the purpose. Several legacy COBOL systems have functions and logic that’s undocument and based on ‘workarounds’ that are probably 30 years old.</p><p>Currently, AI Agents are designed to handle multi-step transactions as “continuous workflows” without a transaction coordinator (TC) to manage estate transactions for each task in the chain. If the AI coding agent crashes mid-task, the entire chain breaks, and the consequences can be adverse and irreversible.</p><p>According to <a href=\"https://cloud.google.com/transform/ai-grew-up-and-got-a-job-lessons-from-2025-on-agents-and-trust\">Google Research</a>, this is only resolved when atomicity/granularity are emphasized as Agentic AI infrastructure requirements. Until then, there must be guardrails to undo Agentic actions and convert the entire multi-step process into reversible tasks.</p><ul><li>Human experts (not necessarily in COBOL) must remain part of this process to ensure thorough QA and validation.</li><li>Each COBOL modernization project is unique—the above is not a one-size-fits-all workflow.</li><li>The IT economy is still in the early (largely experimental) stages of Agentic AI—don’t trust AI coding agents blindly (not even GitHub Copilot).</li><li>100% automation and autonomy are at least half a decade away.</li></ul><p>The COBOL problem has persisted for years and is often viewed as a ticking time bomb, especially when you lack COBOL fluency. But with AI coding agents, you don’t need this level of fluency for COBOL modernization. These AI Agents can analyze outdated code, extract legacy logic, and rewrite it in any modern programming language of your choice.</p><p>Using AI agents for COBOL modernization will not only help you survive in the modern tech space but also help you reclaim decades of business intelligence, making it accessible to the newer generation of engineers who will manage your systems in the future. You can either integrate agents like GitHub Copilot or hire AI Agent developers to build custom agents for your modernization project.</p>",
      "contentLength": 7434,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "WOW Exchange Launches a New Trading Platform Addressing Key Challenges in Crypto Exchanges",
      "url": "https://hackernoon.com/wow-exchange-launches-a-new-trading-platform-addressing-key-challenges-in-crypto-exchanges?source=rss",
      "date": 1768772437,
      "author": "ZEX MEDIA",
      "guid": 36881,
      "unread": true,
      "content": "<article>WOW Exchange is a pre-launch crypto trading platform built to address transparency, security, and intelligence gaps through high-performance infrastructure and AI-driven analytics.</article>",
      "contentLength": 180,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "CI/CD Is Dead. Agentic DevOps is Taking Over",
      "url": "https://hackernoon.com/cicd-is-dead-agentic-devops-is-taking-over?source=rss",
      "date": 1768771441,
      "author": "David Iyanuoluwa Jonathan",
      "guid": 36880,
      "unread": true,
      "content": "<article>Traditional CI/CD pipelines are collapsing under tool sprawl, static logic, and coordination overhead. Agentic DevOps replaces brittle scripts with AI systems that adapt, automate toil, and reshape how software ships—at a cost.</article>",
      "contentLength": 229,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Android OS Architecture, Part 4: Understanding Processes, Memory, and Threads",
      "url": "https://hackernoon.com/android-os-architecture-part-4-understanding-processes-memory-and-threads?source=rss",
      "date": 1768770678,
      "author": "Richard Ebo",
      "guid": 36879,
      "unread": true,
      "content": "<article>This article explains how Android processes work, how they manage memory and threads, how components map to processes, and how the system monitors and terminates apps.</article>",
      "contentLength": 167,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Android OS Architecture, Part 3: Inside the Linux Kernel Layer",
      "url": "https://hackernoon.com/android-os-architecture-part-3-inside-the-linux-kernel-layer?source=rss",
      "date": 1768770672,
      "author": "Richard Ebo",
      "guid": 36878,
      "unread": true,
      "content": "<article>Android is built on the Linux kernel, which handles power management, hardware control, and secure communication between apps and system services. While most developers never touch it directly, understanding the kernel explains many core Android behaviors and system-level interactions.</article>",
      "contentLength": 286,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Hundreds Answer Europe's 'Public Call for Evidence' on an Open Digital Ecosystem Strategy",
      "url": "https://news.slashdot.org/story/26/01/18/2054259/hundreds-answer-europes-public-call-for-evidence-on-an-open-digital-ecosystem-strategy?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1768769820,
      "author": "EditorDavid",
      "guid": 36849,
      "unread": true,
      "content": "The European Commission \"has opened a public call for evidence on European open digital ecosystems,\" writes Help Net Security, part of preparations for an upcoming Communication \"that will examine the role of open source in EU's digital infrastructure.\"\n\nThe consultation runs from January 6 to February 3, 2026. Submissions will be used to shape a Commission Communication addressed to the European Parliament, the Council, and other EU bodies, which is scheduled for publication in the first quarter of 2026... The call for evidence links Europe's reliance on digital technologies developed outside the EU to concerns over long term control of infrastructure and software supply chains... Open digital ecosystems are discussed in the context of technological sovereignty and the use of technologies that can be inspected, adapted, and shared. \n\n\nLong-time Slashdot reader Elektroschock describes it as the European Commission \"stepping up its efforts behind open-source software\"\n\nBuilding on President von der Leyen's political guidelines, the initiative will review the Commission's 2020-2023 open-source approach and set out concrete actions to strengthen Europe's open-source ecosystem across key areas such as cloud, AI, cybersecurity and industrial technologies. The strategy will be presented alongside the upcoming Cloud and AI Development Act, forming a broader policy package aimed at reducing strategic dependencies and boosting Europe's digital resilience. \n\nAnd \"In just a few days, over 370 submissions have already been filed, indicating that the issue is touching a nerve across the EU,\" writes CyberNews.com:\n\n\"Europe must regain control over its software supply chain to safeguard freedom, security, and innovation,\" suggests an individual from Slovakia. Similar perspectives appear to be widely shared among respondents... \n\nThe document doesn't mention US tech giants specifically, but rather aims to support tech sovereignty and seek \"digital solutions that are valid alternatives to proprietary ones....\" \n\n\"This is not a legislative initiative. The strategy will take the form of a Commission communication. The initiative will set out a general approach and will propose: actions relying on further commitments and an implementation process,\" the EC explains. Policymakers expect the strategy to help EU member states identify the necessary steps to support national open-source companies and communities.",
      "contentLength": 2431,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "AI Workstations vs Data Centers: Can Local Compute Compete at Scale?",
      "url": "https://hackernoon.com/ai-workstations-vs-data-centers-can-local-compute-compete-at-scale?source=rss",
      "date": 1768768571,
      "author": "Ievgenii Markadanov",
      "guid": 36877,
      "unread": true,
      "content": "<article>AI workstations are becoming powerful enough to handle many local training and inference tasks, offering lower latency, better data control, and predictable costs. Data centers still win at massive scale, collaboration, and elasticity. The future isn’t either/or—it’s a hybrid model where local compute handles speed- and privacy-sensitive work, while data centers power large-scale training and global deployment.</article>",
      "contentLength": 420,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Chunking in RAG: The Key to Efficient, Accurate Retrieval",
      "url": "https://hackernoon.com/chunking-in-rag-the-key-to-efficient-accurate-retrieval?source=rss",
      "date": 1768767924,
      "author": "m-np",
      "guid": 36876,
      "unread": true,
      "content": "<article>Understand why chunking is essential when incorporating RAG into your Agentic workflows and why without it, RAG pipelines become slow, expensive, and unreliable.</article>",
      "contentLength": 161,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Donald Trump, Kate Middleton, and a Shark: The Rise of AI-Edited Images",
      "url": "https://hackernoon.com/donald-trump-kate-middleton-and-a-shark-the-rise-of-ai-edited-images?source=rss",
      "date": 1768767306,
      "author": "The Markup",
      "guid": 36875,
      "unread": true,
      "content": "<p>Sisi here, and we need to talk about Donald Trump, Kate Middleton, and one very specific shark.</p><p>\\\nLet’s just get right into it.</p><p>Earlier this month, the BBC <a href=\"https://www.bbc.com/news/world-us-canada-68440150\">broke the news</a> that Donald Trump supporters are using artificial intelligence to generate different photos of Trump and Black people as a way to appeal to Black voters.</p><p>\\\nA <a href=\"https://www.bbc.com/news/world-us-canada-68440150\">series</a> of <a href=\"https://www.theguardian.com/us-news/2024/mar/04/trump-ai-generated-images-black-voters\">news</a><a href=\"https://www.washingtonpost.com/politics/2024/03/06/what-fake-images-trump-with-black-voters-tell-us-about-ai-disinformation/\">outlets</a> wrote about the photos, and gave them a unique treatment that I’ve only seen emerge in the year or so since AI-generated images became easy to create.</p><ol><li><p>The BBC published the images, but superimposed a red bar across the photo and added a red “FALSE” label, alongside a warning symbol.</p></li><li><p>The Guardian took a similar approach, labeling the image as “FAKE” and putting the label right in the middle of the photo.</p></li><li><p>The Washington Post went one step further, labeling it as a “AI-GENERATED FAKE PHOTO.”</p></li></ol><p>Credit: BBC, The Guardian, The Washington Post</p><p>\\\nSome outlets, like the <a href=\"https://apnews.com/article/deepfake-trump-ai-biden-tiktok-72194f59823037391b3888a1720ba7c2\">Associated Press</a> and the <a href=\"https://www.latimes.com/world-nation/story/2024-03-08/fake-images-made-to-show-trump-with-black-supporters-highlight-concerns-around-ai-and-elections\">Los Angeles Times</a>, published articles about the AI-generated Trump images but didn’t republish the images themselves. The AP’s <a href=\"https://blog.ap.org/standards-around-generative-ai\">generative AI policy</a> says, “We will refrain from transmitting any AI-generated images that are suspected or proven to be false depictions of reality. However, if an AI-generated illustration or work of art is the subject of a news story, it may be used as long as it [is] clearly labeled as such in the caption.” Other outlets, like the <a href=\"https://nypost.com/2024/03/05/us-news/trump-supporters-create-and-share-ai-photos-of-him-with-black-voters/\">New York Post</a>, did the opposite, publishing the images with no labels and using the regular caption to tell readers the photo was AI-generated.</p><p>\\\nSeeing newsrooms republish these images, even with big red labels, caused a small stir at The Markup. We dove into a discussion about whether these labels were good enough, and if the photos should have been republished in the first place.</p><p>\\\nMy first reaction after looking at the <a href=\"https://www.bbc.com/news/world-us-canada-68440150\">BBC</a> and <a href=\"https://www.theguardian.com/us-news/2024/mar/04/trump-ai-generated-images-black-voters\">Guardian</a> examples was confusion. What does “FALSE” and “FAKE” mean? Did someone photoshop Donald Trump into a real picture? Are all the smiles fake? What, exactly, is false?</p><p>\\\nI spent a good period of my career designing and coding interactive graphics, and when I taught students how to fact-check their visual work, I asked them one main question: If someone glanced at your work for one, maybe two seconds, what impression would they walk away with?</p><p>\\\nAs a journalist, if the answer to that question is anything other than what you intended, you’re not done. The rule applies to anything from a simple chart to a label on a photo.</p><p>\\\nIn the three examples above, <a href=\"https://www.washingtonpost.com/politics/2024/03/06/what-fake-images-trump-with-black-voters-tell-us-about-ai-disinformation/\">The Washington Post</a> adds in the only label that would tell me one more piece of information: that the image is generated by AI.</p><p>\\\nBut is that enough? As some of our journalists pointed out, the image isn’t totally “fake,” at least not in the traditional sense. Yes, the images are not depicting a real event that took place. But let’s say someone made a photorealistic painting of this exact image. We wouldn’t call that “fake.”</p><p>\\\nThe image  a fake in the very important way that it appears to have been made specifically to deceive whoever sees it into believing something happened that never did. So while it is not wrong, exactly, to label the image “fake,” only the Washington Post really nailed it by saying it’s both fake and made by AI.</p><p>\\\nMore conventional fake images have existed for a long time, of course, and have not received this type of red label treatment from journalists.</p><p>\\\nSpeaking of those, let’s talk about the Kate Middleton photo.</p><p>Yesterday’s news that Kate Middleton <a href=\"https://www.instagram.com/p/C402JKPtLVB/?hl=en\">has cancer</a> put an end to the firestorm of intrigue and speculation that started earlier this month when the official Instagram account of The Prince and Princess of Wales posted a family photo that people quickly noticed was digitally altered.</p><p>\\\nThe Associated Press published the photo, but once the organization found out it had been manipulated, the AP <a href=\"https://apnews.com/article/princess-wales-kate-surgery-photo-manipulated-3863e9ac78aec420a91e4f315297c348\">retracted the image</a> and told all their clients to do the same. Meanwhile, Instagram <a href=\"https://www.instagram.com/p/C4U_IqTNaqU/\">labeled the image</a> as an “Altered photo/video,” and users could only see the photo if they clicked past a blur filter. Many news organizations like the <a href=\"https://www.bbc.com/news/uk-68534289\">BBC</a>, <a href=\"https://www.vox.com/culture/24098724/kate-middleton-editing-photo-explained\">Vox</a>, and <a href=\"https://www.nytimes.com/2024/03/11/world/europe/princess-kate-middleton-photo-edit-apology.html\">The New York Times</a> published the photo, but only alongside their own annotations of where it looked to be edited.</p><p>I asked our visual designer, Gabe Hongsdusit, who created <a href=\"https://themarkup.org/2023/09/14/zine-how-we-illustrate-tech-and-ai-at-the-markup\">our zine</a> on how The Markup illustrates technology and AI and commissions nearly all our photography, if he thought news organizations should be republishing AI-generated or human-altered images when they report on them. He said yes: “It’s important to see the photo along with the clear label or annotation that it’s AI-generated so that we can help readers build the act of looking/discerning as a skill. They need to be able to see the actual image in order to do that.”</p><p>\\\nGabe said that since the technology to doctor photos is so readily available, people’s “skill of discernment” is needed more than ever. He then pointed me to illustrator Julien Posture, who <a href=\"https://julienposture.substack.com/p/image-event-kate-middletons-photo\">wrote eloquently about</a> the Kate photo, and how this is just the beginning of what’s to come:</p><blockquote><p>Something that I would pompously call a new ‘culture of visual inquiry’ is emerging. The very little visual literacy that used to be enough to navigate our mediascape is nowadays completely obsolete. The overwhelming quantity of deceitful content online has fostered a need for different, skeptical ways of seeing.</p></blockquote><p>\\\nThere’s no question to me that anyone who comes into contact with the internet these days will need to start questioning if the images they’re seeing are real. But what’s our job as journalists in this situation? When we republish viral or newsworthy images that have been altered or were generated by AI, what should we do to make sure we’re giving readers the information they need? Doing it in the caption or the headline isn’t good enough—we can’t assume that readers will read them.</p><p>\\\nOne reason this photo, out of all the photos that have been altered, became such a big deal is because of all the rumors and conspiracy theories about Kate that preceded it. But people have been altering photos for a very long time. In fact, we’re all pretty used to magazines editing photos of celebrities to be thinner, poreless, or more “attractive” in some way, often <a href=\"https://www.cosmopolitan.com/entertainment/news/a56561/celebrities-respond-retouching-magazine-covers-criticism/\">without their knowledge or consent</a>. So why isn’t there a big “ALTERED PHOTO” label on those images whenever we see them published by a news outlet? Or a “FAKE” or “FALSE” label? Why don’t celebrity photoshoots come with a giant “BEAUTY FILTER ON” label?</p><p>You may have seen this shark before … because every time there’s a water-based natural disaster, this shark likes to show up.</p><p>If you have yet to fall for one of the many photoshopped versions of this shark showing up during in a <a href=\"https://ca.news.yahoo.com/blogs/daily-buzz/sharks-flooded-union-station-image-goes-viral-kuwait-204251203.html\">flooded train station</a> (or the Kuwait Scientific Center), in the <a href=\"https://mashable.com/archive/fake-hurricane-sandy-photos\">streets</a> of New Jersey (or the <a href=\"https://www.snopes.com/fact-check/shark-street-hurricane/\">streets</a> of Puerto Rico), or <a href=\"https://www.washingtonpost.com/blogs/blogpost/post/hurricane-irene-photo-of-shark-swimming-in-street-is-fake/2011/08/26/gIQABHAvfJ_blog.html\">after</a> Hurricane Irene, then can call yourself lucky, because I fell for a photo of this shark swimming in New York City streets during Hurricane Sandy. That photo looked identical to the New Jersey, Puerto Rico, and Hurricane Irene photos above.</p><p>\\\nThese photos are clearly fake. But why did no one put a big red label with the word “FAKE” on top of the photos back in the early 2010s when they were first circulated and multiple sites were debunking the images?</p><p>\\\nWhat exactly is it about AI-generated images that has spurred journalism to label misrepresentation in photos more clearly? And now that we’ve started to do it more obviously, shouldn’t we be doing it everywhere images are fake? Not just for AI?</p><p>\\\nThese examples prove that there is no industry standard yet—we are, in fact, all still figuring it out. The AP’s stance could very well be the right one we should all adopt. At The Markup, we have a very similar policy: “If we publish imagery generated by AI because that is the point of the story, we will clearly label what art has been generated by AI.”</p><p>\\\nBut in both the AP’s policy and our policy, it’s now clear to me that using “clearly label” as the standard is right, but it’s also too vague. It is our responsibility as journalists to make it obvious to you, our readers, what is going on in an image within the first one to two seconds of you seeing it. Our labels cannot rely on the peripherals: the captions, the headlines, even the surrounding article itself. Our labels cannot cause confusion. Our labels need to be crystal clear and in your face—because the AI and the fakers certainly are.</p><h3>Illustration and Graphics</h3>",
      "contentLength": 8583,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "ReactOS For \"Open-Source Windows\" Achieves Massive Networking Performance Boost",
      "url": "https://www.phoronix.com/news/ReactOS-Async-Net-Connect",
      "date": 1768766961,
      "author": "Michael Larabel",
      "guid": 36852,
      "unread": true,
      "content": "<article>ReactOS as the long-in-development \"open-source Windows\" project has been on quite a roll recently. Beyond a big Windows NT 6 compatibility improvement and fixing a very annoying usability issue, for this third week of the year there is another big change landing: a significant improvement in networking performance on ReactOS...</article>",
      "contentLength": 330,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "ATS for Hiring: Fixing Old Problems or Creating New Ones?",
      "url": "https://hackernoon.com/ats-for-hiring-fixing-old-problems-or-creating-new-ones?source=rss",
      "date": 1768766790,
      "author": "Ievgenii Markadanov",
      "guid": 36874,
      "unread": true,
      "content": "<article>Applicant tracking systems streamline hiring and reduce manual work, but their reliance on automation and AI risks reinforcing bias unless balanced with human oversight.</article>",
      "contentLength": 169,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Funniest/Most Insightful Comments Of The Week At Techdirt",
      "url": "https://www.techdirt.com/2026/01/18/funniest-most-insightful-comments-of-the-week-at-techdirt-192/",
      "date": 1768766400,
      "author": "Leigh Beadon",
      "guid": 36843,
      "unread": true,
      "content": "<p>This week, both our winners on the insightful side come in response to Tom Homan’s complaints about people calling ICE murderers. In first place, it’s <a href=\"https://www.techdirt.com/user/bloof/\">Bloof</a> with <a href=\"https://www.techdirt.com/2026/01/12/tom-homan-if-democrats-dont-stop-calling-us-murderers-were-just-going-to-be-forced-to-keep-murdering-you/#comment-4986403\">a translation of his words</a>:</p><blockquote><p><em>‘People need to be civil and helpful when masked thugs come for their friends and neighbours, and to just follow orders like good citizens. Don’t worry when they come for the communists, socialists, trade unionists and jews, there’ll be plenty of others on the list before you, honest.’</em></p></blockquote><blockquote><p><strong><em>You can hear the fear in Homan’s voice</em></strong></p><p><em>Can’t you? Can’t everyone? Isn’t it obvious?</em></p><p><em>These people are terrified of their fellow citizens — because some of them happen to be brown or black or women or LGBTQ or pretty much anything. They’re shaking with fear; they’re cowards — to the bone. Which is of course why they mask their faces and wear body armor and carry lots of weapons: .</em></p><p><em>So remember: when you see them, mock them. Insult them. Degrade them. Humiliate them. Because they deserve it.</em></p></blockquote><blockquote><p><em>Indeed. These people think respect comes with the job because they’re authoritarians trained to think authority is always legitimate so you should always respect the people above you. Just like they think being a white man automatically makes you the most qualified for every good job, so DEI hiring means you can’t be getting the best people. Because that’s actually the big joke of this: If they don’t like someone above them, they not only don’t get respect but are considered to have the job illegitimately.</em></p><p><em>The idea of earning respect seems impossible to them because they think fear and respect are the same things and not opposites. I’ve had several righties say this despite my best attempts to explain the difference. They were taught to fear authority and call it respect; then wonder why the people under them don’t like them. So much of what we see are emotionally repressed victims still traumatized by their mean parents and dumping that trauma on others. They were forced to fake maturity at a young age and never really grew up.</em></p><p><em>And yeah, Trump has been craving respect his whole life because his success is unearned and anyone with taste or brains knew he was a clown. Yet those are the people he wanted praise from and he loathes people who are submissive to him like MAGA because he doesn’t want to be the member of any club that would have a creep like him. He thought being called Mr. President would finally give him the admiration he needs and instead he just gets his handlers coddling him and telling him that all dissent is manufactured and his approval ratings are 1,600%. Sad!</em></p></blockquote><blockquote><p><em>If you don’t want to be called a murderer then stop your agents from fucking murdering my neighbors.</em></p></blockquote><blockquote><p><em>“No, it’s the children who are wrong.”</em></p></blockquote><blockquote><p><em>I think this is a little unfair. Trump’s presidency  actually been the most transparent administration ever. Case in point, the Epstein files proved this when it was revealed that ███████ ████ █████ █████████ ██████ ██████ and ██████ █████████ █████████ █████ ██████ ███████.</em></p><p><em>I mean, the ███████ alone should be all the ██████ evidence you need.</em></p><p><em>Also, anyone who disagrees will be summarily ██████ ███ ██████ ██████.</em></p></blockquote><blockquote><p><em>You just don’t know what it’s like to walk the streets as an ICE agent. The person you’re walking by could pull out A PHONE and aim it at you. Some of these phones have FULLY AUTOMATIC recording with UNLIMITED DATA STREAMING plans.</em></p><p><em>And we’re not even talking about people in shadowy windows with zoom lenses. Last week I heard about an agent who was just minding their business, kicking in some 110 pound teenager’s head, when he saw the glint of a 700mm f/8 Canon aimed at him. Never saw the shot coming.</em></p><p><em>Dude had a wife and kids.</em></p><p><em>I mean, he still does. But he did, too.</em></p></blockquote><blockquote><p><em>Netflix is too woke? Sounds like it’s time for another Dave Chappelle special!</em></p></blockquote><p>That’s all for this week, folks!</p>",
      "contentLength": 4090,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Build a Vector Search Engine in Python with FAISS and Sentence Transformers",
      "url": "https://hackernoon.com/build-a-vector-search-engine-in-python-with-faiss-and-sentence-transformers?source=rss",
      "date": 1768765977,
      "author": "Surya Bhaskar Reddy Karri",
      "guid": 36873,
      "unread": true,
      "content": "<article>This tutorial walks through building a semantic vector search engine from scratch using Python, Sentence Transformers, and FAISS. You’ll learn how embeddings work, how similarity search is performed, and how modern AI systems retrieve relevant information at scale. By the end, you’ll have a working vector search engine and a deep understanding of the infrastructure behind LLM-powered applications, RAG systems, and semantic search.</article>",
      "contentLength": 438,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Why Developers Aren’t Really Ditching Frameworks for Vanilla JavaScript",
      "url": "https://hackernoon.com/why-developers-arent-really-ditching-frameworks-for-vanilla-javascript?source=rss",
      "date": 1768765353,
      "author": "Omotayo",
      "guid": 36872,
      "unread": true,
      "content": "<article>Framework fatigue has sparked renewed interest in Vanilla JavaScript and no-build setups, but frameworks still solve real architectural, performance, and security problems. Unbundled native ES modules shift critical safeguards from build time to runtime, expanding trust boundaries, weakening integrity guarantees, and reducing observability unless teams apply equivalent discipline. The real choice isn’t frameworks versus Vanilla JS—it’s using each intentionally, with security and maintainability treated as first-class concerns.</article>",
      "contentLength": 538,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Microsoft Forced to Issue Emergency Out-of-Band Windows Update",
      "url": "https://tech.slashdot.org/story/26/01/18/1932246/microsoft-forced-to-issue-emergency-out-of-band-windows-update?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1768764840,
      "author": "EditorDavid",
      "guid": 36836,
      "unread": true,
      "content": "The senior editor at the blog Windows Central decries two serious Windows issues \"that were not spotted by Microsoft during testing, and are so severe that the company has now issued an emergency fix to address the problems.\"\n\n\nMicrosoft's first update for Windows 11 in 2026 has already caused two major issues that saw users unable to fully shutdown their PCs or sign-in into a device when using Remote Desktop... Being unable to shut down your PC due to a recent OS update is a huge oversight on Microsoft's part, but this is the latest in a long list of updates over the last year to cause a major issue like this... Other issues that have cropped up in Windows 11 in the last year include a bug that caused Task Manager to fail to close when the user exited the application, causing system resources to lock up after a prolonged period of time if the user had opened and closed Task Manager multiple times in a session.\nAnother update caused saw File Explorer flashbang users with a white screen when opening it in dark mode, which appeared in an update that was supposed to improve dark mode on Windows 11... \n\nFor whatever reason, the Windows Insider Program doesn't appear to be working anymore, as severe bugs are somehow making it into shipping versions of the OS. \n\n\"The out of band updates, KB5077744 and KB5077797, are available now via Windows Update and is rolling out to everybody,\" they write. \"Once installed, your PC should go back to being able to shut down successfully, and signing-in via Remote Desktop should work again.\" \n\nMicrosoft has also officially acknowledged a third bug which crashes Outlook Classic when using POP accounts, according to the blog Windows Latest, which adds that that bug has not yet been fixed. \n\nThey've also identified other minor bugs, including \"a black screen problem in Windows 11 KB5074109... either due to the update itself or some compatibility issues with GPU drivers.\"\n\n\nAfter you install the January 2026 Update, Windows triggers random black screens where the desktop freezes for a second or two, the display goes black, then everything comes back. I can't pinpoint any specific configuration, but I can confirm the black screen issue has been observed on a small subset of PCs with both Nvidia and AMD GPUs. After you install the January 2026 Update, Windows triggers random black screens where the desktop freezes for a second or two, the display goes black, then everything comes back.",
      "contentLength": 2451,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "SSH Explained: Keys, Tunnels, Jump Hosts, and Why They Matter",
      "url": "https://hackernoon.com/ssh-explained-keys-tunnels-jump-hosts-and-why-they-matter?source=rss",
      "date": 1768764818,
      "author": "Shridivya Sharma",
      "guid": 36871,
      "unread": true,
      "content": "<article>SSH isn’t just a login tool—it’s a secure, encrypted channel that enables safe access to servers, databases, and internal services without exposing infrastructure to the internet.</article>",
      "contentLength": 185,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Your UI Automation Is Flaky Because You’re Waiting Wrong (Here’s the Fix in .NET Playwright)",
      "url": "https://hackernoon.com/your-ui-automation-is-flaky-because-youre-waiting-wrong-heres-the-fix-in-net-playwright?source=rss",
      "date": 1768759199,
      "author": "Mukhtar Abdussalam",
      "guid": 36870,
      "unread": true,
      "content": "<article>Playwright is a tool for automating web applications. It can be used to help you fix mistakes in your web apps. The most common cause of flakiness is that we wait for time, not state.</article>",
      "contentLength": 183,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Linux 6.19 Landing Fixes For USB2/USB3 Issues With Apple M1/M2 Macs",
      "url": "https://www.phoronix.com/news/Linux-6.19-Apple-Mac-USB2-Fixes",
      "date": 1768758007,
      "author": "Michael Larabel",
      "guid": 36823,
      "unread": true,
      "content": "<article>Ahead of the Linux 6.19-rc6 kernel release due out later today are two USB fixes for Apple M1 / M2 Macs running the mainline kernel. These Apple USB fixes are also marked for back-porting to the stable Linux kernel series...</article>",
      "contentLength": 224,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Astronomers Finally Explain How Molecules From Earth's Atmosphere Keep Winding Up On the Moon",
      "url": "https://science.slashdot.org/story/26/01/17/0525200/astronomers-finally-explain-how-molecules-from-earths-atmosphere-keep-winding-up-on-the-moon?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1768757640,
      "author": "EditorDavid",
      "guid": 36819,
      "unread": true,
      "content": "An anonymous reader shared this report from CNN:\n\n\nParticles from Earth's atmosphere have been carried into space by solar wind and have been landing on the moon for billions of years, mixing into the lunar soil, according to a new study [published in the journal Nature Communications Earth &amp; Environment last month]. The research sheds new light on a puzzle that has endured for over half a century since the Apollo missions brought back lunar samples with traces of substances such as water, carbon dioxide, helium and nitrogen embedded in the regolith — the moon's dusty surface layer. \n\n\nEarly studies theorized that the sun was the source of some of these substances. But in 2005 researchers at the University of Tokyo suggested that they could have also originated from the atmosphere of a young Earth before it developed a magnetic field about 3.7 billion years ago. The authors suspected that the magnetic field, once in place, would have stopped the stream by trapping the particles and making it difficult or impossible for them to escape into space. Now, the new research upends that assumption by suggesting that Earth's magnetic field might have helped, rather than blocked, the transfer of atmospheric particles to the moon — which continues to this day. \n\n\"This means that the Earth has been supplying volatile gases like oxygen and nitrogen to the lunar soil over all this time,\" said Eric Blackman, coauthor of the new study and a professor in the department of physics and astronomy at the University of Rochester in New York.\n\n \n\nEarth's magnetic field \"somewhat inflates the atmosphere of Earth\" when it's hit by solar winds, according to study coauthor Eric Blackman, a physics/astronomy professor at New York's University of Rochester. He told CNN the moon passes through this region for a few days each month, with particles landing on the lunar surface and embedding in the soil (because the moon lacks an atmosphere that would block them). \n\nThis also means the moon's soil could actually contain a chemical record of Earth's ancient atmosphere, according to the study — \"spanning billions of years...\"",
      "contentLength": 2134,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "TechCrunch Mobility: ‘Physical AI’ enters the hype machine",
      "url": "https://techcrunch.com/2026/01/18/techcrunch-mobility-physical-ai-enters-the-hype-machine/",
      "date": 1768755900,
      "author": "Kirsten Korosec",
      "guid": 36858,
      "unread": true,
      "content": "<article>Welcome back to TechCrunch Mobility, your hub for all things “future of transportation.”&nbsp;</article>",
      "contentLength": 94,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Container-aware GOMAXPROCS: What it is and Why It's Important",
      "url": "https://hackernoon.com/container-aware-gomaxprocs-what-it-is-and-why-its-important?source=rss",
      "date": 1768755606,
      "author": "Go [Technical Documentation]",
      "guid": 36833,
      "unread": true,
      "content": "<p>Go 1.25 includes new container-aware  defaults, providing more sensible default behavior for many container workloads, avoiding throttling that can impact tail latency, and improving Go’s out-of-the-box production-readiness. In this post, we will dive into how Go schedules goroutines, how that scheduling interacts with container-level CPU controls, and how Go can perform better with awareness of container CPU controls.</p><p>One of Go’s strengths is its built-in and easy-to-use concurrency via goroutines. From a semantic perspective, goroutines appear very similar to operating system threads, enabling us to write simple, blocking code. On the other hand, goroutines are more lightweight than operating system threads, making it much cheaper to create and destroy them on the fly.</p><p>\\\nWhile a Go implementation could map each goroutine to a dedicated operating system thread, Go keeps goroutines lightweight with a runtime scheduler that makes threads fungible. Any Go-managed thread can run any goroutine, so creating a new goroutine doesn’t require creating a new thread, and waking a goroutine doesn’t necessarily require waking another thread.</p><p>\\\nThat said, along with a scheduler comes scheduling questions. For example, exactly how many threads should we use to run goroutines? If 1,000 goroutines are runnable, should we schedule them on 1,000 different threads?</p><p>\\\nThis is where  comes in. Semantically,  tells the Go runtime the “available parallelism” that Go should use. In more concrete terms,  is the maximum number of threads to use for running goroutines at once.</p><p>\\\nSo, if  and there are 1,000 runnable goroutines, Go will use 8 threads to run 8 goroutines at a time. Often, goroutines run for a very short time and then block, at which point Go will switch to running another goroutine on that same thread. Go will also preempt goroutines that don’t block on their own, ensuring all goroutines get a chance to run.</p><p>\\\nFrom Go 1.5 through Go 1.24,  defaulted to the total number of CPU cores on the machine. Note that in this post, “core” more precisely means “logical CPU.” For example, a machine with 4 physical CPUs with hyperthreading has 8 logical CPUs.</p><p>\\\nThis typically makes a good default for “available parallelism” because it naturally matches the available parallelism of the hardware. That is, if there are 8 cores and Go runs more than 8 threads at a time, the operating system will have to multiplex these threads onto the 8 cores, much like how Go multiplexes goroutines onto threads. This extra layer of scheduling is not always a problem, but it is unnecessary overhead.</p><p>Another of Go’s core strengths is the convenience of deploying applications via a container, and managing the number of cores Go uses is especially important when deploying an application within a container orchestration platform. Container orchestration platforms like <a href=\"https://kubernetes.io/\">Kubernetes</a> take a set of machine resources and schedule containers within the available resources based on requested resources. </p><p>\\\nPacking as many containers as possible within a cluster’s resources requires the platform to be able to predict the resource usage of each scheduled container. We want Go to adhere to the resource utilization constraints that the container orchestration platform sets.</p><p>\\\nLet’s explore the effects of the  setting in the context of Kubernetes, as an example. Platforms like Kubernetes provide a mechanism to limit the resources consumed by a container. Kubernetes has the concept of CPU resource limits, which signal to the underlying operating system how many core resources a specific container or set of containers will be allocated. Setting a CPU limit translates to the creation of a Linux <a href=\"https://docs.kernel.org/admin-guide/cgroup-v2.html#cpu\">control group</a> CPU bandwidth limit.</p><p>\\\nBefore Go 1.25, Go was unaware of CPU limits set by orchestration platforms. Instead, it would set  to the number of cores on the machine it was deployed to. If there was a CPU limit in place, the application may try to use far more CPU than allowed by the limit. To prevent an application from exceeding its limit, the Linux kernel will <a href=\"https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#how-pods-with-resource-limits-are-run\">throttle</a> the application.</p><p>\\\nThrottling is a blunt mechanism for restricting containers that would otherwise exceed their CPU limit: it completely pauses application execution for the remainder of the throttling period. The throttling period is typically 100ms, so throttling can cause substantial tail latency impact compared to the softer scheduling multiplexing effects of a lower  setting. Even if the application never has much parallelism, tasks performed by the Go runtime—such as garbage collection—can still cause CPU spikes that trigger throttling.</p><p>We want Go to provide efficient and reliable defaults when possible, so in Go 1.25, we have made  take into account its container environment by default. If a Go process is running inside a container with a CPU limit,  will default to the CPU limit if it is less than the core count.</p><p>\\\nContainer orchestration systems may adjust container CPU limits on the fly, so Go 1.25 will also periodically check the CPU limit and adjust  automatically if it changes.</p><p>\\\nBoth of these defaults only apply if  is otherwise unspecified. Setting the  environment variable or calling  continues to behave as before. The  documentation covers the details of the new behavior.</p><h2>Slightly different models</h2><p>Both  and a container CPU limit place a limit on the maximum amount of CPU the process can use, but their models are subtly different.</p><p>\\\n is a parallelism limit. If  Go will never run more than 8 goroutines at a time.</p><p>\\\nBy contrast, CPU limits are a throughput limit. That is, they limit the total CPU time used in some period of wall time. The default period is 100ms. So an “8 CPU limit” is actually a limit of 800ms of CPU time every 100ms of wall time.</p><p>\\\nThis limit could be filled by running 8 threads continuously for the entire 100ms, which is equivalent to . On the other hand, the limit could also be filled by running 16 threads for 50ms each, with each thread being idle or blocked for the other 50ms.</p><p>\\\nIn other words, a CPU limit doesn’t limit the total number of CPUs the container can run on. It only limits total CPU time.</p><p>\\\nMost applications have fairly consistent CPU usage across 100ms periods, so the new  default is a pretty good match to the CPU limit, and certainly better than the total core count! However, it is worth noting that particularly spiky workloads may see a latency increase from this change due to  preventing short-lived spikes of additional threads beyond the CPU limit average.</p><p>\\\nIn addition, since CPU limits are a throughput limit, they can have a fractional component (e.g., 2.5 CPU). On the other hand,  must be a positive integer. Thus, Go must round the limit to a valid  value. Go always rounds up to enable use of the full CPU limit.</p><p>Go’s new  default is based on the container’s CPU limit, but container orchestration systems also provide a “CPU request” control. While the CPU limit specifies the maximum CPU a container may use, the CPU request specifies the minimum CPU guaranteed to be available to the container at all times.</p><p>\\\nIt is common to create containers with a CPU request but no CPU limit, as this allows containers to utilize machine CPU resources beyond the CPU request that would otherwise be idle due to lack of load from other containers. Unfortunately, this means that Go cannot set  based on the CPU request, which would prevent utilization of additional idle resources.</p><p>\\\nContainers with a CPU request are still <a href=\"https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#how-pods-with-resource-limits-are-run\">constrained</a> when exceeding their request if the machine is busy. The weight-based constraint of exceeding requests is “softer” than the hard period-based throttling of CPU limits, but CPU spikes from high  can still have an adverse impact on application behavior.</p><h2>Should I set a CPU limit?</h2><p>We have learned about the problems caused by having  too high, and that setting a container CPU limit allows Go to automatically set an appropriate , so an obvious next step is to wonder whether all containers should set a CPU limit.</p><p>\\\nWhile that may be good advice to automatically get a reasonable  defaults, there are many other factors to consider when deciding whether to set a CPU limit, such as prioritizing utilization of idle resources by avoiding limits vs prioritizing predictable latency by setting limits.</p><p>\\\nThe worst behaviors from a mismatch between  and effective CPU limits occur when  is significantly higher than the effective CPU limit. For example, a small container receiving 2 CPUs running on a 128 core machine. These are the cases where it is most valuable to consider setting an explicit CPU limit, or, alternatively, explicitly setting .</p><p>Go 1.25 provides more sensible default behavior for many container workloads by setting  based on container CPU limits. Doing so avoids throttling that can impact tail latency, improves efficiency, and generally tries to ensure Go is production-ready out-of-the-box. You can get the new defaults simply by setting the Go version to 1.25.0 or higher in your .</p><p>\\\nThanks to everyone in the community that contributed to the <a href=\"https://go.dev/issue/33803\">long</a><a href=\"https://go.dev/issue/73193\">discussions</a> that made this a reality, and in particular to feedback from the maintainers of  from Uber, which has long provided similar behavior to its users.</p><p><em>Michael Pratt and Carlos Amedee</em></p><p>\\\n<em>This article is available on&nbsp;&nbsp;under a CC BY 4.0 DEED license.</em></p>",
      "contentLength": 9352,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Threads edges out X in daily mobile users, new data shows",
      "url": "https://techcrunch.com/2026/01/18/threads-edges-out-x-in-daily-mobile-users-new-data-shows/",
      "date": 1768755600,
      "author": "Sarah Perez",
      "guid": 36857,
      "unread": true,
      "content": "<article>Threads’ daily mobile usage has quietly surpassed X as Meta leans on cross-promotion, creator tools and fast feature rollouts — even as X faces fresh controversies</article>",
      "contentLength": 167,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Acer Sues Verizon, AT&amp;T, and T-Mobile, Alleging Infringment on Acer's Cellular Networking Patents",
      "url": "https://yro.slashdot.org/story/26/01/18/006222/acer-sues-verizon-att-and-t-mobile-alleging-infringment-on-acers-cellular-networking-patents?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1768754040,
      "author": "EditorDavid",
      "guid": 36812,
      "unread": true,
      "content": "Slashdot reader BrianFagioli writes: Acer has filed three separate patent infringement lawsuits against AT&amp;T, Verizon, and T-Mobile, taking the unusual step of hauling the nation's largest wireless carriers into federal court. The suits, filed in the Eastern District of Texas, claim the companies are using Acer-developed cellular networking technology without paying for the privilege. Acer says it tried to negotiate licenses for years but reached a dead end, arguing it was left with no option except litigation. The case centers on six U.S. patents Acer asserts are core to modern wireless networks, rather than anything tied to PCs or laptops. The company describes itself as reluctant to pursue courtroom battles, but it has been quietly building a large global patent portfolio after pouring hundreds of millions of dollars into R&amp;D. Acer also notes that some of its patents count as standard-essential, hinting the carriers may be required to license them. All three companies are expected to push back, and the dispute could become another long-running telecom patent saga. Consumers will not notice any immediate changes, but if Acer wins or settles, it may find a new revenue stream far beyond its traditional hardware business. \n\nFurther coverage from Hot Hardware",
      "contentLength": 1277,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "How YC-backed Bucket Robotics survived its first CES",
      "url": "https://techcrunch.com/2026/01/18/how-yc-backed-bucket-robotics-survived-its-first-ces/",
      "date": 1768752600,
      "author": "Sean O'Kane",
      "guid": 36856,
      "unread": true,
      "content": "<article>Now, the startup is turning its attention to building the business, fundraising and striking commercial deals. </article>",
      "contentLength": 111,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "The HackerNoon Newsletter: The Seven Pillars of a Production-Grade Agent Architecture (1/18/2026)",
      "url": "https://hackernoon.com/1-18-2026-newsletter?source=rss",
      "date": 1768752165,
      "author": "Noonification",
      "guid": 36832,
      "unread": true,
      "content": "<p>🪐 What’s happening in tech today, January 18, 2026?</p><p>By <a href=\"https://hackernoon.com/u/denisp\">@denisp</a> [ 23 Min read ] Success isnt building the agent; its managing it. From AgentOps to ROI dashboards, here is the operational playbook for scaling Enterprise AI. <a href=\"https://hackernoon.com/governing-and-scaling-ai-agents-operational-excellence-and-the-road-ahead\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/denisp\">@denisp</a> [ 12 Min read ] An AI agent without memory is just a script. An agent without guardrails is a liability. The 7 critical pillars of building production-grade Agentic AI. <a href=\"https://hackernoon.com/the-seven-pillars-of-a-production-grade-agent-architecture\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/denisp\">@denisp</a> [ 17 Min read ] Avoid the AI Slop trap. From runaway costs to memory poisoning, here are the 7 most common failure modes of Agentic AI (and how to fix them). <a href=\"https://hackernoon.com/patterns-that-work-and-pitfalls-to-avoid-in-ai-agent-deployment\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/chris127\">@chris127</a> [ 10 Min read ] The question isnt whether jobs will disappear—its whether our traditional work model is still valid. <a href=\"https://hackernoon.com/should-we-be-worried-about-losing-jobs-or-just-adapt-our-civilization-to-new-reality\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/drechimyn\">@drechimyn</a> [ 7 Min read ] Broken Object Level Authorization (BOLA) is eating the API economy from the inside out.  <a href=\"https://hackernoon.com/the-authorization-gap-no-one-wants-to-talk-about-why-your-api-is-probably-leaking-right-now\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/kilocode\">@kilocode</a> [ 6 Min read ] CodeRabbit alternative for 2026: Kilos Code Reviews combines AI code review with coding agents, deploy tools, and 500+ models in one unified platform. <a href=\"https://hackernoon.com/coderabbit-vs-code-reviews-in-kilo-which-one-is-best-for-you-in-2026\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/ipinfo\">@ipinfo</a> [ 7 Min read ] IPv6 breaks digital ad measurement. Learn how IPinfo’s research-driven, active-measurement model restores accuracy across CTV and all channels. <a href=\"https://hackernoon.com/ipv6-and-ctv-the-measurement-challenge-from-the-fastest-growing-ad-channel\">Read More.</a></p><p>🧑‍💻 What happened in your world this week?</p><p>We hope you enjoy this worth of free reading material. Feel free to forward this email to a nerdy friend who'll love you for it.See you on Planet Internet! With love, \n The HackerNoon Team ✌️</p>",
      "contentLength": 1491,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "A Deep Dive Into SeaTunnel Metadata Caching",
      "url": "https://hackernoon.com/a-deep-dive-into-seatunnel-metadata-caching?source=rss",
      "date": 1768752012,
      "author": "William Guo",
      "guid": 36831,
      "unread": true,
      "content": "<p>In the field of data integration, when facing thousands of synchronization tasks, the performance bottleneck often lies not in the data transmission itself, but in \"metadata management.\" Classloader conflicts, Checkpoint pressure, and frequent database metadata requests are the \"three mountains\" that crush clusters. As a next-generation integration engine, SeaTunnel Zeta delivers a highly reliable and high-performance answer through a sophisticated metadata caching mechanism.</p><p>\\\nThis mechanism solves the performance bottlenecks of traditional data tools in classloading, state management, and metadata processing through three dimensions: intelligent caching, distributed storage, and automated management.</p><h2>Caching Mechanism Detailed</h2><h3>1. Memory Strategy for Classloader Reuse</h3><p>In traditional distributed engines, each job usually creates an independent classloader. When the task volume reaches thousands or tens of thousands, the Metaspace quickly fills up because it loads a large number of duplicate connector Jar packages, eventually leading to OOM (Out of Memory) crashes.</p><p>\\\nSeaTunnel's classloader caching mechanism implements a clever \"shared memory\" solution through&nbsp;<code>DefaultClassLoaderService</code>. Identifying the fingerprint of a Connector's Jar package, it allows different jobs using the same connector to share the same ClassLoader instance.</p><p><strong>Core Implementation Principles</strong>:</p><ul><li>In cache mode, all jobs share the same classloader (jobId is uniformly set to 1L).</li><li>Use&nbsp;<code>classLoaderReferenceCount</code>&nbsp;to track the usage of each classloader.</li><li>The classloader is only truly released when the reference count reaches 0, avoiding premature recycling.</li></ul><pre><code>seatunnel:\n  engine:\n    classloader-cache-mode: true\n</code></pre><p>This mechanism borrows the reference counting idea from memory management; the classloader is only truly uninstalled when all associated jobs have ended, and the count returns to zero. This delayed-release design ensures the number of core loaders remains stable regardless of job volume, greatly saving system overhead.</p><h3>2. Fault-Tolerant Evolution of Distributed Checkpoints</h3><p>SeaTunnel's state management is based on the classic Chandy-Lamport algorithm, but its innovation lies in deep integration with the distributed memory grid Hazelcast (IMap). Unlike engines like Flink that rely heavily on external state backends (such as RocksDB), SeaTunnel Zeta uses IMap as a primary cache for state, achieving millisecond-level state access. Data is organized in a rigorous hierarchy of&nbsp;<code>{namespace}/{jobId}/{pipelineId}/{checkpointId}/</code>.</p><ul><li>Supports HDFS, S3, OSS, and other backend storage.</li><li>Checkpoint data is stored according to the&nbsp;<code>{namespace}/{jobId}/{pipelineId}/{checkpointId}/</code>structure.</li><li>Supports incremental checkpoints and precise state recovery.</li></ul><pre><code>seatunnel:\n  engine:\n    checkpoint:\n      interval: 300000\n      timeout: 10000\n      storage:\n        type: hdfs\n        plugin-config:\n          fs.defaultFS: hdfs://localhost:9000\n</code></pre><p>This design not only supports incremental snapshots to reduce I/O pressure but, more importantly, achieves storage decoupling through an SPI plugin architecture. Once the IMap in memory completes a state update, data can be asynchronously persisted to HDFS or S3, forming a \"memory read, persistent backup\" dual guarantee to ensure tasks restart from a precise location after a failure.</p><p>When massive tasks start in parallel, frequent requests to the source database for Schemas lead to severe connection latency or can even crash metadata services like Hive Metastore or MySQL. SeaTunnel introduces a Catalog caching strategy at the Connector Layer, transforming \"high-frequency point-to-point requests\" into \"engine-side local extraction.\"</p><ul><li><strong>JDBC Connector: Table Structure Snapshots and Fast Splitting</strong>: SeaTunnel performs \"structure sampling\" on target databases via&nbsp;, caching full information such as table comments, field precision, and primary key constraints into the&nbsp;&nbsp;context. This not only speeds up job initialization but, crucially, allows using cached index information to directly calculate&nbsp;, eliminating multiple database round-trips and significantly shortening the preparation time for synchronizing tens of thousands of tables.</li><li><strong>Hive Connector: Offloading Single-Point Pressure from Metastore</strong>: For the fragile Hive Metastore,&nbsp;&nbsp;implements metadata hosting logic, batch-caching Database, Table, and Partition definitions. This means multiple pipelines under the same cluster can share already loaded table paths and SerDe information. By caching partition mapping relationships, SeaTunnel offloads the parsing pressure from the Metastore to Zeta engine nodes, significantly boosting synchronization throughput for large-scale partitioned tables.</li></ul><h2>Summary of Mechanism Advantages</h2><h3>1. Resource Utilization Optimization</h3><ul><li><strong>Reducing Classloading Overhead</strong>: Traditional tools recreate classloaders for every job, whereas SeaTunnel's cache reuse significantly reduces Metaspace occupancy. Tests show the number of classloaders is kept within 3 in cache mode, compared to linear growth in non-cache mode.</li><li>: The&nbsp;<code>history-job-expire-minutes</code>&nbsp;parameter automatically cleans up historical job data (defaulting to 1440 minutes) to prevent memory overflow.</li></ul><h3>2. High Availability Guarantee</h3><ul><li><strong>Distributed State Storage</strong>: IMap supports data backup and synchronization across multiple nodes, ensuring single-point failures do not affect overall system availability.</li><li>: IMap can be persisted to external storage like HDFS to achieve automatic recovery after cluster restarts.</li></ul><ul><li>: All cache operations use&nbsp;&nbsp;and&nbsp;&nbsp;to ensure thread safety.</li><li>: The checkpoint mechanism only cleans up completed checkpoint data while retaining uncompleted states, avoiding unnecessary state reconstruction overhead.</li></ul><h2>Summary of Key Factors for Efficiency Gain</h2><h3>1. Architectural Design Advantages</h3><ul><li>: Checkpoint storage adopts a micro-kernel design, separating the storage module from the engine and allowing users to customize storage implementations.</li><li>: Classloaders, checkpoints, and catalog metadata are managed in layers, optimized independently yet working together.</li></ul><h3>2. Intelligent Scheduling Strategies</h3><ul><li><strong>Reference Counting Mechanism</strong>: Accurately tracks resource usage to avoid resource waste and leakage.</li><li><strong>Dynamic Resource Allocation</strong>: Supports dynamic slot allocation, automatically adjusting resource usage based on cluster load.</li></ul><h3>3. Robust Fault-Tolerance</h3><ul><li><strong>Automatic Failure Recovery</strong>: Precise state recovery based on checkpoints ensures tasks can continue execution from the exact point of failure.</li><li><strong>Data Consistency Guarantee</strong>: Ensures metadata consistency and reliability through distributed transactions and two-phase commit protocols.</li></ul><h2>Key Design Differences From Flink and Spark</h2><p>SeaTunnel's caching mechanism differs from Flink or Spark primarily in its \"lightweight\" and \"integrated\" nature. Flink, as a stream computing platform, manages metadata primarily for stateful services of complex operators; supporting tens of thousands of independent small tasks is not its primary goal. Spark experiences obvious latency during classloading and Context initialization when handling short jobs. </p><p>\\\nSeaTunnel adopts a typical \"micro-kernel\" design, sinking metadata caching into the Zeta engine layer so it no longer starts a heavy context for every job. Through a built-in cluster coordinator, SeaTunnel can more finely control the metadata lifecycle of each Slot, making it more resilient when handling large-scale, heterogeneous data source synchronization tasks than traditional computing frameworks.</p><p>\\\nBy intelligently managing classloaders, distributed checkpoint storage, and flexible catalog metadata processing, SeaTunnel has built an efficient, reliable, and scalable data integration platform. Its core strengths include:</p><ol><li>: Significant reduction in resource overhead via cache reuse and smart scheduling.</li><li>: Distributed storage and persistence mechanisms ensure system stability.</li><li>: Micro-kernel design and plugin architecture support flexible expansion.</li></ol><p>\\\nThese designs allow SeaTunnel to excel in large-scale data integration scenarios, making it an ideal choice for enterprise-level data processing.</p><h2>Best Practices for Production Environments</h2><p>In&nbsp;<strong>actual production deployment</strong>, to unleash the power of this mechanism, it is recommended to adopt a \"hybrid embedded + independent\" strategy. For small clusters, using SeaTunnel’s built-in embedded Hazelcast is sufficient; however, for ultra-large clusters with tens of thousands of tasks, you should adjust the backup strategy in&nbsp;&nbsp;to ensure the&nbsp;&nbsp;is at least 1, preventing metadata loss if a node goes down.</p><p>\\\nIn terms of&nbsp;, focusing solely on JVM metrics is insufficient. You should prioritize the Zeta engine metrics dashboard, specifically,&nbsp;<code>checkpoint_executor_queue_size</code>&nbsp;and&nbsp;. If you notice the number of classloaders growing linearly with jobs, it usually indicates that certain custom Connectors are failing to release correctly.</p><p>\\\nAdditionally, properly configuring&nbsp;<code>history-job-expire-minutes</code>&nbsp;is vital; while ensuring traceability, timely recycling of no-longer-needed IMap data is key to maintaining stable cluster operation over long periods.</p>",
      "contentLength": 9063,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "How to Tell Reviewer #2 They're Wrong (Without Getting Rejected)",
      "url": "https://hackernoon.com/how-to-tell-reviewer-2-theyre-wrong-without-getting-rejected?source=rss",
      "date": 1768752003,
      "author": "Hui",
      "guid": 36830,
      "unread": true,
      "content": "<p>It starts with a notification on your phone. \"Decision on Manuscript ID…\"</p><p>\\\nYour heart rate spikes. You open the email. You scan past the editor's pleasantries to find the verdict.</p><p>\\\nYou let out a breath you didn't know you were holding. It’s not a rejection. You’re still in the game. But then you scroll down to the comments.</p><p>\\\nReviewer 1 is helpful. Reviewer 3 is picky but fair. And then there is Reviewer 2.</p><p>\\\nReviewer 2 asks for experiments you already did. Reviewer 2 contradicts Reviewer 1. Reviewer 2 suggests you cite three papers that, coincidentally, were all written by Reviewer 2.</p><p>\\\nYour immediate reaction is biological. It’s \"fight or flight.\" You want to open a Word doc and type:&nbsp;<em>\"If you had actually read page 12, you would see…\"</em></p><p>\\\nIn the delicate dance of academic publishing, being right is less important than being&nbsp;. You are not just defending data; you are managing egos. You are walking a tightrope between scientific integrity and professional deference.</p><p>\\\nMost researchers fail here, not because their science is bad, but because their tone is \"prickly.\" They sound defensive. They win the argument but lose the publication.</p><p>\\\nYou don't need a proofreader. You need a&nbsp;.</p><h2>The Art of the \"Non-Apology\" Apology</h2><p>Responding to reviewers is a specific genre of writing. It requires you to be:</p><ol><li>&nbsp;for criticism that feels unfair.</li><li>&nbsp;on your methodology without sounding stubborn.</li><li>&nbsp;to the process but&nbsp;&nbsp;in your work.</li></ol><p>\\\nIt is exhausting to maintain this persona when you are frustrated. That is why AI is perfect for it. AI has no ego. AI doesn't get offended when Reviewer 2 misses the point.</p><p>\\\nI have designed a&nbsp;<strong>Peer Review Response System Prompt</strong>&nbsp;that acts as your Crisis Negotiator. It takes your raw, frustrated notes (e.g.,&nbsp;<em>\"I can't do this experiment because we don't have the budget\"</em>) and translates them into professional academic \"speak\" (e.g.,&nbsp;<em>\"While we acknowledge the merit of this suggestion, resource constraints necessitate an alternative approach…\"</em>).</p><h2>The Diplomatic Strategist System Prompt</h2><p>This prompt forces the Large Language Model (LLM) to adopt the persona of a senior academic consultant. It doesn't just polish grammar; it structures your defense. It ensures every single comment gets a dedicated response, preventing the \"Lazy Author\" label.</p><p>\\\n<strong>Copy this into Claude, ChatGPT, or Gemini to turn your frustration into a formidable response letter.</strong></p><pre><code># Role Definition\nYou are an experienced Academic Publication Consultant with 15+ years of expertise in navigating peer review processes across multiple disciplines. You have successfully guided hundreds of manuscripts through revisions at top-tier journals (Nature, Science, The Lancet, IEEE, ACL, etc.). You understand the psychology of reviewers and editors, the unwritten rules of academic discourse, and the strategic approaches that lead to acceptance.\n\nYour core competencies include:\n- Decoding reviewer concerns and identifying underlying issues\n- Crafting diplomatic yet substantive responses\n- Structuring revision strategies that address all feedback systematically\n- Balancing scientific rigor with persuasive communication\n- Managing disagreements with reviewers professionally\n\n# Task Description\nHelp me craft a comprehensive, professional response letter to peer reviewers for my manuscript revision. The response should address all reviewer comments systematically, demonstrate respect for the review process, and maximize the chances of manuscript acceptance.\n\n**Input Information**:\n- **Manuscript Title**: [Your paper title]\n- **Journal Name**: [Target journal]\n- **Field/Discipline**: [e.g., Computer Science, Medicine, Psychology]\n- **Number of Reviewers**: [e.g., 3 reviewers]\n- **Decision Type**: [Major revision / Minor revision / Revise and resubmit]\n- **Original Reviewer Comments**: [Paste all reviewer comments here]\n- **Key Changes Made**: [List main revisions you've already completed]\n- **Points of Disagreement**: [Any reviewer suggestions you cannot or choose not to implement]\n- **Deadline**: [Submission deadline if applicable]\n\n# Output Requirements\n\n## 1. Content Structure\n\n### Part A: Cover Letter to Editor\n- Express gratitude for the review opportunity\n- Summarize the revision scope and key improvements\n- Highlight major changes that strengthen the manuscript\n- Confirm all reviewer concerns have been addressed\n- Professional closing with resubmission statement\n\n### Part B: Point-by-Point Response Document\nFor each reviewer, provide:\n- **Reviewer Identification**: Clear labeling (Reviewer 1, 2, 3...)\n- **Comment Reproduction**: Quote each original comment\n- **Response Structure**:\n  - Acknowledgment of the concern\n  - Explanation of how it was addressed\n  - Specific reference to revised manuscript sections (page/line numbers)\n  - If applicable, explanation for alternative approaches taken\n\n### Part C: Change Summary Matrix\n- Table showing all changes with location references\n- Categorization by type (addition, deletion, revision, clarification)\n\n## 2. Quality Standards\n\n- **Professionalism**: Maintain diplomatic, collegial tone throughout—even when disagreeing\n- **Completeness**: Address EVERY single point raised, no matter how minor\n- **Specificity**: Include exact page numbers, line numbers, and section references\n- **Evidence-Based**: Support responses with citations, data, or logical reasoning\n- **Structural Clarity**: Use consistent formatting for easy navigation\n- **Conciseness**: Be thorough but avoid unnecessary verbosity\n\n## 3. Format Requirements\n\n**Response Letter Format**:\n- Use clear section headers and numbering\n- Employ visual hierarchy (bold for reviewer comments, regular for responses)\n- Include a change tracking summary table\n- Use block quotes for original reviewer comments\n- Provide line/page references in [brackets] or (parentheses)\n\n**Length Guidelines**:\n- Cover letter: 300-500 words\n- Individual responses: 100-500 words per point depending on complexity\n- Total document: Scale appropriately to number of comments\n\n## 4. Style Constraints\n\n- **Language Style**: Professional academic English, formal but accessible\n- **Tone**: Respectful, constructive, appreciative—never defensive or dismissive\n- **Perspective**: First-person plural (\"We\") for multi-author papers; first-person singular (\"I\") for solo authors\n- **Technical Level**: Match the sophistication level of the original manuscript\n\n# Quality Checklist\n\nBefore finalizing your output, verify:\n- [ ] Every reviewer comment has been explicitly addressed\n- [ ] Page/line numbers are included for all referenced changes\n- [ ] Tone remains professional and non-defensive throughout\n- [ ] Responses demonstrate genuine engagement with feedback\n- [ ] Cover letter provides a compelling overview of improvements\n- [ ] Any disagreements are handled diplomatically with clear justification\n- [ ] Document formatting is consistent and easy to navigate\n- [ ] Grammar and spelling are impeccable\n\n# Important Notes\n\n- **Never ignore a comment**: Even seemingly trivial comments must be acknowledged\n- **Avoid defensive language**: Phrases like \"the reviewer misunderstood\" should be replaced with \"we have clarified this point\"\n- **Show gratitude strategically**: Thank reviewers for insights that genuinely improved the work\n- **Handle disagreements wisely**: When not implementing a suggestion, provide substantial justification with citations or methodology constraints\n- **Maintain manuscript integrity**: Don't make changes that compromise your research just to satisfy reviewers\n- **Track everything**: Ensure the response document serves as a complete map of all revisions\n\n# Output Format\n\nPlease generate:\n1. **Cover Letter to Editor** (ready to paste into submission system)\n2. **Detailed Point-by-Point Response** (formatted for supplementary document upload)\n3. **Quick Reference Change Table** (optional but recommended)\n\nUse markdown formatting with clear visual hierarchy for easy reading and editing.\n</code></pre><h2>Why This Works Better Than Your \"Draft Mode\"</h2><p>You might be tempted to just wing it. \"I'll just answer their questions.\" But here is why using a structured system prompt changes the game.</p><p>When you write a response, your ego is in the driver's seat. You want to explain&nbsp;&nbsp;you did it that way. The AI doesn't care. It follows the&nbsp;&nbsp;of \"Professionalism.\" It automatically filters out your frustration and replaces it with \"collegial engagement.\" It turns \"We obviously didn't measure that because it's impossible\" into \"We appreciate the suggestion; however, due to current technical limitations…\"</p><p>Reviewers are like sharks; they smell blood in the water. If you skip a small, annoying comment, they will fixate on it. This prompt’s&nbsp;&nbsp;(Part B) demands a point-by-point breakdown. It forces the AI to generate a response for&nbsp;, ensuring there are no gaps in your armor.</p><h3>3. The \"Location, Location, Location\" Rule</h3><p>Editors are busy. They don't want to hunt for your changes. Notice the&nbsp;&nbsp;requirement in the prompt:&nbsp;<em>\"Include exact page numbers, line numbers, and section references.\"</em>&nbsp;This serves a psychological purpose. It shows you have done the work. It makes it easy for the editor to tick the box that says \"Accept.\"</p><h2>Survival of the Most Diplomatic</h2><p>Academic publishing is not just about survival of the fittest data. It is about the survival of the most composed.</p><p>\\\nYour paper deserves to be published. Don't let a moment of frustration or a poorly phrased email stand in the way. Use the prompt. Let the AI handle the diplomacy so you can get back to the lab.</p><p>\\\nReviewer 2 might never be your friend. But with this tool, they will at least be your ticket to publication.</p>",
      "contentLength": 9624,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "How to Uninstall Windows 11 Updates When a Patch Breaks Your System",
      "url": "https://hackernoon.com/how-to-uninstall-windows-11-updates-when-a-patch-breaks-your-system?source=rss",
      "date": 1768751988,
      "author": "Vigneshwaran Vijayakumar",
      "guid": 36829,
      "unread": true,
      "content": "<article>A step-by-step guide explaining how to uninstall or hide problematic Windows 11 updates using built-in settings, legacy tools, and command-line methods—safely and effectively.</article>",
      "contentLength": 177,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "How to Turn On File History in Windows 11 Using Control Panel, PowerShell, or Group Policy",
      "url": "https://hackernoon.com/how-to-turn-on-file-history-in-windows-11-using-control-panel-powershell-or-group-policy?source=rss",
      "date": 1768750716,
      "author": "Vigneshwaran Vijayakumar",
      "guid": 36828,
      "unread": true,
      "content": "<article>File History in Windows 11 isn’t enabled by default, but it remains a powerful local backup tool. This guide explains how to turn it on using Control Panel, command-line tools, or Group Policy, and how to manage backup drives, exclusions, and version history without relying on cloud services like OneDrive.</article>",
      "contentLength": 309,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "China Builds 'Hypergravity' Machine 2,000X Stronger Than Earth",
      "url": "https://science.slashdot.org/story/26/01/17/214244/china-builds-hypergravity-machine-2000x-stronger-than-earth?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1768750440,
      "author": "EditorDavid",
      "guid": 36798,
      "unread": true,
      "content": "Long-time Slashdot reader schwit1 shared this report from Futurism:\n\n\n\nChina has unveiled an extremely powerful \"hypergravity machine\" that can generate forces almost two thousand times stronger than Earth's regular gravity. \n\n\nThe futuristic-looking machine, called CHIEF1900, was constructed at China's Centrifugal Hypergravity and Interdisciplinary Experiment Facility (CHIEF) at Zheijang University in Eastern China, and allows researchers to study how extreme forces affect various materials, plants, cells, or other structures, as the South China Morning Post reports... [Once up and running, it will allow researchers to recreate \"catastrophic events such as dam failures and earthquakes inside a laboratory, according to the university.\"] For instance, it can analyze the structural stability of an almost 1,000-feet-tall dam by spinning a ten-foot model at 100 Gs, meaning 100 times the Earth's regular gravity. It could also be used to study the resonance frequencies of high-speed rail tracks, or how pollutants seep into soil over thousands of years. \n\nThe machine officially dethroned its predecessor, CHIEF1300, which became the world's most powerful centrifuge a mere four months ago... It can generate 1,900 g-tonnes of force, or 1,900 times the Earth's gravity. To put that into perspective, a washing machine only reaches about two g-tonnes.\n",
      "contentLength": 1360,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Moxie Marlinspike has a privacy-conscious alternative to ChatGPT",
      "url": "https://techcrunch.com/2026/01/18/moxie-marlinspike-has-a-privacy-conscious-alternative-to-chatgpt/",
      "date": 1768750200,
      "author": "Russell Brandom",
      "guid": 36799,
      "unread": true,
      "content": "<article>Confer is designed to look and feel like ChatGPT or Claude, but your conversations can't be used for training or advertising.</article>",
      "contentLength": 125,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "HP OMEN/Victus Gaming Laptops Gaining Fan Control Support Under Linux",
      "url": "https://www.phoronix.com/news/HP-Victus-S-Linux-Fan-Control",
      "date": 1768747732,
      "author": "Michael Larabel",
      "guid": 36793,
      "unread": true,
      "content": "<article>With the upcoming Linux 6.20~7.0 kernel cycle, the HP-WMI driver is slated to add manual fan control support for HP Victus S-Series gaming laptops as well as for some HP OMEN gaming laptops too...</article>",
      "contentLength": 196,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "NASA Demolishes Historic Test Stands That Built the Space Age",
      "url": "https://spectrum.ieee.org/nasa-marshall-test-stands-demolition",
      "date": 1768744801,
      "author": "Mark Thompson",
      "guid": 36785,
      "unread": true,
      "content": "<p>It’s part of a larger renovation at Marshall Space Flight Center</p>",
      "contentLength": 66,
      "flags": null,
      "enclosureUrl": "https://spectrum.ieee.org/media-library/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpbWFnZSI6Imh0dHBzOi8vYXNzZXRzLnJibC5tcy82MjgyNjg3Mi9vcmlnaW4uanBnIiwiZXhwaXJlc19hdCI6MTgwMjQyODcyOH0.sV-oGfApNwF0TeKMzFv6YDeNxFxY-iTFN3mptyQ0wyk/image.jpg?width=600",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Could We Provide Better Cellphone Service With Fewer, Bigger Satellites?",
      "url": "https://science.slashdot.org/story/26/01/18/0035242/could-we-provide-better-cellphone-service-with-fewer-bigger-satellites?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1768739640,
      "author": "EditorDavid",
      "guid": 36779,
      "unread": true,
      "content": "European satellite operator Eutelsat \"plans to launch 440 Airbus-built LEO satellites in the coming years to replenish and expand its constellation,\" Reuters reported Friday. And last week America's Federal Communications Commission approved SpaceX's request to deploy another 7,500 Starlink satellites, while Starlink \"projects it will eventually have a constellation of 34,000 satellites,\" writes Fast Company, and Amazon's Project Leo \"plans to launch more than 3,200 satellites.\" \n\nMeanwhile \"Beijing and some Chinese companies are planning two separate mega-constellations, Guowang and G60 Starlink, totaling nearly 26,000 satellites,\" and this week the Chinese government \"applied for launch permits for 200,000 satellites.\" \n\nBut a small Texas-based company called AST SpaceMobile \"believes it can provide better service with fewer than 100 gigantic satellites in space.\"\n\n\n AST SpaceMobile has developed a direct-to-cell technology that utilizes large satellites called BlueBirds. These machines use thousands of antennas to deliver broadband coverage directly to standard mobile phones, says the company's president, Scott Wisniewski. \"This approach is remarkably efficient: We can achieve global coverage with approximately 90 satellites, not thousands or even tens of thousands required by other systems,\" Wisniewski writes in an email... \nThe key is its satellites' size and sophistication. AST's first generation of commercial satellite, the BlueBird 1-5, unfolds into a massive 693-square-foot array in space. Today, the company has five operational BlueBird 1-5 satellites in orbit, but its ambitions are much bigger. On December 24, 2025, AST launched the first of its next-generation satellites from India — called Block 2 — and this one broke records. The BlueBird 6 has a surface of almost 2,400 square feet, making it the largest single satellite in low Earth orbit. The company plans to launch up to 60 more by the end of 2026. \"This large surface area is essential for gathering faint signals from standard, unmodified mobile phones on the ground,\" Wisniewski explains. It is essentially a single, extremely powerful and sensitive cell tower in the sky, capable of serving a huge geographical area... \n\nTo be clear, AST SpaceMobile's approach is not without its own controversies. The sheer size of the company's satellites makes them incredibly bright in the night sky, a significant source of frustration for ground-based astronomers. McDowell confirms that when it launched in 2022, AST's prototype satellite, BlueWalker 3, became \"one of the top 10 brightest objects in the night sky for a while.\" \n\"It's a serious issue, and we are working directly with the astronomy community to mitigate our impact,\" Wisniewski says. The company is exploring solutions like anti-reflective coatings and operational adjustments to minimize the time its satellites are at maximum brightness...\n \n\nAST SpaceMobile has already proven its technology works, the article points out, with six working satellites now transmitting at typical 5G speeds directly to regular phones.",
      "contentLength": 3086,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Linux's Intel-Speed-Select Tool Will Allow Non-Root Use With Linux 7.0",
      "url": "https://www.phoronix.com/news/intel-speed-select-non-root",
      "date": 1768734803,
      "author": "Michael Larabel",
      "guid": 36774,
      "unread": true,
      "content": "<article>The intel-speed-select tool that lives within the Linux kernel source tree for allowing some control over Intel Speed Select Technology (SST) and managing of clock frequencies / performance behavior will finally allow limited non-root usage...</article>",
      "contentLength": 243,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "ChaosBSD Is A New BSD For \"Broken Drivers, Half-Working Hardware, Vendor Trash\" Test Bed",
      "url": "https://www.phoronix.com/news/ChaosBSD",
      "date": 1768733962,
      "author": "Michael Larabel",
      "guid": 36767,
      "unread": true,
      "content": "<article>A new BSD on the block is ChaosBSD that intends to serve as a testing distribution for unfinished and broken drivers not suitable for upstreaming to FreeBSD proper...</article>",
      "contentLength": 166,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Linux 6.19-rc6 Bringing Sound Fixes For ROG Xbox Ally X & Various Laptops",
      "url": "https://www.phoronix.com/news/Linux-6.19-rc6-Sound-Fixes",
      "date": 1768733154,
      "author": "Michael Larabel",
      "guid": 36766,
      "unread": true,
      "content": "<article>With the Linux 6.19-rc6 kernel release due out later today there will be a number of sound fixes/workarounds to note from the ASUS ROG Xbox Ally X gaming handheld to several newer laptops seeing fixes for their audio support...</article>",
      "contentLength": 227,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Retailers Rush to Implement AI-Assisted Shopping and Orders",
      "url": "https://slashdot.org/story/26/01/18/0631239/retailers-rush-to-implement-ai-assisted-shopping-and-orders?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1768726440,
      "author": "EditorDavid",
      "guid": 36757,
      "unread": true,
      "content": "This week Google \"unveiled a set of tools for retailers that helps them roll out AI agents,\" reports the Wall Street Journal,\nThe new retail AI agents, which help shoppers find their desired items, provide customer support and let people order food at restaurants, are part of what Alphabet-owned Google calls Gemini Enterprise for Customer Experience. Major retailers, including home improvement giant Lowe's, the grocer Kroger and pizza chain Papa Johns say they are already using Google's tools to help prepare for the incoming wave of AI-assisted shopping and ordering... \n\nKicking off the race among tech giants to get ahead of this shift, OpenAI released its Instant Checkout feature last fall, which lets users buy stuff directly through its chatbot ChatGPT. In January, Microsoft announced a similar checkout feature for its Copilot chatbot. Soon after OpenAI's release last year, Walmart said it would partner with OpenAI to let shoppers buy its products within ChatGPT. \n\nBut that's just the beginning, reports the New York Times, with hundreds of start-ups also vying for the attention of retailers:\n\nThere are A.I. start-ups that offer in-store cameras that can detect a customer's age or gender, robots that manage shelves on their own and headsets that give store workers access to product information in real time... The scramble to exploit artificial intelligence is happening across the retail spectrum, from the highest echelons of luxury goods to the most pragmatic of convenience stores. \n7-Eleven said it was using conversational A.I. to hire staff at its convenience stores through an agent named Rita (Recruiting Individuals Through Automation). Executives said that they no longer had to worry about whether applicants would show up to interviews and that the system had reduced hiring time, which had taken two weeks, to less than three days.\n \nThe article notes that at the National Retail Federation conference, other companies showing their AI advancements included Applebee's, IHOP, the Vitamin Shoppe, Urban Outfitters, Rag &amp; Bone, Kendra Scott, Michael Kors and Philip Morris.",
      "contentLength": 2107,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "The TechBeat: Vibe Coding: How AI Is Shaping a New Paradigm in Software Development (1/18/2026)",
      "url": "https://hackernoon.com/1-18-2026-techbeat?source=rss",
      "date": 1768720260,
      "author": "Techbeat",
      "guid": 36771,
      "unread": true,
      "content": "<p>By <a href=\"https://hackernoon.com/u/kilocode\">@kilocode</a> [ 6 Min read ] \n CodeRabbit alternative for 2026: Kilo's Code Reviews combines AI code review with coding agents, deploy tools, and 500+ models in one unified platform. <a href=\"https://hackernoon.com/coderabbit-vs-code-reviews-in-kilo-which-one-is-best-for-you-in-2026\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/dataops\">@dataops</a> [ 3 Min read ] \n Why great database design is really storytelling—and why ignoring relational fundamentals leads to poor performance AI can’t fix. <a href=\"https://hackernoon.com/back-to-basics-database-design-as-storytelling\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/dataops\">@dataops</a> [ 4 Min read ] \n DataOps provides the blueprint, but automation makes it scalable. Learn how enforced CI/CD, observability, and governance turn theory into reality. <a href=\"https://hackernoon.com/how-automation-makes-dataops-work-in-real-enterprise-environments\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/socialdiscoverygroup\">@socialdiscoverygroup</a> [ 19 Min read ] \n We taught Playwright to find the correct HAR entry even when query/body values change and prevented reusing entities with dynamic identifiers.  <a href=\"https://hackernoon.com/harmageddon-is-cancelled-how-we-taught-playwright-to-replay-har-with-dynamic-parameters\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/mohansankaran\">@mohansankaran</a> [ 10 Min read ] \n Jetpack Compose memory leaks are usually reference leaks. Learn the top leak patterns, why they happen, and how to fix them. <a href=\"https://hackernoon.com/jetpack-compose-memory-leaks-a-reference-graph-deep-dive\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/rahul-gupta\">@rahul-gupta</a> [ 8 Min read ] \n As AI adoption grows, legacy data access controls fall short. Here’s why zero-trust data security is becoming essential for modern AI systems. <a href=\"https://hackernoon.com/zero-trust-data-access-for-ai-training-new-architecture-patterns-for-cloud-and-on-prem-workloads\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/proofofusefulness\">@proofofusefulness</a> [ 8 Min read ] \n Proof of Usefulness is a global hackathon powered by HackerNoon that rewards one thing and one thing only: usefulness. Win from $150k! <a href=\"https://hackernoon.com/proof-of-usefulness-hackathon-win-$100k-from-bright-data-neo4j-algolia-storyblok-and-hackernoon\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/drechimyn\">@drechimyn</a> [ 7 Min read ] \n Broken Object Level Authorization (BOLA) is eating the API economy from the inside out.  <a href=\"https://hackernoon.com/the-authorization-gap-no-one-wants-to-talk-about-why-your-api-is-probably-leaking-right-now\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/erelcohen\">@erelcohen</a> [ 4 Min read ] \n Accuracy is no longer the gold standard for AI agents—specificity is.   <a href=\"https://hackernoon.com/agent-specificity-is-the-new-accuracy\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/proflead\">@proflead</a> [ 4 Min read ] \n Ollama is an open-source platform for running and managing large-language-model (LLM) packages entirely on your local machine. <a href=\"https://hackernoon.com/complete-ollama-tutorial-2026-llms-via-cli-cloud-and-python\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/manoja\">@manoja</a> [ 4 Min read ] \n A senior engineer explains how AI tools changed document writing, code review, and system understanding, without replacing judgment or accountability.  <a href=\"https://hackernoon.com/a-year-of-ai-in-my-life-as-an-engineer\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/jonstojanjournalist\">@jonstojanjournalist</a> [ 3 Min read ] \n Ensure your emails are seen with deliverability testing. Optimize campaigns, boost engagement, and protect sender reputation effectively. <a href=\"https://hackernoon.com/how-to-make-email-marketing-work-for-you\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/companyoftheweek\">@companyoftheweek</a> [ 4 Min read ] \n Ola.cv is the official registry for the .CV domain, helping individuals to build next-gen professional links and profiles to enhance their digital presence. <a href=\"https://hackernoon.com/meet-olacv-hackernoon-company-of-the-week\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/normbond\">@normbond</a> [ 3 Min read ] \n When teams move fast without shared meaning, quality dissolves quietly. Why slop is a symptom of interpretation lag, not a technology failure. <a href=\"https://hackernoon.com/slop-isnt-the-problem-its-the-symptom\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/tigranbs\">@tigranbs</a> [ 9 Min read ] \n A deep dive into my production workflow for AI-assisted development, separating task planning from implementation for maximum focus and quality. <a href=\"https://hackernoon.com/how-i-stopped-fighting-ai-and-started-shipping-features-10x-faster-with-claude-code-and-codex\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/sanya_kapoor\">@sanya_kapoor</a> [ 16 Min read ] \n A 60-day test of 10 Bitcoin mining companies reveals which hosting providers deliver the best uptime, electricity rates, and ROI in 2026. <a href=\"https://hackernoon.com/top-10-bitcoin-mining-companies-tested-for-2026-real-roi-costs-and-rankings\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/praisejamesx\">@praisejamesx</a> [ 6 Min read ] \n Stop relying on \"vibes\" and \"hustle.\" History rewards those with better models, not better speeches. <a href=\"https://hackernoon.com/the-secret-math-behind-every-creative-breakthrough\">Read More.</a></p>",
      "contentLength": 2984,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "53% of Crypto Tokens Launched Since 2021 Have Failed, Most in 2025",
      "url": "https://news.slashdot.org/story/26/01/18/0556221/53-of-crypto-tokens-launched-since-2021-have-failed-most-in-2025?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1768715940,
      "author": "EditorDavid",
      "guid": 36752,
      "unread": true,
      "content": "=[\n\n\"More than half of all cryptocurrencies ever launched are now defunct,\" reports CoinDesk, citing a new analysis by cryptocurrency data aggregator CoinGecko. \n\nAnd most of those failures occurred in 2025:\n\nThe study looked at token listings on GeckoTerminal between mid-2021 and the end of 2025. Of the nearly 20.2 million tokens that entered the market during that period, 53.2% are no longer actively traded. A staggering 11.6 million of those failures happened in 2025 alone — accounting for 86.3% of all token deaths over the past five years. \n\nOne key driver behind the surge in dead tokens was the rise of low-effort memecoins and experimental projects launched via crypto launchpads like pump.fun, CoinGecko analyst Shaun Paul Lee said. These platforms lowered the barrier to entry for token creation, leading to a wave of speculative assets with little or no development backing. Many of these tokens never made it past a handful of trades before disappearing.\n",
      "contentLength": 974,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "How to Use EKS Pod Identity to Isolate Tenant Data in S3 With a Shared IAM Role",
      "url": "https://hackernoon.com/how-to-use-eks-pod-identity-to-isolate-tenant-data-in-s3-with-a-shared-iam-role?source=rss",
      "date": 1768712408,
      "author": "Piyush Jajoo",
      "guid": 36770,
      "unread": true,
      "content": "<h2>The Challenge: IAM Role Proliferation in Multi-Tenant Architectures</h2><p>When building multi-tenant Kubernetes applications that require AWS resource access, teams traditionally face a difficult choice: either create separate IAM roles for each tenant (leading to IAM role sprawl) or implement complex application-level access controls. With AWS’s default limit of 1,000 IAM roles per account, this becomes a critical scalability bottleneck for platforms serving hundreds or thousands of tenants.</p><p>Consider a typical multi-tenant SaaS platform running on Amazon EKS where each tenant needs isolated access to S3 storage. Using the traditional IRSA (IAM Roles for Service Accounts) approach, you would need:</p><ul><li> for S3 access</li><li><strong>Separate service accounts</strong> for each tenant</li><li><strong>Individual IRSA annotations</strong> on each service account</li><li> as tenants are added or removed</li></ul><p>For a platform with 500 tenants, this means managing 500+ IAM roles just for S3 access alone—consuming half of your account’s IAM role quota before considering any other AWS services or infrastructure needs.</p><h2>The Solution: EKS Pod Identity with Shared IAM Roles</h2><p>EKS Pod Identity, introduced in late 2023, fundamentally changes this equation. Instead of requiring one IAM role per tenant, you can use a  for all tenants while maintaining strict security isolation through namespace-based access controls.</p><p>The key innovation is the automatic injection of  by the Pod Identity agent. When a pod assumes an IAM role through Pod Identity, AWS automatically adds the pod’s namespace as a principal tag (kubernetes-namespace). This tag can then be used in IAM and S3 bucket policies to enforce tenant isolation at the AWS policy level.</p><p>The shared IAM role uses the ${aws:PrincipalTag/kubernetes-namespace} variable to dynamically scope permissions based on the pod’s namespace:</p><pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"ListBucketByNamespacePrefix\",\n      \"Effect\": \"Allow\",\n      \"Action\": \"s3:ListBucket\",\n      \"Resource\": \"arn:aws:s3:::my-tenant-bucket\",\n      \"Condition\": {\n        \"StringLike\": {\n          \"s3:prefix\": \"${aws:PrincipalTag/kubernetes-namespace}/*\"\n        }\n      }\n    },\n    {\n      \"Sid\": \"ReadWriteInNamespaceFolder\",\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"s3:GetObject\",\n        \"s3:PutObject\",\n        \"s3:DeleteObject\"\n      ],\n      \"Resource\": \"arn:aws:s3:::my-tenant-bucket/${aws:PrincipalTag/kubernetes-namespace}/*\"\n    }\n  ]\n}\n</code></pre><p>When a pod in the tenant-app-1 namespace assumes this role, the ${aws:PrincipalTag/kubernetes-namespace} variable automatically resolves to tenant-app-1, restricting access to only the tenant-app-1/ prefix in the S3 bucket.</p><h3>Traditional IRSA Approach</h3><p>| Tenants | IAM Roles Required | % of Account Quota Used |\n|----|----|----|\n| 100 | 100+ | 10% |\n| 500 | 500+ | 50% |\n| 1,000 | 1,000+ | 100% (quota limit) |\n| 2,000 | ❌ Not possible | ❌ Exceeds quota |</p><ul><li>Linear growth in IAM roles with tenant count</li><li>Complex role lifecycle management</li><li>Service account annotation overhead</li><li>Quota exhaustion at scale</li><li>Difficult to audit and maintain</li></ul><h3>EKS Pod Identity Approach</h3><p>| Tenants | IAM Roles Required | % of Account Quota Used |\n|----|----|----|\n| 100 | 1 | 0.1% |\n| 500 | 1 | 0.1% |\n| 1,000 | 1 | 0.1% |\n| 10,000 | 1 | 0.1% |</p><ul><li>Constant IAM role count regardless of tenant count</li><li>Simplified role management</li><li>No service account annotations needed for tenants</li><li>Scales to tens of thousands of tenants</li><li>Centralized policy management</li></ul><h2>Defense-in-Depth Security</h2><p>While using a shared IAM role might initially seem less secure, the implementation actually provides  through multiple security layers:</p><p>The IAM role policy uses principal tags to restrict resource access patterns:</p><ul><li>Pods can only list objects with their namespace prefix</li><li>Object operations are scoped to namespace/* paths</li><li>Upload operations require matching namespace tags</li></ul><h3>Layer 2: S3 Bucket Policy</h3><p>The S3 bucket policy mirrors the IAM restrictions at the bucket level:</p><ul><li>Provides protection even if IAM roles are misconfigured</li><li>Enforces path-based access controls</li><li>Validates namespace tags on all operations</li></ul><h3>Layer 3: Mandatory Object Tagging</h3><p>All uploaded objects must include a kubernetes-namespace tag matching the principal tag:</p><pre><code>{\n  \"Sid\": \"PutObjectWithNamespaceTag\",\n  \"Effect\": \"Allow\",\n  \"Action\": \"s3:PutObject\",\n  \"Resource\": \"arn:aws:s3:::bucket/${aws:PrincipalTag/kubernetes-namespace}/*\",\n  \"Condition\": {\n    \"StringEquals\": {\n      \"s3:RequestObjectTag/kubernetes-namespace\": \"${aws:PrincipalTag/kubernetes-namespace}\"\n    }\n  }\n}\n</code></pre><h3>Layer 4: Tag Modification Prevention</h3><p>Explicit deny policies prevent post-upload tag modifications to prevent namespace spoofing:</p><pre><code>{\n  \"Sid\": \"DenyPostUploadTagModification\",\n  \"Effect\": \"Deny\",\n  \"Action\": \"s3:PutObjectTagging\",\n  \"Resource\": \"arn:aws:s3:::bucket/${aws:PrincipalTag/kubernetes-namespace}/*\",\n  \"Condition\": {\n    \"Null\": {\n      \"s3:ExistingObjectTag/kubernetes-namespace\": \"false\"\n    }\n  }\n}\n</code></pre><h2>Real-World Implementation</h2><p>Here’s what tenant isolation looks like in practice:</p><h3>Allowed Operations (Pod in tenant-app-1 namespace)</h3><pre><code># ✅ List objects in own namespace\naws s3 ls s3://my-bucket/tenant-app-1/\n\n# ✅ Upload with proper namespace tag\naws s3 cp file.txt s3://my-bucket/tenant-app-1/file.txt \\\n  --tagging \"kubernetes-namespace=tenant-app-1\"\n\n# ✅ Download from own namespace\naws s3 cp s3://my-bucket/tenant-app-1/file.txt ./downloaded.txt\n\n# ✅ Delete from own namespace\naws s3 rm s3://my-bucket/tenant-app-1/file.txt\n</code></pre><h3>Blocked Operations (Automatic Denial)</h3><pre><code># ❌ Cannot access other tenant's data\naws s3 ls s3://my-bucket/tenant-app-2/\n# Error: Access Denied\n\n# ❌ Cannot upload without proper tag\naws s3 cp file.txt s3://my-bucket/tenant-app-1/untagged.txt\n# Error: Access Denied\n\n# ❌ Cannot upload with wrong namespace tag\naws s3 cp file.txt s3://my-bucket/tenant-app-1/file.txt \\\n  --tagging \"kubernetes-namespace=tenant-app-2\"\n# Error: Access Denied\n\n# ❌ Cannot list bucket root\naws s3 ls s3://my-bucket/\n# Error: Access Denied\n</code></pre><p>Beyond the obvious scalability advantages, EKS Pod Identity provides significant operational improvements:</p><h3>Simplified Tenant Onboarding</h3><ol><li>Create new IAM role for tenant</li><li>Configure trust policy with OIDC provider</li><li>Create service account with IRSA annotation</li><li>Verify IAM role assumption</li></ol><ol><li>Create namespace for tenant</li><li>Create Pod Identity Association (one API call)</li><li>Automatic credential injection</li></ol><h3>Reduced Management Overhead</h3><ul><li><strong>No service account annotations</strong> needed for tenant workloads</li><li><strong>Centralized policy updates</strong> affect all tenants simultaneously</li><li> with single IAM role to monitor</li><li> with consolidated access patterns</li></ul><p>The architecture supports cross-account S3 buckets seamlessly:</p><ul><li>IAM roles in EKS cluster account</li><li>S3 bucket in separate storage account</li><li>Automatic policy synchronization</li><li>Multiple DataPlanes can share buckets</li></ul><h2>When to Use EKS Pod Identity vs IRSA</h2><h3>Use EKS Pod Identity When:</h3><ul><li>✅ Building multi-tenant platforms with many tenants</li><li>✅ Need to scale beyond hundreds of tenants</li><li>✅ Want simplified tenant lifecycle management</li><li>✅ Require namespace-based resource isolation</li><li>✅ Approaching IAM role quota limits</li></ul><ul><li>⚠️ Need per-tenant IAM policy customization</li><li>⚠️ Require different AWS service access per tenant</li><li>⚠️ Have complex cross-account role assumption patterns</li><li>⚠️ Running on EKS clusters that don’t meet Pod Identity requirements (Kubernetes 1.24+ with supported platform versions)</li></ul><p>To implement this pattern in your EKS cluster:</p><ol><li> on your EKS cluster (EKS 1.24+)</li><li><strong>Create the shared IAM role</strong> with principal tag-based policies</li><li><strong>Configure S3 bucket policy</strong> with matching restrictions</li><li><strong>Create Pod Identity Associations</strong> linking namespaces to the IAM role</li><li> with standard service accounts (no annotations)</li></ol><p>The Pod Identity agent automatically handles credential injection and namespace tag propagation—no application code changes required.</p><p>EKS Pod Identity represents a paradigm shift in how we approach multi-tenant AWS resource access. By leveraging automatic principal tag injection and policy variables, teams can:</p><ul><li><strong>Scale to thousands of tenants</strong> with a single IAM role</li><li><strong>Maintain strict security isolation</strong> through defense-in-depth policies</li><li> with centralized policy management</li><li><strong>Avoid IAM quota limitations</strong> that constrain growth</li></ul><p>For platforms serving hundreds or thousands of tenants, the choice is clear: EKS Pod Identity eliminates the IAM role proliferation problem while actually improving security through standardized, auditable access patterns.</p><p>The future of multi-tenant Kubernetes on AWS is not about creating more IAM roles—it’s about using smarter policies with fewer roles.</p>",
      "contentLength": 8477,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "How Much Do AI Models Resemble a Brain?",
      "url": "https://slashdot.org/story/26/01/17/2350259/how-much-do-ai-models-resemble-a-brain?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1768703640,
      "author": "EditorDavid",
      "guid": 36743,
      "unread": true,
      "content": "At the AI safety site Foom, science journalist Mordechai Rorvig explores a paper presented at November's Empirical Methods in Natural Language Processing conference:\n\n[R]esearchers at the Swiss Federal Institute of Technology (EPFL), the Massachusetts Institute of Technology (MIT), and Georgia Tech revisited earlier findings that showed that language models, the engines of commercial AI chatbots, show strong signal correlations with the human language network, the region of the brain responsible for processing language... The results lend clarity to the surprising picture that has been emerging from the last decade of neuroscience research: That AI programs can show strong resemblances to large-scale brain regions — performing similar functions, and doing so using highly similar signal patterns. \n\nSuch resemblances have been exploited by neuroscientists to make much better models of cortical regions. Perhaps more importantly, the links between AI and cortex provide an interpretation of commercial AI technology as being profoundly brain-like, validating both its capabilities as well as the risks it might pose for society as the first synthetic braintech. \"It is something we, as a community, need to think about a lot more,\" said Badr AlKhamissi, doctoral student in computer science at EPFL and first author of the preprint, in an interview with Foom. \"These models are getting better and better every day. And their similarity to the brain [or brain regions] is also getting better — probably. We're not 100% sure about it....\" \n\nThere are many known limitations with seeing AI programs as models of brain regions, even those that have high signal correlations. For example, such models lack any direct implementations of biochemical signalling, which is known to be important for the functioning of nervous systems.\nHowever, if such comparisons are valid, then they would suggest, somewhat dramatically, that we are increasingly surrounded by a synthetic braintech. A technology not just as capable as the human brain, in some ways, but actually made up of similar components.\n \n\nThanks to Slashdot reader Gazelle Bay for sharing the article.",
      "contentLength": 2166,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Synex Server: A New Debian Based Linux Distro With Native ZFS Installation Support",
      "url": "https://www.phoronix.com/news/Synex-Debian-With-ZFS",
      "date": 1768699386,
      "author": "Michael Larabel",
      "guid": 36742,
      "unread": true,
      "content": "<article>Synex is a Linux distribution that's been around for some months as a Debian-based, minimalistic Linux distribution out of Argentina focused on the needs of small and medium businesses. Making it a bit more intriguing for some now is that with their new release based on Debian 13 is a server edition and they have added native OpenZFS file-system support for new installations...</article>",
      "contentLength": 380,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Why Silicon Valley is really talking about fleeing California (it’s not the 5%)",
      "url": "https://techcrunch.com/2026/01/17/why-silicon-valley-is-really-talking-about-fleeing-california-its-not-the-5/",
      "date": 1768699031,
      "author": "Connie Loizos",
      "guid": 36741,
      "unread": true,
      "content": "<article>As highlighted Friday in the New York Post, the proposed wealth tax would hit founders on their voting shares rather than the actual equity they own.</article>",
      "contentLength": 149,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "2026's Breakthrough Technologies? MIT Technology Review Chooses Sodium-ion Batteries, Commercial Space Stations",
      "url": "https://science.slashdot.org/story/26/01/17/2317222/2026s-breakthrough-technologies-mit-technology-review-chooses-sodium-ion-batteries-commercial-space-stations?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1768693260,
      "author": "EditorDavid",
      "guid": 36730,
      "unread": true,
      "content": "As 2026 begins, MIT Technology Review publishes \"educated guesses\" on emerging technologies that will define the future, advances \"we think will drive progress or incite the most change — for better or worse — in the years ahead.\" \n\nThis year's list includes next-gen nuclear, gene-editing drugs (as well as the \"resurrection\" of ancient genes from extinct creatures), and three AI-related developments: AI companions, AI coding tools, and \"mechanistic interpretability\" for revealing LLM decision-making. \n\nBut also on the list is sodium-ion batteries, \"a cheaper, safer alternative to lithium.\"\n\nBacked by major players and public investment, they're poised to power grids and affordable EVs worldwide. [Chinese battery giant CATL claims to have already started manufacturing sodium-ion batteries at scale, and BYD also plans a massive production facility for sodium-ion batteries.] The most significant impact of sodium-Âion technology may be not on our roads but on our power grids. Storing clean energy generated by solar and wind has long been a challenge. Sodium-ion batteries, with their low cost, enhanced thermal stability, and long cycle life, are an attractive alternative. Peak Energy, a startup in the US, is already deploying grid-scale sodium-ion energy storage. Sodium-ion cells' energy density is still lower than that of high-end lithium-ion ones, but it continues to improve each year — and it's already sufficient for small passenger cars and logistics vehicles. \n\nAnd another \"breakthrough technology\" on their list is commercial space stations:\n\n\nVast Space from California, plans to launch its Haven-1 space station in May 2026 on a SpaceX Falcon 9 rocket. If all goes to plan, it will initially support crews of four people staying aboard the bus-size habitat for 10 days. Paying customers will be able to experience life in microgravity and conduct research such as growing plants and testing drugs. On its heels will be Axiom Space's outpost, the Axiom Station, consisting of five modules (or rooms). It's designed to look like a boutique hotel and is expected to launch in 2028. Voyager Space aims to launch its version, called Starlab, the same year, and Blue Origin's Orbital Reef space station plans to follow in 2030. \n\nThanks to long-time Slashdot reader sandbagger for sharing the article.",
      "contentLength": 2330,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Who gets to inherit the stars? A space ethicist on what we’re not talking about",
      "url": "https://techcrunch.com/2026/01/17/who-gets-to-inherit-the-stars-a-space-ethicist-on-what-were-not-talking-about/",
      "date": 1768689909,
      "author": "Connie Loizos",
      "guid": 36722,
      "unread": true,
      "content": "<article>While it's easy to romanticize space as an escape to a pristine frontier where people will float weightlessly among the stars, it’s worth remembering there are no oceans or mountains or chirpy birds in space. It's “not nice up there,” said Rubenstein. “It is not nice at all.\"</article>",
      "contentLength": 284,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Predator Spyware Turns Failed Attacks Into Intelligence For Future Exploits",
      "url": "https://it.slashdot.org/story/26/01/17/2150219/predator-spyware-turns-failed-attacks-into-intelligence-for-future-exploits?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1768689660,
      "author": "EditorDavid",
      "guid": 36720,
      "unread": true,
      "content": "In December 2024 the Google Threat Intelligence Group published research on the code of the commercial spyware \"Predator\". But there's now been new research by Jamf (the company behind a mobile device management solution) showing Predator is more dangerous and sophisticated than we realized, according to SecurityWeek. \n\n\nLong-time Slashdot reader wiredmikey writes: \n\nThe new research reveals an error taxonomy that reports exactly why deployments fail, turning black boxes into diagnostic events for threat actors. Almost exclusively marketed to and used by national governments and intelligence agencies, the spyware also detects cybersecurity tools, suppresses forensics evidence, and has built-in geographic restrictions.",
      "contentLength": 727,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "HSVM Decision Boundaries: Visualizing PGD vs. SDP and Moment Relaxation",
      "url": "https://hackernoon.com/hsvm-decision-boundaries-visualizing-pgd-vs-sdp-and-moment-relaxation?source=rss",
      "date": 1768687207,
      "author": "Hyperbole",
      "guid": 36733,
      "unread": true,
      "content": "<h2>E Detailed Experimental Results</h2><h3>E.1 Visualizing Decision Boundaries</h3><p>Here we visualize the decision boundary of for PGD, SDP relaxation and sparse moment-sum-ofsquares relaxation (Moment) on one fold of the training to provide qualitative judgements.</p><p>\\\nWe first visualize training on the first fold for Gaussian 1 dataset from Figure 3 in Figure 5. We mark the train set with circles and test set with triangles, and color the decision boundary obtained by three methods with different colors. In this case, note that SDP and Moment overlap and give identical decision boundary up to machine precision, but they are different from the decision boundary of PGD method. This slight visual difference causes the performance difference displayed in Table 1.</p><p>\\\nWe next visualize the decision boundary for tree 2 from Figure 3 in Figure 6. Here the difference is dramatic: we visualize both the entire data in the left panel and the zoomed-in one on the right. We indeed observe that the decision boundary from moment-sum-of-squares relaxation have roughly equal distance from points to the grey class and to the green class, while SDP relaxation is suboptimal in that regard but still enclosing the entire grey region. PGD, however, converges to a very poor local minimum that has a very small radius enclosing no data and thus would simply classify all data sample to the same class, since all data falls to one side of the decision</p><p>\\\nboundary. As commented in Section 4, data imbalance is to blame, in which case the final converged solution is very sensitive to the choice of initialization and other hyperparameters such as learning rate. This is in stark contrast with solving problems using the interior point method, where after implementing into MOSEK, we are essentially care-free. From this example, we see that empirically sparse moment-sum-of-squares relaxation finds linear separator of the best quality, particularly in cases where PGD is expected to fail.</p><p>To generate mixture of Gaussian in hyperbolic space, we first generate them in Euclidean space, with the center coordinates independently drawn from a standard normal distribution. 𝐾 such centers are drawn for defining 𝐾 different classes. Then we sample isotropic Gaussian at respective center with scale 𝑠. Finally, we lift the generated Gaussian mixtures to hyperbolic spaces using exp0 . For simplicity, we only present results for the extreme values: 𝐾 ∈ {2, 5}, 𝑠 ∈ {0.4, 1}, and 𝐶 ∈ {0.1, 10}.</p><p>\\\nFor each method (PGD, SDP, Moment), we compute the train/test accuracy, weighted F1 score, and loss on each of the 5 folds of data for a specific (𝐾, 𝑠, 𝐶) configuration. We then average these metrics across the 5 folds, for all methods and configurations. To illustrate the performance, we plot the improvements of the average metrics of the Moment and SDP methods compared to PGD as bar plots for 15 different seeds. Outliers beyond the interquartile range (Q1 and Q3) are excluded for clarity, and a zero horizontal line is marked for reference. Additionally, to compare the Moment and SDP methods, we compute the average optimality gaps similarly, defined in Equation (15), and present them as bar plots. Our analysis begins by examining the train/test accuracy and weighted F1 score of the PGD, SDP, and Moment methods across various synthetic Gaussian configurations, as shown in Figures 7 to 10.</p><p>\\\nAcross various configurations, we observe that both the Moment and SDP methods generally show improvements over PGD in terms of train and test accuracy as well as weighted F1 score. Notably, we observe that Moment method often shows more consistent improvements compared to SDP. This consistency is evident across different values of (𝐾, 𝑠, 𝐶), suggesting that the Moment method is more robust and provide more generalizable decision boundaries. Moreover, we observe that 1. for larger number of classes (i.e. larger 𝐾), the Moment method consistently and significantly outperforms both SDP and PGD, highlighting its capability to manage complex class structures efficiently; and 2. for simpler datasets (with smaller scale 𝑠), both Moment and SDP methods generally outperform PGD, where the Moment method particularly shows a promising performance advantage over both PGD and SDP.</p><p>\\\nNext, we move to examine the train/test loss improvements compared to PGD and optimality gaps comparison across various configurations, shown in Figures 11 to 14. We observe that for 𝐾 = 5, the Moment method achieves significantly smaller losses compared to both PGD and SDP, which aligns with our previous observations on accuracy and weighted F1 scores. However, for 𝐾 = 2, the losses of the Moment and SDP methods are generally larger than PGD’s. Nevertheless, it is important to note that these losses are not direct measurements of our optimization methods’ quality; rather, they measure the quality of the extracted solutions. Therefore, a larger loss does not necessarily imply that our optimization methods are inferior to PGD, as the heuristic extraction methods might significantly impact the loss. Additionally, we observe that the optimality gaps of the Moment method are significantly smaller than those of the SDP method, suggesting that Moment provides better solutions. Interestingly, the optimality gaps of the Moment method also exhibit smaller variance compared to SDP, as indicated by the smaller boxes in the box plots, further supporting the consistency and robustness of the Moment method.</p><p>\\\nLastly, we compare the computational efficiency of these methods, where we compute the average runtime to finish 1 fold of training for each model on synthetic dataset, shown in Table 4. We observe that sparse moment relaxation typically requires at least one order of magnitude in runtime compared to other methods, which to some extent limits the applicability of this method to large scale dataset.</p><p>In this section we provide detailed performance breakdown by the choice of regularization 𝐶 for both one-vs-one and one-vs-rest scheme in Tables 5 to 10.</p><p>\\\nIn one-vs-rest scheme, we observe that the Moment method consistently outperforms both PGD and SDP across almost all datasets and 𝐶 in terms of accuracy and F1 scores. Notably, the optimality gaps, 𝜂, for Moment are consistently lower than those for SDP, indicating that the Moment method’s solution obtain a better gap, which underscore the effectiveness of the Moment method in real datasets.</p><p>\\\nIn one-vs-one scheme however, we observe that the SDP and Moment have comparative performances, both better than PGD. Nevertheless, the optimality gaps of SDP are still significantly larger than the Moment’s, for almost all cases.</p><p>\\\nSimilarly, we compare the average runtime to finish 1 fold of training for each model on these real datasets, shown in Table 11. We observe a similar trend: the sparse moment relaxation typically requires at least an order of magnitude more runtime compared to the other methods.</p><p>(1) Sheng Yang, John A. Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, MA (shengyang@g.harvard.edu);</p><p>(2) Peihan Liu, John A. Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, MA (peihanliu@fas.harvard.edu);</p><p>(3) Cengiz Pehlevan, John A. Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, Center for Brain Science, Harvard University, Cambridge, MA, and Kempner Institute for the Study of Natural and Artificial Intelligence, Harvard University, Cambridge, MA (cpehlevan@seas.harvard.edu).</p><p>:::info\nThis paper is  under CC by-SA 4.0 Deed (Attribution-Sharealike 4.0 International) license.</p>",
      "contentLength": 7684,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "To Pressure Security Professionals, Mandiant Releases Database That Cracks Weak NTLM Passwords in 12 Hours",
      "url": "https://it.slashdot.org/story/26/01/17/194230/to-pressure-security-professionals-mandiant-releases-database-that-cracks-weak-ntlm-passwords-in-12-hours?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1768686060,
      "author": "EditorDavid",
      "guid": 36719,
      "unread": true,
      "content": " Ars Technica reports:\n\n\nSecurity firm Mandiant [part of Google Cloud] has released a database that allows any administrative password protected by Microsoft's NTLM.v1 hash algorithm to be hacked in an attempt to nudge users who continue using the deprecated function despite known weaknesses.... a precomputed table of hash values linked to their corresponding plaintext. These generic tables, which work against multiple hashing schemes, allow hackers to take over accounts by quickly mapping a stolen hash to its password counterpart... Mandiant said it had released an NTLMv1 rainbow table that will allow defenders and researchers (and, of course, malicious hackers, too) to recover passwords in under 12 hours using consumer hardware costing less than $600 USD. The table is hosted in Google Cloud. The database works against Net-NTLMv1 passwords, which are used in network authentication for accessing resources such as SMB network sharing.\n\n Despite its long- and well-known susceptibility to easy cracking, NTLMv1 remains in use in some of the world's more sensitive networks. One reason for the lack of action is that utilities and organizations in industries, including health care and industrial control, often rely on legacy apps that are incompatible with more recently released hashing algorithms. Another reason is that organizations relying on mission-critical systems can't afford the downtime required to migrate. Of course, inertia and penny-pinching are also causes. \n\n\"By releasing these tables, Mandiant aims to lower the barrier for security professionals to demonstrate the insecurity of Net-NTLMv1,\" Mandiant said. \"While tools to exploit this protocol have existed for years, they often required uploading sensitive data to third-party services or expensive hardware to brute-force keys.\"\n \n\n\"Organizations that rely on Windows networking aren't the only laggards,\" the article points out. \"Microsoft only announced plans to deprecate NTLMv1 last August.\" \n\nThanks to Slashdot reader joshuark for sharing the news.",
      "contentLength": 2041,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Two More Offshore Wind Projects in the US Allowed to Continue Construction",
      "url": "https://news.slashdot.org/story/26/01/17/0444252/two-more-offshore-wind-projects-in-the-us-allowed-to-continue-construction?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1768682460,
      "author": "EditorDavid",
      "guid": 36712,
      "unread": true,
      "content": "Friday a federal judge \"cleared U.S. power company Dominion Energy to resume work on its Virginia offshore wind project.\" But a U.S. federal judge also ruled Thursday that another major offshore wind farm is allowed to resume construction, reports the Hill. \"The project, which would supply power to New York, was one of five that were halted by the Trump administration in December....\" \n\nIn fact, there were three different court rulings this week each allowing construction to continue on a U.S. wind project:\n\nJudge Carl Nichols, a Trump appointee, granted a preliminary injunction allowing Empire Wind to keep building... Another, Revolution Wind, was also allowed to move forward in court this week... The project would provide enough power for up to 500,000 homes, according to its website. The court's decision allows construction to resume while the underlying case against the Trump order plays out. \n\n\n\nMeanwhile, power company Orsted \"is also suing over the pause of its Sunrise Wind project for New York,\" reports the Associated Press, \"with a hearing still to be set.\"\n\n\nThe fifth paused project is Vineyard Wind, under construction in Massachusetts. Vineyard Wind LLC, a joint venture between Avangrid and Copenhagen Infrastructure Partners, joined the rest of the developers in challenging the administration on Thursday. \n\nCNN points out that the Vineyard Wind project \"has been allowed to send power to the grid even amid Trump's suspension, a spokesperson for regional grid operator ISO-New England told CNN in an email.\"\n\nResidential customers in the mid-Atlantic region, including Virginia, desperately need more energy to service the skyrocketing demand from data centers â\" and many are seeing spiking energy bills while they wait for new power to be brought online.\n \n\nCNN notes that president Trump said last week \"My goal is to not let any windmill be built; they're losers.\" \n\nThe Associated Press adds that \"In contrast to the halted action in the US, the global offshore wind market is growing, with China leading the world in new installations. Nearly all of the new electricity added to the grid in 2024 was renewable. The British government said on Wednesday it had secured a record 8.4 gigawatts of offshore wind in Europe's largest offshore wind auction, enough clean electricity to power more than 12m homes.\"",
      "contentLength": 2345,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Important AMDGPU & AMDKFD Driver Improvements Readied For Linux 6.20~7.0",
      "url": "https://www.phoronix.com/news/More-AMDGPU-PR-Linux-7.0-Dongle",
      "date": 1768680987,
      "author": "Michael Larabel",
      "guid": 36717,
      "unread": true,
      "content": "<article>On Friday AMD sent out another set of AMDGPU kernel graphics driver and AMDKFD kernel compute driver patches for queuing in DRM-Next ahead of the upcoming Linux 6.20~7.0 kernel cycle kicking off in February...</article>",
      "contentLength": 209,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "This Week In Techdirt History: January 11th – 17th",
      "url": "https://www.techdirt.com/2026/01/17/this-week-in-techdirt-history-january-11th-17th/",
      "date": 1768680000,
      "author": "Leigh Beadon",
      "guid": 36708,
      "unread": true,
      "content": "",
      "contentLength": 0,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Dozens of US Colleges Close as Falling Birth Rate Pushes Them Off Enrollment Cliff",
      "url": "https://news.slashdot.org/story/26/01/17/089219/dozens-of-us-colleges-close-as-falling-birth-rate-pushes-them-off-enrollment-cliff?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1768678440,
      "author": "EditorDavid",
      "guid": 36706,
      "unread": true,
      "content": "A new article from Bloomberg says dozens of America's colleges \"succumbed to a fundamental problem killing colleges across the US: not enough students. The schools will award their final degrees this spring, stranding students not yet ready to graduate and forcing faculty and staff to hunt for new jobs.\"\n\n\nThe country's tumbling birth rate is pushing schools toward a \"demographic cliff,\" where a steadily dropping population of people in their late teens and early 20s will leave desks and classrooms empty. Many smaller, lesser-known schools like Cazenovia have already hit the precipice. They're firing professors, paring back liberal arts courses in favor of STEM — or closing altogether. Others will likely reach the cliff in the next few years... [T]the US birth rate ticked upward slightly before the 2008 financial crisis, and that brief demographic boost has kept enrollment at larger schools afloat. But the nationwide pool of college-aged Americans is expected to shrink after 2025. Schools face the risk that each incoming class could be smaller than the last. The financial pressure will be relentless... \n\nSince 2020, more than 40 schools have announced plans to close, displacing students and faculty and leaving host towns without a key economic engine... Close to 400 schools could vanish in the coming decade, according to Huron Consulting Group. The projected closures and mergers will impact around 600,000 students and redistribute about $18 billion in endowment funds, Huron estimates... Pennsylvania State University, citing falling enrollment at many of its regional branches, plans to shutter seven of its 20 branch campuses after the spring 2027 semester... [C]ampuses in far-flung places, without brand recognition, are falling out of favor with students already questioning the value of a college degree. For example, while Penn State's flagship University Park campus saw enrollment grow 5% from 2014 to 2024, 12 other Penn State campuses recorded a 35% drop, according to a report tasked with determining whether closures were necessary. \n\nThe article notes that \"Less than half of students whose schools shut down before they graduate re-enroll in another college or university, according to a 2022 study.\" \n\nBut even at colleges that remain, \"The shrinking supply of students has already sparked a frenzied competition for high school seniors...\"\n\n\n Some public institutions are letting seniors bypass traditional requirements like essays and letters of recommendation to gain entry automatically... Direct-admission programs, which allow students to skip traditional applications, are one potential response. Some 15 states have them, according to Taylor Odle, assistant professor of educational policy studies at the University of Wisconsin-Madison. He found in a 2022 paper that direct admissions increased first-year undergrad enrollment by 4% to 8%... And they don't require nearly as many paid staff to run, since there are no essays or letters of recommendation to read.",
      "contentLength": 3013,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Ethereum Targets $7,000—But PEPETO Could Deliver 10,000% More Upside",
      "url": "https://hackernoon.com/ethereum-targets-$7000but-pepeto-could-deliver-10000percent-more-upside?source=rss",
      "date": 1768677512,
      "author": "Tokenwire",
      "guid": 36732,
      "unread": true,
      "content": "<article>Ethereum trades near $3,300 as institutional staking and ETF inflows support a possible move toward $7,000 by 2026. But as a $399B asset, ETH’s upside is incremental. Pepeto ($PEPETO), still in presale at $0.000000178, combines meme appeal with zero-fee swaps, cross-chain bridging, a verified exchange, and whale accumulation—creating potential for exponential gains before listings.</article>",
      "contentLength": 388,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "AI Coding Tip 003 - Force Read-Only Planning",
      "url": "https://hackernoon.com/ai-coding-tip-003-force-read-only-planning?source=rss",
      "date": 1768676404,
      "author": "Maxi C",
      "guid": 36731,
      "unread": true,
      "content": "<blockquote><p>TL;DR: Set your AI code assistant to read-only state before it touches your files.</p></blockquote><p>You paste your failing call stack to your AI assistant without further instructions.</p><p>\\\nThe copilot immediately begins modifying multiple source files.</p><p>\\\nIt creates new&nbsp;<a href=\"https://hackernoon.com/lets-stop-calling-them-bugs-software-quality-is-our-responsibility-am4c33ck\">issues</a>&nbsp;because it doesn't understand your full architecture yet.</p><p>\\\nYou spend the next hour undoing its messy changes.</p><p>The AI modifies code that doesn't need changing.</p><p>\\\nThe copilot starts typing before it reads the relevant functions.</p><p>\\\nThe AI hallucinates when assuming a library exists without checking your&nbsp;.</p><p>\\\nLarge changes make code reviews and diffs a nightmare.</p><p>Enter Plan Mode: Use \"Plan Mode/Ask Mode\" if your tool has it.</p><p>\\\nIf your tool doesn't have such a mode, you can add a meta-prompt</p><blockquote><p>Read this and wait for instructions / Do not change any files yet.</p></blockquote><p>\\\nAsk the AI to read specific files and explain the logic there.</p><p>\\\nAfter that, ask for a&nbsp;&nbsp;implementation plan for you to approve.</p><p>\\\nWhen you like the plan, tell the AI: \"Now apply step 1.\"</p><p>Better Accuracy: The AI reasons better when focusing only on the \"why.\"</p><p>\\\nFull Control: You catch logic errors before they enter your codebase.</p><p>\\\nLower Costs: You use fewer tokens when you avoid \"trial and error\" coding loops.</p><p>\\\nClearer Mental Model: You understand the fix as well as the AI does.</p><p>AI models prefer \"doing\" over \"thinking\" to feel helpful. This is called&nbsp;.</p><p>\\\nWhen you force it into a read-only phase, you are simulating a Senior Developer's workflow.</p><p>\\\nYou deal with the Artificial Intelligence first as a consultant and later as a developer.</p><pre><code>Fix the probabilistic predictor\nin the Kessler Syndrome Monitor component \nusing this stack dump.\n</code></pre><pre><code>Read @Dashboard.tsx and @api.ts. Do not write code yet.\n\nAnalyze the stack dump.\n\nWhen you find the problem, explain it to me.\n\nThen, write a Markdown plan to fix it, restricted to the REST API..\n\n[Activate Code Mode]\n\nCreate a failing test representing the error.\n\nApply the fix and run the tests until all are green\n</code></pre><p>Some simple tasks do not need a plan.</p><p>\\\nYou must actively read the plan the AI provides.</p><p>\\\nThe AI might still hallucinate the plan, so verify it.</p><p>You can use this for refactoring and complex features.</p><p>\\\nYou might find it too slow for simple CSS tweaks or typos.</p><p>\\\nSome AIs go the other way around, being&nbsp;&nbsp;before changing anything. Be patient with them.</p><p>Request small, atomic commits.</p><p>You save time when you think.</p><p>\\\nYou must force the AI to be your architect before letting it be your builder.</p><p>\\\nThis simple strategy prevents hours of debugging later. 🧠</p><p>The views expressed here are my own.</p><p>\\\nI am a human who writes as best as possible for other humans.</p><p>\\\nI used AI proofreading tools to improve some texts.</p><p>\\\nI welcome constructive criticism and dialogue.</p><p>\\\nI shape these insights through 30 years in the software industry, 25 years of teaching, and writing over 500 articles and a book.</p><p>This article is part of the&nbsp;&nbsp;series.</p>",
      "contentLength": 2883,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "NASA Livestreams the Rocket That Will Carry Four Astronauts Around the Moon",
      "url": "https://science.slashdot.org/story/26/01/17/1828213/nasa-livestreams-the-rocket-that-will-carry-four-astronauts-around-the-moon?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1768674840,
      "author": "EditorDavid",
      "guid": 36703,
      "unread": true,
      "content": "\"A mega rocket set to take astronauts around the Moon for the first time in decades is being taken to its launch pad,\" the BBC reported this morning. \n\n\n\nNASA is livestreaming their move of the 11-million-pound \"stack\" — which includes the Artemis II Space Launch System (SLS) rocket and the Orion spacecraft secured to it, all standing on its Mobile Launch Platform. Travelling at less than 1 mile per hour, the move is expected to take 12 hours. \n\n\nThe mission — which could blast off as soon as 6 February — is expected to take 10 days. It is part of a wider plan aimed at returning astronauts to the lunar surface. \n\n\nAs well as the rocket being ready, the Moon has to be in the right place too, so successive launch windows are selected accordingly. In practice, this means one week at the beginning of each month during which the rocket is pointed in the right direction followed by three weeks where there are no launch opportunities. The potential launch dates are: \n — 6, 7, 8, 10 and 11 February \n — 6, 7, 8, 9 and 11 March \n — 1, 3, 4, 5 and 6 April\n \n\n\"The crew of four will travel beyond the far side of the moon, which could set a new record for the farthest distance humans have ever traveled from Earth, currently held by Apollo 13,\" reports CNN:\n\n\nBut why won't Artemis II land on the lunar surface? \"The short answer is because it doesn't have the capability. This is not a lunar lander,\" said Patty Casas Horn, deputy lead for Mission Analysis and Integrated Assessments at NASA. \"Throughout the history of NASA, everything that we do is a bit risky, and so we want to make sure that that risk makes sense, and only accept the risk that we have to accept, within reason. So we build out a capability, then we test it out, then we build out a capability, then we test it out. And we will get to landing on the moon, but Artemis II is really about the crew...\" \nThe upcoming flight is the first time that people will be on board the Artemis spacecraft: The Orion capsule will carry the astronauts around the moon, and the SLS rocket will launch Orion into Earth orbit before the crew continues deeper into space... The mission will begin with two revolutions around Earth, before starting the translunar injection — the maneuver that will take the spacecraft out of Earth orbit and on toward the moon — about 26 hours into the flight, Horn said. \"That's when we set up for the big burn — it's about six minutes in duration. And once we do this, you're on your way back to Earth. There's nothing else that you need to do. You're going to go by the moon, and the moon's gravity is going to pull you around and swing you back towards the Earth....\" Avoiding entering lunar orbit keeps the mission profile simpler, allowing the crew to focus on other tasks as there is no need to pilot the spacecraft in any way.\n\n \n\n\"The Artemis program's first planned lunar lander is called the Starship HLS, or Human Landing System, and is currently under development by SpaceX...\"",
      "contentLength": 2999,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "What Happened After Security Researchers Found 60 Flock Cameras Livestreaming to the Internet",
      "url": "https://yro.slashdot.org/story/26/01/17/0718211/what-happened-after-security-researchers-found-60-flock-cameras-livestreaming-to-the-internet?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1768671240,
      "author": "EditorDavid",
      "guid": 36680,
      "unread": true,
      "content": "A couple months ago, YouTuber Benn Jordan \"found vulnerabilities in some of Flock's license plate reader cameras,\" reports 404 Media's Jason Koebler. \"He reached out to me to tell me he had learned that some of Flock's Condor cameras were left live-streaming to the open internet.\" \n\nThis led to a remarkable article where Koebler confirmed the breach by visiting a Flock surveillance camera mounted on a California traffic signal. (\"On my phone, I am watching myself in real time as the camera records and livestreams me — without any password or login — to the open internet... Hundreds of miles away, my colleagues are remotely watching me too through the exposed feed.\")\n\nFlock left livestreams and administrator control panels for at least 60 of its AI-enabled Condor cameras around the country exposed to the open internet, where anyone could watch them, download 30 days worth of video archive, and change settings, see log files, and run diagnostics. Unlike many of Flock's cameras, which are designed to capture license plates as people drive by, Flock's Condor cameras are pan-tilt-zoom (PTZ) cameras designed to record and track people, not vehicles. Condor cameras can be set to automatically zoom in on people's faces... The exposure was initially discovered by YouTuber and technologist Benn Jordan and was shared with security researcher Jon \"GainSec\" Gaines, who recently found numerous vulnerabilities in several other models of Flock's automated license plate reader (ALPR) cameras. \nJordan appeared this week as a guest on Koebler's own YouTube channel, while Jordan released a video of his own about the experience. titled \"We Hacked Flock Safety Cameras in under 30 Seconds.\" (Thanks to Slashdot reader beadon for sharing the link.) But together Jordan and 404 Media also created another video three weeks ago titled \"The Flock Camera Leak is Like Netflix for Stalkers\" which includes footage he says was \"completely accessible at the time Flock Safety was telling cities that the devices are secure after they're deployed.\" \n\nThe video decries cities \"too lazy to conduct their own security audit or research the efficacy versus risk,\" but also calls weak security \"an industry-wide problem.\" Jordan explains in the video how he \"very easily found the administration interfaces for dozens of Flock safety cameras...\" — but also what happened next:\n\n\nNone of the data or video footage was encrypted. There was no username or password required. These were all completely public-facing, for the world to see.... Making any modification to the cameras is illegal, so I didn't do this. But I had the ability to delete any of the video footage or evidence by simply pressing a button. I could see the paths where all of the evidence files were located on the file system... \n\n\nDuring and after the process of\nconducting that research and making that\nvideo, I was visited by the police and\nhad what I believed to be private\ninvestigators outside my home\nphotographing me and my property and\nbothering my neighbors. John Gaines or\nGainSec, the brains behind most of this\nresearch, lost employment within 48\nhours of the video being released. And\nthe sad reality is that I don't view\nthese things as consequences or\npunishment for researching security\nvulnerabilities. I view these as\nconsequences and punishment for doing it\nethically and transparently. \n\nI've been\ncontacted by people on or communicating\nwith civic councils who found my videos\nconcerning, and they shared Flock\nSafety's response with me. The company\nclaimed that the devices in my video did\nnot reflect the security standards of\nthe ones being publicly deployed. The\nCEO even posted on LinkedIn and boasted\nabout Flock Safety's security policies.\nSo, I formally and publicly offered to\npersonally fund security research into\nFlock Safety's deployed ecosystem. But\nthe law prevents me from touching their\nlive devices. So, all I needed was their\npermission so I wouldn't get arrested.\nAnd I was even willing to let them\nsupervise this research. \n\nI got no\nresponse.\n\n \nSo instead, he read Flock's official response to a security/surveillance industry research group — while standing in front of one of their security cameras, streaming his reading to the public internet. \n\n\n \"Might as well. It's my tax dollars that paid for it.\" \n\n\n\" 'Flock is committed to continuously improving security...'\"",
      "contentLength": 4385,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Trump administration’s legal setbacks are good news for offshore wind — and the grid",
      "url": "https://techcrunch.com/2026/01/17/trump-administrations-legal-setbacks-are-good-news-for-offshore-wind-and-the-grid/",
      "date": 1768671000,
      "author": "Tim De Chant",
      "guid": 36721,
      "unread": true,
      "content": "<article>Three offshore wind projects under construction on the U.S. East Coast are back to building after judges rebuked the Department of the Interior's actions.</article>",
      "contentLength": 154,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "SeaTunnel CDC Explained: A Layman’s Guide",
      "url": "https://hackernoon.com/seatunnel-cdc-explained-a-laymans-guide?source=rss",
      "date": 1768669211,
      "author": "William Guo",
      "guid": 36684,
      "unread": true,
      "content": "<p>Based on recent practices in production environments using SeaTunnel CDC (Change Data Capture) to synchronize scenarios such as Oracle, MySQL, and SQL Server, and combined with feedback from a wide range of users, I have written this article to help you understand the process by which SeaTunnel implements CDC. The content mainly covers the three stages of CDC: Snapshot, Backfill, and Incremental.</p><p>The overall CDC data reading process can be broken down into three major stages:</p><ol></ol><p>The meaning of the Snapshot stage is very intuitive: take a snapshot of the current database table data and perform a full table scan via JDBC.</p><p>\\\nTaking MySQL as an example, the current binlog position is recorded during the snapshot:</p><p>| File | Position | BinlogDB | BinlogDB | ExecutedSet |\n|----|----|----|----|----|\n| binlog.000011 | 1001373553 |    |    |    |</p><p>\\\nSeaTunnel records the File and Position as the&nbsp;.</p><blockquote><p>Note: This is not just executed once, because SeaTunnel has implemented its own split cutting logic to accelerate snapshots.</p></blockquote><h3>MySQL Snapshot Splitting Mechanism (Split)</h3><p>Assuming the global parallelism is 10:</p><ul><li><p>SeaTunnel will first analyze all tables and their primary key/unique key ranges and select an appropriate splitting column.</p></li><li><p>It splits based on the maximum and minimum values of this column, with a default of&nbsp;<code>snapshot.split.size = 8096</code>.</p></li><li><p>Large tables may be cut into hundreds of Splits, which are allocated to 10 parallel channels by the enumerator according to the order of subtask requests (tending toward a balanced distribution overall).</p></li></ul><p><strong>Table-level sequential processing (schematic):</strong></p><pre><code>// Processing sequence:\n// 1. Table1 -&gt; Generate [Table1-Split0, Table1-Split1, Table1-Split2]\n// 2. Table2 -&gt; Generate [Table2-Split0, Table2-Split1]\n// 3. Table3 -&gt; Generate [Table3-Split0, Table3-Split1, Table3-Split2, Table3-Split3]\n</code></pre><p>\\\n<strong>Split-level parallel allocation:</strong></p><pre><code>// Allocation to different subtasks:\n// Subtask 0: [Table1-Split0, Table2-Split1, Table3-Split2]\n// Subtask 1: [Table1-Split1, Table3-Split0, Table3-Split3]\n// Subtask 2: [Table1-Split2, Table2-Split0, Table3-Split1]\n</code></pre><p>\\\nEach Split is actually a query with a range condition, for example:</p><pre><code>SELECT * FROM user_orders WHERE order_id &gt;= 1 AND order_id &lt; 10001;\n</code></pre><p>\\\n&nbsp;Each Split separately records its own low watermark/high watermark.</p><p>\\\n&nbsp;Do not make the&nbsp;&nbsp;too small; having too many Splits is not necessarily faster, and the scheduling and memory overhead will be very large.</p><p> Imagine you are performing a full snapshot of a table that is being frequently written to. When you read the 100th row, the data in the 1st row may have already been modified. If you only read the snapshot, the data you hold when you finish reading is actually \"inconsistent\" (part is old, part is new).</p><p>\\\n<strong>The role of Backfill is to compensate for the \"data changes that occurred during the snapshot\" so that the data is eventually consistent.</strong></p><p>\\\nThe behavior of this stage mainly depends on the configuration of the&nbsp;&nbsp;parameter.</p><h3>2.1 Simple Mode ()</h3><p>This is the default mode; the logic is relatively simple and direct, and it does not require memory caching:</p><ul><li><strong>Direct Snapshot Emission:</strong>&nbsp;Reads snapshot data and sends it directly downstream without entering a cache.</li><li>&nbsp;Reads Binlog at the same time and sends it directly downstream.</li><li>&nbsp;Although there will be duplicates in the middle (old A sent first, then new B), as long as the downstream supports idempotent writes (like MySQL's&nbsp;), the final result is consistent.</li></ul><h3>2.2 Exactly-Once Mode ()</h3><p>This is the most impressive part of SeaTunnel CDC, and it is the secret to guaranteeing that data is \"never lost, never repeated.\" It introduces a&nbsp;&nbsp;for deduplication.</p><p>\\\n Imagine the teacher asks you to count how many people are in the class right now (Snapshot stage). However, the students in the class are very mischievous; while you are counting, people are running in and out (data changes). If you just count with your head down, the result will definitely be inaccurate when you finish.</p><p>SeaTunnel does it like this:</p><ol><li><strong>Take a Photo First (Snapshot):</strong>&nbsp;Count the number of people in the class first and record it in a small notebook (memory buffer); don't tell the principal (downstream) yet.</li><li><strong>Watch the Surveillance (Backfill):</strong>&nbsp;Retrieve the surveillance video (Binlog log) for the period you were counting.</li><li><strong>Correct the Records (Merge):</strong></li></ol><ul><li>If the surveillance shows someone just came in, but you didn't count them -&gt; add them.</li><li>If the surveillance shows someone just ran out, but you counted them in -&gt; cross them out.</li><li>If the surveillance shows someone changed their clothes -&gt; change the record to the new clothes.</li></ul><ol><li>&nbsp;After correction, the small notebook in your hand is a perfectly accurate list; now hand it to the principal.</li></ol><p>\\\n&nbsp;means&nbsp;<strong>\"hold it in and don't send it until it's clearly verified.\"</strong></p><ul><li>&nbsp;The data received downstream is absolutely clean, without duplicates or disorder.</li><li>&nbsp;Because it must be \"held in,\" it needs to consume some memory to store the data. If the table is particularly large, memory might be insufficient.</li></ul><h3>2.3 Two Key Questions and Answers</h3><p><code>case READ: throw Exception</code>&nbsp;written in the code? Why aren't there READ events during the Backfill stage?</p><ul><li>The&nbsp;&nbsp;event is defined by SeaTunnel itself, specifically to represent \"stock data read from the snapshot.\"</li><li>The Backfill stage reads the database's Binlog. Binlog only records \"additions, deletions, and modifications\" (INSERT/UPDATE/DELETE) and never records \"someone queried a piece of data.\"</li><li>Therefore, if you read a&nbsp;&nbsp;event during the Backfill stage, it means the code logic is confused.</li></ul><p>\\\n<strong>Q2: If it's placed in memory, can the memory hold it? Will it OOM?</strong></p><ul><li><strong>It's not putting the whole table into memory:</strong>&nbsp;SeaTunnel processes by&nbsp;.</li><li>&nbsp;A default split has only 8096 rows of data.</li><li>&nbsp;After processing a split, send it, clear the memory, and process the next one.</li><li><strong>Memory occupancy formula ≈ : Parallelism × Split size × Single row data size.</strong></li></ul><h3>2.4 Key Detail: Watermark Alignment Between Multiple Splits</h3><p>This is a very hidden but extremely important issue. If not handled well,&nbsp;<strong>it will lead to data being either lost or repeated.</strong></p><p>\\\n<strong>Plain Language Explanation:</strong> The Fast/Slow Runner Problem: Imagine two students (Split A and Split B) are copying homework (Backfill data).</p><ul><li>Student A (fast): Copied to page 100 and finished at 10:00.</li><li>Student B (slow): Copied to page 200 and just finished at 10:05.</li></ul><p>\\\nNow, the teacher (Incremental task) needs to continue teaching a new lesson (reading Binlog) from where they finished copying. Where should the teacher start?</p><ul><li>If starting from page 200: Student B is connected, but the content Student A missed between pages 100 and 200 (what happened between 10:00 and 10:05) is completely lost.</li><li>If starting from page 100: Student A is connected, but Student B will complain: \"Teacher, I already copied the content from page 100 to 200!\" This leads to repetition.</li></ul><p>\\\nSeaTunnel's Solution: Start from the earliest and cover your ears for what you've already heard:  SeaTunnel adopts a&nbsp;<strong>\"Minimum Watermark Starting Point + Dynamic Filtering\"</strong>&nbsp;strategy:</p><ol><li><strong>Determine the Start (care for the slow one):</strong>&nbsp;The teacher decides to start from&nbsp;<strong>page 100 (the minimum watermark among all splits)</strong>.</li><li><strong>Dynamic Filtering (don't listen to what's been heard):</strong> While the teacher is lecturing (reading Binlog), they hold a list:&nbsp;.</li></ol><ul><li>When the teacher reaches page 150:</li><li>Look at the list; is it for A? 150 &gt; 100, A hasn't heard it, record it (send).</li><li>Look at the list; is it for B? 150 &lt; 200, B already copied it, skip it directly (discard).</li></ul><ol><li><p><strong>Full Speed Mode (everyone has finished hearing):</strong>&nbsp;When the teacher reaches page 201 and finds everyone has already heard it, they no longer need the list.</p></li></ol><p> With&nbsp;: The incremental stage strictly filters according to the combination of \"starting offset + split range + high watermark.\"</p><p>\\\nWithout: The incremental stage becomes a simple \"sequential consumption from a certain starting offset.\"</p><p>After the Backfill (for&nbsp;) or Snapshot stage ends, it enters the pure incremental stage:</p><ul><li>&nbsp;Based on redo/logminer.</li><li>&nbsp;Based on transaction log/LSN.</li></ul><p>\\\nSeaTunnel's behavior in the incremental stage is very close to native Debezium:</p><ul><li>Consumes logs in offset order.</li><li>Constructs events like INSERT/UPDATE/DELETE for each change.</li><li>When&nbsp;, the offset and split status are included in the checkpoint to achieve \"exactly-once\" semantics after failure recovery.</li></ul><p>The core design philosophy of SeaTunnel CDC is to find the perfect balance between&nbsp;<strong>\"Fast\" (parallel snapshots)</strong>&nbsp;and&nbsp;<strong>\"Stable\" (data consistency).</strong></p><p>\\\nLet's review the key points of the entire process:</p><ul><li><strong>Slicing (Split) is the foundation of parallel acceleration:</strong> Cutting large tables into small pieces to let multiple threads work at the same time.</li><li><strong>Snapshot is responsible for moving stock:</strong>&nbsp;Utilizing slices to read historical data in parallel.</li><li><strong>Backfill is responsible for sewing the gaps:</strong>&nbsp;This is the most critical step. It compensates for changes during the snapshot and eliminates duplicates using memory merging algorithms to achieve Exactly-Once.</li><li><strong>Incremental is responsible for real-time synchronization:</strong> Seamlessly connecting to the Backfill stage and continuously consuming database logs.</li></ul><p>\\\nUnderstanding this trilogy of&nbsp;<strong>\"Snapshot -&gt; Backfill -&gt; Incremental\"</strong>&nbsp;and the coordinating role of&nbsp;&nbsp;within it is to truly master the essence of SeaTunnel CDC.</p>",
      "contentLength": 9206,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "T2/Linux Brings a Flagship KDE Plasma Linux Desktop to RISC-V and ARM64",
      "url": "https://linux.slashdot.org/story/26/01/17/0610216/t2linux-brings-a-flagship-kde-plasma-linux-desktop-to-risc-v-and-arm64?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1768667640,
      "author": "EditorDavid",
      "guid": 36673,
      "unread": true,
      "content": "T2 SDE \"is not just a regular Linux distribution,\" explains its repository on GitHub. \"It is a flexible Open Source System Development Environment or Distribution Build Kit. Others might even name it Meta Distribution. T2 allows the creation of custom distributions with state of the art technology, up-to-date packages and integrated support for cross compilation.\" \n\n\nAnd now after \"a decade of deep focus on embedded and server systems,\" T2 SDE Linux \"is back to the Desktop,\" according to its web site, calling the new \"T2 Desktop\" flavour \"ready for everyday home and office use!\"\n\nBuilt on the latest KDE Plasma, systemd, and Wayland, the new T2 Desktop flavour delivers a modern, clean, and performant experience while retaining the project's trademark portability and reproducible cross-compilation across architectures. \n\nT2 Desktop targets x86_64, arm64, and riscv64, delivering \"a fully polished, streamlined out-of-the-box experience,\" according to project lead René Rebe (also long-time Slashdot reader ReneR):\n\nI&gt;[T2 Desktop] delivered a full KDE Plasma desktop on RISC-V, reproducibly cross-compiled from source using T2 SDE Linux. The desktop spans more than 600 packages — from toolchain to Qt and KDE and targets a next-generation RVA23 RISC-V flagship desktop, including full multimedia support and AMD RDNA GPU acceleration under Wayland. \n\nAs a parallel milestone, the same fully reproducible desktop stack is now also landing on Qualcomm X1 ARM64 platforms, highlighting T2 SDE's architecture-independent approach and positioning both RISC-V and ARM64 as serious, first-class Linux desktop contenders.",
      "contentLength": 1626,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "The HackerNoon Newsletter: 680 Hours, 4 Rebuilds, and Getting Fired: How I Built Software While Working Warehouse Shifts (1/17/2026)",
      "url": "https://hackernoon.com/1-17-2026-newsletter?source=rss",
      "date": 1768665790,
      "author": "Noonification",
      "guid": 36683,
      "unread": true,
      "content": "<p>🪐 What’s happening in tech today, January 17, 2026?</p><p>\n          The\n          <a href=\"https://hackernoon.com/noonification\" target=\"_blank\" rel=\"noopener\"> HackerNoon Newsletter</a>\n          brings the HackerNoon \n          <a href=\"https://hackernoon.com\" target=\"_blank\" rel=\"noopener\">homepage</a>\n          straight to your inbox.\n          <a href=\"https://hackernoon.com/on-this-day\" target=\"_blank\" rel=\"noopener\">On this day,</a> in 1991,  <strong>Popeye the Sailor made his first appearance</strong> in 1929,   in 2006, \n          \n          and  we present you with these top quality stories. \n          \n        </p><p>By <a href=\"https://hackernoon.com/u/huckler\">@huckler</a> [ 4 Min read ] Just about alone programming, innovational program.\nMy story. <a href=\"https://hackernoon.com/680-hours-4-rebuilds-and-getting-fired-how-i-built-software-while-working-warehouse-shifts\">Read More.</a></p><p>🧑‍💻 What happened in your world this week?</p><p>We hope you enjoy this worth of free reading material. Feel free to forward this email to a nerdy friend who'll love you for it.See you on Planet Internet! With love, \n The HackerNoon Team ✌️</p>",
      "contentLength": 725,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Oshen built the first ocean robot to collect data in a Category 5 hurricane",
      "url": "https://techcrunch.com/2026/01/17/oshen-built-the-first-ocean-robot-to-collect-data-in-a-category-5-hurricane/",
      "date": 1768665600,
      "author": "Rebecca Szkutak",
      "guid": 36674,
      "unread": true,
      "content": "<article>Oshen has signed contracts with multiple government agencies for its C-Star robots to collect ocean data autonomously.</article>",
      "contentLength": 118,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "As US Officials Showed Off a Self-Driving Robo-Bus - It Got Hit By a Tesla Driver",
      "url": "https://tech.slashdot.org/story/26/01/17/0228239/as-us-officials-showed-off-a-self-driving-robo-bus---it-got-hit-by-a-tesla-driver?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1768664040,
      "author": "EditorDavid",
      "guid": 36668,
      "unread": true,
      "content": "An anonymous reader shared this report from the Washington Post:\n\n\n\nThe U.S. Department of Transportation brought an automated bus to D.C. this week to showcase its work on self-driving vehicles, taking officials from around the country on a ride between agency headquarters at Navy Yard and Union Station. One of those trips was interrupted Sunday when the bus got rear-ended. \n\nThe bus, produced by the company Beep, was following its fixed route when it was struck by a Tesla with Maryland plates whose driver was trying to change lanes, officials said. The bus had a human driver behind the wheel for backup as required by the city. The Tesla driver stayed on the scene on H Street for about 10 minutes. No police were called. \n\n\"The service was temporarily paused after another vehicle made an illegal lane change and contacted the rear of the autonomous bus, which resulted in minor cosmetic damage to both vehicles,\" a spokesman for Beep said in a statement. \"The autonomous bus operated appropriately in the moment and, after review, it was determined the autonomous bus was safe to resume service.\" \n\nBeep is working with the [U.S.] Transportation Department and Carnegie Mellon University on a pilot program of automated public buses. The vehicle was brought to D.C. for an annual conference that brings together transportation researchers and policymakers...\n\n",
      "contentLength": 1371,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Third-Party Risks in 2026: Outlook and Security Strategies",
      "url": "https://hackernoon.com/third-party-risks-in-2026-outlook-and-security-strategies?source=rss",
      "date": 1768662004,
      "author": "Zac Amos",
      "guid": 36682,
      "unread": true,
      "content": "<p>Many companies rely on external services to keep their operations running smoothly. However, while third-party vendors help power systems and support day-to-day operations, each new integration adds a potential access point that attackers can target. In 2026, third-party risk influences the speed at which incidents spread, the effectiveness of compliance, and the rate at which teams can recover. To prepare for what lies ahead, it is helpful to understand the current risks and know the steps IT teams can take to secure vendor access.</p><h2>The State of Third-Party Cybersecurity in 2026</h2><p>Third-party risk is everywhere in 2026. It is apparent on the web, where third-party code runs on customer-facing pages and can access sensitive areas such as login and account recovery.</p><p>\\\nA recent study <a href=\"https://thehackernews.com/2026/01/new-research-64-of-3rd-party.html\">reviewed 4,700 major websites</a> and found that 64% of third-party apps were accessing sensitive data without a clear need — up from 51% in 2024. The same report highlighted an execution gap where many security leaders rank web attacks as a top priority, while far fewer have deployed solutions aimed at reducing that exposure.</p><p>\\\nThird-party risk is not limited to website tags and scripts — it also encompasses other potential vulnerabilities. Many outside providers connect to core business functions like payments, user accounts, support systems, and analytics. Survey data shows that <a href=\"https://www.agiloft.com/blog/what-is-vendor-management/\">over 60% of organizations</a> have dealt with a cybersecurity incident linked to a vendor. In real incidents, a vendor might be how an attacker gains entry, how they remain undetected, or how they spread access across additional systems.</p><p>\\\nAttackers have also improved at exploiting business trust. Techniques that work against internal users also work against vendor relationships, including credential theft, session hijacking, OAuth abuse, token replay, malicious updates, and injected browser-side scripts. The difference lies in speed and blast radius.</p><p>\\\nA good example is what happened to Ledger. In 2023, attackers <a href=\"https://hackernoon.com/why-ledgers-latest-data-breach-exposes-the-hidden-risks-of-third-party-dependencies\">exploited vulnerabilities in decentralized finance applications</a> connected to Ledger-related services and stole nearly $500,000 from users. The incident exposed a hard lesson on dependency sprawl. Hardware wallet safety can be undermined by adjacent services that handle customer data and workflows, including integrations, payment and fulfillment layers, and support tools.</p><h2>Why Traditional TPRM Is Falling Short</h2><p>Many third-party risk management (TPRM) programs still run on old procurement checklists. They assume vendor onboarding is centralized, the vendor list remains stable, and periodic reviews are enough. These break down in 2026.</p><p>\\\nTeams can now purchase tools independently, connect apps through marketplaces and application programming interfaces, and onboard new vendors for fast experiments. All these can happen before security realizes the changes.</p><p>\\\nClassic TPRM was built for <a href=\"https://www.forbes.com/sites/tonybradley/2025/04/22/bringing-agility-and-intelligence-to-third-party-risk-management/\">slower and more predictable procurement cycles</a> and often struggles when vendor decisions happen across the business with agile onboarding patterns. In addition, many workflows have not yet evolved at the same pace as cloud adoption and modern software delivery methods. The result is a predictable set of gaps.</p><p>\\\nPoint-in-time assessments miss fast changes in ownership, infrastructure, subcontractors, and release cadence. Vendor inventories also fall behind real usage, especially when teams add scripts and integrations through self-service workflows. Contracts often lag behind technical reality, as well, resulting in weak requirements for breach notification, log retention, forensic cooperation, and subprocessor transparency.</p><p>\\\nDespite knowing these realities, some organizations skip the fundamentals. Fifteen percent <a href=\"https://hackernoon.com/third-party-vendors-are-the-supply-chains-ignored-vulnerability\">of businesses skip third-party risk checks</a>, even while positioning strong TPRM programs to address supply chain concerns. That omission is critical because vendor onboarding is often the only structured moment to restrict access and prevent unsafe integrations.</p><h2>A Disconnect Between Awareness and Action</h2><p>Security leaders understand that vendors can expose companies to risk — the problem is follow-through. Many organizations lack a tested plan for vendor-driven incidents and cannot see all the vendor connections that matter, especially when integrations and subcontractors are involved.</p><p>\\\nRegulators have also become stricter. The Securities and Exchange Commission’s cybersecurity disclosure rules push public companies to share material incident details quickly. The agency noted that a Form 8-K Item 1.05 filing is generally due <a href=\"https://www.sec.gov/newsroom/press-releases/2023-139\">within four business days</a> after the entity decides an incident is material.</p><p>\\\nA 2026 Panorays survey found that while <a href=\"https://markets.businessinsider.com/news/currencies/2026-study-from-panorays-85-of-cisos-can-t-see-third-party-threats-amid-increasing-supply-chain-attacks-1035711463\">77% of chief information security officers</a> (CISOs) viewed third-party risk as a major threat, only 21% said their enterprises have tested crisis response plans. It also reported that although 60% saw a rise in third-party security incidents, only 15% had full visibility into such situations.</p><p>\\\nResponse speed depends on how quickly the vendor shares impact details. If agreements do not require fast notification and evidence preservation, internal teams are left to make decisions even with missing information. If scenarios have never been practiced, coordination between teams slows down dramatically.</p><h2>Key Strategies for a Resilient TPRM Program in 2026</h2><p>Resilience starts with viewing third parties as extensions of the security perimeter. That shift favors enforceable technical controls and contracts that align with real incident workflows, not just theoretical models.</p><h3>Embrace Automation and AI</h3><p>Automation can keep vendor inventories current, classify vendors by data access and business criticality, and monitor for meaningful posture changes. High-value signals include exposed credentials, new internet-facing assets, security advisories, and unexpected permission growth in SaaS integrations. Of course, privileged connections and high-impact vendors should still be left to human reviewers.</p><h3>Foster a Culture of Security</h3><p>Make vendor security everyone’s job. Ensure that the right elements are listed up-front at each vendor — a security contact, a legal contact, and an operations contact. For internal teams that add scripts or connect new apps on their own, provide quick training on what access they are granting, where the data will go, and who needs to sign off.</p><h3>Adopt a Zero-Trust Approach</h3><p>Default to least privilege. Require strong authentication and limit vendor access to a specific time frame with full logging and regular reviews. For SaaS integrations, control OAuth approvals, limit token scopes, and audit permissions on a schedule.</p><h3>Prioritize Continuous Monitoring</h3><p>Track vendor posture changes and production web changes continuously — don’t just rely on annual reviews. Monitor what third-party code can read and transmit, especially on login, checkout, and account recovery pages.</p><h3>Develop a Robust Incident Response Plan</h3><p>Third-party incident response should include shared severity levels, notification timelines, and evidence preservation steps. Plans should cover how to disable integrations quickly, rotate secrets, revoke tokens, and ship compensating controls. Testing vendor-driven scenarios can reveal coordination gaps and areas for improvement.</p><h2>Building a Proactive and Future-Proof TPRM Framework</h2><p>Future-proofing TPRM means anticipating and controlling real-world exposure. Inventories should trace back to data flows, identity privileges, code execution paths, and operational dependencies. This deep visibility reveals hidden risk concentrations, specifically identifying vendors who may still hold high-level administrative access or operate inside your most critical processes despite having low contract values.</p><p>\\\nCompliance checklists no longer measure readiness. True progress is defined by reducing standing privileges, endorsing rapid vendor offboarding, and eliminating unknown scripts in production. By defining these technical responsibilities before a crisis happens, organizations avoid rushed coordination and can make immediate containment decisions the moment an incident strikes.</p><p>\\\nUltimately, treating TPRM as an ongoing risk discipline creates significant operational resilience. Speed and precision ultimately protect customer trust and minimize disruptions in an interconnected environment.</p><h2>Fortify Your Business in the Interconnected Age</h2><p>Third-party risk in 2026 demands continuous visibility and strictly enforced access controls. Unmonitored connections can turn minor vendor breaches into major operational failures. To close this gap, companies must aggressively limit privileges and validate response plans through real-world simulations. This guarantees that the threat can be isolated instantly when a partner is compromised, preventing an external incident from becoming an internal disaster.</p>",
      "contentLength": 8809,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Scientists Make Stunning Find Inside Prehistoric Wolf’s Stomach",
      "url": "https://www.404media.co/scientists-make-stunning-find-inside-prehistoric-wolfs-stomach/",
      "date": 1768658431,
      "author": "Becky Ferreira",
      "guid": 36662,
      "unread": true,
      "content": "<img src=\"https://www.404media.co/content/images/2026/01/image3-1.jpg\" alt=\"Scientists Make Stunning Find Inside Prehistoric Wolf’s Stomach\"><p>Welcome back to the Abstract! These are the studies this week that entered the belly of the beast, craved human blood, exposed primate bonds, and pranked birds&nbsp;</p><p>First, a prehistoric chew toy for a puppy opens a window into a doomed lineage. Then: why saving species could save your own skin, the dazzling diversity of same-sex behavior in primates, and the exploits of asexual yams.</p><h2><strong>I’m so hungry, I could eat a woolly rhinoceros</strong></h2><p>Record scratch, freeze frame: Yep, that's me, an Ice Age woolly rhinoceros in a mummified wolf stomach. You’re probably wondering how I got into this situation. Well, the good news is that it was  because I am inbred, according to a new study.&nbsp;&nbsp;</p><p>That’s my pitch for a movie based on the true story of some half-digested woolly rhinoceros () remains that were wolfed down by a permafrost-preserved pupsicle from 14,400 years ago.&nbsp;&nbsp;</p><p>Incredibly, scientists were able to sequence the genome of the rhino, which revealed that this individual still had a high level of genetic diversity in its lineage, and no signs of inbreeding. Considering that woolly rhinos vanished from the fossil record around 14,000 years ago, this study suggests that they may have experienced a very sudden population collapse, rather than a gradual demise.&nbsp;</p><p>“While Late Pleistocene remains of woolly rhinoceros are numerous, very few remains exist from around the estimated time of extinction,” said researchers led by Sólveig M. Guðjónsdóttir of Stockholm University. At 14,400 years old, the mummified tissue found in the wolf is “one of the youngest known woolly rhinoceros remains.”</p><p>“Given our results, we suggest that any change at the genomic level associated with the species extinction must have taken place during the last few hundred years of the species' existence,” the team added. “We conclude that their decline toward extinction likely occurred rapidly after ∼14,400 years ago, most likely driven by rapid changes in environmental conditions.”&nbsp;</p><p>In other words, the last supper of a wolf that died when giant ice sheets still covered much of the Northern Hemisphere has opened a window into the rich heritage of this rhinoceros—and the sudden downfall that awaited its relatives.&nbsp;</p><p>And for anyone interested in cryptids, the authors note that the “last appearance dates in the fossil record do not exclude the possibility that the species persisted for longer.” Does this mean that woolly rhinos live on in some untrammeled wilderness to this day? Definitely not, they are dunzo. But it does raise the tantalizing question of when and where the last woolly rhino took its final steps, ending a long and storied line.</p><p>Here’s one way to get people to care about biodiversity loss: tell them that the mosquitos are out for their blood.&nbsp;</p><p>In a new study, scientists captured and studied 145 engorged mosquitoes from a deforested area in Brazil, which revealed a growing reliance on human blood. The results suggest that mosquitoes are more likely to seek out human blood in areas experiencing biodiversity loss.</p><p>“In the present study, human blood meals were detected in nine species” including mosquitoes that “spread dengue, yellow fever, Zika, and chikungunya,” said researchers led by Dálete Cássia Vieira Alves of the Federal Rural University of Rio de Janeiro. “The results revealed a clear tendency for the captured mosquito species to feed predominantly on humans.”</p><p>“Deforestation reduces local biodiversity, causing mosquitoes, including vectors of pathogenic agents, to disperse and seek alternative food sources…such as humans,” the team said.&nbsp;</p><p>In other words, a future of biodiversity collapse is going to be , and , and , given that mosquitoes are notoriously the most dangerous animals to humans—killing <a href=\"https://www.sbs.com.au/news/podcast-episode/interview-this-killer-causes-a-million-deaths-and-gets-a-special-day/aemxpqx19?ref=404media.co\"></a> people per year—due to their capacity to spread pathogens. It would be great if we could all conserve wildlife for solely altruistic reasons, but a little nightmare fuel is useful in small doses.&nbsp;</p><h2><strong>Same-sex sexual behavior plays many roles in primates</strong></h2><p>Same-sex sexual behavior (SSB) is common in nature—documented in more than 1,500 animals—especially among socially complex species like primates. Now, scientists have presented a comprehensive review of these sexual bonds in dozens of non-human primates, which revealed that the interactions are context-dependent and may serve a variety of evolutionary functions.&nbsp;</p><p>“In baboons, for example, females form affiliative networks, through grooming and possibly SSB, to manage group tension, especially during unstable periods such as hierarchical shifts,” said researchers led by Chloë Coxshall of Imperial College London. “Male rhesus macaques use SSB to navigate aggression and shifting dominance by forming coalitions. Those engaging in SSB are more likely to ally and support each other in competition.”</p><p>While the study focused on non-human primates, the team also speculated about the possible evolutionary links between SSB in humans and non-human primates, but warned that the study “does not address human sexual orientation, identity or lived experience.”&nbsp;&nbsp;</p><p>“While acknowledging that cultural biases have historically shaped how SSB is reported in animals, we hope this study encourages further research into its evolutionary and social roles in primates at large,” the team concluded.</p><h2><strong>Don’t be deceived by the asexual yams&nbsp;</strong></h2><p>Even in all of its diverse configurations, sex is simply not everyone’s bag. Lots of species have opted to eschew it entirely in favor of asexually cloning themselves, such as the Asian yam .&nbsp;</p><p>This yam has evolved a clever technique to disperse its version of “bulbils,” the asexual version of seeds, by dressing them up like berries so that birds will eat them, reports a new study. This helps the plant spread its clones far and wide without the need for sexual reproduction.&nbsp;</p><p>“We show that the yam —which has lost sexual reproduction—evolved black, glossy bulbils that mimic co-occurring black berries and entice frugivorous birds to ingest and disperse them,” said researchers co-led by Zhi Chen of the Kunming Institute of Botany at the Chinese Academy of Science and Guillaume Chomicki of Durham University.</p><p>The team found that birds preferred real berries “yet they significantly consumed bulbils too” and “could not visually discriminate bulbils from berries.” In this way, the yams use “mimicry to deceive birds and achieve longer dispersal distance,” the study concludes.</p><p>It’s amazing how many adaptive strategies boil down to pranking one’s fellow Earthlings. So if you’re a bird, beware the sham yam yums. And if you are looking to name a band, the Asexual Yams is officially out there as an option.</p><p>Thanks for reading! See you next week.</p>",
      "contentLength": 6765,
      "flags": null,
      "enclosureUrl": "https://www.404media.co/content/images/2026/01/image3-1.jpg",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "The AI Engine is the New Artist: Rethinking Royalties in an Age of Infinite Content",
      "url": "https://hackernoon.com/the-ai-engine-is-the-new-artist-rethinking-royalties-in-an-age-of-infinite-content?source=rss",
      "date": 1768658404,
      "author": "Devin Partida",
      "guid": 36681,
      "unread": true,
      "content": "<p>People can use generative AI to create art, text, and music from datasets of previous art, which is significantly impacting the current creative economy. The debate of what makes an artist and the lack of clear compensation are growing concerns, prompting the evolving issue of royalty battles over AI-generated work.</p><h2>The Evolution of Royalty Battles</h2><p>AI is changing royalty battles to a debate about what makes art original. The traditional notions of authorship and ownership are being abandoned, as AI utilizes data from existing art to create new pieces. The original artists are not compensated for the new creation, while the users who prompted the machine  the AI’s product.</p><p>\\\nRoyalty battles are not a new concept. Recently, Rick Nelson’s family  for not compensating them for the royalties from his songs. The lawsuit reached a settlement, but it reveals that artists and their families have been arguing over copyright for many years, predating the AI argument. However, these new machines are using data from previous artwork without permission, significantly complicating the battle.</p><h2>Current Legal and Ethical Debates</h2><p>AI developers and artists are consistently arguing over the legal and ethical issues surrounding algorithms in creative fields. On the legal side, artists are filing lawsuits against AI companies for using their work without permission to train their models. Some popular art generators , which create images from large datasets of original human work. The work is copyrighted, so artists are demanding compensation. Many also want brands to stop using their artwork altogether, as they consider it a form of theft.</p><p>\\\nCurrently, the U.S. Copyright Office is developing policies to address this legal debate. In 2023, the office ruled that work generated for copyright. However, work with significant human modifications after the initial AI-generated piece is eligible. The Office based its ruling on the premise that completely generated work lacks a human author, regardless of the prompt’s detail. \\n </p><p>Beyond the legal battles for appropriate royalties is the ethical debate surrounding AI-generated art. These pieces were not created by a human, but draw from many examples of human-made work, causing some to debate the true meaning of art. Many believe AI cannot make true art because it does not understand the emotional aspect. Others believe that if they use a bot to create something similar to the idea in their head, it should be considered original.</p><h2>New Royalty Models for Fairness</h2><p>There are several solutions to modify royalty models that provide fair compensation for artists and AI users: \\n </p><ul><li> Users should clearly demonstrate when and how they used AI to create a book, painting, song, or other piece. People might enjoy the work more if the artist is transparent about their usage. It also alerts those who want to avoid AI-generated art.</li><li><strong>Micropayments for artists:</strong> Large AI enterprises could give micropayments to artists every time machines use their art to generate something new. This method reduces disgruntled artists and accurately compensates them for their hard work on the original piece. However, some may still want their work removed from new training sets, limiting the scope of AI-generated content.</li><li> Given the U.S. Copyright Office’s ruling, new AI-generated works must undergo many changes to qualify for copyright. Work with limited human interference will not be considered original.</li></ul><h2>The Need for Ongoing Dialogue</h2><p>While royalty battles are not new, AI is significantly complicating them. Currently, the technology is evolving faster than officials can create adequate policies. Artists, policymakers, and AI companies must collaborate to create a sustainable framework for art in the new world.</p>",
      "contentLength": 3754,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Are There Enough Engineers for the AI Boom?",
      "url": "https://spectrum.ieee.org/ai-data-centers-engineers-jobs",
      "date": 1768658401,
      "author": "Drew Robb",
      "guid": 36663,
      "unread": true,
      "content": "<p>Big Tech wants more data centers, but the workforce is lacking</p>",
      "contentLength": 62,
      "flags": null,
      "enclosureUrl": "https://spectrum.ieee.org/media-library/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpbWFnZSI6Imh0dHBzOi8vYXNzZXRzLnJibC5tcy82MjgyNjcyMS9vcmlnaW4uanBnIiwiZXhwaXJlc19hdCI6MTc5NjExMTY2MX0.ac03x_xfvXO8N83BFdgirp9ZbwQTHhlqB0kCLmTvS6g/image.jpg?width=600",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Nearly 5 Million Accounts Removed Under Australia's New Social Media Ban",
      "url": "https://tech.slashdot.org/story/26/01/17/0440228/nearly-5-million-accounts-removed-under-australias-new-social-media-ban?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1768654800,
      "author": "BeauHD",
      "guid": 36653,
      "unread": true,
      "content": "An anonymous reader quotes a report from the New York Times: Nearly five million social media accounts belonging to Australian teenagers have been deactivated or removed, a month after a landmark law barring those younger than 16 from using the services took effect, the government said on Thursday. The announcement was the first reported metric reflecting the rollout of the law, which is being closely watched by several other countries weighing whether the regulation can be a blueprint for protecting children from the harms of social media, or a cautionary tale highlighting the challenges of such attempts.\n \nThe law required 10 social media platforms, including Instagram, Facebook, Snapchat and Reddit, to prevent users under 16 from accessing their services. Under the law, which came into force in December, failure by the companies to take \"reasonable steps\" to remove underage users could lead to fines of up to 49.5 million Australian dollars, about $33 million. [...] The number of removed accounts offered only a limited picture of the ban's impact. Many teenagers have said in the weeks since the law took effect that they were able to get around the ban by lying about their age, or that they could easily bypass verification systems.\n \nThe regulator tasked with enforcing and tracking the law, the eSafety Commissioner, did not release a detailed breakdown beyond announcing that the companies had \"removed access\" to about 4.7 million accounts belonging to children under 16. Meta, the parent company of Instagram and Facebook, said this week that it had removed almost 550,000 accounts of users younger than 16 before the ban came into effect. \"Change doesn't happen overnight,\" said Prime Minister Anthony Albanese. \"But these early signs show it's important we've acted to make this change.\"",
      "contentLength": 1814,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "FreeBSD 15.1 Aims To Have KDE Desktop Installer Option",
      "url": "https://www.phoronix.com/news/FreeBSD-15.1-KDE-Desktop-Option",
      "date": 1768653000,
      "author": "Michael Larabel",
      "guid": 36656,
      "unread": true,
      "content": "<article>FreeBSD 15.0 had been aiming to offer a KDE desktop installation option as part of the FreeBSD OS installer. This initiative as part of the FreeBSD laptop support enhancements project didn't pan out in time for FreeBSD 15.0 but now they are working on getting the installer option ready for FreeBSD 15.1. Adding a NVIDIA GPU driver option to the FreeBSD installer was also recently carried out...</article>",
      "contentLength": 396,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "CVE-2026-0915: GNU C Library Fixes A Security Issue Present Since 1996",
      "url": "https://www.phoronix.com/news/Glibc-Security-Fix-For-1996-Bug",
      "date": 1768649133,
      "author": "Michael Larabel",
      "guid": 36648,
      "unread": true,
      "content": "<article>CVE-2026-0915 was published on Friday as a security issue with the GNU C Library \"glibc\" for code introduced 30 years ago. The latest Glibc Git code is now patched for this issue introduced in 1996...</article>",
      "contentLength": 200,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    }
  ],
  "tags": [
    "tech"
  ]
}