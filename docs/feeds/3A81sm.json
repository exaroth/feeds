{
  "id": "3A81sm",
  "title": "Tech",
  "displayTitle": "Tech",
  "url": "",
  "feedLink": "",
  "isQuery": true,
  "isEmpty": false,
  "isHidden": false,
  "itemCount": 206,
  "items": [
    {
      "title": "Funniest/Most Insightful Comments Of The Week At Techdirt",
      "url": "https://www.techdirt.com/2026/03/01/funniest-most-insightful-comments-of-the-week-at-techdirt-198/",
      "date": 1772395200,
      "author": "Leigh Beadon",
      "guid": 49449,
      "unread": true,
      "content": "<blockquote><p><em>Exactly why I would never own a cloud based camera system.</em></p></blockquote><blockquote><blockquote><p><em>Immigration law is pretty clear that prospective citizens not engage or have engaged in activity harmful to the US or support organizations that do.</em></p></blockquote><p><em>So, none of Trump‚Äôs companies or associates or business partners‚Ä¶</em></p><blockquote><p><em>Social media is a hot bed of anti US and terrorist supporting information.</em></p></blockquote><p><em>Yeah, Truth Social and X are full of Trump and Trump officials spewing anti-American hate, including against American immigrants.</em></p><blockquote><p><em>Requiring access to social media will help verify the immigrant is not involved in these things.</em></p></blockquote><p><em>Except that wouldn‚Äôt prove they‚Äôre not involved in such things. It would just possibly prove that the accounts provided don‚Äôt have such content. It encourages people to create performative accounts. Also, depending on who is doing the review of content, ‚Äúanti-American‚Äù will be subjective. For instance, pointing out that Trump is a convicted felon is factual and pro-American, but the current administration might not take kindly to the truth.</em></p><blockquote><p><em>If the immigrant has lied on their application, their immigration status will be lawfully revoked.</em></p></blockquote><p><em>Sure, and if ICE identifies a citizen, they‚Äôll promptly let them go and not beat or detain them or throw their documents away and say ‚ÄúI don‚Äôt care.‚Äù</em></p></blockquote><blockquote><p><em>Speaking of killers, leeches, and entitlement junkies ‚Äì just look at who was sitting behind Trump at his inauguration. Every. Accusation. Is. A. Confession.</em></p></blockquote><blockquote><p><em>This is where it‚Äôd be nice to have a Federal anti-SLAPP law in place. Then you could simply separate claims about the content the platform selects for recommendation from claims about the user-generated content itself. The content is attributed to the user, Section 230 applies to trying to hold the platform liable for it. The recommendation is attributed to the platform, and the anti-SLAPP law would apply to any lawsuit over that. It‚Äôd be on the plaintiff to show that the recommendation falls into the handful of exceptions to First Amendment protection, and the judge can rule on that without involving the platform at all. That takes all the wind out of the sails of the people trying to get rid of Section 230.</em></p></blockquote><blockquote><p><em>Nono, it‚Äôs the activist judges.</em></p></blockquote><blockquote><p><em>Because having copyright enabled Miss Frank to profit off of her work; so encouraging the arts.</em></p></blockquote><blockquote><p><em>They are playing 12-D chess here. A pandemic can‚Äôt happen if the entire population is already dead.</em></p></blockquote><blockquote><p><em>The only way this could have come off worse for them is if they sprang to hire the remaining members of Queen to sing ‚ÄòWe will, we will, track you! Track you!‚Äô</em></p></blockquote><p>That‚Äôs all for this week, folks!</p>",
      "contentLength": 2589,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "America Used Anthropic's AI for Its Attack On Iran, One Day After Banning It",
      "url": "https://tech.slashdot.org/story/26/03/01/1945208/america-used-anthropics-ai-for-its-attack-on-iran-one-day-after-banning-it?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1772394420,
      "author": "EditorDavid",
      "guid": 49450,
      "unread": true,
      "content": " Engadget reports:\n\nIn a lengthy post on Truth Social on February 27, President Trump ordered all federal agencies to \"immediately cease all use of Anthropic's technology\" following strong disagreements between the Department of Defense and the AI company. A few hours later, the U.S. conducted a major air attack on Iran with the help of Anthropic's AI tools, according to a report from The Wall Street Journal. \n\nEven Trump's post noted there would be a six-month phase-out for Anthropic's technology (adding that Anthropic \"better get their act together, and be helpful during this phase out period, or I will use the Full Power of the Presidency to make them comply, with major civil and criminal consequences to follow.\") \n\nAnthropic's Claude technology was also used by the U.S. military less than two months ago in its operation in Venezuela ‚Äî reportedly making them the first AI developer known to be used in a classified U.S. War Department operation. The Wall Street Journal reported Anthropic's technology found its way into the mission through Anthropic's contract with Palintir.",
      "contentLength": 1093,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Polymarket saw $529M traded on bets tied to bombing of Iran",
      "url": "https://techcrunch.com/2026/03/01/polymarket-saw-529m-traded-on-bets-tied-to-bombing-of-iran/",
      "date": 1772391935,
      "author": "Anthony Ha",
      "guid": 49432,
      "unread": true,
      "content": "<article>Six newly-created accounts made a profit of $1 million by correctly betting that the U.S. would strike Iran by February 28.</article>",
      "contentLength": 123,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Let‚Äôs explore the best alternatives to Discord",
      "url": "https://techcrunch.com/2026/03/01/best-discord-alternatives-age-verification-identity-privacy/",
      "date": 1772391601,
      "author": "Lauren Forristal",
      "guid": 49431,
      "unread": true,
      "content": "<article>With many users feeling uneasy about Discord's new age verification requirement, here are some alternatives that could be worth exploring. </article>",
      "contentLength": 139,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Americans Listen to Podcasts More Than Talk Radio Now, Study Shows",
      "url": "https://tech.slashdot.org/story/26/03/01/054233/americans-listen-to-podcasts-more-than-talk-radio-now-study-shows?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1772390040,
      "author": "EditorDavid",
      "guid": 49427,
      "unread": true,
      "content": "\"Podcasts have officially overtaken AM/FM talk radio as the more popular medium for spoken-word audio in the United States,\" reports TechCrunch, citing Edison Research's Share of Ear survey:\n\nThe researchers have tracked these statistics over the last decade, and almost always, the percentage of time people spent listening to podcasts increased, while their time with spoken radio broadcasts decreased. For the first time this year, podcasts eclipsed spoken-word radio with 40% of listening time, as opposed to 39% for radio... \n\nWe checked with Edison to see if these statistics include video podcasts, and they do. But the need to clarify that question points to the undeniable growing prevalence of video podcasts, hosted on platforms like Spotify and YouTube, which marks another key trend in podcasting... YouTube said that viewers watched 700 million hours of podcasts each month in 2025 on living room devices, like TVs, up from 400 million the previous year.",
      "contentLength": 968,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "North America's Bird Populations Are Shrinking Faster. Blame Climate Change and Agriculture",
      "url": "https://news.slashdot.org/story/26/03/01/0332257/north-americas-bird-populations-are-shrinking-faster-blame-climate-change-and-agriculture?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1772386440,
      "author": "EditorDavid",
      "guid": 49406,
      "unread": true,
      "content": "\"Billions fewer birds are flying through North American skies than decades ago,\" reports the Associated Press, \"and their population is shrinking ever faster, mostly due to a combination of intensive agriculture and warming temperatures, a new study found.\"\n\n\nNearly half of the 261 species studied showed big enough losses in numbers to be statistically significant and more than half of those declining are seeing their losses accelerate since 1987, according to Thursday's journal Science... The only consolation is that the birds that are shrinking in numbers the fastest are species ‚Äî such as the European starling, American crow, grackle and house sparrow ‚Äî with large enough populations that they aren't yet at risk of going extinct, said study lead author Francois Leroy, also an Ohio State ecologist... \n\nWhen it came to population declines ‚Äî not the acceleration ‚Äî the scientists noticed bigger losses further south. When they did a deeper analysis they statistically connected those losses to warmer temperatures from human-caused climate change. \"In regions where temperatures increase the most, we are seeing strongest declines in populations,\" [said study co-author Marta Jarzyna, an ecologist at Ohio State University]. \"On the other hand, the acceleration of those declines, that's mostly driven by agricultural practices.\" The scientists found statistical correlations between speeded-up decline rates and high fertilizer use, high pesticide use and amount of cropland, Leroy said. He said they couldn't say any of those caused the acceleration of losses, but it indicates agriculture in general is a factor. \"The stronger the agriculture, the faster we will lose birds,\" said Leroy... \n\nMcGill University wildlife biologist David Bird, who wasn't part of the study, said it was done well and that its conclusions made sense. With a growing human population, agriculture practices are intensified, more bird habitats are being converted to cropland, modern machinery often grind up nests and eggs and single crop plantings offer less possibilities for birds to find food and nests, said Bird, the editor of Birds of Canada. \"The biggest impact of agricultural intensity though is our war on insects. Numerous recent studies have shown that insect populations in many places throughout the world, including the U.S., have crashed by well over 40 percent,\" Bird said in an email. \"Many of the birds in this new study showing population declines depend heavily on insects for food.\" \n\n\nA 2019 study of the same bird species by Cornell University conservation scientist Kenneth Rosenberg also found that North America had 3 billion fewer birds than in 1970, the article points out.",
      "contentLength": 2702,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Google looks to tackle longstanding RCS spam in India ‚Äî but not alone",
      "url": "https://techcrunch.com/2026/03/01/google-looks-to-tackle-longstanding-rcs-spam-in-india-but-not-alone/",
      "date": 1772386200,
      "author": "Jagmeet Singh",
      "guid": 49410,
      "unread": true,
      "content": "<article>Google is integrating carrier-level filtering into RCS in India through a partnership with Airtel to strengthen protections against spam.</article>",
      "contentLength": 137,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "The Soft Bigotry of AI Doom: Because Users Are Just Too Incompetent",
      "url": "https://hackernoon.com/the-soft-bigotry-of-ai-doom-because-users-are-just-too-incompetent?source=rss",
      "date": 1772384403,
      "author": "The_AI_Ethicist",
      "guid": 49415,
      "unread": true,
      "content": "<p>When a new, disruptive technology comes along, fearmongering is never far behind. Writing was said to erode our memory, yet most of you still somehow managed to remember to put underwear on today. Movies and television were supposed to destroy our imaginations, yet the Star Wars and Harry Potter universes are bursting with human imagination, and the sheer volume of their wildly inappropriate fan fiction likewise proves so. Smartphones supposedly eradicated our attention spans, yet‚Ä¶ wow, that‚Äôs really shiny! I‚Äôm sure I don‚Äôt need to tell you how disruptive AI is, so naturally, the fearmongering has followed. </p><p>\\\nThe thing is, this particular brand of fearmongering around AI has escalated rather quickly, even in the face of both absurd and hyperbolic arguments, such as AI destroying our critical thinking, collapsing our institutions, and ending our world. Even better, there‚Äôs an unspoken thread in this fearmongering that implicates you, the user of AI, as part of this destruction because, apparently, you‚Äôre just too damned incompetent.</p><h2><strong>Destruction of Critical Thinking</strong></h2><p><img src=\"https://cdn.hackernoon.com/images/8pmL8ZpO2yTCxdRc1VIehxMAYNQ2-dz939nr.jpeg\" alt=\"\">One of the supposed negative side effects of AI use is the destruction of critical thinking. It seems we are going to be so enamored with AI that we‚Äôre going to use it to supplant much of our thinking. No longer will you have to sit and have a think because you can simply have your AI do it for you. Don‚Äôt know what‚Äôs for dinner? Ask AI! Unsure of the moral implications of capital punishment in a contemporary society? Just ask AI! Is there life after death? AI, my friend. AI.</p><p>\\\nThe argument basically boils down to this: because AI is so ubiquitous, we are going to be unloading so much of our cognitive effort that our critical thinking skills will diminish. It‚Äôs the old ‚Äúuse it or lose it‚Äù idea. But if the logic is inventions that reduce cognitive effort therefore reduce critical thinking, why didn‚Äôt the invention of writing prevent the invention of books, which should have prevented the invention of adding machines, which should have prevented the invention of computers, which should have prevented the invention of AI, whose creation required some of the most arduous collective critical thinking ever undertaken by humanity? </p><p>\\\nIt seems as though the best evidence for this brand of fearmongering is that students who use AI to write their papers are not engaging their critical thinking. Unfortunately, even this claim can‚Äôt be supported. What  definitively be said about students using AI to generate their papers is not that their critical thinking skills are degrading, but that they are spending less time writing. Do we need a reminder that writing is not critical thinking? Because if it is, Socrates was an idiot, as he didn‚Äôt write. So while writing can certainly be tied to critical thinking, it is not critical thinking itself.</p><p>\\\nThe problem is, many of these arguments use writing as a measure for critical thinking, demonstrating a deep lack of critical thinking. Not that it needs to be said, but two things can be true at once: you can be a good critical thinker and a crap writer. You also don‚Äôt have to think critically to write a paper. As a community college instructor, I‚Äôve seen plenty of papers that are bereft of even a grain of critical thinking, but somehow, there were still a bunch of words printed on paper. So my students broke reality in addition to my hopes for them.</p><p>\\\nNo, the best claim that can be made is that many students are spending less time writing, so it‚Äôs  there might be a reduction in time spent on critical thinking. But even then, it would be a leap to assume none ever occurs. Am I to understand that students using AI to write papers are not even going to see what the AI wrote and use critical thinking to evaluate the essay? Are they completely unaware that AI hallucinates and makes errors? If all that is the case, it‚Äôs not the AI that is preventing critical thinking, now, is it? As surprising as it is, cheating predates AI.</p><p>\\\nWait a minute‚Ä¶ I must wholeheartedly apologize. I am absolutely unqualified to think about this critically, as I was in the top 1% of users who sent messages to ChatGPT in 2025. Therefore, I will start acting appropriately: Derrrrrr! Duh, AI good!</p><h2><strong>The Fall of Civic Institutions</strong></h2><p><img src=\"https://cdn.hackernoon.com/images/8pmL8ZpO2yTCxdRc1VIehxMAYNQ2-s8b398k.jpeg\" alt=\"\">Our beloved civic institutions will also fall due to AI. An infamous paper recently made its way around the AI doom circles on this exact topic, <em>How AI Destroys Institutions</em>, and it proposes that this is going to happen through three mechanisms: deteriorating expertise through cognitive offloading, interfering with our decision-making, and isolating humans from each other.</p><p>\\\nMuch like the argument for critical thinking, our professional skills are going to be eroded because of skill offloading from AI. It‚Äôs not that we might get worse at that specific thing AI is doing for us; rather, it‚Äôs that our professional skills will degrade. This is why I can never use an LLM for classroom content as an English as a second language instructor‚Äîmy English skills would degrade, I wouldn‚Äôt be able to speak English anymore, and I‚Äôd be out of a job. Thanks, AI!</p><p>\\\nSo we are to believe that professionals, people who have invested time and money into education and building up careers, are simply going to let important skills get unknowingly chipped away at because of AI? Are lawyers just going to become people who bring Claude into court? So all these people who‚Äôve been highly trained won‚Äôt notice they‚Äôre not as effective at their jobs as they used to be? Their bosses won‚Äôt? The clients who pay for competent services won‚Äôt? That‚Äôs an extremely dependent and extraordinarily unlikely inverted pyramid made from a lack of self-awareness.</p><p>\\\nSo I guess I won‚Äôt notice the degradation of my accountant‚Äôs skills when I have to pay six times more in taxes because of their mistakes, and I guess the parents of students won‚Äôt notice their children‚Äôs grades slipping because the teacher used AI and therefore sucks at teaching. Apparently, AI functions as a global blindfold. It‚Äôs fun when you find unintended uses of products!</p><p>\\\nApparently, we‚Äôre also just going to have AI make our difficult moral choices for us because we‚Äôre just so damned lazy. We‚Äôre going to outsource our morality and judgment, all hidden behind an unknowable algorithm. No one will ever hash it out and come to a better agreement because we‚Äôre just going to outsource all of that to AI. I know how eager the public is to outsource our ethics, judgment, and morality to AI. Thank goodness there‚Äôs never, ever, ever been any pushback on this idea. Like ever. I guess Catholics will ask for repentance through Grok rather than through priests.</p><p>\\\nIn order to collapse our civic institutions, such as education and the justice system, AI will also erode human relationships. Now, it is true that AI will displace some relationships; there‚Äôs a good chance the relationship you had with your assistants will be a faint memory when AI replaces them. Honestly, I still haven‚Äôt replaced the relationship I had with my ice block delivery man or the horse he rode on. Gosh, I sure do miss the 80s‚Ä¶ The 1880s, that is.</p><p>\\\nAnd of course, all of this destruction of human relationships will happen only because of AI. If you thought it started happening with the decline of the monoculture as digital technology ramped up, well, you‚Äôre just wrong.</p><p>\\\nAdditionally, people will become isolated because, with AI being so agreeable, there‚Äôs less reason to hash stuff out with others in an uncomfortable manner. I get it; people are conflict-averse. That‚Äôs why when I turn on the news, I only see stories about rainbows and puppies rather than wars and protests. Humanity is so harmonious!</p><p>\\\nSo yeah, our beloved civic institutions will crumble. Damn you, AI!</p><p><img src=\"https://cdn.hackernoon.com/images/8pmL8ZpO2yTCxdRc1VIehxMAYNQ2-ygc39fx.jpeg\" alt=\"\">If destroying our society wasn‚Äôt bad enough, AI is also going to contribute to the end of the world. The Doomsday Clock by the Bulletin of the Atomic Scientists has been moved to 85 seconds to midnight, in part because of the threat from AI. Biological, nuclear, and informational warfare AI upgrades are pushing us closer than we‚Äôve ever been. And while these threats do actually have some merit, the hyperbolic conclusion still leaves this firmly in the fearmongering camp.</p><p>\\\nThe fear of‚Äô biological warfare is that AI will create a new, dangerous pathogen that people have no defense against. For nuclear warfare, AI‚Äôs implementation could mask the decision-making process, increasing the chances of error with a devastating weapon. And for informational warfare, it‚Äôs more about sowing chaos through deepfakes and the like.</p><p>\\\nI‚Äôll be the first one to admit that these particular threats do seem a bit more compelling, though I‚Äôm still unsure that inching us toward doom is the appropriate conclusion. It is very conceivable that AI could design an extremely dangerous pathogen, but to be fair, we‚Äôve kept plenty of dangerous pathogens for many years, so I‚Äôm just going to continue keeping my fingers crossed.</p><p>\\\nFor nuclear warfare, technology in general typically reduces the need for human judgment, and it‚Äôs easily argued that it reduces errors from human judgment, so the doom argument seems like a wash at best. As for informational warfare with deepfakes, yeah, that one‚Äôs hard to refute. Society is just going to have to figure that one out as we did with other disruptive technologies, though again, contributing to the end of the world seems a bit of a hyperbolic conclusion in the meantime.</p><p>While AI doom slop has always annoyed me, it wasn‚Äôt until I sat down and thought about what binds them together, somehow without the help of AI, that I found the thread: humans are too incompetent to use AI responsibly. See, the allure of AI is simply too great for humanity, so naturally, the result is a degradation of our critical thinking, the collapse of our society, and even the destruction of our world.</p><p>\\\nWe must first acknowledge that for any of these doom scenarios to come to fruition, it requires an incredible amount of human failure stacked on human failure stacked on human failure. We‚Äôve already been warned by the doomers who seem immune to AI‚Äôs negative effects, yet we‚Äôre just not going to do anything to mitigate these potential disasters? Is AI not going to improve in any marked way? The companies that create AI have no incentive not let it destroy the world? I had no idea profits continued to percolate to the afterlife.</p><p>\\\nIt seems parents and educators will simply shrug and accept that their children won‚Äôt be very good thinkers. The institutions that prop up our societies apparently can‚Äôt do anything in the face of AI to save themselves from ultimate destruction. And the great powers of the world would certainly never do anything to mitigate the risk of world destruction, even though the primary goal of conflict is to not be destroyed, but whatever. Remember, humanity is incompetent. They won‚Äôt say it outright, but it‚Äôs an implicit requirement in all of these predictions.</p><p>\\\nPlus, while we may be a bit late to the party, historically, we have always recognized the dangers of technology and done our best to minimize the risks. Cars now have seatbelts and airbags, houses now have circuit breakers and grounded outlets, guns have safeties, and even the Three Mile Island, Chornobyl, and Fukushima disasters produced increased nuclear safety. I wonder which magical property of AI makes it resistant to our inevitable improvements.</p><p>\\\nWhat can actually be stated with confidence is that it‚Äôs possible we might become too reliant on AI for problem-solving. It‚Äôs possible AI will collapse our institutions, but the sheer number of required failures to get there makes it virtually impossible. It‚Äôs also possible AI will be participating in the destruction of the planet, but if over 80 years of humanity having nuclear technology is any indication, we‚Äôre about 23.95 hours till midnight rather than 85 seconds.</p><p>\\\nTo be clear, none of this means we shouldn‚Äôt be cautious; caution with a new disruptive technology should be a requirement. However, we all know the claims being made aren‚Äôt advising caution; that‚Äôs gone out the window, and they‚Äôre predicting disaster.</p><p>\\\nI suppose <em>AI Will Erode Our Critical Thinking</em> is a bit catchier than <em>AI Will Erode Our Critical Thinking If We Simply Do Nothing But Twiddle All Our Thumbs As It Happens</em>. <em>How AI Destroys Institutions</em> is a bold and head-turning title whose cup overflows with hyperbole; <em>AI Has The Possibility To Generate Some Negative Effects On Our Institutions, So Let‚Äôs Prepare Ahead Of Time</em> isn‚Äôt nearly so bold. <em>AI Is Pushing Us Closer To Global Doom</em> naturally gets many clicks; <em>AI Is A New Tool, So Let‚Äôs Proceed Cautiously</em> doesn‚Äôt, even if it‚Äôs more accurate.</p><p>So, what can be learned from these AI doom stories? Well, it seems they think you‚Äôre incompetent and can‚Äôt use AI responsibly. They think you‚Äôre not going to do anything to mitigate any potential problems from AI. They also think you are simply going to use it in a manner that is ultimately destructive. So really, what we‚Äôve learned is that the soft bigotry of low expectations has come to the world of AI.</p>",
      "contentLength": 13267,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Investors spill what they aren‚Äôt looking for anymore in AI SaaS companies",
      "url": "https://techcrunch.com/2026/03/01/investors-spill-what-they-arent-looking-for-anymore-in-ai-saas-companies/",
      "date": 1772384400,
      "author": "Dominic-Madori Davis",
      "guid": 49409,
      "unread": true,
      "content": "<article>TechCrunch spoke with VCs to learn what investors aren't looking for in AI SaaS startups anymore. </article>",
      "contentLength": 98,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Collabora Clashes With LibreOffice Over Move To Revive LibreOffice Online",
      "url": "https://news.slashdot.org/story/26/03/01/042207/collabora-clashes-with-libreoffice-over-move-to-revive-libreoffice-online?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1772382840,
      "author": "EditorDavid",
      "guid": 49392,
      "unread": true,
      "content": "Slashdot reader darwinmac writes: The Document Foundation (TDF), the organization behind LibreOffice, has decided to bring back its LibreOffice Online project which been inactive since 2022. Collabora, a company that was a major contributor to the original LibreOffice Online, is not pleased with this development. After the original project went dormant, Collabora forked the code and created its own product, Collabora Online.\n\n Collaboras Michael Meeks, who also sits on the TDF board, reacted to the TDFs decision by saying that a fully supported, free online version already exists in the form of Collabora Online, and that resurrecting a dead repository makes little sense when an active, open community around the online suite already exists.\n\n For now, The Document Foundation plans to reopen the old repository for new contributions. The organization has issued a warning that the code is not ready for live deployment and users should wait until the development team confirms it is stable.",
      "contentLength": 999,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "OpenAI reveals more details about its agreement with the Pentagon",
      "url": "https://techcrunch.com/2026/03/01/openai-shares-more-details-about-its-agreement-with-the-pentagon/",
      "date": 1772382610,
      "author": "Anthony Ha",
      "guid": 49408,
      "unread": true,
      "content": "<article>By CEO Sam Altman‚Äôs own admission, OpenAI‚Äôs deal with the Department of Defense was ‚Äúdefinitely rushed,‚Äù and ‚Äúthe optics don‚Äôt look good.‚Äù</article>",
      "contentLength": 152,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Yes, Crypto Millionaires Exist: Here‚Äôs How They Did It",
      "url": "https://hackernoon.com/yes-crypto-millionaires-exist-heres-how-they-did-it?source=rss",
      "date": 1772381363,
      "author": "Obyte",
      "guid": 49414,
      "unread": true,
      "content": "<p>It‚Äôs fair to think that this could only be a myth, but it's actually not. There  people who have become millionaires with Bitcoin and crypto investments. Does this mean you will do it, too? Who knows. The reality is more complex than just a little investment, and without a doubt, the crypto market is much more complex now than it was before.</p><p><strong>What we do know, though, is that the stories of these people are real. The stats are real, and their luck or conscious decisions were real</strong>. At this point, when we say ‚Äúcrypto millionaire,‚Äù we mean someone who holds (or held in the past) at least one million US dollars in cryptocurrencies, measured by market value. Probably, this amount was initially just a few cents or dollars that grew with time and patience.</p><p>Let‚Äôs explore this idea of crypto millionaires and what they did to become one.</p><p>Most cryptocurrencies have public chains, so we have public stats. We know which addresses are richer, and how many. The  estimated that <strong>over 241,700 users worldwide held at least one million dollars in crypto assets at some point during the previous year.</strong> That count included around 145,100 Bitcoin millionaires alone, reflecting Bitcoin‚Äôs dominant share of total market value. We can even  in real time with percentages and USD equivalents.</p><p>To include some names, we have  of the top Bitcoin holders in 2026. Besides Satoshi Nakamoto and institutions like Binance, Robinhood, Bitfinex, Tether, and the US government, we also have unknown whales around, with millions and up to billions in BTC holdings.</p><p>Market capitalization and historical prices aren‚Äôt a myth, either. We can travel back to 2013, for instance, when the total crypto market cap was around $1.6 billion, and the Bitcoin price was about $135 per coin []. By January 2026, the total market cap surpassed $3 trillion, and the Bitcoin price was at $86k (not to mention previous records of over $126k). That represents increases of 187,400% and up to 93,233%, respectively.</p><p>In other words, if you had bought $1,200 in BTC in 2013 and held on for dear life (HODL) all these years, you would have over one million dollars today.</p><p>Besides stats and anonymous addresses, we have some well-documented cases with names and stories. Likely the younger millionaire here is , who invested in Bitcoin when he was barely 12 years-old. <strong>His grandma gave him $1,000, and he bought BTC at $12 per unit in 2011.</strong> He founded an educational startup with his earnings in 2014 and sold it for 300 BTC in 2015. So, thanks to Bitcoin, he was a millionaire before turning 18.</p><p> is another young investor: he sold some of his toys to invest in Bitcoin when he was just 11 years-old, in 2012. He also bought Ether in 2016 and made himself a millionaire with his crypto trades. Now, also speaking about Ether,  is worth mentioning. He bet his life savings and family house on buying ETH in 2016, when the currency was barely known. The result was $13 million by 2017. He did his research, but of course, doesn‚Äôt recommend trying this extremely risky move at home (or with your house).</p><p>The  isn‚Äôt exactly a non-anonymous case, but we know that the person behind it‚Äôs an early Bitcoin miner. <strong>This charity fund appeared in 2017, revealing plans to donate more than 5,000 BTC to ONGs and some individuals in need.</strong> That was between $55 and $86 million at the time. The organizer, ‚ÄúPine,‚Äù explained that the coins had been acquired quietly years earlier and left untouched while Bitcoin climbed. They had more money than they could ever spend.</p><p>More recently, we can mention the case of two middle-aged . Tommy, James, and several of their family members bought about $8,000 in Shiba Inu (SHIB), a memecoin, before the price exploded in 2021. They ended up making up to $9 million.</p><p>Well, not every crypto millionaire around just bought and sat to wait. Some of them are familiar faces who became wealthy by building infrastructure or companies related to digital assets. <strong>Among them, Changpeng Zhao (CZ), founder of Binance,  for having sold his apartment to buy Bitcoin in 2013.</strong> He launched the exchange in 2017 after a successful Initial Coin Offering (ICO), and now, , he‚Äôs the 23rd richest person in the world, with a net worth of around $78.8 billion.</p><p>Jihan Wu is another good example. He co-founded Bitmain in 2013, one of the largest manufacturers of ASIC machines for Bitcoin mining. In 2021, he also launched Bitdeer, which is among the largest Bitcoin miners by computing power. Wu‚Äôs net worth has been  at around $2.3 billion.</p><p>Around 2013 as well, when Bitcoin was young and Ethereum didn‚Äôt exist yet, <strong>Cameron and Tyler Winklevoss turned a famous $65 million legal settlement over Facebook into a huge cryptocurrency presence.</strong> about $11 million to buy Bitcoin when it was roughly $100-120 per coin, giving them 1% of all Bitcoin in existence at the time. Some years later, in 2014, they founded the regulated crypto exchange Gemini. This platform became one of the biggest U.S. exchanges for buying, selling, and storing digital assets.  lists each twin with a net worth of around $3.7 billion as of early 2026, largely from crypto holdings and Gemini‚Äôs growth.</p><p>At this point, there are plenty of predictions. The dream of every crypto investor is to see Bitcoin reach one million per coin. If that‚Äôs even possible, we don‚Äôt know yet. If you can buy a memecoin for a few cents today and see a price explosion of 100,000%+ tomorrow, only luck can tell. All investors mentioned above went in before mainstream awareness, when prices were low, and uncertainty was high. Holding through sharp drops mattered just as much. This is really a mix of research and faith, but we need to remember that cryptocurrencies aren‚Äôt just speculation.</p><p><strong>They were created as a way to get rid of middlemen like banks and governments. It‚Äôs free money (as in freedom) available for everyone, everywhere, anytime.</strong> If you have your keys, no one else can have your coins. In , we have our own  of addresses (for GBYTE holdings), but what really matters is that no middleman can take your coins away.</p><p>Without miners or ‚Äúvalidators,‚Äù Obyte offers a multipurpose platform where you can trade and invest your crypto holdings without censorship concerns. At the end of the day, the first real step to becoming a millionaire is having complete control over your assets.</p><p>:::info\nFeatured Vector Image by macrovector / </p>",
      "contentLength": 6384,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "The HackerNoon Newsletter: The 7 Best Coparenting Apps in 2026 (3/1/2026)",
      "url": "https://hackernoon.com/3-1-2026-newsletter?source=rss",
      "date": 1772381046,
      "author": "Noonification",
      "guid": 49413,
      "unread": true,
      "content": "<p>ü™ê What‚Äôs happening in tech today, March 1, 2026?</p><p>By <a href=\"https://hackernoon.com/u/microsoft\">@microsoft</a> [ 27 Min read ] Microsoft‚Äôs AutoDev uses AI agents to write, test, and fix code autonomously, hitting 91.5% on HumanEval in Docker. <a href=\"https://hackernoon.com/microsoft-autodev-the-ai-that-builds-code-on-its-own\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/solosatoshi\">@solosatoshi</a> [ 7 Min read ] I replaced $1,200/year in cloud subscriptions with one home server. Heres the setup, costs, apps, Bitcoin node, local AI, and what Id do differently.  <a href=\"https://hackernoon.com/i-replaced-$1200year-in-cloud-subscriptions-with-a-single-home-server-heres-what-i-learned\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/confluent\">@confluent</a> [ 5 Min read ] Learn how Python developers build real-time AI agents using MCP, Kafka, and Flink‚Äîmodern agentic workflows explained on HackerNoon. <a href=\"https://hackernoon.com/how-python-devs-can-build-ai-agents-using-mcp-kafka-and-flink\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/melissaindia\">@melissaindia</a> [ 4 Min read ] Learn 6 proven strategies to secure executive buy-in for Master Data Management by aligning MDM with ROI, risk reduction, and business goals. <a href=\"https://hackernoon.com/selling-master-data-management-to-leadership-6-proven-strategies\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/saumyatyagi\">@saumyatyagi</a> [ 15 Min read ] Most teams plateau at AI writes code, a human reviews it. This article presents the Dark Factory Pattern ‚Äî a four-phase architecture using holdout scenarios a <a href=\"https://hackernoon.com/the-dark-factory-pattern-moving-from-ai-assisted-to-fully-autonomous-coding\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/stevebeyatte\">@stevebeyatte</a> [ 7 Min read ] Compare the 7 best co-parenting apps in 2026, including BestInterest, OurFamilyWizard, and TalkingParents. Find the right app for high-conflict situations.  <a href=\"https://hackernoon.com/the-7-best-coparenting-apps-in-2026\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/chris127\">@chris127</a> [ 8 Min read ] Stablecoins arent just crypto dollars‚Äîtheyre experiments in digital money stability. Each type offers different trade-offs, learn more about them here <a href=\"https://hackernoon.com/a-comprehensive-guide-to-stablecoins-types-risks-and-the-future-of-digital-money\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/mexcmedia\">@mexcmedia</a> [ 2 Min read ] MEXC COO Vugar Usi explains why retail-first exchanges are winning in crypto‚Äôs 2026 reset, leveraging zero-fee trading and user trust. <a href=\"https://hackernoon.com/navigating-cryptos-2026-reset-why-retail-first-exchanges-are-winning\">Read More.</a></p><p>üßë‚Äçüíª What happened in your world this week?</p><p>We hope you enjoy this worth of free reading material. Feel free to forward this email to a nerdy friend who'll love you for it.See you on Planet Internet! With love, \n The HackerNoon Team ‚úåÔ∏è</p>",
      "contentLength": 1774,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Galileo's Handwritten Notes Discovered in a Medieval Astronomy Text",
      "url": "https://science.slashdot.org/story/26/02/28/0419233/galileos-handwritten-notes-discovered-in-a-medieval-astronomy-text?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1772379240,
      "author": "EditorDavid",
      "guid": 49381,
      "unread": true,
      "content": "In a library in Florence, Italy, historian Ivan Malara noticed handwritten notes on a book printed in the 1500s ‚Äî and recognized the handwriting as Galileo's. The finding \"promises new insights into one of the most famous ideological transitions in the history of science,\" writes Science magazine ‚Äî since the book Galileo annotated was a reprint of Ptolemy's second-century work arguing that the earth was the center of the universe.\n\nGalileo's notes, perhaps written around 1590, or roughly 2 decades before his groundbreaking telescope observations of the Moon and Jupiter, reveal someone who both revered and critically dissected Ptolemy's work. And they imply, Malara argues, that Galileo ultimately broke with Ptolemy's cosmos because his mastery of the traditional paradigm's reasoning convinced him that a heliocentric [sun-centered] system would better fulfill Ptolemy's own mathematical logic.\n",
      "contentLength": 908,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Honor says its ‚ÄòRobot phone‚Äô with moving camera can dance to music",
      "url": "https://techcrunch.com/2026/03/01/honor-says-its-robot-phone-with-moving-camera-can-dance-to-music/",
      "date": 1772379000,
      "author": "Ivan Mehta",
      "guid": 49384,
      "unread": true,
      "content": "<article>Honor first teased its ‚ÄúRobot phone‚Äù with a movable camera arm earlier this year. Ahead of the Mobile World Congress (MWC) in Barcelona, the Chinese company provided more details about the device, including how the robot can respond to different situations without commands. The company said that it is planning to launch this device in [‚Ä¶]</article>",
      "contentLength": 346,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Honor launches its new slim foldable Magic V6 with a 6,600 mAh battery",
      "url": "https://techcrunch.com/2026/03/01/honor-launches-its-new-slim-foldable-magic-v6-with-a-6600-mah-battery/",
      "date": 1772377989,
      "author": "Ivan Mehta",
      "guid": 49383,
      "unread": true,
      "content": "<article>Honor also previewed battery tech that could take foldable batteries over 7,000 mAh mark</article>",
      "contentLength": 88,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Linux 7.1 Expected To See Nice Improvements For Reducing HRTICK Timer Overhead",
      "url": "https://www.phoronix.com/news/Linux-7.1-HRTICK-Timer",
      "date": 1772376925,
      "author": "Michael Larabel",
      "guid": 49376,
      "unread": true,
      "content": "<article>A big set of kernel patches look like they will be submitted for the Linux 7.1 kernel cycle this spring to optimize the scheduler HRTICK timer and in turn allowing it to be enabled by default...</article>",
      "contentLength": 194,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Rust 1.77.0: C-String Literals and More",
      "url": "https://hackernoon.com/rust-1770-c-string-literals-and-more?source=rss",
      "date": 1772373634,
      "author": "Rust (Technical Documentation)",
      "guid": 49412,
      "unread": true,
      "content": "<p>The Rust team is happy to announce a new version of Rust, 1.77.0. Rust is a programming language empowering everyone to build reliable and efficient software.</p><p>\\\nIf you have a previous version of Rust installed via , you can get 1.77.0 with:</p><p>\\\nIf you'd like to help us out by testing future releases, you might consider updating locally to use the beta channel () or the nightly channel (). Please <a href=\"https://github.com/rust-lang/rust/issues/new/choose\">report</a> any bugs you might come across!</p><p>This release is relatively minor, but as always, even incremental improvements lead to a greater whole. A few of those changes are highlighted in this post, and others may yet fill more niche needs.</p><p>Rust now supports C-string literals () which expand to a nul-byte terminated string in memory of type . This makes it easier to write code interoperating with foreign language interfaces which require nul-terminated strings, with all of the relevant error checking (e.g., lack of interior nul byte) performed at compile time.</p><h3>Support for recursion in </h3><p>Async functions previously could not call themselves due to a compiler limitation. In 1.77, that limitation has been lifted, so recursive calls are permitted so long as they use some form of indirection to avoid an infinite size for the state of the function.</p><p>\\\nThis means that code like this now works:</p><pre><code>async fn fib(n: u32) -&gt; u32 {\n   match n {\n       0 | 1 =&gt; 1,\n       _ =&gt; Box::pin(fib(n-1)).await + Box::pin(fib(n-2)).await\n   }\n}\n</code></pre><p>1.77.0 stabilizes  for struct fields, which provides access to the byte offset of the relevant public field of a struct. This macro is most useful when the offset of a field is required without an existing instance of a type. Implementing such a macro is already possible on stable, but without an instance of the type the implementation would require tricky unsafe code which makes it easy to accidentally introduce undefined behavior.</p><p>\\\nUsers can now access the offset of a public field with <code>offset_of!(StructName, field)</code>. This expands to a  expression with the offset in bytes from the start of the struct.</p><h3>Enable strip in release profiles by default</h3><p>Cargo <a href=\"https://doc.rust-lang.org/stable/cargo/reference/profiles.html\">profiles</a> which do not enable <a href=\"https://doc.rust-lang.org/stable/cargo/reference/profiles.html#debug\">debuginfo</a> in outputs (e.g., ) will enable  by default.</p><p>\\\nThis is primarily needed because the (precompiled) standard library ships with debuginfo, which means that statically linked results would include the debuginfo from the standard library even if the local compilations didn't explicitly request debuginfo.</p><p>\\\nUsers which do want debuginfo can explicitly enable it with the <a href=\"https://doc.rust-lang.org/stable/cargo/reference/profiles.html#debug\">debug</a> flag in the relevant Cargo profile.</p><ul><li><code>slice::split_first_chunk_mut</code></li><li><code>slice::split_last_chunk_mut</code></li></ul><p>Many people came together to create Rust 1.77.0. We couldn't have done it without all of you. <a href=\"https://thanks.rust-lang.org/rust/1.77.0/\">Thanks!</a></p>",
      "contentLength": 2675,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Online Censorship in Schools Is Impacting Teachers As Much as Students",
      "url": "https://hackernoon.com/online-censorship-in-schools-is-impacting-teachers-as-much-as-students?source=rss",
      "date": 1772373604,
      "author": "The Markup",
      "guid": 49411,
      "unread": true,
      "content": "<p><em>The Markup, now a part of CalMatters, uses investigative reporting, data analysis, and software engineering to challenge technology to serve the public good. Sign up for</em><em><a href=\"https://mrkup.org/XvjZS\">Klaxon</a>, a newsletter that delivers our stories and tools directly to your inbox.</em></p><p>\\\nElizabeth Tyree was recently trying to teach her West Texas students about the connections between Emily Dickinson‚Äôs letters and her poetry. The project she designed asked students to read Dickinson‚Äôs correspondence and compare them to her art, finding examples of how one led to the other. Dickinson‚Äôs letters are available for free through The Internet Archive, a nonprofit, digital library that has, among other content, 44 million digitized books and texts at archive.org.</p><p>\\\nBut Tyree and her students couldn‚Äôt get to them. Archive.org is blocked by their school district. The federal government <a href=\"https://www.fcc.gov/consumers/guides/childrens-internet-protection-act\">effectively mandated</a> web filters for schools in 2000 through the Children‚Äôs Internet Protection Act. At the time, filters were seen as an important way to keep kids from accessing online porn. <a href=\"http://mrkup.org/block\">A Markup investigation</a> published earlier this month, however, showed these filters have morphed into tools of digital censorship, keeping students in some districts from abortion information, sex ed, and LGBTQ+ resources, including suicide prevention.</p><p>\\\nAfter our investigation published, teachers‚Äîincluding Tyree‚Äîtook to social media to point out how the web filters frustrate them, too.</p><p>\\\nTyree has been in classrooms for 16 years, teaching students of all ages a mix of English, writing, science, and music. Because the federal government only requires districts to keep students from obscene and harmful content and otherwise leaves them to block whatever else they want, Tyree has had different problems from one district to another. Sometimes tech support will unblock websites she asks to be unblocked, but her request to get her students access to Archive.org was recently denied over a concern that the website also hosts adult content.</p><p>\\\n‚ÄúIt was the only place online that we could get access to Emily Dickinson‚Äôs correspondence for free,‚Äù Tyree said. ‚ÄúWe had to change the entire project.‚Äù</p><p>\\\nKaitlyn D‚ÄôAnnibale, an athletic trainer in Washington, D.C. who works with high school athletes, has run into similar hurdles. She needs access to the healthcare website MedBridge both for continuing education and to create home exercise programs for the students she works with, but the site is blocked by her school.</p><p>\\\n‚ÄúThey pay for the membership, but I can‚Äôt access the site,‚Äù D‚ÄôAnnibale said.</p><p>\\\nWhen she needs to review hospital MRIs to assess students‚Äô playing capacity, she can‚Äôt go through the hospital portal to open them because such portals are blocked. Her workaround? Wait until she gets home to look on her own computer.</p><p>\\\nShe recently wanted to look up suicide prevention resources for a student. ‚ÄúAnything I put into Google that was ‚Äòsuicidal‚Äô anything got blocked,‚Äù D‚ÄôAnnibale said. Eventually she made it to a useful PDF by getting creative with the wording of her search terms.</p><p>\\\nD‚ÄôAnnibale said she has asked for sites to be unblocked in the past but the process is tedious and resolution is short-lived. Sites that the IT department has unblocked for her have reverted to being blocked. She hasn‚Äôt been able to figure out why.</p><p>\\\nOne commenter on TikTok said that the process for requesting sites be unblocked in her district requires her to do research about the blocked site (at home, where she can access it), make a case to an administrator, answer follow-up questions, wait for that person to take the request to a board for approval, and then answer more follow-up questions before a decision can be made.</p><p>\\\nAnother described a similar situation: ‚ÄúMy district has sites blocked that are actually in the curriculum. We‚Äôre supposed to contact our district [department] heads to ask them to get it unblocked. Like they don‚Äôt have enough to do. It‚Äôs ridiculous.‚Äù</p><p>\\\nOther teachers told The Markup about how hard it can be to make lesson plans for substitute teachers, because they aren‚Äôt sure which of the sites that are available to them are actually blocked to subs and students. They described indiscriminate blocks to YouTube, Pinterest, and Wikipedia‚Äîsites that have useful educational resources mixed in with other content.</p><p>\\\nNancy Willard saw this all coming.</p><p>\\\nBack in 2000, Willard worked at the Center for Advanced Technology in Education at the University of Oregon and submitted testimony to the Children‚Äôs Internet Safety Committee, urging Congress not to require filters in the Children‚Äôs Internet Protection Act. Reached by phone this week, Willard called the filters a ‚Äútechnical, quick-fix solution‚Äù that either don‚Äôt work‚Äîbecause students find ways around them‚Äîor leave kids unprepared for the real world.</p><p>\\\n‚ÄúTheir world doesn‚Äôt have filtering software on their computers at home and their world as adults isn‚Äôt going to have filtering software,‚Äù Willard said. ‚ÄúSo if they haven‚Äôt developed the self-control, the ability to assess credibility of information, the ability to focus on the task at hand and not go play [online games], if they haven‚Äôt developed that ability, how effective are they going to be as adults?‚Äù</p><p>\\\nWillard‚Äôs insistence that schools teach students about safe internet use made it into the law. Of course, much to her dismay and the continued frustration of teachers all over the country, the filtering requirement did, too.</p>",
      "contentLength": 5513,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "SaaS in, SaaS out: Here‚Äôs what‚Äôs driving the SaaSpocalypse",
      "url": "https://techcrunch.com/2026/03/01/saas-in-saas-out-heres-whats-driving-the-saaspocalypse/",
      "date": 1772373600,
      "author": "Dominic-Madori Davis",
      "guid": 49371,
      "unread": true,
      "content": "<article>What's behind the SaaSpocalypse? It simply seems a new supreme has risen. </article>",
      "contentLength": 74,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "ASUS Linux HID Driver Preparing To See Support For Newer Devices",
      "url": "https://www.phoronix.com/news/ASUS-WMI-Linux-Driver-New-2026",
      "date": 1772365800,
      "author": "Michael Larabel",
      "guid": 49352,
      "unread": true,
      "content": "<article>There's been a recent lull in activity around the open-source Linux driver for ASUS devices with the HID interface used for supporting various features. But developer Denis Benato who has worked on the ASUS Armoury Linux driver and the like is working on advancing the ASUS HID driver for Linux systems...</article>",
      "contentLength": 305,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Some Linux LTS Kernels Will Be Supported Even Longer, Announces Greg Kroah-Hartman",
      "url": "https://linux.slashdot.org/story/26/03/01/0429234/some-linux-lts-kernels-will-be-supported-even-longer-announces-greg-kroah-hartman?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1772364840,
      "author": "EditorDavid",
      "guid": 49340,
      "unread": true,
      "content": "An anonymous reader shared this report from the blogIt's FOSS:\n\nGreg Kroah-Hartman has updated the projected end-of-life (EOL) dates for several active longterm support kernels via a commit. The provided reasoning? It was done \"based on lots of discussions with different companies and groups and the other stable kernel maintainer.\" The other maintainer is Sasha Levin, who co-maintains these Linux kernel releases alongside Greg. Now, the updated support schedule for the currently active LTS kernels looks like this: \n ‚Äî Linux 6.6 now EOLs Dec 2027 (was Dec 2026), giving it a 4-year support window. \n\n ‚Äî Linux 6.12 now EOLs Dec 2028 (was Dec 2026), also a 4-year window. \n\n ‚Äî Linux 6.18 now EOLs Dec 2028 (was Dec 2027), at least 3 years of support. \n\nWorth noting above is that Linux 5.10 and 5.15 are both hitting EOL this year in December, so if your distro is still running either of these, now is a good time to start thinking about a move.\n",
      "contentLength": 956,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Linux 7.0 Development & Intel Panther Lake Proved Most Popular In February",
      "url": "https://www.phoronix.com/news/February-2026-Recap",
      "date": 1772364555,
      "author": "Michael Larabel",
      "guid": 49351,
      "unread": true,
      "content": "<article>During the last month on Phoronix there were 289 original open-source/Linux-related news articles and another 20 featured articles as in Linux hardware reviews and multi-page benchmark articles. There was a lot of interesting software and hardware happenings the past month but standing out the most was the Linux 7.0 merge window developments and the ramp of Intel Panther Lake Linux testing...</article>",
      "contentLength": 395,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "GNU Hurd On Guix Is Ready With 64-bit Support, SMP Multi-Processor Support \"Soon\"",
      "url": "https://www.phoronix.com/news/GNU-Hurd-64-bit-2026",
      "date": 1772363280,
      "author": "Michael Larabel",
      "guid": 49350,
      "unread": true,
      "content": "<article>After hearing last month that GNU Hurd is \"almost there\" with x86_64 support, it was exciting to kickoff today by seeing a developer headline \"The 64-bit Hurd is Here!\" GNU Hurd 64-bit support is now said to be ready but SMP support for multiple processor cores and the like remain still in development...</article>",
      "contentLength": 305,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Intel's Clear Linux Website No Longer Online",
      "url": "https://www.phoronix.com/news/Clear-Linux-Org-No-More",
      "date": 1772362856,
      "author": "Michael Larabel",
      "guid": 49349,
      "unread": true,
      "content": "<article>Last July Intel sadly ended their Clear Linux distribution amid cost-cutting measures at the company. Clear Linux for a decade served at the forefront of Linux performance innovations and was consistently the fastest out-of-the-box Linux x86_64 distribution until Intel ended the Linux distribution without any advanced notice for its users. Intel had kept up the ClearLinux.org website online to download the final releases and access other technical content and forum discussions, etc. Sadly, that too was recently taken offline...</article>",
      "contentLength": 533,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Letting Machines Decide What Matters",
      "url": "https://spectrum.ieee.org/ai-new-physics",
      "date": 1772362803,
      "author": "Eliza Strickland",
      "guid": 49330,
      "unread": true,
      "content": "<p>AI systems in particle detectors now shape what physicists study</p>",
      "contentLength": 64,
      "flags": null,
      "enclosureUrl": "https://spectrum.ieee.org/media-library/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpbWFnZSI6Imh0dHBzOi8vYXNzZXRzLnJibC5tcy82NTAwNTQ3Ni9vcmlnaW4ucG5nIiwiZXhwaXJlc19hdCI6MTgyNDE3MjAxOX0.QlMo5IFUTRcgh7zKth97HuudGJgWc1nPjwiH9gJ6cEo/image.png?width=600",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Anthropic's Claude Leaps to #2 on Apple's 'Top Apps' Chart After Pentagon Controversy",
      "url": "https://slashdot.org/story/26/02/28/2046221/anthropics-claude-leaps-to-2-on-apples-top-apps-chart-after-pentagon-controversy?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1772354040,
      "author": "EditorDavid",
      "guid": 49329,
      "unread": true,
      "content": "Anthropic's Claude AI assistant \"jumped to the No. 2 slot on Apple's chart of top U.S. free apps late on Friday,\" reports CNBC:\n\n\nThe rise in popularity suggests that Anthropic is benefiting from its presence in news headlines, stemming from its refusal to have its models used for mass domestic surveillance or for fully autonomous weapons... OpenAI's ChatGPT sat at No. 1 on the App Store rankings on Saturday, while Google's Gemini was at No. 3... On Jan. 30, [Claude] was ranked No. 131 in the U.S., and it bounced between the top 20 and the top 50 for much of February, according to data from analytics company Sensor Tower... [And Friday night, for 85.3 million followers] pop singer Katy Perry posted a screenshot of Anthropic's Pro subscription for consumers, with a heart superimposed over it. \n\nFriday Anthropic posted \"We are deeply grateful to our users, and to the industry peers, policymakers, veterans, and members of the public who have voiced their support in recent days. Thank you. \"",
      "contentLength": 1002,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "The TechBeat: The State of The Noonion: Blogging Our Way Through the AI Boom (3/1/2026)",
      "url": "https://hackernoon.com/3-1-2026-techbeat?source=rss",
      "date": 1772349077,
      "author": "Techbeat",
      "guid": 49344,
      "unread": true,
      "content": "<p>By <a href=\"https://hackernoon.com/u/mexcmedia\">@mexcmedia</a> [ 2 Min read ] \n MEXC COO Vugar Usi explains why retail-first exchanges are winning in crypto‚Äôs 2026 reset, leveraging zero-fee trading and user trust. <a href=\"https://hackernoon.com/navigating-cryptos-2026-reset-why-retail-first-exchanges-are-winning\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/crafinsstudio\">@crafinsstudio</a> [ 20 Min read ] \n I tested eight piano apps on two pianos for three weeks. Here's what I'd actually recommend. <a href=\"https://hackernoon.com/best-piano-learning-apps-in-2026-an-in-depth-comparison-of-music-education-technology\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/lomitpatel\">@lomitpatel</a> [ 5 Min read ] \n How CMOs win CFO buy-in using incrementality, trust, AI, and capital allocation to drive margin expansion and revenue durability. <a href=\"https://hackernoon.com/how-cmos-win-cfo-buy-in-at-scale\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/qatech\">@qatech</a> [ 8 Min read ] \n Manual testing can't keep up with modern development. See how QA.tech's AI testing automation catches bugs on every PR -- no Playwright or Cypress scripts to ma <a href=\"https://hackernoon.com/the-ai-builder-stack-linear-cursor-vercel-and-qatech\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/saumyatyagi\">@saumyatyagi</a> [ 15 Min read ] \n Most teams plateau at \"AI writes code, a human reviews it.\" This article presents the Dark Factory Pattern ‚Äî a four-phase architecture using holdout scenarios a <a href=\"https://hackernoon.com/the-dark-factory-pattern-moving-from-ai-assisted-to-fully-autonomous-coding\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/scylladb\">@scylladb</a> [ 5 Min read ] \n Blitz migrated from Postgres and Elixir to Rust and ScyllaDB, cutting latency, costs, and 100+ cores down to four cloud nodes. <a href=\"https://hackernoon.com/rust-rewrite-postgres-exit-blitz-revamps-its-league-of-legends-backend\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/noonion\">@noonion</a> [ 13 Min read ] \n HackerNoon‚Äôs 2016‚Äì2026 evolution: $727k Q4 revenue, 62% Business Blogging CAGR, 4.4M monthly pageviews, and resilient, AI-aware publishing. <a href=\"https://hackernoon.com/the-state-of-the-noonion-blogging-our-way-through-the-ai-boom\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/melissaindia\">@melissaindia</a> [ 4 Min read ] \n Learn 6 proven strategies to secure executive buy-in for Master Data Management by aligning MDM with ROI, risk reduction, and business goals. <a href=\"https://hackernoon.com/selling-master-data-management-to-leadership-6-proven-strategies\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/confluent\">@confluent</a> [ 5 Min read ] \n Learn how Python developers build real-time AI agents using MCP, Kafka, and Flink‚Äîmodern agentic workflows explained on HackerNoon. <a href=\"https://hackernoon.com/how-python-devs-can-build-ai-agents-using-mcp-kafka-and-flink\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/chris127\">@chris127</a> [ 8 Min read ] \n Stablecoins aren't just \"crypto dollars\"‚Äîthey're experiments in digital money stability. Each type offers different trade-offs, learn more about them here <a href=\"https://hackernoon.com/a-comprehensive-guide-to-stablecoins-types-risks-and-the-future-of-digital-money\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/mexcmedia\">@mexcmedia</a> [ 2 Min read ] \n MEXC ranks No. 1 globally in XAUT perpetual volume, hitting $3.43B as tokenized gold demand rises amid record spot gold prices in 2026. <a href=\"https://hackernoon.com/mexc-ranks-no-1-in-xaut-perpetual-volume-globally-demonstrating-strong-liquidity-and-user-activity\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/scylladb\">@scylladb</a> [ 4 Min read ] \n Discover how Yieldmo migrated from DynamoDB to ScyllaDB to cut database costs, achieve multicloud flexibility, and deliver ads in single-digit millisecond laten <a href=\"https://hackernoon.com/how-yieldmo-cut-database-costs-and-cloud-dependencies\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/opensourcetheworld\">@opensourcetheworld</a> [ 7 Min read ] \n I replaced $1,200/year in cloud subscriptions with one home server. Here's the setup, costs, apps, Bitcoin node, local AI, and what I'd do differently.  <a href=\"https://hackernoon.com/i-replaced-$1200year-in-cloud-subscriptions-with-a-single-home-server-heres-what-i-learned\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/khamisihamisi\">@khamisihamisi</a> [ 4 Min read ] \n Western tech is built in environments of abundance. In emerging markets, these assumptions often fail quickly. <a href=\"https://hackernoon.com/building-for-emerging-markets-what-western-startups-miss\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/davidiyanu\">@davidiyanu</a> [ 8 Min read ] \n Cloud cost and system reliability are the same problem viewed through different instruments.  <a href=\"https://hackernoon.com/when-cloud-bills-crash-the-system-cost-as-a-reliability-issue\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/thomascherickal\">@thomascherickal</a> [ 51 Min read ] \n Google Antigravity is not just for coding. It is for your entire computer. Stop scrolling - everything you do on a computer has just been automated. <a href=\"https://hackernoon.com/google-antigravity-the-disruptor-that-just-changed-the-computing-world-forever\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/johnpphd\">@johnpphd</a> [ 4 Min read ] \n How precompiling context for AI agents beats context stuffing. Lessons from building 100+ specialized agents for a web3 application. <a href=\"https://hackernoon.com/lessons-from-building-a-100-agent-swarm-in-web3\">Read More.</a></p><p>](https://hackernoon.com/the-complete-guide-to-ai-agent-memory-files-claudemd-agentsmd-and-beyond)** <img src=\"https://cdn.hackernoon.com/images/mpDOI8AQeYeu5cc9VGleWjM9xvB2-mu0383b.png\" alt=\"\">\n By <a href=\"https://hackernoon.com/u/paoloap\">@paoloap</a> [ 7 Min read ] \n Learn how CLAUDE.md, AGENTS.md, and AI memory files work. Covers file hierarchy, auto-memory, @imports, and which files you actually need for your setup. <a href=\"https://hackernoon.com/the-complete-guide-to-ai-agent-memory-files-claudemd-agentsmd-and-beyond\">Read More.</a></p>",
      "contentLength": 3343,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Silicon Valley's Ideas Mocked Over Penchant for Favoring Young Entrepreneurs with 'Agency'",
      "url": "https://slashdot.org/story/26/03/01/011246/silicon-valleys-ideas-mocked-over-penchant-for-favoring-young-entrepreneurs-with-agency?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1772343240,
      "author": "EditorDavid",
      "guid": 49296,
      "unread": true,
      "content": "In a 9,000-word expose, a writer for Harper's visited San Francisco's young entrepreneurs in September to mockingly profile \"tech's new generation and the end of thinking.\" \nThere's Cluely founder Roy Lee. (\"His grand contribution to the world was a piece of software that told people what to do.\") And the Rationalist movement's Scott Alexander, who \"would probably have a very easy time starting a suicide cult...\"\n\nAlexander's relationship with the AI industry is a strange one. \"In theory, we think they're potentially destroying the world and are evil and we hate them,\" he told me. In practice, though, the entire industry is essentially an outgrowth of his blog's comment section... \"Many of them were specifically thinking, I don't trust anybody else with superintelligence, so I'm going to create it and do it well.\" Somehow, a movement that believes AI is incredibly dangerous and needs to be pursued carefully ended up generating a breakneck artificial arms race. \n\nThere's a fascinating story about teenaged founder Eric Zhu (who only recently turned 18):\n\nClients wanted to take calls during work hours, so he would speak to them from his school bathroom. \"I convinced my counselor that I had prostate issues... I would buy hall passes from drug dealers to get out of class, to have business meetings.\" Soon he was taking Zoom calls with a U.S. senator to discuss tech regulation... Next, he built his own venture-capital fund, managing $20 million. At one point cops raided the bathroom looking for drug dealers while Eric was busy talking with an investor. Eventually, the school got sick of Eric's misuse of the facilities and kicked him out. He moved to San Francisco. \n\nEric made all of this sound incredibly easy. You hang out in some Discord servers, make a few connections with the right people; next thing you know, you're a millionaire... Eric didn't think there was anything particularly special about himself. Why did he, unlike any of his classmates, start a $20 million VC fund? \"I think I was just bored. Honestly, I was really bored.\" Did he think anyone could do what he did? \"Yeah, I think anyone genuinely can.\" \n\nThe article concludes Silicon Valley's investors are rewarding young people with \"agency\". Although \"As far as I could tell, being a highly agentic individual had less to do with actually doing things and more to do with constantly chasing attention online.\" Like X.com user Donald Boat, who successfully baited Sam Altman into buying him a gaming PC in \"a brutally simplified miniature of the entire VC economy.\" (After which \"People were giving him stuff for no reason except that Altman had already done it, and they didn't want to be left out of the trend.\")\n\nShortly before I arrived at the Cheesecake Factory, [Donald Boat] texted to let me know that he'd been drinking all day, so when I met him I thought he was irretrievably wasted. In fact, it turned out, he was just like that all the time... He seemed to have a constant roster of projects on the go. He'd sent me occasional photos of his exploits. He went down to L.A. to see Oasis and ended up in a poker game with a group of weapons manufacturers. \"I made a bunch of jokes about sending all their poker money to China,\" he said, \"and they were not pleased....\" \n\n\"I don't use that computer and I think video games are a waste of time. I spent all the money I made from going viral on Oasis tickets.\" As far as he was concerned, the fact that tech people were tripping over themselves to take part in his stunt just confirmed his generally low impression of them. \"They have too much money and nothing going on...\" Ever since his big viral moment, he'd been suddenly inundated with messages from startup drones who'd decided that his clout might be useful to them. One had offered to fly him out to the French Riviera. \n\nThe author's conclusion? \"It did not seem like a good idea to me that some of the richest people in the world were no longer rewarding people for having any particular skills, but simply for having agency.\"",
      "contentLength": 4037,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Rebuild Your Life in 180 Days: The No-Excuses Blueprint",
      "url": "https://hackernoon.com/rebuild-your-life-in-180-days-the-no-excuses-blueprint?source=rss",
      "date": 1772343004,
      "author": "BenoitMalige",
      "guid": 49343,
      "unread": true,
      "content": "<p>\\\n\\\nIf you apply what‚Äôs on this email to the T, you can rebuild yourself in six months. Bold statement? Yes.</p><p>But give me a few minutes and I‚Äôll gift you the EXACT blueprint for:</p><ul><li>A different baseline of energy.</li><li>A different standard for what you tolerate.</li><li>A different life altogether.</li></ul><p>And this is not manifestation. This is&nbsp;, and this is what we do here.</p><p>We will work on: identity, body, skills, environment, mind, and social circle. \\n Run all six or don‚Äôt waste your time. Half-transformations are just elaborate procrastination.</p><p>180 days. For a completely new life. This is important. This is doable. All you have to do is apply this.</p><p>\\\nIf you don‚Äôt change your identity, you‚Äôll drag the same problems into your ‚Äúnew‚Äù life like a moldy suitcase. Most people fail not here because they try to bolt new habits onto an old self-image.</p><p>&nbsp;and&nbsp;&nbsp;transformation begins when you burn the blueprint of the person you‚Äôve been and draw a new one from scratch. Humans behave in a way that matches the story they believe about themselves, even when the story sucks.</p><p>If you think of yourself as someone who&nbsp;to get in shape, you‚Äôll sabotage yourself like clockwork. \\n If you think of yourself as someone who&nbsp;in shape, your decisions start matching that identity automatically.</p><p>before strategy. \\n before habits. \\n &nbsp;before everything.</p><p>Everything (how you eat, how you talk, how you sit, how you dress) has to come from the new identity. If it doesn‚Äôt align, it dies.</p><p>When your actions don‚Äôt match the person you claim to be, your brain rings the alarm. Everyone around you feels it too. Nothing smells worse than someone pretending to have standards they don‚Äôt enforce.</p><p>Stop being the person who ‚Äúintends.‚Äù \\n <strong>Become the person who ‚Äúdoes.‚Äù</strong></p><p>Before you rebuild, you rip out the rotten floorboards:</p><ul></ul><p>Each one gets one question:</p><p><strong>Does this serve the future I‚Äôm building?</strong></p><p>If it‚Äôs not a hell yes, it‚Äôs a surgical no.</p><p>Delete the apps. \\n Cut the friends. \\n Change the job. \\n Burn the costume.</p><p>Yes, it hurts. \\n No, it won‚Äôt kill you. \\n .</p><h3><strong>Treat your new identity like religion</strong></h3><p>Rituals. Symbols. Structure.</p><p>Morning routines, nighttime reflections, clothes that match your new standard, reminders on your wall, habits you don‚Äôt negotiate.</p><p>Your&nbsp;&nbsp;won‚Äôt die quietly. It will bribe you with nostalgia, craving, laziness, and bullshit stories about balance.</p><p>Expect relapse thoughts. \\n Prepare counters. \\n .</p><ol><li>Choose your archetype ‚Äî Write your identity profile: habits, values, style, energy, boundaries, even flaws.</li><li>Cut contradictions ‚Äî If your environment belongs to the old you,&nbsp;</li><li>Act as if from day one ‚Äî No ‚Äúwarming up.‚Äù You switch&nbsp;</li><li>Document the proof ‚Äî Log every moment you acted like the new identity.</li><li>Protect the signal ‚Äî Avoid people, environments, or content that drag you back.</li><li>Accelerate the feedback loop ‚Äî Put yourself in rooms where the new identity is&nbsp;&nbsp;to belong.</li></ol><p>Once the identity locks in, your reality rearranges itself around you.</p><p><em>(Your body is the receipt for your discipline.)</em></p><p>You can talk about transformation all day. \\n Your body is the part you can‚Äôt fake.</p><p>When you walk into a room with a completely different body:</p><ul><li>People treat you differently</li><li>You treat yourself differently</li></ul><p>This isn‚Äôt about six-pack obsession. \\n This is about building a body that proves you finish what you start.</p><p>Every rep becomes a vote. Every walk reinforces grit. Every choice cements identity.</p><p>Most people fail because they try to ‚Äúfit fitness in.‚Äù \\n You don‚Äôt fit transformation into your life. \\n You build your damn life around it.</p><p>Discipline in the kitchen ‚Üí discipline everywhere. \\n Sloppiness in the body ‚Üí sloppiness in ambition.</p><p>‚ÄúHow you do one thing is how you do everything‚Äù is clich√© because it‚Äôs true.</p><p>One day, I decided to work out every single day. It‚Äôs a non negotiable. This is what I do, but you don‚Äôt have to go that extreme.</p><p>1. Train 4x/week minimum ‚Äî Heavy lifts. Push/pull/legs/full-body. \\n Bonus: Add two long incline walks weekly.</p><p>2. Eat like an adult, not a toddler</p><ul><li>Same meals every day (or close)</li></ul><p>Alcohol, weed, binge nights. Anything that unravels discipline. Cut it.</p><p>4. Walk 10,000 steps a day </p><p>Rain or shine. Inside or outside. No excuses.</p><p>5. Sleep like it‚Äôs a performance drug </p><p>Because It is. \\n 7.5 hours minimum. \\n No screens 1‚Äì2 hours before bed. \\n No caffeine after 2 p.m.</p><p>If you‚Äôre not measuring, you‚Äôre guessing. \\n And guessing is how you stay average.</p><p>The gap is where normal people quit and transformed people are born.</p><p>You lift when you‚Äôre tired. \\n You walk when it rains. \\n You prep meals when everyone else is ordering Uber Eats.</p><p>That‚Äôs what creates the gulf between you and the old you.</p><p><em>(You don‚Äôt need more confidence. You need skills that print confidence on demand.)</em></p><p>\\\nOnce the body and identity are locked in, you weaponize them.</p><p>Power in the modern world = skills. \\n Stackable, monetizable, rare skills.</p><p>Skills put you in rooms the old you couldn‚Äôt even pronounce.</p><p>Most people ‚Äúlearn‚Äù the slow way by dabbling, exploring, taking courses and doing nothing with them.</p><p>You? \\n You learn like your life depends on it. There is a full chapter dedicated to that in. Use it.</p><p>The old you takes 6 months to start something. \\n The new you learns a high-income skill in 2 weeks and gets paid by week 4.</p><p>It‚Äôs not intelligence. \\n It‚Äôs intensity.</p><ul></ul><p>Pick ONE. \\n Master it. \\n Stack the others later.</p><h3><strong>The 90-day mastery protocol</strong></h3><ol><li><p>Choose one skill ‚Äî Eliminate everything else.</p></li><li><p>7-day deep dive ‚Äî Saturate your brain. \\n 6+ hours/day. (you‚Äôll find the time) \\n Books, videos, podcasts, notes.</p></li><li><p>Build one real project ‚Äî Landing page, video, funnel, outreach sequence. Something you can show.</p></li><li><p>Get feedback fast ‚Äî Ask someone 10 steps ahead to tear it apart. (ChatGPT can do that very well if you ask it nicely).</p></li><li><p>50 videos \\n 100 tweets \\n 100 cold emails \\n 10 funnels \\n Whatever matches your skill. VOLUME is king.</p></li><li><p>Get paid ASAP ‚Äî Even $39 counts. \\n Once someone pays you, you‚Äôre in business.</p></li></ol><p>Repeat until you‚Äôre dangerous.</p><p><em>(Willpower is overrated. Your environment is the real puppet master.)</em></p><p>\\\nYour environment will beat your discipline over time. \\n Always.</p><p>You can have the perfect mindset. \\n You can read the books. \\n You can ‚Äúbe motivated.‚Äù</p><p>But if you live in the same messy room, around the same lazy friends, with the same digital junk food‚Ä¶</p><p>You will snap back to baseline.</p><ul><li>Delete apps that hijack focus.</li><li>Unfollow accounts that normalize mediocrity.</li><li>Unfollow friends that don‚Äôt have what you want.</li><li>Clear your space of old-self objects and clutter.</li><li>Remove junk food, trash habits, and triggers.</li></ul><h3><strong>Make good habits frictionless</strong></h3><ul></ul><ul><li>Logged out of Netflix (have someone else change the password for you)</li><li>No snacks in the house. Seriously.</li></ul><h3><strong>Your circle counts as environment</strong></h3><p>If the people around you crawl, you won‚Äôt sprint.</p><p>You don‚Äôt need dramatic exits, just become harder to reach. \\n Distance does the work for you.</p><p>And sometimes? You literally need to move. \\n New city. \\n New apartment. \\n New country.</p><p>Fresh soil grows different roots. Don‚Äôt be scared of change.</p><ul><li>Create sacred zones (work, training, rest)</li></ul><p>When your environment stops tolerating the old you, the old you suffocates.</p><p><em>(If your mind is brittle, your success has an expiration date.)</em></p><p>You can have the body, the skills, the money.. but if your mind collapses under stress, criticism, or uncertainty, you‚Äôre toast.</p><p>Real resilience isn‚Äôt ‚Äústaying positive.‚Äù \\n That‚Äôs .</p><p><strong>Resilience is taking hits without turning them into excuses.</strong></p><ul><li>You become mentally strong by doing hard things on purpose.</li><li>You don‚Äôt react to every feeling.</li><li>The gap between impulse and action is where adulthood starts.</li><li>Most burned-out people aren‚Äôt doing too much ‚Äî they‚Äôre doing too little of what matters.</li></ul><p>When weakness shows up, you don‚Äôt negotiate with it. \\n You kill it.</p><p>You need a sentence that snaps you back into execution instantly.</p><p>Mine used to be: \\n <strong>‚ÄúStop bullshitting yourself. Move.‚Äù</strong></p><ul><li>3‚Äì5 non-negotiables daily</li><li>Weekly voluntary hardship (fasting, cold, public speaking, etc.)</li><li>Cut mental junk food (fear-driven news, gossip, chaos content)</li><li>Reinforce identity nightly</li></ul><p>When your mind becomes unshakeable, your life becomes predictable in the best way.</p><p><em>(Your circle is the hidden thermostat of your life.)</em></p><p>Every relationship is either a plus-one or a minus-one. \\n There is no neutral.</p><p>Someone is either feeding your fire or smothering it.</p><p>You become unrecognizable when you stop asking, \\n ‚ÄúDo I like this person?‚Äù \\n and start asking, \\n ‚ÄúDo they make me better?‚Äù</p><ul><li>Score each person (+1 / 0 / -1)</li><li>Replace with higher-caliber people</li><li>Hold boundaries like your life depends on it</li></ul><p>Your social ecosystem becomes a force multiplier. \\n When everyone around you is winning, discipline stops feeling like effort, it becomes the baseline.</p><p>\\\n<strong>The part everyone skips and wonders why nothing changes.</strong></p><ol><li>Pick a start date within 72 hours. No ‚Äúnext Monday‚Äù bullshit.</li><li>Run all six pillars in parallel. This is not a buffet. \\n You don‚Äôt pick favorites.</li><li>Measure your progress daily. Body, skills, environment, mindset, social shifts.&nbsp;.</li><li>Audit every 2 weeks. What works stays. \\n What stalls gets replaced.</li><li>Treat this like a mission, not a vibe. You‚Äôre not here to worship the process. \\n You‚Äôre here to become unrecognizable.</li></ol>",
      "contentLength": 9235,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Sam Altman Answers Questions on X.com About Pentagon Deal, Threats to Anthropic",
      "url": "https://news.slashdot.org/story/26/03/01/0233230/sam-altman-answers-questions-on-xcom-about-pentagon-deal-threats-to-anthropic?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1772332740,
      "author": "EditorDavid",
      "guid": 49279,
      "unread": true,
      "content": "Saturday afternoon Sam Altman announced he'd start answering questions on X.com about OpenAI's work with America's Department of War ‚Äî and all the developments over the past few days. (After that department's negotions had failed with Anthropic, they announced they'd stop using Anthropic's technology and threatened to designate it a \"Supply-Chain Risk to National Security\". Then they'd reached a deal for OpenAI's technology ‚Äî though Altman says it includes OpenAI's own similar prohibitions against using their products for domestic mass surveillance and requiring \"human responsibility\" for the use of force in autonomous weapon systems.) \nAltman said Saturday that enforcing that \"Supply-Chain Risk\" designation on Anthropic \"would be very bad for our industry and our country, and obviously their company. We said [that] to the Department of War before and after. We said that part of the reason we were willing to do this quickly was in the hopes of de-esclation.... We should all care very much about the precedent... To say it very clearly: I think this is a very bad decision from the Department of War and I hope they reverse it. If we take heat for strongly criticizing it, so be it.\" \n\n\nAltman also said that for a long time, OpenAI was planning to do \"non-classified work only,\" but this week found the Department of War \"flexible on what we needed...\"\n\n Sam Altman: The reason for rushing is an attempt to de-escalate the situation. I think the current path things are on is dangerous for Anthropic, healthy competition, and the U.S. We negotiated to make sure similar terms would be offered to all other AI labs. \n\nI know what it's like to feel backed into a corner, and I think it's worth some empathy to the Department of War. They are... a very dedicated group of people with, as I mentioned, an extremely important mission. I cannot imagine doing their work. Our industry tells them \"The technology we are building is going to be the high order bit in geopolitical conflict. China is rushing ahead. You are very behind.\" And then we say \"But we won't help you, and we think you are kind of evil.\" I don't think I'd react great in that situation. I do not believe unelected leaders of private companies should have as much power as our democratically elected government. But I do think we need to help them. \n\n\n\nQuestion: Are you worried at all about the potential for things to go really south during a possible dispute over what's legal or not later on and be deemed a supply chain risk...? \n\n\n\nSam Altman: Yes, I am. If we have to take on that fight we will, but it clearly exposes us to some risk. I am still very hopeful this is going to get resolved, and part of why we wanted to act fast was to help increase the chances of that... \n\n\nQuestion: Why the rush to sign the deal ? Obviously the optics don't look great. \n\n\nSam Altman: It was definitely rushed, and the optics don't look good. We really wanted to de-escalate things, and we thought the deal on offer was good. \nIf we are right and this does lead to a de-escalation between the Department of War and the industry, we will look like geniuses, and a company that took on a lot of pain to do things to help the industry. If not, we will continue to be characterized as as rushed and uncareful. I don't where it's going to land, but I have already seen promising signs. I think a good relationship between the government and the companies developing this technology is critical over the next couple of years... \n\n\n\nQuestion: What was the core difference why you think the Department of War accepted OpenAI but not Anthropic? \n\n\nSam Altman: [...] We believe in a layered approach to safety--building a safety stack, deploying FDEs [embedded Forward Deployed Engineers] and having our safety and alignment researcher involved, deploying via cloud, working directly with the Department of War. Anthropic seemed more focused on specific prohibitions in the contract, rather than citing applicable laws, which we felt comfortable with. We feel that it it's very important to build safe system, and although documents are also important, I'd clearly rather rely on technical safeguards if I only had to pick one... \n\n\n\n\nI think Anthropic may have wanted more operational control than we did... \n\n\n\nQuestion: Were the terms that you accepted the same ones Anthropic rejected? \n\n\nSam Altman: No, we had some different ones. But our terms would now be available to them (and others) if they wanted. \n\n\n\nQuestion: Will you turn off the tool if they violate the rules? \n\n\n\nSam Altman: Yes, we will turn it off in that very unlikely event, but we believe the U.S. government is an institution that does its best to follow law and policy. What we won't do is turn it off because we disagree with a particular (legal military) decision. We trust their authority.\n\n \n\nQuestions were also answered by OpenAI's head of National Security Partnerships (who at one point posted that they'd managed the White House response to the Snowden disclosures and helped write the post-Snowden policies constraining surveillance during the Obama years.) And they stressed that with OpenAI's deal with Department of War, \"We control how we train the models and what types of requests the models refuse.\"\n\n\n\n\nQuestion: Are employees allowed to opt out of working on Department of War-related projects? \n\n\nAnswer: We won't ask employees to support Department of War-related projects if they don't want to. \n\n\n\nQuestion: How much is the deal worth? \n\n\nAnswer: It's a few million $, completely inconsequential compared to our $20B+ in revenue, and definitely not worth the cost of a PR blowup. We're doing it because it's the right thing to do for the country, at great cost to ourselves, not because of revenue impact... \n\n\n\n\nQuestion: Can you explicitly state which specific technical safeguard OpenAI has that allowed you to sign what Anthropic called a 'threat to democratic values'? \n\n\nAnswer: We think the deal we made has more guardrails than any previous agreement for classified AI deployments, including Anthropic's. Other AI labs (including Anthropic) have reduced or removed their safety guardrails and relied primarily on usage policies as their primary safeguards in national security deployments. Usage policies, on their own, are not a guarantee of anything. Any responsible deployment of AI in classified environments should involve layered safeguards including a prudent safety stack, limits on deployment architecture, and the direct involvement of AI experts in consequential AI use cases. These are the terms we negotiated in our contract. \n\nThey also detailed OpenAI's position on LinkedIn:\n\nDeployment architecture matters more than contract language. Our contract limits our deployment to cloud API. Autonomous systems require inference at the edge. By limiting our deployment to cloud API, we can ensure that our models cannot be integrated directly into weapons systems, sensors, or other operational hardware... \n\n\n\nInstead of hoping contract language will be enough, our contract allows us to embed forward deployed engineers, commits to giving us visibility into how models are being used, and we have the ability to iterate on safety safeguards over time. If our team sees that our models aren't refusing queries they should, or there's more operational risk than we expected, our contract allows us to make modifications at our discretion. This gives us far more influence over outcomes (and insight into possible abuse) than a static contract provision ever could. \n\n\n\nU.S. law already constrains the worst outcomes. We accepted the \"all lawful uses\" language proposed by the Department, but required them to define the laws that constrained them on surveillance and autonomy directly in the contract. And because laws can change, having this codified in the contract protects against changes in law or policy that we can't anticipate.",
      "contentLength": 7920,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "AerynOS 2026.02 Brings More Wayland Compositor Options, Other Improvements",
      "url": "https://www.phoronix.com/news/AerynOS-2026.02",
      "date": 1772327623,
      "author": "Michael Larabel",
      "guid": 49272,
      "unread": true,
      "content": "<article>AerynOS 2026.02 was released for closing out February as the newest alpha release for this Linux distribution formerly known as Serpent OS. In AerynOS 2026.02 are many package updates plus continued work on the tooling and other innovations around this Linux distribution...</article>",
      "contentLength": 274,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "The trap Anthropic built for itself",
      "url": "https://techcrunch.com/2026/02/28/the-trap-anthropic-built-for-itself/",
      "date": 1772323738,
      "author": "Connie Loizos",
      "guid": 49264,
      "unread": true,
      "content": "<article>Anthropic, OpenAI, Google DeepMind and others have long promised to govern themselves responsibly. Now, in the absence of rules, there's not a lot to protect them.</article>",
      "contentLength": 163,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Duolingo Grows, But Users Disliked Increased Ads and Subscription Pushes. Stock Plummets Again",
      "url": "https://slashdot.org/story/26/02/28/2321238/duolingo-grows-but-users-disliked-increased-ads-and-subscription-pushes-stock-plummets-again?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1772321100,
      "author": "EditorDavid",
      "guid": 49261,
      "unread": true,
      "content": "Friday was \"a horrible day\" for investors in Duolingo, reports Fast Company. But Friday's one-day 14% drop is just part of a longer story. \n\nSince last May, Duolingo's stock has dropped 81%. Yes, the company faced a social media backlash that month after its CEO promised they'd become an \"AI-first\" company (favoring AI over human contractors). And yes, Duolingo did double its language offerings using generative AI. But more importantly, that summer OpenAI showed how easy it was to just roll your own language-learning tool from a short prompt in a GPT-5 demo, while Google built an AI-powered language-learning tool into its Translate app. \n\n\nAnd yet, Friday Duolingo's shares dropped another 14%, after announcing good fourth quarter results but an unpopular direction for its future. Fast Company reports:\n\n\nOn the surface, many of the company's most critical metrics saw decent gains for the quarter, including: \n ‚Äî Daily Active Users: 52.7 million (up 30% year-over-year) \n ‚Äî Paid Subscribers: 12.2 million (up 28% year-over-year) \n ‚Äî Revenue: $282.9 million (up 35% year-over-year) \n ‚Äî Total bookings: $336.8 million (up 24% year-over-year) \n\nThe company also reported its full-year 2025 financials, revealing that for the first time in its history, it crossed the $1 billion revenue mark for a fiscal year. \n\nBut the Motley Fool explains that Duolingo's higher ad loads and repeated pushes for subscription plans \"generated revenues in the short term, but made the Duolingo platform less engaging. Ergo, user growth decelerated while revenues rose.\" Thursday Duolingo announced a big change to address that, including moving more features into lower-priced tiers. Barron's reports:\n\nD.A. Davidson analyst Wyatt Swanson, who rates Duolingo stock at Neutral, posited that the push to monetize \"led to disgruntled users and a meaningful negative impact to 'word-of-mouth' marketing.\" Duolingo has guided for bookings growth between 10% and 12% in 2026, compared with the 20% rate the company would have expected to see \"if we operated like we have in past years....\"\nIf stock reaction is any indication, investors are concerned about Duolingo's new focus.",
      "contentLength": 2171,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Why did Netflix back down from its deal to acquire Warner Bros.?",
      "url": "https://techcrunch.com/2026/02/28/why-did-netflix-back-down-from-its-deal-to-acquire-warner-bros/",
      "date": 1772316468,
      "author": "Anthony Ha",
      "guid": 49254,
      "unread": true,
      "content": "<article>Netflix's co-CEO reportedly told Trump, \"I took your advice.\"</article>",
      "contentLength": 61,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "New 'Star Wars' Movies Are Coming to Theatres. But Will Audiences?",
      "url": "https://entertainment.slashdot.org/story/26/02/28/0514259/new-star-wars-movies-are-coming-to-theatres-but-will-audiences?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1772314440,
      "author": "EditorDavid",
      "guid": 49246,
      "unread": true,
      "content": "\"The drought of upcoming Star Wars movies is coming to an end soon,\" writes Cinemablend. In May the The Mandalorian and Grogu opens, and one year later there's the release of the Ryan Gosling-led Star Wars: Starfighter. \n\nBut \"there are some insiders who already believe that Starfighter will be a bigger hit than The Mandalorian and Grogu...\"\n\nAccording to unnamed sources who spoke with Variety, there's a \"sense\" that Star Wars: Starfighter, which is directed by Deadpool &amp; Wolverine's Shawn Levy, will be a more satisfying viewing experience. These same sources are allegedly impressed by the early footage they've seen of Ryan Gosling's performance and also suggested that Levy has \"recaptured the franchise's spirit of fun.\" Furthermore, the article states that there's concern that because The Mandalorian and Grogu is spinning out of a streaming-exclusive series, it might not have as much appeal to people who aren't already fans of The Mandalorian... Star Wars: Starfighter, on the other hand, will be accessible to everyone equally. It's set five years after The Rise of Skywalker, which is an unexplored period for the Star Wars franchise onscreen. It's also expected that most, if not all of its featured characters will be brand-new, so no knowledge of past adventures is required. \nSlashdot reader gaiageek reminds us that 2027 will also see a special 50-year anniversary event in movie in theatres: a \"newly restored\" version of the original 1977 Star Wars.",
      "contentLength": 1473,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "What to know about the landmark Warner Bros. Discovery sale",
      "url": "https://techcrunch.com/2026/02/28/warner-bros-netflix-paramount-acquisition-timeline-wbd/",
      "date": 1772314086,
      "author": "Lauren Forristal",
      "guid": 49233,
      "unread": true,
      "content": "<article>Learn more about Paramount's planned acquisition of Warner Bros. Discovery ‚Äî a historic Hollywood megadeal valued at $111 billion ‚Äî as it continues to develop.</article>",
      "contentLength": 163,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Anthropic‚Äôs Claude rises to No. 1 in the App Store following Pentagon dispute",
      "url": "https://techcrunch.com/2026/03/01/anthropics-claude-rises-to-no-2-in-the-app-store-following-pentagon-dispute/",
      "date": 1772312706,
      "author": "Anthony Ha",
      "guid": 49225,
      "unread": true,
      "content": "<article>Anthropic‚Äôs chatbot Claude seems to have benefited from the attention around the company‚Äôs fraught negotiations with the Pentagon.</article>",
      "contentLength": 134,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Scientists Reveal the Surprising Sex Lives of Neanderthals and Early Humans",
      "url": "https://www.404media.co/scientists-reveal-the-surprising-sex-lives-of-neanderthals-and-early-humans/",
      "date": 1772311707,
      "author": "Becky Ferreira",
      "guid": 49231,
      "unread": true,
      "content": "<img src=\"https://www.404media.co/content/images/2026/02/image2.jpg\" alt=\"Scientists Reveal the Surprising Sex Lives of Neanderthals and Early Humans\"><p>Welcome back to the Abstract! Here are the studies this week that exposed prehistoric hookups, marched toward death, feasted on their own bodies, and found a buried legend in the Sahara.</p><p>First, Neanderthal males had lots more babies with human females than human males had with Neanderthal females. What‚Äôs up with that?! Then, strap in for a stellar swan song, antlers for breakfast, and a timeless style icon from the Cretaceous.</p><h2><strong>Dad‚Äôs a Neanderthal, Mom‚Äôs a human, I‚Äôm in therapy</strong></h2><p>Humans and our close relatives, Neanderthals, produced children together many times before the latter went extinct about 40,000 years ago. As a result, the vast majority of people living today carry a pinch of Neanderthal DNA‚Äîthe enduring proof of past copulations between our species.</p><p>Now, scientists have proposed that these prehistoric partnerships overwhelmingly occurred between Neanderthal males and females of our own species, , with far fewer couplings between Neanderthal females and human males. This strong sexual bias provides the most \"parsimonious‚Äù explanation for the uneven distribution of Neanderthal alleles (variants of specific genes) in modern human genomes, according to a new study.</p><p>‚ÄúOne of the notable features evident in alignments of Neanderthal genomes to those of modern humans is the presence of ‚ÄòNeanderthal deserts‚Äô within modern human genomes: genomic regions where Neanderthal alleles are conspicuously rare in the modern human (and ancient modern human) gene pool,‚Äù said researchers led by Alexander Platt of the University of Pennsylvania.&nbsp;&nbsp;</p><p>In particular, the team noted that Neanderthal deserts show up on the human X chromosome, which they think hints at a strong sex bias toward breeding between Neanderthal males and human females.&nbsp;</p><p>The team compared Neanderthal genomes with genetic data from some sub-Saharan African populations that have no Neanderthal ancestry. This approach allowed them to track ancient gene flow from anatomically modern humans (AMHs)‚Äîin other words, our ancient  ancestors‚Äîinto Neanderthal populations.&nbsp;</p><p>The results revealed that the Neanderthal X chromosomes had a 62 percent relative excess of DNA from AMHs. In other words, not only are there Neanderthal deserts on human X chromosomes, there are corollary ‚Äúfloods‚Äù or ‚Äúoases‚Äù (whatever metaphor you like) of human DNA on Neanderthal X chromosomes.&nbsp;</p><p>This discovery is strong evidence that humans were contributing more alleles to the Neanderthal X chromosome, and Neanderthals were contributing less to the human X chromosome, due to an unexplained asymmetry in mate preference.&nbsp;</p><p>Overall, the genetic patterns the team observed ‚Äúwere likely colored by a persistent preference for pairings between males of predominantly Neanderthal ancestry and females of predominantly AMH ancestry over the reverse,‚Äù the researchers concluded. ‚ÄúThe bias that we inferred seems to have remained consistent across admixture events separated by 200,000 years.‚Äù</p><p>Men prefer blondes; women prefer Neanderthals? I don‚Äôt know. This is just wildly interesting.&nbsp;</p><h2><strong>A (hypergiant) star is born</strong></h2><p>We‚Äôve all been there: One day, you‚Äôre an extreme red supergiant, and the next, you‚Äôre a yellow hypergiant. A new study reports that WOH‚ÄâG64, one of the biggest known stars in the sky, went through this ‚Äúdramatic transition‚Äù sometime in 2014 (or at least, that‚Äôs when astronomers first captured this spectral shift in the star, which is located about 163,000 light years from Earth).</p><p>If the Sun were as big as WOH‚ÄâG64, it would stretch to the orbit of Saturn. This late-stage stellar titan offers an ultra-rare opportunity to see how red supergiants (RSGs) end their lives, a process that is shrouded in mystery‚Äîoften literally, as these stars tend to be obscured by a lot of circumstellar gas.</p><p>‚ÄúThe apparent lack of luminous RSGs detected as supernova progenitors has sparked an ongoing debate over the fate of these stars,‚Äù said researchers led by Gonzalo Mu√±oz-Sanchez of the National Observatory of Athens. ‚ÄúWOH‚ÄâG64 thus provides critical insight into post-RSG evolution and the formation of dense circumstellar environments seen in core-collapse supernovae.‚Äù&nbsp;</p><p>It could be that WOH‚ÄâG64 does detonate. In fact, this may have already happened, but the light show hasn‚Äôt reached us yet. It may also collapse directly into a black hole with no supernova to show for it. We‚Äôll just have to keep watching this space! This has been Big Star News.</p><p>Antlers in deer are usually a male ornamentation that allows females to judge potential mates based on the quality of their head-bling. Caribou females, however, buck this trend as the only female deer with antlers. So, as a folktale might ask: How did the caribou get her antlers?&nbsp;</p><p>One answer is that antlers make a great post-partum snack, according to a new study. In migratory populations, female caribou shed their antlers when they reach calving grounds, usually just days before they give birth, which may give nursing mothers a much-needed vitamin boost.&nbsp;</p><p>‚ÄúPervasive antler consumption by caribou suggests that synchroneity between birthing and antler shedding evinces the importance of nutrient (calcium, phosphorus) transport for supporting calf survival,‚Äù said researchers led by Madison Gaetano of the University of Cincinnati. ‚ÄúThough intriguing, additional research will be important to more explicitly evaluate the dietary and fitness benefits (for both females and their calves) of antler-derived nutrients.‚Äù</p><p>Given that caribou also eat their placentas, it‚Äôs really impressive how these new mothers nourish themselves and their young with the fruits of their own bodies. Hardcore. Respect.&nbsp;</p><h2><strong>New spinosaur just dropped</strong></h2><p>Speaking of animals with rad headgear, we‚Äôll close with a shoutout to , a newly-discovered species of giant carnivorous dinosaur that rocked an epic scimitar-shaped skull crest. Move over, rock band T. Rex‚Äîthis killer is the new wave of dinosaurian glam.&nbsp;</p><p>‚Äú‚Ä¶discovered in the central Sahara alongside long-necked dinosaurs in a riparian habitat, is distinguished by a scimitar-shaped bony crest projecting far above its skull roof,‚Äù said researchers led by Paul C. Sereno of the University of Chicago.</p><p>Spinosaurus stock has gone through the roof in recent decades as new finds have confirmed that they were the biggest land predators of all time, dethroning  from a tyrant king to a mere tyrant vassal. As the ultimate charismatic megafauna, spinosaurs are popular in dino-blockbusters. Indeed, one of my favorite gags in cinematic history is when a Spinosaurus swallows a satellite phone in , so you know it‚Äôs lurking when you hear the Nokia ring tone. Pure dinosaurian comedic gold.&nbsp;</p><p>In any case, the new study sheds new light into the semi-aquatic nature of this majestic hunter, suggesting that this particular species was ‚Äúa wading, shoreline predator with visual display an important aspect of its biology.‚Äù While this animal was no doubt visually captivating, it‚Äôs best to view it from a safe distance of about 94 million years.</p><p>Thanks for reading! See you next week.</p>",
      "contentLength": 7109,
      "flags": null,
      "enclosureUrl": "https://www.404media.co/content/images/2026/02/image2.jpg",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "The billion-dollar infrastructure deals powering the AI boom",
      "url": "https://techcrunch.com/2026/02/28/billion-dollar-infrastructure-deals-ai-boom-data-centers-openai-oracle-nvidia-microsoft-google-meta/",
      "date": 1772311315,
      "author": "Russell Brandom",
      "guid": 49224,
      "unread": true,
      "content": "<article>Here's everything we know about the biggest AI infrastructure projects, including major spending from Meta, Oracle, Microsoft, Google, and OpenAI.</article>",
      "contentLength": 146,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "US Threatens Anthropic with 'Supply-Chain Risk' Designation. OpenAI Signs New War Department Deal",
      "url": "https://tech.slashdot.org/story/26/02/28/2028232/us-threatens-anthropic-with-supply-chain-risk-designation-openai-signs-new-war-department-deal?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1772310840,
      "author": "EditorDavid",
      "guid": 49222,
      "unread": true,
      "content": "It started Friday when all U.S. federal agencies were ordered to \"immediately cease\" using Anthropic's AI technology after contract negotiations stalled when Anthropic requested prohibitions against mass domestic surveillance or fully autonomous weapons. But later Friday there were even more repercussions... \n\n\nIn a post to his 1.1 million followers on X.com, U.S. Secretary of War Pete Hegseth criticized Anthropic for what he called \"a master class in arrogance and betrayal as well as a textbook case of how not to do business with the United States Government or the Pentagon.\"\n\nOur position has never wavered and will never waver: the Department of War must have full, unrestricted access to Anthropic's models for every LAWFUL purpose in defense of the Republic... Cloaked in the sanctimonious rhetoric of \"effective altruism,\" [Anthropic and CEO Dario Amodei] have attempted to strong-arm the United States military into submission ‚Äî a cowardly act of corporate virtue-signaling that places Silicon Valley ideology above American lives. The Terms of Service of Anthropic's defective altruism will never outweigh the safety, the readiness, or the lives of American troops on the battlefield. Their true objective is unmistakable: to seize veto power over the operational decisions of the United States military. That is unacceptable... \n\nIn conjunction with the President's directive for the Federal Government to cease all use of Anthropic's technology, I am directing the Department of War to designate Anthropic a Supply-Chain Risk to National Security. Effective immediately, no contractor, supplier, or partner that does business with the United States military may conduct any commercial activity with Anthropic... America's warfighters will never be held hostage by the ideological whims of Big Tech. This decision is final. \n\nMeanwhile, Anthrophic said on Friday that \"no amount of intimidation or punishment from the Department of War will change our position.\" (And \"We will challenge any supply chain risk designation in court.\")\nDesignating Anthropic as a supply chain risk would be an unprecedented action ‚Äî one historically reserved for US adversaries, never before publicly applied to an American company. We are deeply saddened by these developments. As the first frontier AI company to deploy models in the US government's classified networks, Anthropic has supported American warfighters since June 2024 and has every intention of continuing to do so. We believe this designation would both be legally unsound and set a dangerous precedent for any American company that negotiates with the government... Secretary Hegseth has implied this designation would restrict anyone who does business with the military from doing business with Anthropic. The Secretary does not have the statutory authority to back up this statement. \n\nAnthropic also defended the two exceptions they'd requested that had stalled contract negotiations. \"[W]e do not believe that today's frontier AI models are reliable enough to be used in fully autonomous weapons. Allowing current models to be used in this way would endanger America's warfighters and civilians. Second, we believe that mass domestic surveillance of Americans constitutes a violation of fundamental rights.\" \n\n\nAlso Friday, OpenAI announced that \"we reached an agreement with the Department of War to deploy our models in their classified network.\"\n\nOpenAI CEO Sam Altman emphasized that the agreement retains and confirms OpenAI's own prohibitions against using their products for domestic mass surveillance ‚Äî and requires \"human responsibility\" for the use of force including for autonomous weapon systems. \"The Department of War agrees with these principles, reflects them in law and policy, and we put them into our agreement. We also will build technical safeguards to ensure our models behave as they should, which the Department of War also wanted. \"\n\nWe are asking the Department of War to offer these same terms to all AI companies, which in our opinion we think everyone should be willing to accept. We have expressed our strong desire to see things de-escalate away from legal and governmental actions and towards reasonable agreements. We remain committed to serve all of humanity as best we can. The world is a complicated, messy, and sometimes dangerous place.\n",
      "contentLength": 4349,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "This Week In Techdirt History: February 22nd ‚Äì 28th",
      "url": "https://www.techdirt.com/2026/02/28/this-week-in-techdirt-history-february-22nd-28th/",
      "date": 1772308800,
      "author": "Leigh Beadon",
      "guid": 49221,
      "unread": true,
      "content": "",
      "contentLength": 0,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Antarctica's Massive Neutrino Observatory Gets an Upgrade",
      "url": "https://science.slashdot.org/story/26/02/28/0632201/antarcticas-massive-neutrino-observatory-gets-an-upgrade?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1772307240,
      "author": "EditorDavid",
      "guid": 49213,
      "unread": true,
      "content": "There's already 5,000 sensors embedded in Antarctica's ice to look for evidence of neutrinos, reports the Washington Post. But in November scientists drilled six new holes at least a mile and a half deep and installed cables with hundreds more light detectors ‚Äî an upgrade to the massive 15-year-old IceCube Neutrino Observatory to detect the charged particles produced by lower-energy neutrinos interacting with matter:\n\n\n\nWhen they do, the neutrinos produce charged particles that travel through the ice at nearly the speed of light, creating a blue glow called Cherenkov radiation... \"Within the first couple years, we should be making much better measurements,\" [said Erin O'Sullivan, an associate professor of physics at Uppsala University in Sweden and a spokesperson for the project.] \"There's hope to expand the detector, by an order of magnitude in volume, so the important thing there is we're not just seeing a few neutrino point sources, but we're starting to be a true telescope. ... That's really the dream.\" \n\nThe scientists spent seven years planning the upgrade, according to the article. \"To drill holes a mile and a half deep takes about 30 hours, and 18 more hours to return to the surface,\" the article points out. \"Then, the race begins because almost immediately, the hole starts to shrink as the water refreezes.\" (\"If it takes too much time, the principal investigator says, \"the instruments don't fit in anymore!\")",
      "contentLength": 1442,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "The Simplest Way to Understand How LLMs Actually Work!",
      "url": "https://hackernoon.com/the-simplest-way-to-understand-how-llms-actually-work?source=rss",
      "date": 1772305206,
      "author": "Amit Juneja",
      "guid": 49265,
      "unread": true,
      "content": "<p>The magic of transformers lies in their attention mechanism. But what does that actually mean?</p><p>\\\nHere's a simplified explanation to build intuition.</p><p>Consider: \"What is the capital of France?\"</p><p>As humans, we parse this as:</p><ul><li>\"What\" signals a question</li><li>\"is\" indicates the current timeframe</li><li>\"capital\" means the main city</li><li>\"France\" is the country for which I want the capital</li></ul><p>We process it instantly. But for a computer? Different story.</p><h2>THE ATTENTION MECHANISM: Q, K, V</h2><p>Transformers use a clever trick: for every word (technically tokens), the model creates three different representations:</p><p><strong>Query (Q) - \"What information am I looking for?\"</strong></p><p>For the word \"capital,\" the query is something like: \"What kind of entity am I describing?\"</p><p><strong>Key (K) - \"What information can I provide?\"</strong></p><p>Every word gets a key that describes what it offers. For the word \"capital,\" the key is something like: \"I'm a noun describing geographic/political entities.\"</p><p><strong>Value (V) - \"Here's my actual meaning.\"</strong></p><p>The word \"capital\" has the semantic meaning \"main city, governmental center, and administrative importance.\"</p><p>The model compares the query from one word against the keys of all other words. This produces .</p><p>Here is what happens when the word \"capital\", with its query of \"What kind of entity am I describing?\", checks against the keys of all the other words:</p><ul><li>\"France\" responds with its key ‚Üí </li><li>\"What\" responds with </li><li>\"is\" responds with </li></ul><p>Higher scores contribute more to the final understanding. So after this, the representation of \"capital\" is enriched with strong context from \"France.\"</p><p>This doesn't happen just once. Transformers use  running in parallel, like several people reading the same sentence, each noticing different patterns. One might focus on grammar, another on meaning, another on long-range dependencies.</p><p>In another head, the word \"capital\" could be querying for the timeframe. In this case, the word \"is\" will give a high score for the current time.</p><p>All these attention scores combined give a rich context to each word. So the word \"capital\" knows that it is a question, it is for the current timeframe, and it is about \"France.\"</p><p>After each attention layer, information flows through a Feed Forward Network. This is where the answers start to form. This network processes the context-enriched representations, helping build toward output predictions like 'Paris.'</p><p>The combination of attention + FFN, repeated across layers, gives transformers their power.</p><p>Unlike older models that processed words one at a time, transformers:</p><ul><li>Look at the entire sentence at once</li><li>Let every word \"attend to\" every other word</li><li>Capture relationships between distant words</li><li>Build understanding through multiple layers</li></ul><p>That's transformer attention in action.</p><p>*This explanation simplifies many technical details to focus on core concepts. For a deeper dive, check out \"Attention Is All You Need\" by Vaswani et al.*</p>",
      "contentLength": 2839,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "'World's Largest Battery' Soon At Google Data Center: 100-Hour Iron-Air Storage",
      "url": "https://hardware.slashdot.org/story/26/02/28/0446211/worlds-largest-battery-soon-at-google-data-center-100-hour-iron-air-storage?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1772303640,
      "author": "EditorDavid",
      "guid": 49195,
      "unread": true,
      "content": " Interesting Engineering reports:\n\nUS tech giant Google announced on Tuesday that it will build a new data center in Pine Island, Minnesota. The new facility will be powered by 1.9 gigawatts (GW) of clean energy from wind and solar, coupled with a 300-megawatt battery, claimed to be the 'world's largest', with a 30-gigawatt-hour (GWh) capacity and 100-hour duration... The planned battery would dwarf a 19 GW lithium-ion project in the UAE... \n\nForm Energy's batteries work very differently from most large batteries today. Instead of using lithium like the batteries in electric cars, they store electricity by making iron rust and then reversing the rusting process to release the energy when needed... Form's iron-air batteries are heavier and less efficient than their counterparts; they can only return about 50% to 70% of the energy used to charge them, while lithium-ion batteries return more than 90%. However, Form's batteries have one distinct advantage. They are cheaper than lithium-ion batteries, costing about $20 per kilowatt-hour of storage, which is almost three times as cheap... It will store 150 MWh of electricity and can supply to the grid for up to 100 hours, delivering about 1.5 MW at peak output.\n \nThanks to long-time Slashdot reader schwit1 for sharing the article.",
      "contentLength": 1295,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "After US-Israel Attacks, 90 Million Iranians Lose Internet Connectivity",
      "url": "https://news.slashdot.org/story/26/02/28/1733240/after-us-israel-attacks-90-million-iranians-lose-internet-connectivity?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1772300100,
      "author": "EditorDavid",
      "guid": 49185,
      "unread": true,
      "content": "CNN reports that images from Iran's capital \"have shown cars jammed along Tehran's street, with heavy traffic on major roads after today's wave of attacks by the US and Israel.\" And though Iran has a population of 93 million, the attacks suddenly plunged Iran into \"a near-total internet blackout with national connectivity at 4% of ordinary levels,\" according to internet monitoring experts at NetBlocks. \n\nCNN reports:\n\nSince Iran's brutal crackdown earlier this year, the regime has made progress to allow only a subset of people with security clearance to access the international web, experts said. After previous internet shutdowns, some platforms never returned. The Iranian government blocked Instagram after the internet shutdown and protests in 2022, and the popular messaging app Telegram following protests in 2018. \n\n\nThe International Atomic Energy Agency announced an hour ago that they're \"closely monitoring developments\" ‚Äî keeping in contact with countries in the region and so far seeing \"no evidence of any radiological impact.\" They're also urging \"restraint to avoid any nuclear safety risks to people in the region.\" \n\nUPDATE (1 PM PST):\nQatar, Bahrain and Kuwait \"are shifting to remote learning starting Sunday until further notice following Iran√¢(TM)s retaliatory strikes on Saturday,\" reports CNN.",
      "contentLength": 1327,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "AMD Prepares Linux For Instruction-Based Sampling Improvements With Zen 6",
      "url": "https://www.phoronix.com/news/Linux-Perf-AMD-IBS-Zen-6",
      "date": 1772297925,
      "author": "Michael Larabel",
      "guid": 49178,
      "unread": true,
      "content": "<article>A set of patches recently posted to the Linux kernel mailing list have now been queued up to a tip/tip.git branch for planned introduction in Linux 7.1. These patches are for enhancing the Linux perf subsystem support for AMD Instruction-Based Sampling (IBS) improvements with next-gen Zen 6 processors...</article>",
      "contentLength": 305,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "America's Teenagers Say AI Cheating Has Become a Regular Feature of Student Life",
      "url": "https://news.slashdot.org/story/26/02/28/0541228/americas-teenagers-say-ai-cheating-has-become-a-regular-feature-of-student-life?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1772296440,
      "author": "EditorDavid",
      "guid": 49157,
      "unread": true,
      "content": "Tuesday Pew Research announced their newest findings: that 54% of America's teens use AI help with schoolwork:\nOne-in-five teens living in households making less than $30,000 a year say they do all or most of their schoolwork with AI chatbots' help. A similar share of those in households making $30,000 to just under $75,000 annually say this. Fewer teens living in higher-earning households (7%) say the same.\" \n\n\"The survey did not ask students whether they had used chatbots to write essays or generate other assignments...\" notes the New York Times. \"But nearly 60% of teenagers told Pew that students at their school used chatbots to cheat 'very often' or 'somewhat often.'\" Agreeing with that are the Pew Researchers themselves. \"Our survey shows that many teens think cheating with AI has become a regular feature of student life.\" \n\nOne worried teenager still told the researchers that AI \"makes people lazy and takes away jobs.\" But another teenager told the researchers that \"Everyone's going to have to know how to use AI or they'll be left behind.\" \n\nThanks to long-time Slashdot reader theodp for sharing the article.",
      "contentLength": 1131,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "OpenAI‚Äôs Sam Altman announces Pentagon deal with ‚Äòtechnical safeguards‚Äô",
      "url": "https://techcrunch.com/2026/02/28/openais-sam-altman-announces-pentagon-deal-with-technical-safeguards/",
      "date": 1772295456,
      "author": "Anthony Ha",
      "guid": 49162,
      "unread": true,
      "content": "<article>OpenAI's CEO claims its new defense contract includes protections addressing the same issues that became a flashpoint for Anthropic.</article>",
      "contentLength": 132,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "How Researchers Measure, Detect and Benchmark AI Manipulation",
      "url": "https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss",
      "date": 1772295326,
      "author": "Tencent",
      "guid": 49174,
      "unread": true,
      "content": "<ol><li>Enes Altuncu, ea483@kent.ac.uk (University of Kent, UK)</li><li>Virginia N. L. Franqueira, V.Franqueira@kent.ac.uk (University of Kent, UK)</li><li>Shujun Li, S.J.Li@kent.ac.uk (University of Kent, UK)</li></ol><p>Recent advancements in AI, especially deep learning, have contributed to a significant increase in the creation of new realistic-looking synthetic media (video, image, and audio) and manipulation of existing media, which has led to the creation of the new term ‚Äúdeepfake‚Äù. Based on both the research literature and resources in English and in Chinese, this paper gives a comprehensive overview of deepfake, covering multiple important aspects of this emerging concept, including 1) different definitions, 2) commonly used performance metrics and standards, and 3) deepfake-related datasets, challenges, competitions and benchmarks. In addition, the paper also reports a meta-review of 12 selected deepfake-related survey papers published in 2020 and 2021, focusing not only on the mentioned aspects, but also on the analysis of key challenges and recommendations. We believe that this paper is the most comprehensive review of deepfake in terms of aspects covered, and the first one covering both the English and Chinese literature and sources.</p><p>: Deepfake, Survey, Definition, Datasets, Benchmarks, Challenges, Competitions, Standards, Performance Metrics.</p><p>Recent advancements in AI and machine learning have increased the capability to produce more realistic media, e.g., video, image, and audio. Especially, state-of-the-art deep learning methods enabled the generation of ‚Äúdeepfakes‚Äù, manipulated or synthetic media the realness of which are not easily recognisable by the human eye. Although deepfake is a relatively new phenomenon (having first appeared at the end of 2017), its growth has been remarkable. According to the 2019 and 2020 Deeptrace reports on the state of deepfake [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark139\">2</a>], the number of deepfake videos in the English-speaking internet grew from 7,964 (December 2018) to 14,678 (July 2019) to 85,047 (December 2020), representing a 968% increase from 2018 to 2020.</p><p>In this work, we review existing deepfake-related research ecosystem in terms of various aspects, including performance metrics and standards, datasets, challenges, competitions, and benchmarks. Furthermore, we provide a meta-review of 12 selected deepfake-related survey papers which covers several additional aspects other than the mentioned ones in a systematic manner, such as performance comparison, key challenges, and recommendations.</p><p>Despite being a hugely popular term, there is a lack of consensus on the definition of ‚Äúdeepfake‚Äù and the boundary between deepfakes and non-deepfakes is not clear cut. For this survey, we adopt a relatively more inclusive approach to cover all forms of manipulated or synthetic media that are considered deepfakes in a broader sense. We also cover closely related topics including biometrics and multimedia forensics, since deepfakes are often used to launch presentation attacks against biometrics-based authentication systems and detection of deepfakes can be considered part of multimedia forensics. A more detailed discussion on different definitions of ‚Äúdeepfake‚Äù is given next.</p><h2>1.1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Definitions of the Term Deepfake</h2><p>As its name implies, the term ‚Äúdeepfake‚Äù is derived from the combination of ‚Äúdeep‚Äù (referring to  (DL)) and ‚Äúfake‚Äù. It is normally used to refer to manipulation of existing media (image, video and/or audio) or generation of new (synthetic) media using DL-based approaches. The most commonly discussed deepfake data are fake face images, fake speech forgeries, and fake videos that combine both fake images and fake speech forgeries. While having ‚Äúfake‚Äù in the word indicates manipulated or synthesised media, there are plenty of benign applications of the deepfake technology, e.g., for entertainment and creative arts. With this respect, another term ‚Äúdeep synthesis‚Äù has been proposed as a more neutral-sounding alternative [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark197\">60</a>]. This new term, however, has not been widely adopted.</p><p>In addition to the lack of a universal definition, as mentioned already, the boundary between deepfakes and non-deep fakes is actually not a clear cut. There are at least two important aspects we should consider, one on detection of and the other on creation of deepfakes.</p><p>First, detection of deepfakes often follows very similar approaches to detection of traditional fakes generated without using DL techniques. Advanced detection methods have also started leveraging DL to improve their performance, but they do not necessarily need to know how a target media is created (deep or not). To some extent, one could argue that detecting deepfakes does not involve developing deepfake-specific methods (even though some researchers choose to do so), but a more robust and universal detector that can handle any (deep or not) fake media. This can be seen for two closely related topics: biometrics and multimedia forensics. For biometrics, there is a trend of using deep learning techniques to generate fake biometric signals (e.g., face images and videos) for biometric spoofing or presentation attacks. For multimedia forensics, deepfake-based forgeries have become a new threat to the traditional problem of ‚Äúforgery detection‚Äù. For both topics, detection of biometric spoofing and multimedia forgeries have evolved to consider both deep and non-deep fakes.</p><p>Second, one may argue that the word ‚Äúdeep‚Äù in ‚Äúdeepfake‚Äù does not necessarily refer to the use of ‚Äúdeep learning‚Äù, but any ‚Äúdeep‚Äù (i.e., sophisticated) technology that creates a very believable fake media. For instance, Brady [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark146\">9</a>] considered deepfake as audio-visual manipulation using ‚Äúa spectrum of technical sophistication ‚Ä¶ and techniques‚Äù. They also introduced two new terms,  and , referring to ‚Äúlow level manipulation of audio-visual media created with (easily) accessible software [or no software] to speed, slow, restage or re-contextualise content‚Äù. This broader understanding of ‚Äúdeepfake‚Äù has also been adopted by law makers for new legislations combating malicious deepfakes. For instance, the following two United States acts define ‚Äúdeepfakes‚Äù as follows:</p><ul><li>2018 Malicious Deep Fake Prohibition Act<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark1\">1</a>:</li></ul><p>¬ß1041.(b).(2): ‚Äú<em>the term ‚Äòdeep fake‚Äô means an audiovisual record created or altered in a manner that the record would falsely appear to a reasonable observer to be an authentic record of the actual speech or conduct of an individual.</em>‚Äù</p><ul><li>2019 DEEP FAKES Accountability Act<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark2\">2</a>:</li></ul><p>¬ß1041.(n).(3): ‚Äú<em>The term ‚Äòdeep fake‚Äô means any video recording, motion-picture film, sound recording, electronic image, or photograph, or any technological representation of speech or conduct substantially derivative thereof‚Äî</em></p><p><em>(A)&nbsp; which appears to authentically depict any speech or conduct of a person who did not in fact engage in such speech or conduct; and</em></p><p><em>(B)&nbsp; the production of which was substantially dependent upon technical means, rather than the ability of another person to physically or verbally impersonate such person.</em>‚Äù</p><p>As we can see from the above legal definitions of ‚Äúdeepfake‚Äù, the use of DL as a technology is not mentioned at all. The focus here is on ‚Äúauthenticity‚Äù, ‚Äúimpersonation‚Äù and (any) ‚Äútechnical means‚Äù.</p><h2>1.2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Scope and Contribution</h2><p>Based on the above discussion on definitions of deepfake, we can see it is not always straightforward or meaningful to differentiate deepfakes from non-deep fakes. In addition, for our focus on performance evaluation and comparison, the boundary between deepfakes and non-deep fakes is even more blurred. This is because DL is just a special (deeper) form of machine learning (ML), and as a result, DL and non-deep ML methods share many common concepts, metrics and procedures.</p><p>Despite the fact that deepfake may be understood in a much broader sense, in this work, we have a sufficiently narrower focus to avoid covering too many topics. We, therefore, decided to define the scope of this survey as follows:</p><ul><li>For metrics and standards, we chose to include all commonly used ones for evaluating general ML methods and those specifically defined for evaluating deepfake creation or detection methods.</li><li>For datasets, challenges, competitions and benchmarks, we considered those related to fake media covered in the deepfake-related survey papers and those with an explicit mention of the term ‚Äúdeepfake‚Äù or a comparable term.</li><li>For the meta-review, we considered only survey papers whose authors explicitly referred to the term ‚Äúdeepfakes‚Äù in the meta data (title, abstract and keywords).</li></ul><p>Research papers covered in this survey (i.e., the deepfake-related survey papers) were identified via systematic searches on the scientific databases, Scopus and China Online Journals (COJ)<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark4\">3</a>. The following search queries were used to perform the searches on Scopus and COJ, respectively:</p><p>(deepfake* OR deep-fake* OR ‚Äúdeep fake*‚Äù) AND (review OR survey OR overview OR systemati* OR SoK)</p><p>(deepfake OR Ê∑±Â∫¶‰º™ÈÄ†) AND (ÁªºËø∞ OR ËøõÂ±ï)</p><p>The searches returned 41 survey papers in English and 15 survey papers in Chinese. Out of these papers, eight published in English and four published in Chinese were selected for consideration.</p><p>Deepfake-related challenges, competitions and benchmarks were identified via multiple sources: the survey papers selected, research papers from the co-authors‚Äô personal collections, Google Web searches, and manual inspection of websites of major AI-related conferences held in 2020 and 2021 (where such challenges and competitions are routinely organised). The inspected conferences include those listed in the ACL (Association for Computational Linguistics) Anthology<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark5\">4</a>, ICCV, CVPR, AAAI, ICML, ICLR, KDD, SIGIR, WWW, and many others. In addition, a comprehensive list of datasets was compiled based on the selected survey papers and the identified challenges, competitions, and benchmarks. Relevant standards were identified mainly via research papers covered in this survey, the co-authors‚Äô personal knowledge, and Google Web searches. For performance metrics, we covered those commonly used based on relevant standards, the survey papers, and the identified challenges, competitions, and benchmarks.</p><p>In this survey, we focus on performance evaluation and comparison of deepfake generation and detection methods. The metrics used for such performance evaluations are at the core of our discussions. In this section, we review the performance metrics that are commonly used to evaluate deepfake generation and detection algorithms. Note that all metrics covered in this section are also commonly used for evaluating performance of similar systems that are not for generating or detecting deepfakes. Therefore, this section can be seen as a very brief tutorial on general performance metrics.</p><p>In the last subsection, we also briefly discuss how the related performance metrics are covered in formal standards. By ‚Äúformal standards‚Äù, we refer to standards defined following a formal procedure, often by one or more established standardisation bodies such as the International Organization for Standardization (ISO)<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark6\">5</a> and the International Electrotechnical Commission (IEC)<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark7\">6</a>. Note that we consider a broad range of documents defined to be standards by standardisation bodies, e.g., International Telecommunication Union (ITU)<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark8\">7</a> recommendations and ISO technical reports (TRs).</p><h2>3.1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The Confusion Matrix</h2><p>Deepfake detection is primarily a binary classification problem. A binary classifier takes an input that is  or  and outputs a binary value denoting it to be  or . For example, a deepfake detection system will take a suspected image as the input that may be  or  and output  or .</p><p>A fundamental tool used in evaluating a binary classifier is the  that summarises the success and failure of the classification model. On one axis are the two  values and on the other axis are the two  values. The classification is  (true positive and true negative) when the actual and the predicted values match. It is  (false positive and false negative) when the actual and predicted values do not match. Table <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark9\">1</a> shows the confusion matrix for a binary deepfake classifier (detector). The two cells in green, TP (the number of ) and TN (the number of ), indicate correct prediction results, and the two cells in red, FN (the number of ) and FP (the number of ), indicate two different types of errors when making incorrect prediction results.</p><p>\\\nTable 1: Confusion matrix for a binary classifier for detecting deepfake.</p><p>|    | fake (predicted) | real (predicted) |\n|----|----|----|\n| fake (actual) | TP | FN |\n| real (actual) | FP | TN |</p><h2>3.2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Precision and Recall</h2><p>Based on the four fundamental values introduced in Section <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark3\">3.1</a>, i.e., TP, TN, FP and FN, we define two important performance metrics for a binary classifier ‚Äì  and .</p><p>Precision of a binary classifier is defined as the fraction of  samples among all the . In the confusion matrix, it is the fraction of true samples in the first column. It can be formally defined as Eq. (<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark10\">1</a>).</p><p>When the ‚Äúnatural‚Äù ratio between positive and negative samples is significantly different from the test set, it is often useful to adjust the weight of the false positives, which leads to the  (wP) defined in Eq. (<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark11\">2</a>), where  0 is a weight determined by the ratio between the negative and positive samples.</p><p>Recall of a binary classifier is the fraction of  samples among the  samples, as shown in Eq. (<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark12\">3</a>). In the confusion matrix, it is the fraction of true samples in the first row.</p><p>Let us consider an example binary classifier that predicts if an image from a database containing both deepfake and real (authentic) images is fake or not. Precision of the classifier is the fraction of correctly classified images among all images classified as deepfake. On the other hand, recall is the fraction of deepfake images identified by the classifier, among all deepfake images in the database.</p><h2>3.3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; True and False Positive Rates</h2><p>Focusing on predicted positive samples, we can also define two metrics:  (TPR), also called  (CDR), as the fraction of the predicted positive samples among the actually positive samples and  (FPR), also called  (FAR), as the fraction of the predicted positive samples among the actually negative samples, as shown in Eqs. (<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark13\">4</a>) and</p><p>(<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark14\">5</a>). In the confusion matrix, TPR is the fraction of predicted positive samples in the first row and FPR is the fraction of predicted positive samples in the second row. Note that TPR is basically a different name for  (Eq. (<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark12\">3</a>)).</p><h2>3.4&nbsp;&nbsp;&nbsp;&nbsp; True and False Negative Rates</h2><p>Similar to true and false positive rates, we can define two other rates focusing on negative predicted results:  (TNR) indicating the fraction of the predicted negative samples among the actually negative samples, and  (FNR) indicating the fraction of the predicted negative samples among the actually positive samples, as shown in Eqs. (<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark15\">6</a>) and (<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark16\">7</a>).</p><h2>3.5&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Sensitivity and Specificity</h2><p>In some applications of binary classifiers, especially in biology and medicine, the TPR and the TNR are more commonly used, and they are often called  (TPR) and  (TNR). The focus of these two terms is on the two types of correctness of the predicted results. These are less used in deepfake-related research, hence, we will not refer to them in the remainder of this paper.</p><p>Focusing on error rates means that we need to consider the FPR and the FNR. These two rates normally conflict with each other so that reducing one rate normally leads to an increase in the other. Therefore, rather than trying to reduce both error rates at the same time, which is normally impossible, the more realistic task in practical applications is to find the right balance so that they are both below an acceptable threshold.</p><p>In some applications, such as biometrics, people are particularly interested in establishing the so-called  (EER) or  (CER), the point where the FPR and the FNR are equal. The EER/CER is not necessarily a good metric for some applications, especially when the two types of errors are of different levels of importance, e.g., for detecting critical deepfakes (e.g., fake news that can influence how people cast their votes) we can often tolerate more false positives (false alarms) than false negatives (missed alarms).</p><h2>3.7&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Accuracy and F-Score</h2><p>In addition to the EER/CER, there are also other metrics that try to reflect both types of errors, in order to give a more balanced indication of the overall performance of a binary classifier. The two most commonly used are  and  (also called ). Both metrics can be defined based on the four fundamental values (TP, TN, FP, and FN).</p><p>Accuracy of a binary classifier is defined as the fraction of  samples (true positives and true negatives) among the total number of samples that have been classified, as shown in Eq. (<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark17\">8</a>).</p><p>The F-score of a binary classifier is actually a family of metrics. Its general form can be described based on a parameter  as defined in Eq. (<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark18\">9</a>).</p><p>The most widely used edition of all F-scores is the so-called , which is effectively the F-score with  = 1. More precisely, it is defined as shown in Eq. (<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark19\">10</a>).</p><h2>3.8&nbsp;&nbsp;&nbsp;&nbsp; Receiver Operating Characteristic Curve and Area Under Curve</h2><p><strong>Receiver operating characteristic</strong> (ROC) curves are commonly used to measure the performance of binary classifiers that output a score (or probability) of prediction.</p><p>Consider the following. Let  be the set of all test samples and let the output scores  () (for all  ‚àà ) lie in the interval [] on the real line. Let  ‚àà [] be a prediction threshold for the model, and assume that the classifiers works as follows for all  ‚àà :</p><p>\\\nIt is easy to see that, for  = , all the samples will be classified as positive, leading to FN = TN = 0 so TPR = FPR = 1; while for  = , all the samples will be classified as negative, leading to FP = TP = 0 so TPR = FPR = 0. For other threshold values between  and , the values of TPR and FPR will normally be between 0 and 1. By changing  from  to  continuously, we can normally get a continuous curve that describes how the TPR and FPR values change from (0,0) to (1,1) on the 2D plane. This curve is the ROC curve of the binary classifier.</p><p>For a random classifier, assuming that  () distributes uniformly on [] for the test set, we can mathematically derive its ROC curve being the TPR = FPR line, whose area under the ROC curve (AUC) is 0.5. For a binary classifier that performs better than a random predictor, we can also mathematically prove that its AUC is always higher than 0.5, with 1 being the best possible value. Note that no binary classifier can have an AUC below 0.5, since one can simply flip the prediction result to get a better predictor with an AUC of 1 ‚àí AUC. The relationship between the ROC and the AUC is graphically illustrated in Figure <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark20\">1</a>.</p><p>Another widely used performance metric for binary classifiers that can return a probability score for the predicted label is . For a binary classification with a true label  ‚àà {0*,* 1} and an estimated probability  = Pr( = 1), the log loss per sample is the negative log-likelihood of the classifier given the true label, defined as shown in Eq. (<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark21\">12</a>).</p><p>Given a testing set with  samples, the log loss score of a binary classifier can be calculated using Eq. (<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark22\">13</a>), where  is 1 if the -th sample is true and 0 if false, and ÀÜ is the predicted probability of  = 1.</p><h2>3.10&nbsp;&nbsp;&nbsp;&nbsp; Extension to Multi-class Classifiers</h2><p>All metrics that are defined based on the four basic values TP, TN, FP and FN can be easily extended to <strong>multi-class classification</strong> by considering the prediction to be true or false individually with respect to each class. For example, if the system is classifying animals (cats, dogs, horses, lions, tigers, etc.), then a true positive prediction of an image to be of a cat, would simultaneously be true negative predictions for the remaining classes (dogs, horses, lions, tigers, etc.). If an image of a cat is incorrectly predicted to be that of a dog, it would be a false negative with respect to a cat, a false positive with respect to a dog, and a true negative with respect to all other classes.</p><h2>3.11&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Perceptual Quality Assessment (PQA) Metrics</h2><p>By definition, the main goal of deepfakes is to make it hard or impossible for human consumers (listeners or viewers) to distinguish fake media from real media. Therefore, when evaluating the quality of deepfake media, the quality perceived by human consumers of the media is key. This calls for subjective assessment of the perceptual quality of the deepfake media as the ‚Äúgold standard‚Äù. The most widely used subjective perceptual quality assessment (PQA) metric for audio-visual signals is  (MOS), which has been widely used by the signal processing and multimedia communication communities, including digital TV and other multimedia-related consumer applications. As its name implies, MOS is calculated by averaging the subjective scores given by a number of human judges, normally following a numerical scale between 1 and 5 or between 0 and 100. MOS has been used in some deepfake-related challenges (see Section <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark113\">5.2</a>) and also for evaluating and comparing the quality (realness/naturalness) of deepfake datasets (see Section <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark64\">4.6</a>).</p><p>As a general subjective PQA metric, MOS has been standardised by the ITU<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark23\">8</a>. There are also ITU standards defining more specific subjective Video Quality Assessment (VQA) metrics and the standard procedures one should follow to conduct VQA user studies, e.g., ITU-T Recommendation P.910 ‚ÄúSubjective video quality assessment methods for multimedia applications‚Äù<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark24\">9</a>. Note that the ITU standards focus more on traditional perceptual quality, i.e., how good a signal looks or sounds, even if it looks or sounds not real (e.g., too smooth). On the other hand, for deepfakes, the focus is rather different because what matters is the realness and naturalness of the created media, i.e., how real and natural it looks or sounds, even if it is of low quality. To some extent, we can also consider realness and naturalness as a special aspect of perceptual quality.</p><p>One major problem of subjective PQA metrics like MOS is the need to recruit human judges and to have a well-controlled physical testing environment and protocol, which are not easy for many applications. To help reduce the efforts and costs of conducting PQA-related user studies, various objective PQA metrics have been proposed, where the term ‚Äúobjective‚Äù refers to the fact that such metrics are human-free, i.e., automatically calculated following a computational algorithm or process. Depending on whether a reference exists, such objective PQA metrics can be largely split into three categories: full-reference (FR) metrics (when the original ‚Äúperfect-quality‚Äù signal is available as the reference), reduced-reference (RR) metrics (when some features of the original ‚Äúperfect-quality‚Äù signal are available as the reference), and no-reference (NR) metrics (when the original signal is unavailable or such an original signal does not exist). For deepfakes, normally NR or RR metrics are more meaningful because the ‚Äúfake‚Äù part of the word means that part of the whole data does not exist in the real world, hence a full reference cannot be obtained. RR metrics are still relevant because deepfakes are often produced for a target‚Äôs specific attributes (e.g., face and voice), where the reduced reference will be such attributes. NR metrics will be useful to estimate the realness and naturalness of a deepfake, simulating how a human judge would rate it in a controlled subjective PQA user study.</p><p>PQA is a very active research area and many PQA metrics have been proposed, some of which have been widely used in real-world products and services, e.g.,  (MSE), <strong>peak signal-to-noise ratio</strong> (PSNR) and <strong>structural similarity index measure</strong> (SSIM) for FR PQA of digitalimages and videos defined as in Eqs. (14), (15), and (16), respectively, where X = {xi} n i is the reference (the original signal), Y = {yi} n i is the signal whose visual quality is assessed, n is the number of pixels in X and Y , L is the maximum possible pixel value of X and Y (e.g., 255 for 8-bit gray-scale images), c1 = (k1L) 2 and c2 = (k2L) 2 ) are two stabilising parameters (k1 = 0.01 and k2 = 0.03 by default). For more about PQA metrics for different types of multimedia signals, we refer readers to some relevant surveys [3, 51, 72].</p><h2>3.12&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; More about Standards</h2><p>Many of the basic performance metrics described in this section have been widely used by deepfake researchers as de facto standards, e.g., EER, log loss and MOS have been widely used in deepfake-related challenges (see Section <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark74\">5</a>). Also, the combination of precision, recall and F1-score has been widely used to assess performance of binary classifiers. While there have been a number of ITU standards on PQA to date, there does not seem to be many standardisation efforts on the performance metrics for evaluation of binary classifiers. This was the case until at least 2017, when ISO and IEC jointly set up the ISO/IEC JTC 1/SC 42<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark28\">10</a>, a standardisation subcommittee (SC) focusing on AI under ISO/IEC JTC 1<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark29\">11</a>, the joint technical committee for standardising ‚Äúinformation technology‚Äù.</p><p>One recent effort that ISO/IEC JTC 1/SC 42 made is to produce the ISO/IEC TR 24029-1:2021 ‚ÄúArtificial Intelligence (AI) ‚Äì Assessment of the robustness of neural networks ‚Äì Part 1: Overview‚Äù<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark30\">12</a>, a technical report (TR) that systematically covers many commonly used performance assessment concepts, methods and metrics. Although the technical report has ‚Äúneural networks‚Äù in its title, most performance assessment concepts, methods and metrics included are common ones for all supervised machine learning models.</p><p>In terms of performance metrics, two other ongoing work items of the ISO/IEC JTC 1/SC 42 that deserve attention are as follows:</p><ul><li>ISO/IEC DTS (Draft Technical Specification) 4213 ‚ÄúInformation technology ‚Äì Artificial Intelligence ‚Äì Assessment of machine learning classification performance‚Äù<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark31\">13</a></li><li>ISO/IEC AWI (Approved Work Item) TS (Technical Specifications) 5471 ‚ÄúArtificial intelligence ‚Äì Quality evaluation guidelines for AI systems‚Äù<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark32\">14</a></li></ul><p>While the ISO/IEC JTC 1/SC 42 was created very recently, another standardisation subcommittee under ISO/IEC JTC1 has a much longer history of nearly 20 years: the ISO/IEC JTC 1/SC 37<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark33\">15</a> that focuses on biometrics-related technology. This standardisation subcommittee is highly relevant for deepfake since deepfake faces can be used to spoof biometrics-based user authentication systems. In this context, the following three standards are of particular relevance:</p><p><strong>ISO/IEC 19795-1:2021 ‚ÄúInformation technology ‚Äì Biometric performance testing and reporting ‚Äì Part 1: Principles and framework‚Äù</strong><a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark34\">16</a>: This standard covers general metrics about evaluating biometric systems. Two major metrics in this context are  (FAR) and  (FRR), which refer to the standard FPR and FNR, respectively. This standard also deprecates the use of single-number metrics including the EER and AUC (which were widely used in biometrics-related research in the past).</p><p><strong>ISO/IEC 30107-1:2016 ‚ÄúInformation technology ‚Äì Biometric presentation attack detec-tion ‚Äì Part 1: Framework‚Äù</strong><a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark36\">17</a>: This standard defines a general framework about <strong>presentation attack detection</strong> (PAD) mechanisms, where the term ‚Äú‚Äù refers to the ‚Äú<em>presentation of an artefact or of human characteristics to a biometric capture subsystem in a fashion intended to in-terfere with system policy</em>‚Äù. It focuses on biometric recognition systems, where a PAD mechanism is a binary classifier trying to predict presentation attacks (also called attack presentations, e.g., fake faces) as positive and bona fide (real) presentations as negative.</p><p><strong>ISO/IEC 30107-3:2017 ‚ÄúInformation technology ‚Äì Biometric presentation attack detection ‚Äì Part 3: Testing and reporting‚Äù</strong><a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark37\">18</a>: This standard defines a number of special performance metrics for evaluating PAD mechanisms standardised in the ISO/IEC 30107-1:2016. Three such metrics look at error rates: <strong>attack presentation classification error rate</strong> (APCER) referring to the standard FPR, <strong>normal/bona fide presentation classification error rate</strong> (NPCER/BPCER) referring to the standard FNR, and <strong>average classification error rate</strong> (ACER) that is defined as the average of the APCER and the NPCER/BPCER. Such metrics have been used in biometrics-related challenges such as Face Anti-spoofing (Presentation Attack Detection) Challenges<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark38\">19</a>. When deepfake images or videos are used to spoof a biometric system, such standardised metrics will become relevant.</p><p>This section provided a comprehensive summary of performance metrics used for evaluating and bench-marking binary classifiers. It is rare that all such metrics are used for a specific application. Instead, one or several are chosen based on specific needs. For a deepfake detection system as a binary classifier, many researchers have chosen to use overall metrics such as accuracy, AUC, EER and log loss, but the combination of precision, recall and F1-score is also common. Some deepfake-related challenges and competitions have introduced their own specific metrics, some of which will be described in Section <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark74\">5</a>. The use of different performance metrics can make comparison of different reported results more difficult, so we hope the expected new ISO/IEC standard particularly ISO/IEC 4213 will help.</p><p>It is worth mentioning that, in addition to evaluating performance of deepfake detectors, the introduced performance metrics for evaluating binary classifiers can also be used to evaluate performance of deepfake generation methods by considering how deepfake detectors fail. For instance, organisers of the Voice Conversion Challenge 2018 and 2020 used this approach to benchmark how well voice conversion (VC) systems can generate high-quality fake speech samples.</p><p>Another point we would like to mention is that for deepfake videos there are two levels of performance metrics: those at the frame level (metrics of each frame), and those at the video level (metrics for the whole video). Generally speaking, the latter can be obtained by averaging the former for all frames, potentially following an adaptive weighting scheme, so that more important (key) frames will be counted more.</p><p>In this section, we cover all deepfake-related datasets we identified from the meta-review of deepfake-related survey papers, deepfake-related challenges, competitions and benchmarks covered, one online collection of deepfake-related datasets on GitHub<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark39\">20</a>, and the co-authors‚Äô personal collections. Table <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark40\">2</a> shows basic information about these datasets. We explain them in four categories: deepfake image datasets, deepfake video datasets, deepfake audio/speech datasets, and hybrid deepfake datasets (mainly mixed image and video datasets).</p><p>Note that many datasets of real (authentic) media were also used by deepfake researchers for two purposes. First, any detectors would need both fake and real media to demonstrate their performance. Second, real media have also been used to train deepfake generators as the training set. In this section, we include only datasets containing deepfake media, some of which contain both deepfake and real media.</p><p>Some datasets, especially those created for deepfake-related challenges and competitions, have separate subsets for training and evaluation (testing) purposes. The split is necessary for such challenges and competitions, but not very useful for people who just want to use such datasets. Therefore, in this section when introducing such datasets we will ignore that level of details and focus on the total number of data including the number of real and fake samples.</p><h2>4.1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Deepfake Image Datasets</h2><p><strong>SwapMe and FaceSwap dataset</strong> [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark215\">78</a>]: This dataset contains 4,310 images, including 2,300 real images and 2,010 fake images created using FaceSwap<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark41\">21</a> and the SwapMe iOS app (now discontinued).</p><p><strong>Fake Faces in the Wild (FFW) dataset</strong> [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark169\">32</a>]: This dataset contains 131,500 face images, including 78,500 images extracted from 150 videos in the FaceForensics dataset and 53,000 images extracted from 150 fake videos collected from YouTube.</p><p><strong>generated.photos datasets</strong><a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark42\">22</a>: This is a number of commercial datasets provided by the Generated Media, Inc., with up to nearly 2.7 million synthetic face images generated by StyleGAN. A free edition with 10,000 128x128 synthetic images is made available for academic research. The website also provides an interactive face generator<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark43\">23</a> and an API<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark44\">24</a>. The generated.photos datasets have a good diversity: five age groups (infants, children, youth, adults, middle-aged), two genders (male and female), four ethnicities (white, black, Latino, Asian), four eye colours (brown, grey, blue, green), four hair colours (brown, black, blond, gray), three hair length (short, medium, long), facial expressions, three head poses (front facing, left facing, right facing), two emotions (joy and neutral), two face styles (natural, beautified). (According to a number of research papers we read, an earlier 100K-Faces dataset was released by generated.photos for academic research in 2018, which was used by many researchers. This dataset is not currently available any longer.)</p><p> [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark138\">1</a>]: This dataset includes 19,457 face images, including 7,948 deepfake images generated from on 175 forged videos collected online and 11,509 real face images collected from various online sources. (Table 2 of the paper shows the dataset size is 19,509, but the dataset downloaded from pCloud contains just 19,457 images.)</p><p> [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark167\">30</a>]: This dataset includes 100,000 synthesised face, bedroom, car and cat images by a GAN generator trained based on real images in the FFHQ<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark45\">25</a> and LSUN<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark46\">26</a> datasets (three object types ‚Äì bedrooms, cars and cats ‚Äì for the latter). Note that the name ‚Äú100K-Generated-Images‚Äù was not a proper one as the authors [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark167\">30</a>] just used this to name a sub-folder of their Google Drive shared space, but it was used in one of the survey papers [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark202\">65</a>].</p><p><strong>Ding et al.‚Äôs swapped face dataset</strong> [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark154\">17</a>]: This dataset contains 420,053 images of celebrities, including 156,930 real ones downloaded using Google Image API and 263,123 fake face-swapped ones created using two different methods (Nirkin‚Äôs method and Auto-Encoder-GAN)</p><p> [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark185\">48</a>]: This dataset includes 87,000 224x224 face images, generated by processing some StyleGAN-generated synthetic images using the GAN-fingerprint Removal approach (GANprintR) proposed by <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark185\">Neves et al.</a>. It is the replaced version of the  dataset, which contains 150,000 face images generated using an earlier version of GANprintR.</p><p> [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark158\">21</a>]: This dataset includes 40,000 images, half real and half deepfake. The images were collected from four sources: the CelebA-HQ dataset<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark47\">27</a>, the Flickr-Faces-HQ dataset<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark48\">28</a>, the 100K-Faces dataset<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark49\">29</a> (not available any longer, see the description of generated.photos datasets), and <a href=\"https://thispersondoesnotexist.com/\">thisperson-doesnotexist.com</a>.</p><p> [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark212\">75</a>]: This dataset includes 625,537 synthesised face images of 10,177 celebrities, with 43 rich attributes on face, illumination, environment and spoof types. The real images were selected from the CelebA dataset<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark50\">30</a>. The 43 attributes include 40 for real images, covering all facial components and accessories (e.g., skin, nose, eyes, eyebrows, lip, hair, hat, eyeglass), and 3 for fake images, covering spoof types, environments and illumination conditions.</p><p><strong>Diverse Fake Face Dataset (DFFD)</strong> [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark148\">11</a>]: This dataset contains 299,039 images, including 58,703 real images sampled from three datasets (FFHQ<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark51\">31</a>, CelebA<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark52\">32</a> and FaceForensics++<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark53\">33</a>) and 240,336 fake ones in four main facial manipulation types (identity swap, expression swap, attribute manipulation, and entire synthesis). The images cover two genders (male and female), a wide age groups (the majority between 21 and 50 years old), and both low- and high-quality levels.</p><h2>4.2&nbsp;&nbsp;&nbsp;&nbsp; Deepfake Video Datasets</h2><p> [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark172\">35</a>]: This dataset contains 620 deepfake face videos, generated by face swapping without manipulation of audio, covering 32 subjects and two quality levels (high and low).</p><p> (FF) [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark192\">55</a>]: This dataset contains 1,004 face videos with over 500,000 frames, covering various quality levels and two types of facial manipulation. This dataset is now replaced by the larger FaceForensics++ dataset (see below).</p><p> (FF++) [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark193\">56</a>]: This dataset contains 5,000 face videos with over 1.8 million manipulated frames, including 1,000 real videos (with 509,914 frames) downloaded from YouTube, and 4,000 fake videos created using four face manipulation methods (Deepfakes, Face2Face, FaceSwap and NeuralTextures). The videos cover two genders (male and female), and three quality levels (VGA/480p, HD/720p, and FHD/1080p).</p><p> [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark176\">39</a>]: This dataset contains 98 face videos, half (49) are real ones downloaded from Youtube, and the other half are fake ones generated using the FakeApp mobile application (which is now discontinued). The video dataset was created to used to demonstrate a deepfake video detection method based on detection of eye blinking behaviours, so all videos contain at least one eye-blinking event. All fake videos were created by swapping the original face in each of the real videos with the face of the actor Nicolas Cage<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark54\">34</a>, thus, only one subject is represented.</p><p> [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark147\">10</a>]: This dataset contains 142 ‚Äúin the wild‚Äù deepfake portrait videos, collected from a range of online sources including news articles, online forums, mobile apps, and research presentations. The videos are diverse, covering the source generative model, resolution, compression, illumination, aspect-ratio, frame rate, motion, pose, cosmetics, occlusion, content, and context.</p><p><strong>DFDC (Deepfake Detection Challenge) preview dataset</strong> [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark155\">18</a>]: This dataset contains 5,244 face videos of 66 subjects with both face and voice manipulation. It was released as a preview of the full dataset of the 2020 Deepfake Detection Challenge (DFDC, see below).</p><p><a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark55\">35</a>: This dataset contains 1,203 face videos of celebrities, including 408 real videos collected from YouTube with subjects of different ages, ethic groups and genders, and 795 deepfake videos synthesised from these real videos.</p><p> [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark177\">40</a>]: This dataset contains 6,229 face videos of celebrities, including 590 real videos collected from YouTube with subjects of different ages, ethic groups and genders, and 5,639 deepfake videos synthesised from these real videos.</p><p><strong>DeepFake Detection (DFD) Dataset</strong> [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark157\">20</a>]: This dataset contains 3,363 face videos, covering 28 subjects, gender, and skin colour. It was created as a joint effort between two units of Google, Inc.: Google AI<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark56\">36</a> and JigSaw<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark57\">37</a>.</p><p> [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark164\">27</a>]: This dataset contains 60,000 indoor face videos (with 17.6 million frames) generated by face swapping, covering 100 subjects, four skin tones (white, black, yellow, brown), two gen-ders (male and female), different age groups (20-45), 26 nationalities, 7 different angles, 8 face expressions, and different head poses.</p><p><strong>DFDC (Deepfake Detection Challenge) full dataset</strong> [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark155\">18</a>]: This dataset contains 128,154 face videos of 960 subjects, including 23,654 real videos from 3,426 paid actors and 104,500 deepfake videos created using eight different methods (DF-128, DF-256, MM/NN face swap, NTH, FSGAN, StyleGAN, refinement, and audio swap).</p><p>10<strong>(Face Forensics in the Wild) dataset</strong> [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark216\">79</a>]: This dataset contains 10,000 high-quality forgery videos, with video- and face-level annotations. The dataset focuses on a more challenging case for forgery detection: each video involves one to 15 individuals, but only some (a minority of) faces are manipulated.</p><p><strong>Korean DeepFake Detection Dataset (KoDF)</strong> [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark173\">36</a>]: This dataset contains 37,942 videos of paid subjects (395 Koreans and 8 Southeastern Asians), including 62,166 real videos and 175,776 fake ones created using six methods ‚Äì FaceSwap, DeepFaceLab, FSGAN, First Order Motion Model (FOMM), Audio-driven Talking Face HeadPose (ATFHP) and Wav2Lip. The videos cover a balanced gender ratio and a wide range of age groups.</p><p> [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark160\">23</a>]: This dataset contains 1,737 videos with 1,666,816 frames, including 1,339,843 real frames and 326,973 fake frames generated using the Deep Video Portraits (DVP) [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark171\">34</a>] method. The original videos were obtained from three sources: the dataset used in [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark170\">33</a>], the Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS) [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark179\">42</a>], and YouTube. Most videos have a resolution of 1280√ó720.</p><p> [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark218\">81</a>]: This dataset contains 7,314 face sequences extracted from 707 deepfake videos that were collected completely from the Internet. It covers diverse scenes, multiple persons in each scene and rich facial expressions. Different from other deepfake video datasets, WildDeepfake contains only face sequences not the full videos. This makes the dataset more like between an image dataset and a video one. We decided to keep it in the video category since the selection process was still more video-focused.</p><h2>4.3&nbsp;&nbsp;&nbsp;&nbsp; Deepfake Audio/Speech Datasets</h2><p>Voice conversion (VC) is a technology that can be used to modify an audio and speech sample so that it appears as if spoken by a different (target) person than the original (source) speaker. Obviously, it can be used to generate deepfake audio/speech samples. The biennial Voice Conversion Challenge<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark58\">38</a> that started in 2016 is a major challenge series on VC. Datasets released from this challenge series are very different from other deepfake datasets: the deepfake data is not included in the original dataset created by the organisers of each challenge, but in the participant submissions (which are retargeted/fake utterances produced by VC systems built by participants). The challenge datasets also include the evaluation (listening-based) results of all submissions. Some fake utterances may be produced by DL-based VC systems, so we consider all datasets from this challenge series relevant for our purpose of this survey.</p><p><strong>Voice Conversion Challenge 2016 database</strong> [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark199\">62</a>]: The original dataset created by the challenge organisers was derived from the DAPS (Device and Produced Speech) Dataset [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark184\">47</a>]. It contains 216 utterances (162 for training and 54 for testing) per speaker from 10 speakers. Participating teams (17) developed their own VC systems for all 25 source-target speaker pairs, and then submitted generated utterances for evaluation. At least six participating teams used DL-related techniques (LSTM, DNN) in their VC systems (see Table 2 of the result analysis paper<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark59\">39</a>), so the submitted utterances can certainly be considered deepfakes.</p><p><strong>Voice Conversion Challenge 2018 database</strong> [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark181\">44</a>]: The original dataset created by the challenge organisers was also based on the DAPS dataset. It contains 116 utterances (81 for training and 35 for testing) per speaker from 12 speakers in two different tasks (called Hub and Spoke). Participating teams (23 in total, all for Hub and 11 for Spoke) developed their own VC systems for all 16 source-target speaker pairs, and then submitted generated utterances for evaluation. Comparing with the 2016 challenge, more participating teams used DL-related techniques (e.g., WaveNet, LSTM, DNN, CycleGAN, DRM ‚Äì deep relational models, and ARBM ‚Äì adaptive restricted Boltzmann machines) in their VC systems.</p><p><strong>Voice Conversion Challenge 2020 database</strong> [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark207\">70</a>]: This dataset is based on the Effective Multilingual Interaction in Mobile Environments (EMIME) dataset<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark60\">40</a>, a bilingual (Finnish/English, German/English, and Mandarin/English) database. It contains 145 utterances (120 for training and 25 for testing) per speaker from 14 speakers for two different tasks (with 4 √ó 4 and 4 √ó 6 source-target speaker pairs, respectively). Participating teams (33 in total, out of which 31 for Task 1 and 28 for Task 2) developed their own VC systems for all source-target speaker pairs, and then submitted generated utterances for evaluation. Comparing with the 2018 challenge, DL-based VC systems were overwhelmingly used by almost all participating teams (WaveNet and WaveGAN among the most used DL-based building blocks).</p><p>A major set of deepfake speech datasets were created for the  (Automatic Speaker Verification Spoofing and Countermeasures) Challenge<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark61\">41</a> (2015-2021, held biannually). The datasets for the 2019 and 2021 contain speech data that can be considered deepfakes.</p><p><strong>ASVspoof 2019 Challenge database</strong> [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark204\">67</a>]: This dataset is based on the Voice Cloning Toolkit (VCTK) corpus<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark62\">42</a>, a multi-speaker English speech database captured from 107 speakers (46 males and 61 females). Two attack scenarios were considered: logical access (LA) involving spoofed (synthetic or converted) speech, and physical access (PA) involving replay attacks of previously recorded bona fide recordings). For our purpose in this survey, the LA scenario is more relevant. The LA part of the dataset includes 12,483 bona fide (real) utterances and 108,978 spoofed utterances. Some of the spoofed speech data for the LA scenario were produced using a generative model involving DL-based techniques such as long short-term memory (LSTM)<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark63\">43</a>, WaveNet [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark187\">50</a>], WaveRNN [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark165\">28</a>], WaveCycleGAN2 [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark195\">58</a>]. Note that the challenge organisers did not use the term ‚Äúdeepfake‚Äù explicitly, despite the fact that the DL-generated spoofed speech data can be considered as deepfakes.</p><p><strong>ASVspoof 2021 Challenge ‚Äì Logical Access Database</strong> [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark151\">14</a>]: This dataset contains bona fide and spoofed speech data for the logical access (LA) task. The challenge is still ongoing and we did not find a detailed paper on the dataset, so cannot include more details other than its size (7.8 GB after compression). Although we did not see details of the generative algorithms used to produce spoofed speech data, we believe similar DL-based algorithms were used like for the 2019 challenge.</p><p><strong>ASVspoof 2021 Challenge ‚Äì Speech Deepfake Database</strong> [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark152\">15</a>]: In 2021, the challenge included an explicitly defined track on deepfake, but the task description suggests that the organisers of the challenge considered a broader definition of the term ‚Äúdeepfake‚Äù by looking at spoofing human listeners rather than ASV (Automatic Speaker Verification) systems. The size of the dataset is 34.5 GB after compression.</p><p>Possibly because of the long history and wide participation of the community in the ASVspoof challenges for creating the dedicated datasets, there are very few other deepfake audio/speech datasets. One such dataset was created by a group of researcher from Baidu Research [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark142\">5</a>]. This dataset was created to demonstrate a proposed voice cloning method. It is relatively small, and contains 134 utterances, including 10 real ones, 120 cloned ones, and 4 manipulated ones. Another dataset was created by Google AI and Google News Initiative<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark65\">44</a>, but it was made part of the ASVspoof 2019 dataset. This dataset contains thousands of phrases spoken by 68 synthetic ‚Äúvoices‚Äù covering a variety of regional accents.</p><h2>4.4&nbsp;&nbsp;&nbsp;&nbsp; Hybrid Deepfake Datasets</h2><p><strong>NIST OpenMFC (Open Media Forensics Challenge) Datasets</strong><a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark66\">45</a>: These datasets were created by the DARPA Media Forensics (MediFor) Program<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark67\">46</a> for the 2020 OpenMFC<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark68\">47</a>. There are two GAN-generated deepfake datasets, one with more than 1,000 deepfake images and the other with over 100 deepfake videos. The datasets were made available to registered participants of the competition only.</p><p> [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark162\">25</a>]: This dataset is named as ‚Äúa versatile benchmark for comprehensive forgery analysis‚Äù. It contains 2,896,062 images and 221,247 videos, including 1,457,861 fake images and 121,617 fake videos. The videos and images cover seven image-level and eight video-level manipulation approaches, 36 different types of perturbations and more mixed perturbations, and a large number of annotation labels (6.3 million classification labels, 2.9 million manipulated area annotations and 221,247 temporal forgery segment labels). The dataset is being used for supporting the Face Forgery Analysis Challenge 2021<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark69\">48</a> at the SenseHuman 2021 (3rd Workshop on Sensing, Understanding and Synthesizing Humans)<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark70\">49</a>, co-located at the ICCV 2021 conference<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark71\">50</a>.</p><h2>4.5&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; A Deepfake Dataset Generator</h2><p> [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark211\">74</a>]: This is not actually a dataset per se, but a system for producing large datasets more automatically, including generating deepfake datasets. One may argue the automatically generated datasets are fake since they are not produced from real-world scenes.</p><h2>4.6&nbsp;&nbsp;&nbsp;&nbsp; Subjective Quality of Deepfakes in Different Databases</h2><p>As mentioned in Section <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark73\">4.7</a>, subjective quality evaluation is necessary to evaluate the realness, realisticness, and naturalness of deepfake media. While there has been very limited work on this topic, in 2020, Jiang et al. [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark164\">27</a>] conducted a user study on realness of deepfake videos. They recruited 100 professional participants (most of whom are computer vision researchers), who were asked to evaluate the realness of 30 randomly selected videos from 7 deepfake video datasets (DeeperForensics-1.0, UADFV, DeepFake-TIMIT, Celeb-DF, FaceForensics++, Deep Fake Detection, and DFDC). Participants were asked to respond to the statement ‚ÄúThe video clip looks real.‚Äù and gave scores following a five-point Likert scale (1 ‚Äì clearly disagree, 2 ‚Äì weakly disagree, 3 ‚Äì borderline, 4 ‚Äì weakly agree, 5 ‚Äì clearly agree).</p><p>Table <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark72\">3</a> shows the results. Interestingly, we can see a huge difference between the realness levels of different datasets. What is probably quite surprising is that FaceForensics++, one of the most widely used deepfake datasets, has a very low MOS score and less than 9% of participants considered the 30 selected videos as real.</p><p>Table 3: Human-judged subjective quality (realness) of deepfake videos in 7 datasets. The MOS scores were not reported by <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark164\">Jiang et al.</a>, but calculated by us based on the raw data shown in Table 3 of [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark164\">27</a>].</p><h2>4.7&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Discussion: Datasets</h2><p>Among all deepfake image and video datasets, a significant majority are about face images and videos. This is not surprising since face swapping, face attribution manipulation, and fully synthesised face images are among the hottest topics within deepfake research and real-world applications. We hope more non-face deepfake image and video datasets can be produced to support a broader range of research activities on deepfake.</p><p>The subjective quality results shown in Table <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark72\">3</a> indicate that it is important to check realness of deep-fake media to support any performance evaluation or comparison. To ensure that the quality evaluation of datasets is fair, transparent and reliable, standard procedures need defining and a common pool of qualified human experts should be used.</p><p>Many authors of deepfake-related datasets attempted to classify such datasets into different generations. Chronologically speaking, we could broadly split such datasets into two generations: before 2019 and since 2019. Typically, datasets created before 2019 are relatively less advanced and smaller, while those created after 2019 tend to be larger, more diverse (i.e., covering more attributes), and of higher quality (i.e., produced by more advanced generative models). This can also be seen from the data in Table <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark72\">3</a>, in which the top two datasets (DeeperForensics-1 and Celeb-DF) fall within the new generation (2020), while others belong to the old generation. In addition to the two generations, a newer generation has also emerged in 2021: a number of very recent datasets started focusing on more realistic deepfakes (i.e., in the wild) or more specified areas of deepfakes (e.g., 10 focusing on multiple faces in the same video, and KoDF focusing on Korean faces). This trend shows that the deepfake research community has grown significantly in the past few years so that narrower topics have also started gaining attention and interest from some researchers.</p><p>This section reviews initiatives aiming to advance the state-of-the-art of detection and generation of synthetic or manipulated media (such as video, image and audio) via competitions or challenges open to the public, and ongoing benchmarks tackling specific problems.</p><p>The Deepfake Detection Challenge (DFDC)<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark75\">51</a> was an initiative promoted by an AI and Media Steering Committee<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark76\">52</a>, including BBC, Facebook, Amazon, Microsoft and New York Times, and some universities around the world including the University of Oxford. The competition remained open from 5 September 2019 till 31 March 2020, and involved 3 stages. At first, the DFDC preview dataset was released. At a later stage, the DFDC full dataset was also made available to the 2,114 participants of the competition incorporating face and audio swap techniques for generation of deepfake content. At the final stage, the submitted models were evaluated using a test dataset (referred to as the ‚Äúblack box dataset‚Äù) of 10,000 videos which included  deepfake videos. The best performance on the black box dataset had an accuracy of 65.18%, according to the released results [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark159\">22</a>]. Submissions were ranked<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark78\">53</a> according to the overall log loss score, as defined in Eq. (<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark22\">13</a>). All top five ranked models (the winner had the lowest overall log loss) are available on GitHub. Results indicate how challenging the detection of deepfake is since the best accuracy was low and ‚Äú<em>many submissions were simply random</em>‚Äù, according to Dolhansky et al. [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark156\">19</a>]. Figure <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark77\">2</a> shows a screenshot of the leaderboard with the five finalists. The first top ranked model used MTCNN (Multi-tasked Cascaded Convolutional Network), the second used WS-DAN (Weakly Supervised Data Augumentation Network), and the third used the EfficientNetB7 architecture. Meta compiling the common themes observed in the winning models, they were: clever augmentations, architectures, and absence of forensics methods. Moving forward, they called for ‚Äú<em>solutions that go beyond analysing images and video. Considering context, provenance, and other signals may be the way to improve deepfake detection models</em>‚Äù.</p><p>\\\nThe Automatic Speaker Verification Spoofing And Countermeasures Challenge Workshop (ASVspoof)<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark79\">54</a> has been running biennially since 2015. This competition is organised by an international consortium that includes Inria and EURECOM (France), University of Eastern Finland, National Institute of Informatics (Japan), and Institute for Infocomm Research (Singapore). This year the ASVspoof challenge includes, for the first time, a sub-challenge focused on  where the envisioned use case is an adversary trying to fool a human listener. The metric used for evaluating performance of submitted solutions (i.e., classifiers) is EER. Four baseline solutions<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark80\">55</a> (also called ‚Äúcountermeasures‚Äù), each using a different technique, were made available to participants with their corresponding EER metric values. The ASVspoof 2021 Speech Deepfake Database containing audio recordings with original and spoofed utterances has also been made available. The competition involves three phases<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark81\">56</a>: a progress phase, an evaluation phase and a post-evaluation phase; it is unclear how teams move from one phase to the next. More information about the 2021 competition is available in the published evaluation plan [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark150\">13</a>]. The organisers of the competition noted that they opted for the EER as the performance evaluation met-ric for countermeasures submitted to the speech deepfake task for legacy reasons. They acknowledged, however, that ‚Äú<em>EER reporting is deprecated</em> ‚Äù by the ISO/IEC 19795-1:2021<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark82\">57</a> standard. Despite the fact that only the 2021 ASVspoof competition contained a track explicitly related to deepfake, some data in the ASVspoof 2019 dataset (Logical Access task) used for the 2019 competition was generated using DL-based algorithms as mentioned in Section <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark35\">4</a>. We expect that this also holds for the ASVspoof 2021 dataset (Logical Access task). The ASVspoof 2019 competition used the EER as secondary metric; the primary performance metric used was the tandem detection cost function (t-DCF) [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark200\">63</a>]. According to its evaluation plan [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark206\">69</a>], t-DCF assesses the performance of the whole tandem system whereby ‚Äú<em>a CM [countermeasure] serves as a ‚Äògate‚Äô to determine whether a given speech input originates from a bona fide (genuine) user, before passing it the main biometric verifier (the ASV system)</em>‚Äù. It is calculated according to Eq. (<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark83\">17</a>), where  cm () and  cm() are, respectively, ‚Äú<em>the miss rate and the false alarm rate of the CM system at threshold s</em>‚Äù.</p><p>For further information about Eq. (<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark83\">17</a>), including constants 1 and 2, please refer to the ASVspoof 2019 evaluation plan [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark206\">69</a>].</p><p>An implementation of the t-DCF metric has been made available by the ASVspoof 2019‚Äôs organisers in Python<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark85\">58</a> and Matlab<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark86\">59</a> formats.</p><p>The Face Anti-spoofing (Presentation Attack Detection) Challenge<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark87\">60</a> started in 2019. Its first two editions were held at the 2019 and 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR 2020), respectively. Its third edition was moved to be co-located with the 2021 IEEE/CVF International Conference on Computer Vision (ICCV 2021). This competition series was organised by a group of researchers from academia and industry in China, Mexico, Spain, Finland and the US. The 2021 competition was focused on 3D high-fidelity mask attacks, and followed a 2-phased<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark88\">61</a> process. The first phase is the ‚Äúdevelopment phase‚Äù; it started in April 2021 when the CASIA-SURF HiFiMask dataset<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark89\">62</a> was released to participants. The second phase is the ‚Äúfinal ranking phase‚Äù (June 2021), when the competition ended. The competition adopted the following performance metrics for evaluation<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark90\">63</a> of the solutions submitted: attack presentation classification error rate (APCER), normal/bona fide presentation classification error rate (NPCER/BPCER), and average classification error rate (ACER), in accordance with the ISO/IEC 30107-3:2017<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark91\">64</a> standard. Figure <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark84\">3</a> provides the leaderboard for the top three solutions.</p><p>\\\nThe FaceForensics Benchmark<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark92\">65</a> is an ongoing automated benchmark for detection of face manipulation. The organisers of the benchmark made the FaceForensics++ dataset available for training. Manipulated videos (4,000 in total) were created using four techniques, i.e., two computer graphics-based approaches (Face2Face and FaceSwap) and two learning-based approaches (DeepFakes and Neural Textures). The deepfakes videos were generated using a slightly modified version of FaceSwap<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark93\">66</a>, and the Neural Textures videos were created using the approach proposed by Thies et al. [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark198\">61</a>]. The benchmark test dataset is created from the collection of 1,000 images randomly selected from either the manipulation methods or the original videos [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark193\">56</a>]. Participants have to submit results to the benchmark, rather then code like other competitions; this is illustrated in Figure <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark94\">4a</a>. The outcome of a submission is illustrated in Figure <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark94\">4b</a>, where the scores are a measure of accuracy (Eq. (<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark17\">8</a>)).</p><p>\\\nThe Open Media Forensics Challenge (OpenMFC, formerly DARPA MFC)<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark96\">67</a> is an annual image and video forensics evaluation aiming to facilitate development of multimedia manipulation detection systems. It has been organised annually<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark97\">68</a> starting from 2017 under the name of DARPA MFC. In 2020, the National Institute of Standards and Technology (NIST) initiated the  as a new evaluation platform, based on their previous experiences with the DARPA MFC series, to make the participation more convenient for all researchers. In OpenMFC 2020, two deepfake-related tasks were included for the first time: Image GAN Manipulation Detection (IGMD) and Video GAN Manipulation Detection (VGMD). The organisers provided an image evaluation dataset for the IGMD task, containing 1,000 images from over 200 image journals<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark98\">69</a>, and a video evaluation dataset for the VGMD task, including over 100 test videos. Furthermore, they provided the datasets<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark99\">70</a> used in the previous MFC challenges as development datasets. The challenge is composed of two main phases for development and evaluation, respectively, and a pre-challenge phase for quality control testing. For evaluation of submissions, AUC-ROC is used as the primary metric. Furthermore, CDR@FAR, where CDR refers to correct detection rate or TPR (Eq. (<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark13\">4</a>)) and FAR refers to false alarm rate or FPR (Eq. (<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark14\">5</a>)), is also used as a metric [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark186\">49</a>]. The DeeperForensics Challenge 2020<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark100\">71</a> is a deepfake face detection challenge held at the 2020 ECCV</p><p>SenseHuman Workshop<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark101\">72</a>. The challenge used the DeeperForensics1.0 dataset.</p><p>The organisers provided a hidden test dataset to better simulate real-world scenarios. The challenge involved two phases: the ‚Äúdevelopment phase‚Äù that started in August 2020 allowing 100 successful sub-missions, and the ‚Äúfinal test phase‚Äù that started in October 2020 allowing 2 successful submissions until the end of the month. The submissions were evaluated using the binary cross-entropy loss (BCELoss) metric, calculated according to Eq. (<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark95\">18</a>), where  is the number of videos in the hidden test set,  is the ground truth label of video  (fake:1, real:0), and () is the predicted probability that video  is fake.</p><p>Results<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark102\">73</a> of the competition were discussed by Jiang et al. [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark163\">26</a>]. The top solution used three models, i.e., EfficientNet-B0, EfficientNet-B1 and EfficientNet-B2, for classification. The second top used EfficientNet-B5 for both an image-based model and a video-based model. The third ranked solution used a 3D convolutional neural network (3DCNN).</p><p>\\\nThe Face Forgery Analysis Challenge 2021<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark104\">74</a> is a competition hosted at the 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR 2021). It is organised by researchers from a number of organisations in China including universities and SenseTime Research (the research arm of SenseTime<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark105\">75</a>, one of the major AI ‚Äúunicorns‚Äù in China). The challenge aims to advance the state-of-the-art in detection of photo-realistic manipulation of images and videos. Participants are able to use a large annotated face dataset (i.e., the ForgeryNet dataset) that was obtained by applying a number of techniques for manipulation (15) and perturbation (36) to train their solutions. The phases comprise of Forgery Image Analysis, Forgery Video Analysis, Forgery Video Temporal Localization phases, and the final phase (i.e., ‚Äúprivate test‚Äù) where participants‚Äô models will be tested against an unseen dataset. The following metrics will be used [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark162\">25</a>]: AUC, average precision (AP) at some ‚Äútemporal Intersection over Union‚Äù (AP@tIoU) compared to a threshold  ‚àà [0*.,* 0*.*95], and average recall (AR) at  (AR@) where  is the top  labels returned for multi-class classifiers.</p><p>The 2020 CelebA-Spoof Face Anti-Spoofing Challenge<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark106\">76</a> was hosted at the 16 European Conference on Computer Vision (ECCV 2020). The challenge ran between August and October 2020, and aimed to advance the state-of-the-art in detecting ‚Äú<em>whether a presented face is live or spoof</em> ‚Äù [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark213\">76</a>]. The organisers made the face CelebA-Spoof dataset available for the competition containing rich annotation across a range of attributes. The competition only had one phase where participants submitted their solutions to be evaluated against a test dataset; the spoof class was considered as ‚Äúpositive‚Äù and the live class as ‚Äúnegative‚Äù. Metric TPR@FPR was used and collected at three points where the TPR when FPR = 104 determined the final ranking. The top three finalists (see Figure <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark103\">5</a>) used deep learning models ResNet, EfficientNet-B7, and a novel architecture combining Central Difference Convolutional Networks (CDCN) and Dual Attention Network (DAN). The two top ranked solutions used different strategies to boost their models‚Äô performance: a heuristic voting scheme was used by the top-ranked solution, and a weight-after-sorting strategy was used by the second ranked solution.</p><p>The 2021 CSIG Challenge<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark107\">77</a> is the second edition of a challenge organised by the China Society of Image and Graphics<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark108\">78</a>. The 2021 challenge has the Fake Media Forensic Challenge<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark109\">79</a> as its 6 track, co-organised by CSIG‚Äôs Digital Media Forensics and Security Technical Committee<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark110\">80</a> and Institute of Information Engineering, Chinese Academy of Sciences<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark111\">81</a>. This track has two tasks, one on deepfake video detection, and the other on deepfake audio/speech detection. For the deepfake video detection task, the dataset used contains a public training set with 10,000 sound-free face videos (including 4,000 fake videos), a public test set with 20,000 face videos (the percentage of deepfake videos is unknown to participants), and a private test set that will be determined and used at the final session for selecting the winners. All videos contain faces of Eastern Asian people, and cover a wide range of parameters such as multiple resolutions and encoding quality factors, the use of blurring or sharpening filters, and added noise. Deepfake videos were created using public tools including DeepFaceLab [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark190\">53</a>], Faceswap<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark112\">82</a>, Faceswap-GAN, Recycle-GAN [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark143\">6</a>] and ALAE (Adversarial Latent Autoencoders) [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark191\">54</a>]. For the deepfake audio/speech detection task, the dataset used contains a public training set with 10,000 speech samples (including 6,000 fake ones), a public test set with 20,000 face videos (the percentage of deepfake videos is unknown to participants), and a private test set for the final session (the same as the deepfake video detection task). The tools used for generating the fake speech samples include TTS (text-to-speech) voice synthesis tools and VC (voice conversion) tools. The main TTS tools used include open-source tools such as DeepVoice, TensorFlowTTS<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark114\">83</a> and GAN-TTS [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark145\">8</a>] and commercial software tools such as those from iFlytek<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark115\">84</a> and IBM. The main VC tools used include Adaptive-VC and CycleGAN-VC [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark166\">29</a>]. For both deepfake detection tasks, the performance metric used is log loss.</p><p>2020 China Artificial Intelligence<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark116\">85</a> was the second edition of a Chinese AI competition open for the general public to participate, organised by the municipal government of the City of Xiamen in China. In 2020, it had two sub-competitions, Multimedia Information Recognition Technology Competition<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark117\">86</a> and Language and Knowledge Technology Competition<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark118\">87</a>. The Multimedia Information Recognition Technology Competition included two tasks on deepfakes: one on deepfake video detection<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark119\">88</a> and one on deepfake audio/speech detection<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark120\">89</a>. The deepfake video detection task used 3,000 videos, and log loss was used as the sole performance metric. The deepfake audio/speech detection task used 20,000 audio samples (mostly in Chinese, and the remaining in English), and EER was used as the sole performance metric. For both tasks, the ratio between real and deepfake samples was 1:1. We did not find where to download the datasets used for the tasks nor a more detailed technical description of the datasets. For the deepfake video detection tasks, the top two winning teams (with an A prize) were from Netease (Hangzhou) Network Co., Ltd. and Beijing RealAI Technology Co., Ltd., followed by three other teams winning a B prize: Xiamen Fuyun Information Technology Co., Ltd.; Institute of Computing Technology, Chinese Academy of Sciences; and Wuhan Daqian Information Technology Co., Ltd. For the deepfake audio/speech task, there was no team winning an A prize, but one team winning a B prize: SpeakIn Technologies Co., Ltd. The final results of some teams were published, but some teams were allowed to hide their results. We did not find a detailed technical report summarising the results and explaining the work of the winning teams.</p><p>One of the B-prize winning team is from Beijing RealAI Technology Co., Ltd., a Chinese company active in deepfake-related R&amp;D.</p><p>The Voice Conversion Challenge<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark121\">90</a> is a biennial competition that has been running since 2016. The challenge and the corresponding workshop, hosted at the INTERSPEECH conference<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark122\">91</a>, is supported by the SynSig (Speech Synthesis Special Interest Group)<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark123\">92</a> of the International Speech Communication Association (ISCA)<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark124\">93</a>. Its aim is to promote progress in voice conversion (VC) technology that can be applied to a number of positive and negative use cases, such as spoofing voice biometric systems. The 2020 challenge focused on speaker conversion, a sub-problem of VC, and included two tasks. For the first task ‚Äúintra-lingual semi-parallel voice conversion‚Äù, participants had to develop 16 VC systems (speaker-pair combinations) including male and female speakers and English sentences, using the provided Voice Conversion Challenge 2020 database v1.0 for training (refer to Section <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark35\">4</a>). For the second task ‚Äúcross-lingual voice conversion‚Äù, participants had to develop 24 VC systems, also including male and female speakers, but uttering sentences in three languages (Finnish, German and Mandarin), based on the provided training dataset. Figure <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark126\">6</a> illustrates the process of training and generation of VC systems.</p><p>Submissions were evaluated for ‚Äú<em>perceived naturalness and similarity through listening tests</em>‚Äù<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark125\">94</a>. As such, the organisers used  [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark207\">70</a>] and recruited both native and non-native English speakers (i.e., Japanese native speakers) via crowd-sourcing for the listening tests. Naturalness (answering the question ‚ÄúHow natural does the converted voice sound? ‚Äù) was measured using the metric MOS (covered in Section 4.6), and similarity (answering the question ‚Äúhow similar the converted voice sound comparing source and target speakers? ‚Äù) was measured in terms of speaker recognition as ‚Äúsame‚Äù or ‚Äúdifferent‚Äù, as elaborated by Wester et al. [68]. Tests also focused on the effects of language differences on the performance of VC systems submitted to the competition. The most popular CNN/RNN/GANbased VC systems submitted used WaveNet, WaveRNN, and Parallel WaveGAN. Results indicated that, in terms of similarity, the best performing VC systems were as good as natural speech but none reached human-level naturalness for task 1; scores were lower for task 2 which was more complex [70]. The organisers of the 2020 competition also used objective evaluation [12]. The metrics used for evaluation of speaker similarity were: equal error rate (EER), false acceptance rate of target (P tar fa ), miss rate of source (P src miss), and cosine similarity of speaker embedding vectors (cos-sim) according to Eq. (19) where A is the speaker embedding vectors for the converter audio and B is the speaker embedding vectors for the original audio. The performance of the VC systems as a spoof countermeasure was also evaluated using EER, while to evaluate the quality of the subjective MOS obtained via listening tests, a DL-based model to predict MOS, called MOSNet [43], was used. Lastly, to evaluate intelligibility of the converted transcribed speech, in comparison with the original transcribed speech, the word error rate (WER) [4] was used. WER is calculated according to Eq. (20) where I refers to insertions, D refers to deletions, S refers to substitutions, and N refers to the total number of words in the original transcript.</p><p>The Deepfake Africa Challenge (2021)<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark129\">95</a> is a new initiative of the AI Africa Expo, in partnership with a film and media production company (Wesgro) and the African Data Science competition platform Zindi. Its aim is ‚Äú<em>to create convincing deepfakes to highlight the power of this synthetic media, illustrating its creative potential for exploitation for both positive and negative outcomes and focusing debate about its ethical use / misuse in an African context</em> ‚Äù. Eligible participants were required to be citizens and residents of the African continent. Submissions, accepted up to end of July 2021, can be either video or audio. Evaluation of submissions is defined in terms of artistic creativity, relevance of challenge topic, and innovation in the process of generation as long as participants use tools and packages publicly available. The top three finalists will receive a prize, present their work at the Expo, and will have to grant copyrights to Zindi. Unlike the other competitions reviewed in this section, which were focused on advancing the state-of-the-art in detection of synthetic or manipulated media, this competition focused on the generation of deepfake which seems more humanities-centred. This is a trend observed in arts [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark168\">31</a>] and culture [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark194\">57</a>].5.3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Generation and Detection of Manipulated Media</p><p>The DeepFake Game Competition (DFGC)<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark132\">96</a> is in its first edition, hosted at the 2021 International Joint Conference on Biometrics (IJCB 2021). Its organisers are mainly from the Institute of Automation Chinese Academy of Sciences (CASIA). The idea of the competition was to promote an adversarial game between agents pushing for advances in both deepfake creation and detection. In order to achieve this, a 6-stage protocol was designed interleaving three creation phase (C-phase) and detection phase (D-phase), typically one week apart; submissions closed in April 2021. Both C-phases and D-phases were bound to the Celeb-DF (v2) dataset [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark177\">40</a>], containing 6,229 videos (590 real/original videos and 5,639 fake/manipulated videos), for training purposes. As such, submissions to a C-phase would consist of datasets extracted from Celeb-DF (v2) which included novel face-swap approaches to obtain evaluation results. Submissions to a D-phase would consist of detection models/codes to obtain evaluation results. The models submitted for a D-phase were evaluated against the datasets submitted for the previous C-phase [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark189\">52</a>]. The metrics used for evaluation<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark133\">97</a> were: a detection score, used for evaluation of a D-phase, and a creation score, used for evaluation of a C-phase. The top three finalists for the detection phase employed CNN-based classifiers EfficientNet-B3, Efficientnet-B0 and EfficientNetV2.</p><p>The Detection Score () metric captures the models‚Äô ability to correctly classify fake images submitted to the previous C-phase against a set of real images in the CelebDF test dataset. It is calculated using Eq. (<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark130\">21</a>), where  is the number of valid submissions of created synthesis test sets in the last C-phase.</p><p>The Creation Score () metric used to evaluate creation models submitted to this challenge is calculated by Eq. (<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark131\">22</a>), where  is the number of valid submissions of detection methods in the last D-phase, the noise score (noise) penalises noisy images, the other three parts of the equation relate to the following<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark134\">98</a>: ‚Äú<em>ID level similarity to the donor ID, image level similarity to the target frame, and the deception ability against detection models. ID level similarity is scored by a face recognition model using dot product of two ID features (fake face ID and donor ID). The image level similarity is scored by SSIM [Structural Similarity Index] to make sure the face-swapped image is similar to the corresponding target image in content and quality</em> ‚Äù.</p><p>Peng et al. [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark189\">52</a>] observed a commonality between the three winning teams for the creation task, i.e., the use of the FaceShifter [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark174\">37</a>] framework for face swapping. They highlighted two overall reflections about the competition: (1) the limited diversity of the deepfake datasets submitted and the use of repetitive methods to generate them, and (2) the limited size of the Celeb-DF (v2) dataset itself flagging the need for a larger dataset for next year‚Äôs competition. The organisers of the competition also applied the top two detection models to unseen datasets (DFDC and FaceForensics++) and noticed that they do not generalise well.</p><p>This section presents a meta-review of 12 selected deepfake-related survey papers, including eight published in English [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark153\">16</a>, <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark182\">45</a>, <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark183\">46</a>, <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark201\">64</a>‚Äì<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark203\">66</a>, <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark208\">71</a>, <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark210\">73</a>] and four published in Chinese [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark144\">7</a>, <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark175\">38</a>, <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark178\">41</a>, <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark196\">59</a>]. It covers the following aspects in a systematic manner: definitions and scope, performance metrics, datasets, challenges/competitions/benchmarks, performance comparison, key challenges and recommendations.</p><p>The meta-review aims at drawing some high-level insights for monitoring future development of deepfake-related technologies and their applications.</p><h2>6.1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Definitions and Scope</h2><p>As we discussed in Section <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark0\">1.1</a>, among researchers, practitioners and law makers there is no universally accepted definition of ‚Äúdeepfake‚Äù as a term. This is also reflected in how the authors of the 12 survey papers considered this aspect. Most authors talked about the history of deepfakes and pointed out that the term reflects the combination of ‚Äúdeep learning‚Äù and ‚Äúfake‚Äù, but some used a broader definition, e.g., Lyu [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark182\">45</a>] defined deepfake as ‚Äú<em>high quality fake videos and audios generated by AI algorithms</em>‚Äù. Some authors also referred to deepfake-related legislations, but none of them pointed out that the definitions in some such legislations are completely different from the more technical definitions involving the use of deep learning. No authors discussed the blurred boundary between deepfakes and non-deepfakes, although some surveys actually cover both, e.g., Tao et al. [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark196\">59</a>] focused on speech forgery and did not explicitly highlight ‚Äúdeepfake‚Äù.</p><p>In terms of the scope, while some authors (correctly) considered all types of media that can be produced by deepfake-related techniques [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark175\">38</a>, <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark178\">41</a>, <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark182\">45</a>, <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark202\">65</a>], some considered only a narrow scope, e.g., authors of [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark144\">7</a>, <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark201\">64</a>, <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark208\">71</a>, <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark210\">73</a>] considered only videos, and only authors of [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark153\">16</a>, <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark203\">66</a>] have considered images and videos. Another phenomenon we observed is that many authors focused more on face images and videos, and authors of three surveys [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark153\">16</a>, <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark201\">64</a>, <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark208\">71</a>] even limited the definition of ‚Äúdeepfake‚Äù to such a narrow scope:</p><ul><li>Deshmukh and Wankhade [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark153\">16</a>] defined it as ‚Äú<em>a technology which creates fake images or videos of targeted humans by swapping their faces [by] another character saying or doing things that are not absolutely done by them and humans start believing in such fake as it is not always recognisable with the everyday human eye</em>‚Äù;</li><li>Younus and Hasan [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark208\">71</a>] considered deepfake as a technique allowing ‚Äú<em>any computer user to exchange the face of one person with another digitally in any video</em>‚Äù; and</li><li>Tolosana et al. [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark201\">64</a>] defined it as ‚Äú<em>a deep learning based technique able to create fake videos by swapping the face of a person by the face of another person</em>‚Äù.</li></ul><p>Such unnecessarily narrow definitions and scopes can lead to confusion and do not help exchanges between researchers and practitioners working on different types of deepfakes.</p><p>We call on more researchers to accept a broader definition of ‚Äúdeepfake‚Äù so that highly realistic/natural media of any kind generated by a sophisticated automated method (often AI-based) is considered deepfake. Here, we provide two examples of such a broader definition: the image2image (or pixel2pixel) technique [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark217\">80</a>] that allows the production of deepfake images and videos of any objects (e.g., the ‚Äúhorse2zebra‚Äù deepfake image shown in Figure <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark135\">7</a>), and the the so-called ‚Äúdeepfake geography [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark214\">77</a>]‚Äù, where AI-based techniques are used to generate realistic-looking satellite images.</p><p>\\\nAnother important fact missed or not sufficiently discussed by authors of all the 12 surveys is that deepfake techniques can be used for positive applications, e.g., creative arts, entertainment and protecting online users‚Äô privacy. We call for more researchers and practitioners to follow the proposal in the 2020 Tencent AI White Paper [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark197\">60</a>] to start using the more neutral-sounding term ‚Äúdeep synthesis‚Äù. Accordingly,we can use different words for different types of data generated using ‚Äúdeep synthesis‚Äù techniques, e.g., ‚Äúdeep art‚Äù, ‚Äúdeep animation‚Äù, ‚Äúdeep music‚Äù, and ‚Äúdeepfake‚Äù. While authors of the 12 survey papers did not recognise the positive applications of ‚Äúdeepfake‚Äù technologies, some other researchers did, e.g., organisers of the Voice Conversion Challenge 2020<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark136\">99</a> who said the VC technology (for speech deepfake) ‚Äú<em>is useful in many applications, such as customizing audio book and avatar voices, dubbing, movie industry, teleconferencing, singing voice modification, voice restoration after surgery, and cloning of voices of historical persons</em>‚Äù.</p><p>Surprisingly, none of the 12 surveys have covered performance metrics explicitly. Some directly used performance metrics to explain and compare performance of covered deepfake generation and detection methods. The most used performance metrics include accuracy, ERR, and AUC. This may be explained by the page constraints of such survey papers, which did not allow the authors to extend their coverage significantly to cover performance metrics systematically. The subjective quality of deepfakes is an area least covered by the surveys, which seems related to an unbalanced coverage on deepfake generation and deepfake detection in terms of performance evaluation and comparison (the former much less than the latter).</p><p>Many of the 12 survey papers list a number of deepfake-related datasets, but none of them have coverage as complete as ours shown in Section <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark35\">4</a>. For instance, none of the surveys have covered the Voice Conversion Challenge 2016/2018/2020 datasets and the ASVspoof 2019/2021 datasets are covered briefly only in two surveys [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark175\">38</a>, <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark196\">59</a>]. In addition, more recent deepfake datasets especially those released in 2021 are also not covered by any of the surveys. We believe that our Section <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark35\">4</a> is the most comprehensive review of deepfake-related datasets so far.</p><p>Some survey papers include datasets that are likely deepfakes, e.g., Verdoliva [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark203\">66</a>] covered many general fake image datasets where the manipulated images were not generated by deep learning or even AI-based methods, and some surveys (e.g., [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark175\">38</a>]) mentioned ASVspoof 2015 datasets but we did not see the use of deep learning for generating data used in the dataset.</p><p>Many surveys cover deepfake-related challenges, competitions and benchmarks. The coverage is, however, mostly limited, and some challenges (e.g., the Voice Conversion Challenge 2016/2018/2020 and the two Chinese challenges we covered in Section <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark74\">5</a>) are not covered by any of the surveys. The level of detail of challenges, competitions and benchmarks is also normally limited, compared with what we chose to include in Section <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark74\">5</a>. Similar to the datasets we covered in Section <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark35\">4</a>, we believe that our coverage of deepfake-related challenges, competitions and benchmarks in Section <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark74\">5</a> is also the most comprehensive so far.</p><p>Most surveys have a good coverage of related methods for deepfake generation and detection, but only some explicitly covered performance comparison between different methods [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark175\">38</a>, <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark183\">46</a>, <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark201\">64</a>].</p><p>Among all the survey papers, Li et al. [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark175\">38</a>] conducted the most comprehensive study on performance of different deepfake detection methods. In addition to showing the performance metrics of a number of deepfake detection methods in Table 3 of [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark175\">38</a>], they also looked at general characteristics and issues of different types of deepfake detection methods, as shown in Table <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark137\">4</a>. Furthermore, they also looked at research on robustness of deepfake detection methods against adversarial samples, referring to some work that showed a lack of such robustness.</p><p>Due to quality issues of many deepfake-related datasets (discussed in Section <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark64\">4.6</a>), we need to treat any performance metrics and comparison of different detection methods with caution. Without testing all methods on a sufficiently large, diverse and high-quality deepfake dataset, the performance comparison results can be misleading. This highlights the importance of having more challenges, competitions and benchmarks to encourage performance comparison on standard datasets and using consistent performance metrics.</p><p>The authors of some surveys identified some key challenges and future research directions for the deepfake community.</p><p>Not surprisingly, how to develop more robust, scalable, generalisable and explainable deepfake detection methods is one of the most discussed key challenges and also a major future research direction [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark144\">7</a>, <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark153\">16</a>, <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark175\">38</a>, <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark178\">41</a>, <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark182\">45</a>, <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark196\">59</a>, <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark202\">65</a>, <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark203\">66</a>, <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark208\">71</a>]. Considering the arms race between deepfake generation and detection, this research direction will likely remain the hottest topic in deepfake research.</p><p>A couple of surveys [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark175\">38</a>, <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark203\">66</a>] mentioned fusion as a key future research direction, where ‚Äúfusion‚Äù refers to combining different methods (e.g., combining multiple detectors of different types) and data sources (e.g., jointly considering audio-visual analysis) to achieve better performance for deepfake detection. Lyu [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark182\">45</a>] suggested that, for detection of deepfake videos, we need to consider video-level detection more, which can be considered fusion of detection results of all video frames.</p><p>The authors of three surveys, Lyu [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark182\">45</a>] , Deshmukh and Wankhade [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark153\">16</a>] and Younus and Hasan [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark208\">71</a>], argued that better (higher-quality, more up-to-date, and more standard) deepfake datasets are needed to develop more effective deepfake detection methods. Lyu [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark182\">45</a>] also suggested that we need to consider  effects in training data and improve the evaluation of datasets. We agree with them on these points.</p><p>Tao et al. [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark196\">59</a>] suggested that low-cost deepfake generation/detection should be considered as a future research direction. This is a valid recommendation since lightweight methods will allow less powerful computing devices (e.g., IoT devices) to benefit from such technologies.</p><p>Two Chinese surveys [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark175\">38</a>, <a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark178\">41</a>] also mentioned the need to have new deepfake-related legislations combating malicious use of deepfakes and the need to train end users such as journalists. This is likely an area where interdisciplinary research can grow.</p><p>There are also other ad-hoc recommendations given by the authors of some surveys. For example, Lyu [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark182\">45</a>] argued that deepfake detection should be considered a (more complicated) multi-class, multi-label and local detection problem. Tolosana et al. [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark201\">64</a>] discussed specific research directions for different deep-fake generation methods (face synthesis, identity swap, attribute manipulation, and expression swap). Liang et al. [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark178\">41</a>] and Li et al. [<a href=\"https://hackernoon.com/how-researchers-measure-detect-and-benchmark-ai-manipulation?source=rss#_bookmark175\">38</a>] recommended more active defence mechanisms such as using digital watermarking and blockchain technologies to build trustworthy media frameworks against deepfakes.</p><p>The rapid growth in the capability to manipulate media or create synthetic media which look realistic and natural paved the way for deepfakes. At first, this paper adopted a critical approach to look at different definitions of the term ‚Äúdeepfake‚Äù. In that regard, we point out the different contradicting definitions and call for the wider community to consider how to define a new term that has a more consistent scope and meaning. For instance, replacing ‚Äúdeepfake‚Äù by ‚Äúdeep synthesis‚Äù can be more inclusive by embracing positive applications of deepfake techniques, e.g., in entertainment and for simulation purposes.</p><p>This paper provided a comprehensive overview of multiple aspects of the deepfake ecosystem drawing from the research literature and other online sources published in two languages: English and Chinese. It covers commonly used performance metrics and standards, related datasets, challenges, competitions and benchmarks. It also presents a meta-review of 12 selected deepfake-related survey papers published in 2020 and 2021, covering not only the above mentioned aspects, but also highlighting key challenges and recommendations.</p><p>[1]&nbsp;&nbsp; Darius Afchar, Vincent Nozick, Junichi Yamagishi, and Isao Echizen. 2018. MesoNet: A Compact Facial Video Forgery Detection Network. In <em>Proceedings of the 2018 IEEE International Workshop on Information Forensics and Security</em>. IEEE, 1‚Äì7. <a href=\"https://doi.org/10.1109/WIFS.2018.8630761\">https://doi.org/10.1109/WIFS.2018.8630</a><a href=\"https://doi.org/10.1109/WIFS.2018.8630761\">761</a></p><p>[2]&nbsp;&nbsp; Henry Ajder, Giorgio Patrini, Francesco Cavalli, and Laurence Cullen. 2019. The State of Deepfakes: Landscape, Threats, and Impact. Deeptrace. , 27 pages.&nbsp; <a href=\"https://sensity.ai/reports/\">https://sensity.ai/reports/</a></p><p>[4]&nbsp;&nbsp; Ahmed Ali and Steve Renals. 2018. Word Error Rate Estimation for Speech Recognition: e-WER. In <em>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</em>. Association for Computational Linguistics, 20‚Äì24. <a href=\"https://doi.org/10.18653/v1/P18-2004\">https://doi.org/10.18653/v1/P18-2004</a></p><p>[6]&nbsp;&nbsp; Aayush Bansal, Shugao Ma, Deva Ramanan, and Yaser Sheikh. 2018. Recycle-GAN: Unsupervised Video Retargeting. In <em>Proceedings of the 2018 European Conference on Computer Vision</em>. Springer, 17 pages.&nbsp; <a href=\"https://doi.org/10.1007/978-3-030-01228-1_8\">https://doi.org/10.1007/978-3-030-01228-1 8</a></p><p>[8]&nbsp;&nbsp; Mikol-aj Bin¬¥kowski, Jeff Donahue, Sander Dieleman, Aidan Clark, Erich Elsen, Norman Casagrande, Luis C. Cobo, and Karen Simonyan. 2019. High Fidelity Speech Synthesis with Adversarial Networks.&nbsp; <a href=\"https://doi.org/10.48550/ARXIV.1909.11646\">https://doi.org/10.48550/ARXIV.1909.11646</a></p><p>[10]&nbsp;&nbsp; Umur Aybars Ciftci, Ilke Demir, and Lijun Yin. 2020. FakeCatcher: Detection of Synthetic Portrait Videos using Biological Signals. <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em> (2020), 17 pages. <a href=\"https://doi.org/10.1109/TPAMI.2020.3009287\">https://doi.org/10.1109/TPAMI.2020.3009287</a></p><p>[11]&nbsp;&nbsp; Hao Dang, Feng Liu, Joel Stehouwer, Xiaoming Liu, and Anil K. Jain. 2020. On the Detection of Digital Face Manipulation. In <em>Proceedings of the 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>. IEEE, 10 pages. <a href=\"https://doi.org/10.1109/CVPR42600.2020.00582\">https://doi.org/10.1109/CVPR42600.2020.00582</a></p><p>[12]&nbsp;&nbsp;Rohan Kumar Das, Tomi Kinnunen, Wen-Chin Huang, Zhen-Hua Ling, Junichi Yamagishi, Zhao Yi, Xiaohai Tian, and Tomoki Toda. 2020. Predictions of Subjective Ratings and Spoofing Assessments of Voice Conversion Challenge 2020 Submissions. In <em>Proceedings of the Joint Workshop for the Blizzard Challenge and Voice Conversion Challenge 2020</em>. International Speech Communication Association, 99‚Äì120. <a href=\"https://doi.org/10.21437/VCC_BC.2020-15\">https://doi.org/10.21437/VCC BC.2020-15</a></p><p>[13]&nbsp;H¬¥ector Delgado, Nicholas Evans, Tomi Kinnunen, Kong Aik Lee, Xuechen Liu, Andreas Nautsch, Jose Patino, Md Sahidullah, Massimiliano Todisco, Xin Wang, and Junichi Yamagishi. 2021. ASVspoof 2021: Automatic Speaker Verification Spoofing and Countermeasures Challenge Evaluation Plan.&nbsp; <a href=\"https://www.asvspoof.org/asvspoof2021/asvspoof2021_evaluation_plan.pdf\">https://www.asvspoof.org/asvspoof2021/asvspoof2021 evaluation plan.pdf</a></p><p>[14]&nbsp;&nbsp; H¬¥ector Delgado, Nicholas Evans, Tomi Kinnunen, Kong Aik Lee, Xuechen Liu, Andreas Nautsch, Jose Patino, Md Sahidullah, Massimiliano Todisco, Xin Wang, and Junichi Yamagishi. 2021.</p><p>[15]&nbsp;&nbsp; H¬¥ector Delgado, Nicholas Evans, Tomi Kinnunen, Kong Aik Lee, Xuechen Liu, Andreas Nautsch, Jose Patino, Md Sahidullah, Massimiliano Todisco, Xin Wang, and Junichi Yamagishi. 2021. ASVspoof 2021 Challenge - Speech Deepfake Database.&nbsp; <a href=\"https://doi.org/10.5281/zenodo.4835108\">https://doi.org/10.5281/zenodo.4835108</a></p><p>[16]&nbsp;&nbsp;  ![](file:///C:/Users/user/AppData/Local/Temp/msohtmlclip1/01/clip_image051.gif)Anushree Deshmukh and Sunil B. Wankhade. 2021. Deepfake Detection Approaches Using Deep Learning: A Systematic Review. In <em>Intelligent Computing and Networking: Proceedings of IC-ICN 2020 (Lecture Notes in Networks and Systems, Vol. 146)</em>. Springer, 293‚Äì302. <a href=\"https://doi.org/10.1007/978-981-15-7421-4_27\">https://doi.org/</a><a href=\"https://doi.org/10.1007/978-981-15-7421-4_27\">10.1007/978-981-15-7421-4 27</a></p><p>[17]&nbsp;&nbsp; Xinyi Ding, Zohreh Raziei, Eric C. Larson, Eli V. Olinick, Paul Krueger, and Michael Hahsler. 2020. Swapped Face Detection using Deep Learning and Subjective Assessment. <em>EURASIP Journal on Information Security</em> 2020, 1 (2020), 1‚Äì12. <a href=\"https://doi.org/10.1186/s13635-020-00109-8\">https://doi.org/10.1186/s13635-020-00109-8</a></p><p>[18]&nbsp;&nbsp; Brian Dolhansky, Joanna Bitton, Ben Pflaum, Jikuo Lu, Russ Howes, Menglin Wang, and Cristian Canton Ferrer. 2020. The DeepFake Detection Challenge (DFDC) Dataset.&nbsp; <a href=\"https://doi.org/10.48550/ARXIV.2006.07397\">https://doi.org/10.48550/ARXIV.2006.07397</a></p><p>[19]&nbsp;&nbsp; Brian Dolhansky, Joanna Bitton, Ben Pflaum, Jikuo Lu, Russ Howes, Menglin Wang, and Cristian Canton Ferrer. 2020. The DeepFake Detection Challenge (DFDC) Dataset. arXiv:2006.07397. <a href=\"https://arxiv.org/abs/2006.07397\">https://arxiv.org/abs/2006.07397</a></p><p>[23]&nbsp;&nbsp; Gereon Fox, Wentao Liu, Hyeongwoo Kim, Hans-Peter Seidel, Mohamed Elgharib, and Christian Theobalt. 2021. Videoforensicshq: Detecting High-Quality Manipulated Face Videos. In <em>Proceedings of the 2021 IEEE International Conference on Multimedia and Expo</em>. IEEE, 1‚Äì6. <a href=\"https://doi.org/10.1109/ICME51207.2021.9428101\">https://doi.or</a><a href=\"https://doi.org/10.1109/ICME51207.2021.9428101\">g/10.1109/ICME51207.2021.9428101</a></p><p>[24]&nbsp;&nbsp; Haiying Guan, Andrew Delgado, Yooyoung Lee, Amy N. Yates, Daniel Zhou, Timothee Kheyrkhah, and Jon Fiscus. 2021. User Guide for NIST Media Forensic Challenge (MFC) Datasets. <a href=\"https://doi.org/10.6028/NIST.IR.8377\">https://doi.org/10.6028/NIST.IR.8377</a></p><p>[25]&nbsp;&nbsp; Yinan He, Bei Gan, Siyu Chen, Yichun Zhou, Guojun Yin, Luchuan Song, Lu Sheng, Jing Shao, and Ziwei Liu. 2021. ForgeryNet: A Versatile Benchmark for Comprehensive Forgery Analysis. In <em>Proceedings of the 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>. IEEE,&nbsp; 4360‚Äì4369.&nbsp;&nbsp;&nbsp; <a href=\"https://doi.org/10.1109/CVPR46437.2021.00434\">https://doi.org/10.1109/CVPR46437.2021.00434</a></p><p>[26]&nbsp;&nbsp; Liming Jiang, Zhengkui Guo, Wayne Wu, Zhaoyang Liu, Ziwei Liu, Chen Change Loy, Shuo Yang, Yuanjun Xiong, Wei Xia, Baoying Chen, Peiyu Zhuang, Sili Li, Shen Chen, Taiping Yao, Shouhong Ding, Jilin Li, Feiyue Huang, Liujuan Cao, Rongrong Ji, Changlei Lu, and Ganchao Tan. 2021. DeeperForensics Challenge 2020 on Real-World Face Forgery Detection: Methods and Results. arXiv:2102.09471. <a href=\"https://arxiv.org/pdf/2102.09471.pdf\">https://arxiv.org/pdf/2102.09471.pdf</a></p><p>[27]&nbsp;&nbsp; Liming Jiang, Ren Li, Wayne Wu, Chen Qian, and Chen Change Loy. 2020. DeeperForensics-1.0: A Large-Scale Dataset for Real-World Face Forgery Detection. In <em>Proceedings of the 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>. IEEE, 2886‚Äì2895. <a href=\"https://doi.org/10.1109/CVPR42600.2020.00296\">https://doi.org/</a><a href=\"https://doi.org/10.1109/CVPR42600.2020.00296\">10.1109/CVPR42600.2020.00296</a></p><p>[28]&nbsp;&nbsp; Nal Kalchbrenner, Erich Elsen, Karen Simonyan, Seb Noury, Norman Casagrande, Edward Lockhart, Florian Stimberg, Aaron van den Oord, Sander Dieleman, and Koray Kavukcuoglu. 2018. Efficient Neural Audio Synthesis. <a href=\"https://doi.org/10.48550/ARXIV.1802.08435\">https://doi.org/10.48550/ARXIV.1802.08435</a></p><p>[30]&nbsp;&nbsp; Tero Karras, Samuli Laine, and Timo Aila. 2019. A Style-based Generator Architecture for Generative Adversarial Networks. In <em>Proceedings of the 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>. IEEE, 4401‚Äì4410. <a href=\"https://doi.org/10.1109/CVPR.2019.00453\">https://doi.org/10.1109/CVPR.2019.00453</a></p><p>[32]&nbsp;&nbsp; Ali Khodabakhsh, Raghavendra Ramachandra, Kiran Raja, Pankaj Wasnik, and Christoph Busch. 2018. Fake Face Detection Methods: Can They Be Generalized?. In <em>Proceedings of the 2018 International Conference of the Biometrics Special Interest Group</em>. IEEE, 1‚Äì6. <a href=\"https://doi.org/10.23919/BIOSIG.2018.8553251\">https://doi.org/10.2</a><a href=\"https://doi.org/10.23919/BIOSIG.2018.8553251\">3919/BIOSIG.2018.8553251</a></p><p>[33]&nbsp;&nbsp; Hyeongwoo Kim, Mohamed Elgharib, Hans-Peter Zoll¬®ofer, Michael Seidel, Thabo Beeler, Christian Richardt, and Christian Theobalt. 2019. Neural Style-Preserving Visual Dubbing. <em>ACM Transactions on Graphics</em> 38, 6, Article 178 (2019), 13 pages. <a href=\"https://doi.org/10.1145/3355089.3356500\">https://doi.org/10.1145/3355089.3356500</a></p><p>[34]&nbsp;&nbsp; Hyeongwoo Kim, Pablo Garrido, Ayush Tewari, Weipeng Xu, Justus Thies, Matthias Niessner, Patrick P¬¥erez, Christian Richardt, Michael Zollh¬®ofer, and Christian Theobalt. 2018. Deep Video Portraits. <em>ACM Transactions on Graphics</em> 37, 4, Article 163 (2018), 14 pages. <a href=\"https://doi.org/10.1145/3197517.3201283\">https://doi.org/</a><a href=\"https://doi.org/10.1145/3197517.3201283\">10.1145/3197517.3201283</a></p><p>[35]&nbsp;&nbsp; Pavel Korshunov and S¬¥ebastien Marcel. 2019. Vulnerability Assessment and Detection of Deepfake Videos. In <em>Proceedings of the 2019 International Conference on Biometrics</em>. IEEE, 1‚Äì6. <a href=\"https://doi.org/10.1109/ICB45273.2019.8987375\">https://doi.org/10.1109/ICB45273.2019.8987375</a></p><p>[36]&nbsp;&nbsp; Patrick Kwon, Jaeseong You, Gyuhyeon Nam, Sungwoo Park, and Gyeongsu Chae. 2021. KoDF: A Large-scale Korean DeepFake Detection Dataset. In <em>Proceedings of the 2021 IEEE/CVF International Conference on Computer Vision</em>. IEEE, 10724‚Äì10733. <a href=\"https://doi.org/10.1109/ICCV48922.2021.01057\">https://doi.org/10.1109/ICCV</a><a href=\"https://doi.org/10.1109/ICCV48922.2021.01057\">48922.2021.01057</a></p><p>[37]&nbsp;&nbsp; Lingzhi Li, Jianmin Bao, Hao Yang, Dong Chen, and Fang Wen. 2020. FaceShifter: Towards High Fidelity And Occlusion Aware Face Swapping. arXiv:1912.13457. <a href=\"https://arxiv.org/abs/1912.13457\">https://arxiv.org/abs/1912.13457</a></p><p>[38]&nbsp;&nbsp; Xurong Li, Shouling Ji, Chunming Wu, Zhenguang Liu, Shuiguang Deng, Peng Cheng, Min Yang, and Xiangwei Kong. 2021. Survey on Deepfakes and Detection Techniques.  32, 2 (2021), 496‚Äì518. <a href=\"http://www.jos.org.cn/1000-9825/6140.htm\">http://www.jos.org.cn/1000-9825/6140.htm</a></p><p>[39]&nbsp;&nbsp; Yuezun Li, Ming-Ching Chang, and Siwei Lyu. 2018. In Ictu Oculi: Exposing AI Created Fake Videos by Detecting Eye Blinking. In <em>Proceedings of the 2018 IEEE International Workshop on Information Forensics and Security</em>. IEEE, 1‚Äì7. <a href=\"https://doi.org/10.1109/WIFS.2018.8630787\">https://doi.org/10.1109/WIFS.2018.8630787</a></p><p>[40]&nbsp;&nbsp; Yuezun Li, Xin Yang, Pu Sun, Honggang Qi, and Siwei Lyu. 2020. Celeb-DF: A Large-Scale Challenging Dataset for DeepFake Forensics. In <em>Proceedings of the 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>. IEEE, 3204‚Äì3213. <a href=\"https://doi.org/10.1109/CVPR42600.2020.00327\">https://doi.org/10.1109/CVPR42600.</a><a href=\"https://doi.org/10.1109/CVPR42600.2020.00327\">2020.00327</a></p><p>[42]&nbsp;&nbsp; Steven R. Livingstone and Frank A. Russo. 2018. The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS): A Dynamic, Multimodal Set of Facial and Vocal Expressions in North American English.  13, 5 (2018), 35 pages.</p><p>[43]&nbsp;&nbsp; Chen-Chou Lo, Szu-Wei Fu, Wen-Chin Huang, Xin Wang, Junichi Yamagishi, Yu Tsao, and Hsin-Min Wang. 2021. MOSNet: Deep Learning based Objective Assessment for Voice Conversion. arXiv:1904.08352. <a href=\"https://arxiv.org/pdf/1904.08352.pdf\">https://arxiv.org/pdf/1904.08352.pdf</a></p><p>[44]&nbsp;&nbsp; Jaime Lorenzo-Trueba, Junichi Yamagishi, Tomoki Toda, Daisuke Saito, Fernando Villavicencio, Tomi Kinnunen, and Zhenhua Ling. 2018. The Voice Conversion Challenge 2018: Promoting Development of Parallel and Nonparallel Methods. In <em>Proceedings of the Odyssey 2018 The Speaker and Language Recognition Workshop</em>. International Speech Communication Association, 195‚Äì202. <a href=\"https://doi.org/10.21437/Odyssey.2018-28\">https://doi.org/10.21437/Odyssey.2018-28</a></p><p>[46]&nbsp;&nbsp; Yisroel Mirsky and Wenke Lee. 2021. The Creation and Detection of Deepfakes: A Survey.  54, 1, Article 7 (2021), 41 pages. <a href=\"https://doi.org/10.1145/3425780\">https://doi.org/10.1145/3425780</a></p><p>[47]&nbsp;&nbsp; Gautham J. Mysore. 2015. Can we Automatically Transform Speech Recorded on Common Consumer Devices in Real-World Environments into Professional Production Quality Speech?‚ÄîA Dataset, Insights, and Challenges. <em>IEEE Signal Processing Letters</em> 22, 8 (2015), 1006‚Äì1010. <a href=\"https://doi.org/10.1109/LSP.2014.2379648\">https://doi.org/10.1109/LSP.2014.2379648</a></p><p>[48]&nbsp;&nbsp; JoÀúao C. Neves, Ruben Tolosana, Ruben Vera-Rodriguez, Vasco Lopes, Hugo Proen¬∏ca, and Julian Fierrez. 2020. GANprintR: Improved Fakes and Evaluation of the State of the Art in Face Manipulation Detection. <em>IEEE Journal of Selected Topics in Signal Processing</em> 14, 5 (2020), 1038‚Äì1048. <a href=\"https://doi.org/10.1109/JSTSP.2020.3007250\">https://doi.org/10.1109/JSTSP.2020.3007250</a></p><p>[50]&nbsp;&nbsp; Aaron van den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol Vinyals, Alex Graves, Nal Kalchbrenner, Andrew Senior, and Koray Kavukcuoglu. 2016. WaveNet: A Generative Model for Raw Audio.&nbsp; <a href=\"https://doi.org/10.48550/ARXIV.1609.03499\">https://doi.org/10.48550/ARXIV.1609.03499</a></p><p>[51]&nbsp;&nbsp; Debajyoti Pal and Tuul Triyason. 2018. A Survey of Standardized Approaches towards the Quality of Experience Evaluation for Video Services: An ITU Perspective. <em>International Journal of Digital Multimedia Broadcasting</em> 2018, Article 1391724 (2018), 25 pages. <a href=\"https://doi.org/10.1155/2018/1391724\">https://doi.org/10.1155/20</a><a href=\"https://doi.org/10.1155/2018/1391724\">18/1391724</a></p><p>[52]&nbsp;&nbsp; Bo Peng, Hongxing Fan, Wei Wang, Jing Dong, Yuezun Li, Siwei Lyu, Qi Li, Zhenan Sun, Han Chen, Baoying Chen, Yanjie Hu, Shenghai Luo, Junrui Huang, Yutong Yao, Boyuan Liu, Hefei Ling, Guosheng Zhang, Zhiliang Xu, Changtao Miao, Changlei Lu, Shan He, Xiaoyan Wu, and Wanyi Zhuang. 2021. DFGC 2021: A DeepFake Game Competition. arXiv:2106.01217. <a href=\"https://arxiv.org/abs/2106.01217\">https:</a></p><p>[53]&nbsp;&nbsp; Ivan Perov, Daiheng Gao, Nikolay Chervoniy, Kunlin Liu, Sugasa Marangonda, Chris Um¬¥e, Mr. Dpfks, Carl Shift Facenheim, Luis RP, Jian Jiang, Sheng Zhang, Pingyu Wu, Bo Zhou, and Weiming Zhang. 2020. DeepFaceLab: Integrated, Flexible and Extensible Face-swapping Framework. <a href=\"https://doi.org/10.48550/ARXIV.2005.05535\">https://doi.org/10.48550/ARXIV.2005.05535</a></p><p>[54]&nbsp;&nbsp; Stanislav Pidhorskyi, Donald A. Adjeroh, and Gianfranco Doretto. 2020. Adversarial Latent Au-toencoders. In <em>Proceedings of the 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>. IEEE, 10 pages. <a href=\"https://doi.org/10.1109/CVPR42600.2020.01411\">https://doi.org/10.1109/CVPR42600.2020.01411</a></p><p>[55]&nbsp;&nbsp; Andreas R¬®ossler, Davide Cozzolino, Luisa Verdoliva, Christian Riess, Justus Thies, and Matthias Nie√üner. 2018. FaceForensics: A Large-scale Video Dataset for Forgery Detection in Human Faces. <a href=\"https://doi.org/10.48550/ARXIV.1803.09179\">https://doi.org/10.48550/ARXIV.1803.09179</a></p><p>[56]&nbsp;&nbsp; Andreas R¬®ossler, Davide Cozzolino, Luisa Verdoliva, Christian Riess, Justus Thies, and Matthias Nie√üner. 2019. FaceForensics++: Learning to Detect Manipulated Facial Images. In <em>Proceedings of the 2019 International Conference on Computer Vision</em>. IEEE, 1‚Äì11. <a href=\"https://doi.org/10.1109/ICCV.2019.00009\">https://doi.org/10.110</a><a href=\"https://doi.org/10.1109/ICCV.2019.00009\">9/ICCV.2019.00009</a></p><p>[61]&nbsp;&nbsp; Justus Thies, Michael Zollh¬®ofe, and Matthias Niessner. 2019. Deferred Neural Rendering: Image Synthesis using Neural Textures. <em>ACM Transactions on Graphics</em> 38, Article 66 (2019), 12 pages. Issue&nbsp; 4.&nbsp;&nbsp; <a href=\"https://doi.org/10.1145/3306346.3323035\">https://doi.org/10.1145/3306346.3323035</a></p><p>[62]&nbsp;&nbsp; Tomoki Toda, Ling-Hui Chen, Daisuke Saito, Fernando Villavicencio, Mirjam Wester, Zhizheng Wu, and Junichi Yamagishi. 2016. The Voice Conversion Challenge 2016. In <em>Proceedings of Interspeech 2016</em>. International Speech Communication Association, 1632‚Äì1636. <a href=\"https://doi.org/10.21437/Interspeech.2016-1066\">https://doi.org/10.21437/Interspeech.2016-1066</a></p><p>[63]&nbsp;&nbsp; Massimiliano Todisco, Xin Wang, Ville Vestman, Md Sahidullah, Hector Delgado, Andreas Nautsch, Junichi Yamagishi, Nicholas Evans, Tomi Kinnunen, and Kong Aik Lee. 2019. ASVspoof 2019: Future Horizons in Spoofed and Fake Audio Detection. arXiv:1904.05441. <a href=\"https://arxiv.org/pdf/1904.05441.pdf\">https://arxiv.org/</a><a href=\"https://arxiv.org/pdf/1904.05441.pdf\">pdf/1904.05441.pdf</a></p><p>[64]&nbsp;&nbsp; Ruben Tolosana, Ruben Vera-Rodriguez, Julian Fierrez, Aythami Morales, and Javier Ortega-Garcia. 2020. Deepfakes and beyond: A Survey of face manipulation and fake detection.  64 (2020), 131‚Äì148.&nbsp; <a href=\"https://doi.org/10.1016/j.inffus.2020.06.014\">https://doi.org/10.1016/j.inffus.2020.06.014</a></p><p>[65]&nbsp;&nbsp; Xin Tong, Luona Wang, Xiaoqin Pan, and Jingya Wang. 2020. An Overview of Deepfake: The Sword of Damocles in AI. In <em>Proceedings of the 2020 International Conference on Computer Vision, Image and Deep Learning</em>. IEEE, 265‚Äì273. <a href=\"https://doi.org/10.1109/CVIDL51233.2020.00-88\">https://doi.org/10.1109/CVIDL51233.2020.00-88</a></p><p>[67]&nbsp;&nbsp; Xin Wang, Junichi Yamagishi, Massimiliano Todisco, H¬¥ector Delgado, Andreas Nautsch, Nicholas Evans, Md Sahidullah, Ville Vestman, Tomi Kinnunen, Kong Aik Lee, Lauri Juvela, Paavo Alku, Yu-Huai Peng, Hsin-Te Hwang, Yu Tsao, Hsin-Min Wang, S¬¥ebastien Le Maguer, Markus Becker, Fergus Henderson, Rob Clark, Yu Zhang, Quan Wang, Ye Jia, Kai Onuma, Koji Mushika, Takashi Kaneda, Yuan Jiang, Li-Juan Liu, Yi-Chiao Wu, Wen-Chin Huang, Tomoki Toda, Kou Tanaka, Hirokazu Kameoka, Ingmar Steiner, Driss Matrouf, Jean-Fran¬∏cois Bonastre, Avashna Govender, Srikanth Ronanki, Jing-Xuan Zhang, and Zhen-Hua Ling. 2020. ASVspoof 2019: A Large-scale Public Database of Synthesized, Converted and Replayed Speech. <em>Computer Speech &amp; Language</em> 64 (2020), 27 pages.&nbsp; <a href=\"https://doi.org/10.1016/j.csl.2020.101114\">https://doi.org/10.1016/j.csl.2020.101114</a></p><p>[68]&nbsp;&nbsp; Mirjam Wester, Zhizheng Wu, and Junichi Yamagishi. 2016. Analysis of the Voice Conversion Challenge 2016 Evaluation Results. In <em>Proceedings of the Interspeech 2016 Conference</em>. International Speech Communication Association, 1637‚Äì1641. <a href=\"https://doi.org/10.21437/Interspeech.2016-1331\">https://doi.org/10.21437/Interspeech.201</a><a href=\"https://doi.org/10.21437/Interspeech.2016-1331\">6-1331</a></p><p>[70]&nbsp;&nbsp;Zhao Yi, Wen-Chin Huang, Xiaohai Tian, Junichi Yamagishi, Rohan Kumar Das, Tomi Kinnunen, Zhen-Hua Ling, and Tomoki Toda. 2020. Voice Conversion Challenge 2020 ‚Äì Intra-lingual Semi-parallel and Cross-lingual Voice Conversion ‚Äì. In <em>Proceedings of the Joint Workshop for the Blizzard Challenge and Voice Conversion Challenge 2020</em>. International Speech Communication Association, 80‚Äì98. <a href=\"https://doi.org/10.21437/VCC_BC.2020-14\">https://doi.org/10.21437/VCC BC.2020-14</a></p><p>[71]&nbsp;&nbsp; Mohammed A. Younus and Taha M. Hasan. 2020. Abbreviated View of Deepfake Videos Detection Techniques. In <em>Proceedings of the 2020 6th International Engineering Conference</em>. IEEE, 115‚Äì120. <a href=\"https://doi.org/10.1109/IEC49899.2020.9122916\">https://doi.org/10.1109/IEC49899.2020.9122916</a></p><p>[73]&nbsp;&nbsp; Teng Zhang, Lirui Deng, Liang Zhang, and Xianglei Dang. 2020. Deep Learning in Face Synthesis: A Survey on Deepfakes. In <em>Proceedings of the 2020 IEEE 3rd International Conference on Computer and Communication Engineering Technology</em>. IEEE, 67‚Äì70. <a href=\"https://doi.org/10.1109/CCET50901.2020.9213159\">https://doi.org/10.1109/CCET5090</a><a href=\"https://doi.org/10.1109/CCET50901.2020.9213159\">1.2020.9213159</a></p><p>[74]&nbsp;&nbsp; Yuxuan Zhang, Huan Ling, Jun Gao, Kangxue Yin, Jean-Francois Lafleche, Adela Barriuso, Antonio Torralba, and Sanja Fidler. 2021. DatasetGAN: Efficient Labeled Data Factory with Minimal Human Effort. In <em>Proceedings of the 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>. IEEE, 10140‚Äì10150. <a href=\"https://doi.org/10.1109/CVPR46437.2021.01001\">https://doi.org/10.1109/CVPR46437.2021.01001</a></p><p>[75]&nbsp;&nbsp;  ![](file:///C:/Users/user/AppData/Local/Temp/msohtmlclip1/01/clip_image051.gif)Yuanhan Zhang, ZhenFei Yin, Yidong Li, Guojun Yin, Junjie Yan, Jing Shao, and Ziwei Liu. 2020. CelebA-Spoof: Large-Scale Face Anti-spoofing Dataset with Rich Annotations. In <em>Proceedings of the 2020 European Conference on Computer Vision</em>. Springer, 70‚Äì85. <a href=\"https://doi.org/10.1007/978-3-030-58610-2_5\">https://doi.org/10.1007/97</a><a href=\"https://doi.org/10.1007/978-3-030-58610-2_5\">8-3-030-58610-2 5</a></p><p>[76]&nbsp;&nbsp; Yuanhan Zhang, Zhenfei Yin, Jing Shao, Ziwei Liu, Shuo Yang, Yuanjun Xiong, Wei Xia, Yan Xu, Man Luo, Jian Liu, Jianshu Li, Zhijun Chen, Mingyu Guo, Hui Li, Junfu Liu, Pengfei Gao, Tianqi Hong, Hao Han, Shijie Liu, Xinhua Chen, Di Qiu, Cheng Zhen, Dashuang Liang, Yufeng Jin, and Zhanlong Hao. 2021. CelebA-Spoof Challenge 2020 on Face Anti-Spoofing: Methods and Results. arXiv:2102.12642. <a href=\"https://arxiv.org/pdf/2102.12642.pdf\">https://arxiv.org/pdf/2102.12642.pdf</a></p><p>[77]&nbsp;&nbsp; Bo Zhao, Shaozeng Zhang, Chunxue Xu, Yifan Sun, and Chengbin Deng. 2021. Deep Fake Ge-ography? When Geospatial Data Encounter Artificial Intelligence. <em>Cartography and Geographic Information Science</em> 48, 4 (2021), 338‚Äì352. <a href=\"https://doi.org/10.1080/15230406.2021.1910075\">https://doi.org/10.1080/15230406.2021.1910075</a></p><p>[78]&nbsp;&nbsp; Peng Zhou, Xintong Han, Vlad I. Morariu, and Larry S. Davis. 2017. Two-Stream Neural Networks for Tampered Face Detection. In <em>Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops</em>. IEEE, 1831‚Äì1839. <a href=\"https://doi.org/10.1109/CVPRW.2017.229\">https://doi.org/10.1109/CVPRW.2017.229</a></p><p>[79]&nbsp;&nbsp; Tianfei Zhou, Wenguan Wang, Zhiyuan Liang, and Jianbing Shen. 2021. Face Forensics in the Wild. In <em>Proceedings of the 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>. IEEE,&nbsp; 5774‚Äì5784.&nbsp;&nbsp;&nbsp; <a href=\"https://doi.org/10.1109/CVPR46437.2021.00572\">https://doi.org/10.1109/CVPR46437.2021.00572</a></p><p>[80]&nbsp;&nbsp; Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A. Efros. 2017. Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks. In <em>Proceedings of the 2017 IEEE International Conference on Computer Vision</em>. IEEE, 2242‚Äì2251. <a href=\"https://doi.org/10.1109/ICCV.2017.244\">https://doi.org/10.1109/ICCV.2</a><a href=\"https://doi.org/10.1109/ICCV.2017.244\">017.244</a></p><p>[81]&nbsp;&nbsp; Bojia Zi, Minghao Chang, Jingjing Chen, Xingjun Ma, and Yu-Gang Jiang. 2020. WildDeepfake: A Challenging Real-World Dataset for Deepfake Detection. In <em>Proceedings of the 2020 28th ACM International Conference on Multimedia</em>. ACM, 2382‚Äì2390. <a href=\"https://doi.org/10.1145/3394171.3413769\">https://doi.org/10.1145/339417</a><a href=\"https://doi.org/10.1145/3394171.3413769\">1.3413769</a></p><p>:::info\nThis paper is&nbsp;<a href=\"https://arxiv.org/abs/2208.10913\">available on arxiv</a>&nbsp;under CC by 4.0 Deed (Attribution 4.0 International) license.  </p>",
      "contentLength": 105782,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "The HackerNoon Newsletter: Why ‚ÄúSmall Changes‚Äù Don‚Äôt Exist in Production Game Systems (2/28/2026)",
      "url": "https://hackernoon.com/2-28-2026-newsletter?source=rss",
      "date": 1772294565,
      "author": "Noonification",
      "guid": 49173,
      "unread": true,
      "content": "<p>ü™ê What‚Äôs happening in tech today, February 28, 2026?</p><p>By <a href=\"https://hackernoon.com/u/ktdevjournal\">@ktdevjournal</a> [ 5 Min read ] It doesn‚Äôt matter if you build games or a banking app - you don‚Äôt just have a pile of features and assets. You have an ecosystem for each bit of work <a href=\"https://hackernoon.com/why-small-changes-dont-exist-in-production-game-systems\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/Lima_Writes\">@Lima_Writes</a> [ 9 Min read ] When language comes back at you fast, coherent, and emotionally attuned, it feels like truth. Especially when you‚Äôre tired. Or lonely.  <a href=\"https://hackernoon.com/how-to-navigate-identity-direction-story-and-sovereignty-in-the-age-of-ai\">Read More.</a></p><p>üßë‚Äçüíª What happened in your world this week?</p><p>We hope you enjoy this worth of free reading material. Feel free to forward this email to a nerdy friend who'll love you for it.See you on Planet Internet! With love, \n The HackerNoon Team ‚úåÔ∏è</p>",
      "contentLength": 677,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Go 1.22: A Change in Loop Scoping",
      "url": "https://hackernoon.com/go-122-a-change-in-loop-scoping?source=rss",
      "date": 1772294421,
      "author": "Go [Technical Documentation]",
      "guid": 49172,
      "unread": true,
      "content": "<p>Go 1.21 includes a preview of a change to  loop scoping that we plan to ship in Go 1.22, removing one of the most common Go mistakes.</p><p>If you‚Äôve written any amount of Go code, you‚Äôve probably made the mistake of keeping a reference to a loop variable past the end of its iteration, at which point it takes on a new value that you didn‚Äôt want. For example, consider this program:</p><pre><code>func main() {\n    done := make(chan bool)\n\n    values := []string{\"a\", \"b\", \"c\"}\n    for _, v := range values {\n        go func() {\n            fmt.Println(v)\n            done &lt;- true\n        }()\n    }\n\n    // wait for all goroutines to complete before exiting\n    for _ = range values {\n        &lt;-done\n    }\n}\n</code></pre><p>\\\nThe three created goroutines are all printing the same variable , so they usually print ‚Äúc‚Äù, ‚Äúc‚Äù, ‚Äúc‚Äù, instead of printing ‚Äúa‚Äù, ‚Äúb‚Äù, and ‚Äúc‚Äù in some order.</p><p>\\\nAlthough concurrency is often involved, it need not be. This example has the same problem but no goroutines:</p><pre><code>func main() {\n    var prints []func()\n    for i := 1; i &lt;= 3; i++ {\n        prints = append(prints, func() { fmt.Println(i) })\n    }\n    for _, print := range prints {\n        print()\n    }\n}\n</code></pre><p>\\\nThis kind of mistake has caused production problems at many companies, including a <a href=\"https://bugzilla.mozilla.org/show_bug.cgi?id=1619047\">publicly documented issue at Lets Encrypt</a>. In that instance, the accidental capture of the loop variable was spread across multiple functions and much more difficult to notice:</p><pre><code>// authz2ModelMapToPB converts a mapping of domain name to authz2Models into a\n// protobuf authorizations map\nfunc authz2ModelMapToPB(m map[string]authz2Model) (*sapb.Authorizations, error) {\n    resp := &amp;sapb.Authorizations{}\n    for k, v := range m {\n        // Make a copy of k because it will be reassigned with each loop.\n        kCopy := k\n        authzPB, err := modelToAuthzPB(&amp;v)\n        if err != nil {\n            return nil, err\n        }\n        resp.Authz = append(resp.Authz, &amp;sapb.Authorizations_MapElement{\n            Domain: &amp;kCopy,\n            Authz: authzPB,\n        })\n    }\n    return resp, nil\n}\n</code></pre><p>\\\nThe author of this code clearly understood the general problem, because they made a copy of , but it turns out  used pointers to fields in  when constructing its result, so the loop also needed to make a copy of .</p><p>\\\nTools have been written to identify these mistakes, but it is hard to analyze whether references to a variable outlive its iteration or not. These tools must choose between false negatives and false positives. The  analyzer used by  and  opts for false negatives, only reporting when it is sure there is a problem but missing others. Other checkers opt for false positives, accusing correct code of being incorrect. We ran an analysis of commits adding  lines in open-source Go code, expecting to find bug fixes. Instead we found many unnecessary lines being added, suggesting instead that popular checkers have significant false positive rates, but developers add the lines anyway to keep the checkers happy.</p><p>\\\nOne pair of examples we found was particularly illuminating:</p><p>This diff was in one program:</p><pre><code>     for _, informer := range c.informerMap {\n+        informer := informer\n         go informer.Run(stopCh)\n     }\n</code></pre><p>\\\nAnd this diff was in another program:</p><pre><code>     for _, a := range alarms {\n+        a := a\n         go a.Monitor(b)\n     }\n</code></pre><p>\\\nOne of these two diffs is a bug fix; the other is an unnecessary change. You can‚Äôt tell which is which unless you know more about the types and functions involved.</p><p>For Go 1.22, we plan to change  loops to make these variables have per-iteration scope instead of per-loop scope. This change will fix the examples above, so that they are no longer buggy Go programs; it will end the production problems caused by such mistakes; and it will remove the need for imprecise tools that prompt users to make unnecessary changes to their code.</p><p>\\\nTo ensure backwards compatibility with existing code, the new semantics will only apply in packages contained in modules that declare  or later in their  files. This per-module decision provides developer control of a gradual update to the new semantics throughout a codebase. It is also possible to use  lines to control the decision on a per-file basis.</p><p>\\\nOld code will continue to mean exactly what it means today: the fix only applies to new or updated code. This will give developers control over when the semantics change in a particular package. As a consequence of our <a href=\"https://go.dev/blog/toolchain\">forward compatibility work</a>, Go 1.21 will not attempt to compile code that declares  or later. We included a special case with the same effect in the point releases Go 1.20.8 and Go 1.19.13, so when Go 1.22 is released, code written depending on the new semantics will never be compiled with the old semantics, unless people are using very old, <a href=\"https://go.dev/doc/devel/release#policy\">unsupported Go versions</a>.</p><p>Go 1.21 includes a preview of the scoping change. If you compile your code with  set in your environment, then the new semantics are applied to all loops (ignoring the  lines). For example, to check whether your tests still pass with the new loop semantics applied to your package and all your dependencies:</p><pre><code>GOEXPERIMENT=loopvar go test\n</code></pre><p>\\\nWe patched our internal Go toolchain at Google to force this mode during all builds at the start of May 2023, and in the past four months we have had zero reports of any problems in production code.</p><p>\\\nYou can also try test programs to better understand the semantics on the Go playground by including a  comment at the top of the program, like in <a href=\"https://go.dev/play/p/YchKkkA1ETH\">this program</a>. (This comment only applies in the Go playground.)</p><p>Although we‚Äôve had no production problems, to prepare for that switch, we did have to correct many buggy tests that were not testing what they thought they were, like this:</p><pre><code>func TestAllEvenBuggy(t *testing.T) {\n    testCases := []int{1, 2, 4, 6}\n    for _, v := range testCases {\n        t.Run(\"sub\", func(t *testing.T) {\n            t.Parallel()\n            if v&amp;1 != 0 {\n                t.Fatal(\"odd v\", v)\n            }\n        })\n    }\n}\n</code></pre><p>\\\nIn Go 1.21, this test passes because  blocks each subtest until the entire loop has finished and then runs all the subtests in parallel. When the loop has finished,  is always 6, so the subtests all check that 6 is even, so the test passes. Of course, this test really should fail, because 1 is not even. Fixing for loops exposes this kind of buggy test.</p><p>\\\nTo help prepare for this kind of discovery, we improved the precision of the  analyzer in Go 1.21 so that it can identify and report this problem. You can see the report <a href=\"https://go.dev/play/p/WkJkgXRXg0m\">in this program</a> on the Go playground. If  is reporting this kind of problem in your own tests, fixing them will prepare you better for Go 1.22.</p><p>\\\nIf you run into other problems, <a href=\"https://go.dev/wiki/LoopvarExperiment#my-test-fails-with-the-change-how-can-i-debug-it\">the FAQ</a> has links to examples and details about using a tool we‚Äôve written to identify which specific loop is causing a test failure when the new semantics are applied.</p><p>\\\n<em>This article is available on&nbsp;&nbsp;under a CC BY 4.0 DEED license.</em></p>",
      "contentLength": 6922,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Why ‚ÄúSmall Changes‚Äù Don‚Äôt Exist in Production Game Systems",
      "url": "https://hackernoon.com/why-small-changes-dont-exist-in-production-game-systems?source=rss",
      "date": 1772294403,
      "author": "Constantine",
      "guid": 49171,
      "unread": true,
      "content": "<p>It‚Äôs just a small change!</p><p>\\\nHow often do we hear that we need to fix something? We need to add a small feature. We need to tweak something. Code-wise or publishing, just realized they need this for retention, or maybe an analyst brought the newest data, so now we have to add just a few lines to the code. They don‚Äôt affect performance or any other departments, I promise. And it‚Äôs just like 3 minutes of coder work - why not? Fast forward: they broke the ‚ÄúBuy‚Äù button on the front page of the store on release.</p><p>\\\nWhy does this always happen with small changes? Well, if we think about it, we don‚Äôt usually think about it. Let me explain:</p><p>Designers think in features and user experience. \\n Engineers think in whole systems. \\n Producers think in tasks. \\n Stakeholders think in business outcomes.</p><p>\\\nAnd one small change is always perceived as something isolated and usually without everyone‚Äôs awareness. So, it is basically a cognitive shortcut. And that happens not because everyone is wrong or unprofessional. It‚Äôs because modern production systems are highly interconnected, so it‚Äôs impossible to know what could potentially be affected by anything - especially if you haven‚Äôt worked on this project for 15 years.</p><p>What is modern production? I‚Äôm glad you asked!</p><p>\\\nIt doesn‚Äôt matter if you build games or a banking app - you don‚Äôt just have a pile of features and assets. You have an ecosystem for each bit of work: Art, Code, Design, UI, Marketing, Publishing (maybe even Project Management - wow, you are a rich developer), etc. And each one of them has its own infrastructure, pipelines, workflows, and shared assets. To simplify, it can be shared data schemas, builds, automation processes, UI bindings, and many other things.</p><p>\\\nWhat‚Äôs wrong if I just make a small color change to one of the icons? Well, that means you spend 3 seconds changing a color code. Then you have to assemble a build. Then QA has to check your small change to confirm that you indeed changed the color. Then you have to assemble the build again, which should be in a queue with other builds in the waiting list.</p><p>\\\nThen we have to update the server with your changes - oh wait, did you tell anyone about that? No? Oh, that‚Äôs great, because you just submitted your changes during the commit freeze, and now deployment engineers have to fix the CI/CD pipeline, and we have to postpone the release for 4 days because it‚Äôs Friday.</p><p>\\\nAnd by the way - we have to communicate that to users because they were waiting for this new version, and some of them decided not to wait that long and removed your app. Whoops, that‚Äôs awkward. Sorry to hear that.</p><p>That‚Äôs alright, I‚Äôm here to help you! Let me introduce you to Change Propagation Surface (CPS) - the number of systems, pipelines, assets, and workflows that a change must pass through before it reaches the player.</p><p>\\\nYour change should not be estimated by its task size, like ‚Äú1 hour of work.‚Äù Your change equals CPS √ó Coupling Density (the amount of work other departments need to do in order for this change to pass).</p><p>\\\nThink about it this way:</p><ul><li>One small UI tweak touches no shared data - low CPS.</li><li>A gameplay rule change touching code, balance, design, analytics, player experience - high CPS.</li></ul><p>\\\nLet‚Äôs go back to the situation where you want to change the color of the icon. Those 3 seconds of work would affect UI, builds, player perception, experience, and design. It might also affect color coding for accessibility rules, plus build assembling, and finally server updates. It‚Äôs high CPS - of course, if you didn‚Äôt sneak that change in without everyone‚Äôs awareness (I see that - drop it!).</p><p>\\\nThe same goes for asset swaps or changing a stat value: it affects memory, AI tuning, destruction logic, etc. Don‚Äôt do that unless someone from senior leadership said it‚Äôs low CPS - then just do it and see how it goes.</p><p>\\\nYou can apply this approach basically anywhere in production because it is not an abstract thing at all and can be estimated.</p><ul></ul><p>\\\nEach of these items counts as a plus 1 CPS factor. Subsequently, the more of the same ‚Äúitems‚Äù you touch, the higher the CPS number you will get. And with that information, you can create a small estimation matrix like:</p><p>CPS 1-2 - Local change \\n CPS 3-5 - Cross-functional change \\n CPS 6+ - Systemic change</p><p>\\\nOne more time, the formula is: Impact = CPS √ó Coupling Density. Easy!</p><p>Let‚Äôs see how it works in a real-life example:</p><p>\\\nSo your developer went on holiday and completed a math course on LinkedIn. And when he came back, he said that there is a more efficient way of calculating EXP. This change is ‚Äúone line of code.‚Äù Okay, but after reading this article, you already know how it works in reality and that it touches multiple things:</p><ul><li>Player progression pacing</li></ul><p>\\\nThat means CPS is more than 7. So now you see that even though the code diff is tiny, the propagation surface is systemic and has a massive potential outcome. In other words, if XP progression speeds up things like economy, availability of the content, battle pass value, retention curves, etc., you should know that even if the implementation takes about 10 minutes, the ripple effect can take weeks of work.</p><p>\\\nWhy does live service production make it worse? Because it is amplified by content being reused across multiple features, by telemetry and economy being tightly coupled, and by systems being persistent and often requiring backward compatibility.</p><p>\\\nSo, the real cost you pay for propagation lies in prolonged timelines, hidden rework, cross-team friction, technical debt, burnout, and eventually, people resigning directly or indirectly.</p><p>\\\nInstead of thinking, ‚ÄúOh, this is a small change,‚Äù we should probably think, ‚ÄúWhat systems does this change touch?‚Äù Think about this as infrastructure, not a feature, and always try to bring that to cross-team awareness. And if you are capable enough, try to estimate the surface area, not just this exact small change.</p><p>\\\n**The whole point of my way-too-long introduction is that there is no such thing as a small change in production systems. There are only changes in misunderstood affected areas. And the more senior you become, the more your vision shifts toward understanding how this change will travel instead of trying to avoid the change altogether.</p>",
      "contentLength": 6294,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Startup Plans April Launch for a Satellite Reflect Sunlight to Earth at Night",
      "url": "https://science.slashdot.org/story/26/02/28/076229/startup-plans-april-launch-for-a-satellite-reflect-sunlight-to-earth-at-night?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1772292840,
      "author": "EditorDavid",
      "guid": 49141,
      "unread": true,
      "content": "A start-up called Reflect Orbital \"proposes to use large, mirrored satellites to redirect sunlight to Earth at night,\" reports the Washington Post, \"with plans to bathe solar farms, industrial sites and even entire cities in light that could, if desired, reach the intensity of daylight....\" \n\nSlashdot noted their idea in 2022 ‚Äî but Reflect Orbital now expects to launch its first satellite in April, according to the article. \"But its grand vision is largely 'aspirational,' as its young founder, Ben Nowack, told me...\"\n\nReflect Orbital's Nowack describes a scene right out of sci-fi: An extremely bright star appears on the northern horizon and makes its way across the sky, illuminating a 5-kilometer circle on Earth, then setting on the southern horizon about five minutes later, just as another such \"star\" appears in the north. To make the night even brighter, a customer could make 10 \"stars\" appear at once in the north by ordering them on an app. Two such artificial stars are in development in Reflect Orbital's factory. Nowack showed them to me on a Zoom call. The first to launch is 50 feet across, but he plans later to build them three times that size. If all goes according to plan, he'll have 50,000 of them circling the Earth in 2035 at an altitude of around 400 miles. \nNowack plans to start selling the service \"in mostly developing nations or places that don't have streetlights yet.\" Eventually, he thinks, he can illuminate major cities, turn solar fields and farms into round-the-clock operations for any business or municipality that pays for it. He likened his technology to the invention of crop irrigation thousands of years ago. \"I see this as much the same thing,\" he said, arguing that people would no longer have to \"wait for the sun to shine.\" \n\nThe article adds that Elon Musk's SpaceX \"wants to launch as many as a million satellites to serve as orbiting data centers ‚Äî 70 times the number of satellites now in orbit.\" (America's satellite-regulation Federal Communications Commission\ngrants a \"categorical exclusion\" from environmental review to satellites on the grounds that their operations \"normally do not have significant effects on the human environment.\") \n\nThe public comment periods for the two proposals close on March 6 and March 9.",
      "contentLength": 2285,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Startup Plans April Launch for a Satellite to Reflect Sunlight to Earth at Night",
      "url": "https://science.slashdot.org/story/26/02/28/076229/startup-plans-april-launch-for-a-satellite-to-reflect-sunlight-to-earth-at-night?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1772292840,
      "author": "EditorDavid",
      "guid": 49156,
      "unread": true,
      "content": "A start-up called Reflect Orbital \"proposes to use large, mirrored satellites to redirect sunlight to Earth at night,\" reports the Washington Post, \"with plans to bathe solar farms, industrial sites and even entire cities in light that could, if desired, reach the intensity of daylight....\" \n\nSlashdot noted their idea in 2022 ‚Äî but Reflect Orbital now expects to launch its first satellite in April, according to the article. \"But its grand vision is largely 'aspirational,' as its young founder, Ben Nowack, told me...\"\n\nReflect Orbital's Nowack describes a scene right out of sci-fi: An extremely bright star appears on the northern horizon and makes its way across the sky, illuminating a 5-kilometer circle on Earth, then setting on the southern horizon about five minutes later, just as another such \"star\" appears in the north. To make the night even brighter, a customer could make 10 \"stars\" appear at once in the north by ordering them on an app. Two such artificial stars are in development in Reflect Orbital's factory. Nowack showed them to me on a Zoom call. The first to launch is 50 feet across, but he plans later to build them three times that size. If all goes according to plan, he'll have 50,000 of them circling the Earth in 2035 at an altitude of around 400 miles. \nNowack plans to start selling the service \"in mostly developing nations or places that don't have streetlights yet.\" Eventually, he thinks, he can illuminate major cities, turn solar fields and farms into round-the-clock operations for any business or municipality that pays for it. He likened his technology to the invention of crop irrigation thousands of years ago. \"I see this as much the same thing,\" he said, arguing that people would no longer have to \"wait for the sun to shine.\" \n\nThe article adds that Elon Musk's SpaceX \"wants to launch as many as a million satellites to serve as orbiting data centers ‚Äî 70 times the number of satellites now in orbit.\" (America's satellite-regulation Federal Communications Commission\ngrants a \"categorical exclusion\" from environmental review to satellites on the grounds that their operations \"normally do not have significant effects on the human environment.\") \n\nThe public comment periods for the two proposals close on March 6 and March 9.",
      "contentLength": 2285,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Meet M6: The Chinese AI That Understands Text and Images at Scale",
      "url": "https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss",
      "date": 1772292503,
      "author": "Alibaba",
      "guid": 49170,
      "unread": true,
      "content": "<ol><li>Junyang Lin, junyang.ljy@alibaba-inc.com (Alibaba Group, China)</li><li>Rui Men, menrui.mr@alibaba-inc.com (Alibaba Group, China)</li><li>An Yang, ya235025@alibaba-inc.com (Alibaba Group, China)</li><li>Chang Zhou, ericzhou.zc@alibaba-inc.com (Alibaba Group, China)</li><li>Ming Ding, dm18@mails.tsinghua.edu.cn (Tsinghua University, China)</li><li>Yichang Zhang, yichang.zyc@alibaba-inc.com (Alibaba Group, China)</li><li>Peng Wang, zheluo.wp@alibaba-inc.com (Alibaba Group, China)</li><li>Ang Wang, wangang.wa@alibaba-inc.com (Alibaba Group, China)</li><li>Le Jiang, jiangle.jl@alibaba-inc.com (Alibaba Group, China)</li><li>Xianyan Jia, xianyan.xianyanjia@alibaba-inc.com (Alibaba Group, China)</li><li>Jie Zhang, wanglin.zj@alibaba-inc.com (Alibaba Group, China)</li><li>Jianwei Zhang, zhangjianwei.zjw@alibaba-inc.com (Alibaba Group, China)</li><li>Xu Zou, zoux18@mails.tsinghua.edu.cn (Tsinghua University, China)</li><li>Zhikang Li, zhikang.lzk@alibaba-inc.com (Alibaba Group, China)</li><li>Xiaodong Deng, xiaodongdeng.dxd@alibaba-inc.com (Alibaba Group, China)</li><li>Jie Liu, sanshuai.lj@alibaba-inc.com (Alibaba Group, China)</li><li>Jinbao Xue, zhiji.xjb@alibaba-inc.com (Alibaba Group, China)</li><li>Huiling Zhou, zhule.zhl@alibaba-inc.com (Alibaba Group, China)</li><li>Jianxin Ma, jason.mjx@alibaba-inc.com (Alibaba Group, China)</li><li>Jin Yu, kola.yu@alibaba-inc.com (Alibaba Group, China)</li><li>Yong Li, jiufeng.ly@alibaba-inc.com (Alibaba Group, China)</li><li>Wei Lin, weilin.lw@alibaba-inc.com (Alibaba Group, China)</li><li>Jingren Zhou, jingren.zhou@alibaba-inc.com (Alibaba Group, China)</li><li>Jie Tang, jietang@tsinghua.edu.cn (Tsinghua University, China)</li><li>Hongxia Yang, yang.yhx@alibaba-inc.com (Alibaba Group, China)</li></ol><p>In this work, we construct the largest dataset for multimodal pre-training in Chinese, which consists of over 1.9TB images and 292GB texts that cover a wide range of domains. We propose a cross-modal pretraining method called , referring to ulti-odality to ulti-odality ultitask ega-transformer, for unified pretraining on the data of single modality and multiple modalities. We scale the model size up to 10 billion and  parameters, and build the largest pretrained model in Chinese. We apply the model to a series of downstream applications, and demonstrate its outstanding performance in comparison with strong baselines. Furthermore, we specifically design a downstream task of text-guided image generation, and show that the finetuned M6 can create high-quality images with high resolution and abundant details.</p><p>Multimodal Pretraining; Multitask; Text-to-Image Generation</p><p>Pretraining has become a focus in the research in natural language processing (NLP) [<a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark17\">1</a>, <a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark18\">2</a>, <a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark23\">7</a>, <a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark32\">16</a>, <a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark34\">18</a>, <a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark35\">19</a>, <a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark43\">27</a>, <a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark47\">31</a>, <a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark53\">37</a>, <a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark60\">44</a>, <a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark65\">49</a>]. The recent GPT-3 with over 175 billion parameters demonstrates that large models trained on big data have extremely large capacity and it can outperform the state-of-the-arts in downstream tasks especially in the zero-shot setting. Also, the rapid development of pretraining in NLP sparkles cross-modal pretraining. A number of studies [<a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark20\">4</a>, <a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark27\">11</a>, <a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark33\">17</a>, <a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark38\">22</a>, <a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark40\">24</a>, <a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark41\">25</a>, <a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark44\">28</a>, <a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark45\">29</a>, <a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark54\">38</a>, <a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark67\">51</a>] have created new state-of-the-art performances for various cross-modal downstream tasks.</p><p>A pity is that most recent studies focus on the pretraining on English data. There are lack of both large-scale datasets in Chinese and large-scale models pretrained on the data of Chinese. Therefore, in this work, we develop a large-scale dataset M6-Corpus, which consists of over 1.9TB images and 292GB texts. To the best of our knowledge, this is the largest dataset in Chinese for pretraining in both multimodality and natural language. The dataset collected from the webpages consists of different types of data and covers a large scale of domains, including encyclopedia, question answering, forum discussion, product description, etc. Also, we design sophisticated cleaning procedures to ensure that the data are of high quality.</p><p>Furthermore, in order to sufficiently leverage such a large amount of high-quality data, we propose to build an extremely large model that can process data of multiple modalities and adapt to different types of downstream tasks. Thus we propose a novel model called M6, referring to MultiModality-to-MultiModality Multitask Mega-transformer. The model is based on the transformer, and it is pretrained with multiple tasks. Pretraining endows the model with the capability of single-modality and multimodality understanding and generation. Based on the architecture of M6, we build  and , which are scaled up to 10 billion and 100 billion pa-rameters respectively. To be more specific,  is the recent largest model pretrained on Chinese data. We apply the model to a series of downstream applications, including product description generation, visual question answering, community question answering, Chinese poem generation, etc., and our experimental results show that M6 outperforms a series of strong baselines.</p><p>Another contribution of this work is that we first incorporate pretraining with text-to-image generation. Following Ramesh et al. <a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark48\">[32]</a>, we leverage a two-stage framework for image generation. To be more specific, we apply a trained vector-quantized generative adversarial network to representing images with discrete image codes, and we then use the pretrained M6 to learn the relations between texts and codes. Such learning can bridge the two modalities and enables controllable text-to-image generation.</p><p>To summarize, the contributions of M6 are as follows:</p><ul><li>We collect and build the largest Chinese multi-modal pre-training data in industry, which includes 300GB texts and 2TB images.</li><li>We propose M6 for multimodal pretraining in Chinese, and we scale the model size to up to 10 and 100 billion parameters. Both M6-10B and M6-100B are the recent largest multimodal pretrained model.</li><li>M6 is versatile and exceeds strong baselines by 11.8% in VQA, 18.4 in image captioning, and 10.3% in image-text matching. Furthermore M6 is able to generate high-quality images.</li><li>With carefully designed large-scale distributed training optimizations, M6 has obvious advantages in training speed and greatly reduces training costs, creating the possibility for more widespread use of multi-modal pretraining.</li></ul><p>We collect and develop the largest multi-modality and text dataset in Chinese for now, which is one of the key contributions of this paper. In this section, we first identify the limitations of existing datasets and then describe the construction and preprocessing procedure of our proposed dataset.</p><h2>2.1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Existing Datasets</h2><p>The construction of large-scale corpus with high quality and do-main coverage is crucial to Chinese pretraining. In early previous works, the Chinese Wikipedia1&nbsp;is one of the most frequently used datasets to train Chinese language models. It contains 1.6GB texts (around 0.4B tokens) covering around 1M encyclopedia entries. Another corpus with a comparable size is the THUCTC[<a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark55\">39</a>] dataset, which includes 740K news articles. However, with the rapidly increasing capacity of recent language models, the scale of these existing datasets is clearly insufficient. Recently, Cui et al. <a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark21\">[5]</a> employ unreleased extended data that are 10 times larger than the CN-Wikipedia to pretrain their Chinese language model. Xu et al.</p><p><a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark63\">[47]</a> released a 100GB corpus named CLUECorpus2020, which is retried from the multilingual Common Crawl dataset. However, the scale of the datasets is still insufficient to facilitate super large-scale pretraining compared with existing English pretrained models. For example, GPT-3 contains 175B parameters and is trained on 570GB texts. Meanwhile, the dataset should contain image-text pairs rather than plain texts for multi-modal pretraining.</p><h2>2.2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Standards for a High-quality Dataset</h2><p>To perform large-scale multi-modal pretraining and learn complex world knowledge in Chinese, the dataset is highly required to provide both plain texts and image-text pairs on super large scale, covering a wide range of domains. In order to perform large-scale multi-modal pretraining in Chinese, we focus on the construction of large-scale datasets in Chinese. Specifically, while we unify our pretraining for both natural language and multimodalities, we construct large datasets of both plain texts and image-text pairs. We are interested in obtaining large-scale data that covers a wide range of domains, so that it is possible for the model to learn the complex world knowledge of different fields. Also, we aim to collect data of multiple modalities for the cross-modal pretraining. This raises the difficulty for the construction of a large-scale dataset as the data for multimodal pretraining are usually image-text pairs, where in each pair the text provides a detailed description of a fraction of the image.</p><p>Though there are a tremendous amount of text resources and images on the world wide web, the corpus for multimodal pretraining is assumed to be better when satisfying the following properties:</p><p>(1). the sentences should be fluent natural language within a normal length, and should not contain meaningless tokens, such as markups, duplicate punctuation marks, random combinations of characters, etc.; (2). the images should be natural and realistic, and the resolutions of the images need to be identifiable by humans; (3). both the texts and images should not contain illegal content, such as pornography, violence, etc.; (4). the images and texts should be semantically relevant; (5). the datasets should cover a wide range of fields, say sports, politics, science, etc., and therefore it can endow the model with sufficient world knowledge.</p><h2>2.3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Dataset Construction</h2><p>Based on the requirements above, we collect data of both plain texts and image-text pairs. There are different types of data, including encyclopedia, crawled webpage, community question answering, forum, product description, etc. We present the details in Table <a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark2\">3.</a> The collected corpus consists of bothag plain-texts and image-text pairs, which is compatible with the designed text-only and multi-modal pretraining tasks. Also, the data has a large coverage over domains, such as science, entertainment, sports, politics, common-sense of life, etc. We have also compared some characteristics of our corpus with existing datasets used for Chinese pretraining in Table <a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark1\">2.</a> The size of our dataset is much larger than the previous ones. To our knowledge, this is the first large-scale, multimodal and multidomain corpus for Chinese pretraining.</p><p>We implement sophisticated preprocessing to obtain clean data. For text data, we first remove HTML markups and duplicate punctuation marks, and we only reserve characters and punctuation marks that are in Chinese and English. We remove the topics that are shorter than 5 characters and contents shorter than 15 characters. We further apply in-house spam detection to remove sentences that contain words related to certain political issues, pornography, or words in the list of dirty, naughty, and other bad words. In order to preserve the linguistic acceptance of the texts, we implement a language model to evaluate their perplexities, and sentences with high perplexities are discarded. Only images with at least 5000 pixels are reserved for pretraining. A sequence of classifiers and heuristic rules are applied to filter out images containing illegal content. We also use a pretrained image scorer to evaluate the qual-ities of images. For images and texts in crawled webpages, we only consider images and their surrounding text as relevant image-text pairs. Other sentences in the webpages are discarded.</p><p>Multimodal pretraining leverages both the power of self-attention-based transformer architecture and pretraining on large-scale data. We endeavor to endow the model with strong capability of cross-modal understanding and generation. In this section, we describe the details of our proposed pretrained model , which refers to ulti-odality-to-ulti-odality ultitask ega-transformer.</p><h2>3.1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; √Ö &nbsp; Visual and Linguistic Inputs</h2><p>The mainstream multimodal pretraining methods transform images to feature sequences via object detection. However, the performance of the object detectors as well as the expressivity of their backbones strongly impact the final performance of the pretrained models in the downstream tasks. We observe that a large proportion of the images contain only a few objects. Take the images of the data of e-commerce as an example. We randomly sample 1M images and perform object detection on the images. The results show that over 90% of the images contain fewer than 5 objects. Also, the objects have high overlapping with each other. To alleviate such influence, we turn to a simple but effective solution following Gao et al. [\\[12\\]](#<em>bookmark28) and Dosovitskiy et al. [\\[8\\]](#</em>bookmark24). In general, we split an image into patches and extract features of the 2D patches with a trained feature extractor, say ResNet-50. Then we line up the representations to a sequence by their positions.  The processing of the input word sequence is much simpler. We follow the similar preprocessing procedures in the previous work [<a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark20\">4</a>, <a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark27\">11</a>, <a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark40\">24</a>]. We apply WordPiece [<a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark50\">34</a>, <a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark61\">45</a>] and masking to the word sequence and embed them with an embedding layer, following BERT <a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark22\">[6].</a></p><h2>3.2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Unified Encoder-Decoder</h2><p>We integrate the image embeddings ùëíùëñ&nbsp;and the word embeddings ùëíùë°&nbsp;into the cross-modal embedding sequence ùëí = {ùëíùëñ, ùëíùë° }. We send the sequence to the transformer backbone for high-level feature extraction. To differ their representations, we add corresponding segment embeddings for different modalities. Specifically, we leverage the</p><p>self-attention-based transformer blocks for our unified cross-modal representation learning. To be more specific, the building block is identical to that of BERT or GPT, which consists of self attention and point-wise feed-forward network (FFN). On top of the transformer backbone, we add an output layer for word prediction, and thus we tie its weights to those of the embedding layer.</p><p>In the unified framework, we use different masking strategies to enable encoding and decoding. The input is segmented into three parts, including visual inputs, masked linguistic inputs, and complete linguistic inputs. We apply bidirectional masking to both the visual inputs and masked linguistic inputs, and we apply causal masking to the complete linguistic inputs. Thus the model is allowed to encode and decode in the same framework.</p><h2>3.3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Pretraining Methods</h2><p>We pretrain the model with the multitask setup, including text-to-text transfer, image-to-text transfer, and multimodality-to-text transfer. Thus the model can process information of different modalities and perform both single-modal and cross-modal understanding and generation.</p><p> As demonstrated in Figure <a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark3\">3,</a> the model learns to perform text denoising and language modeling in the setting of text-to-text transfer. In text denoising, we mask the input text by a proportion, which is 15% in practice following BERT [<a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark22\">6</a>]. Specifically, we mask a continuous span of text with a single mask, and the model should learn to decode the whole sequence. This encourages the model to learn both recovering and length predict-ing. Besides, in order to improve the model ability in generation, we add a setup of language modeling, where the encoder receives no inputs and the decoder learns to generate words based on the previous context.</p><p>\\\n Image-to-text transfer is similar to image captioning, where the model receives the visual information as the input, and learns to generate a corresponding description. In this setting, we add the aforementioned patch feature sequence to the input and leave the masked input blank. The model encodes the patch features, and decodes the corresponding text.</p><p><strong>Multimodality-to-text transfer</strong> Based on the setup of image-to-text transfer, we additionally add masked linguistic inputs, and thus the model should learn to generate the target text based on both the visual information and the noised linguistic information. This task allows the model to adapt to the downstream tasks with both visual and linguistic inputs.</p><h2>3.4&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Scaling up to 10 and 100 Billion Parameters</h2><p>We scale up the model size to 10 billion parameters and 100 billion parameters, which are named M6-10B and M6-100B. The increase in model size provides a much larger capacity for the model that it can learn knowledge from more data. For the construction of M6-10B, we simply scale up the model by hyperparameter tuning.</p><p>To be more specific, we increase the size of hidden states and the number of layers. To better leverage GPU memory, we apply mixed-precision training and activation checkpointing to save memory. Still, the model cannot be fit into one single GPU, and thus we use model parallelism to split the feed-forward networks and attention heads to multiple GPUs following the implementation of Megatron-LM <a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark52\">[36].</a></p><p>However, directly scaling up to M6-100B is much more difficult as there are more challenges for the computation resources. Alternatively, inspired by the recent progress in sparse activations [<a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark26\">10</a>, <a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark36\">20</a>, <a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark51\">35</a>], we combine Mixture-of-Experts (MoE) with M6 to build the version of 100 billion parameters. Note that the original MoE requires mesh-tensorflow as well as TPUs. This sets limits for a number of researchers without such resources. Thus we implement the M6-100B with MoE with our in-house framework Whale [<a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark59\">43</a>] to perform model parallelism with GPUs. We demonstrate the key statistics of the models of different scales in Table <a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark4\">4.</a></p><p>Specifically, different from the conventional FFN layer, the MoE layer is a parallel combination of multiple FFN layers, each of which acts as an expert. This is also called expert parallelism. The model first learns a sparse gating network to route the tokens to specific experts. Thus each token is only sent to a small set of experts and the computation can be much less compared with that in dense models. This kind of model is highly efficient as it realizes data parallelism and expert parallelism across workers. The computation of MoE layer for a specific token ùë• can be described as below:</p><p>where ùëî(¬∑) refers to the sparse gating function, and T refers to the indices of top-ùëò values of ùëî(¬∑). The output of MoE is a linear combination of the computation of selected expert FFNs ùëì (¬∑).</p><p>In expert parallelism, the parameters of experts do not share across workers, while those of other parts are identical across workers. Therefore, it is necessary to perform all-to-all communication across workers at the MoE layers in order to dispatch tokens to selected experts and combine them to their original experts. While Lepikhin et al. <a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark36\">[20]</a> and Fedus et al. <a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark26\">[10]</a> implement the MoE on TPUs with one expert in each MoE layer on a TPU, we implement our model on Nvidia GPUs where there are several experts in each MoE layer on a GPU so as to fully utilize the memory. As all-to-all communication takes up a large amount of time, the optimization to improve efficiency is highly significant. We implement a series of optimization, including half-precision communication. A key problem is load balancing, which denotes that tokens can gather to only a few experts due to dynamic routing. Following Fedus et al. <a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark26\">[10]</a>, we apply expert capacity, which refers to the number of tokens for an expert (ùê∂ = ùëÅ&nbsp;- ùëê/m, where ùê∂ refers to expert capacity, ùëÅ refers to the number of tokens in a batch, ùëê refers to capacity factor (which is a hyperparameter usually larger than 1.0) and ùëö refers to the number of experts), to alleviate this problem. Tokens out of the capacity of an expert are dropped from the computation and they are sent to next layers through residual connections. We find that the overloading problem can be severe, and this issue can be a significant one in the future research of expert models.</p><p>Besides the optimization in all-to-all communication, we com-pare the top-2 gating and top-1 gating and find that they can achieve similar model performance in perplexity, while the latter converges slightly slower. The effectiveness of top-1 gating enables faster computation. Besides, we also apply methods of memory optimization for higher efficiency. We find that gradient clipping globally can increase costs on all-to-all communication as it computes norms across all experts, and thus we apply local clipping for memory saving. We implement M6-100B with around 100 billion parameters on 128 Nvidia A100s and the speed of pretraining achieves 1440 samples/s (for samples of the sequence length of 272).</p><p>We demonstrate that using MoE structure for model size scaling is effective and it can achieve similar performance to that of M6-10B, the largest dense model, within 2-3 times shorter time. The negative log perplexity of M6-100B reaches ‚àí2.297, in comparison with M6-10B that reaches ‚àí2.253 but with twice of time.2 This shows that the MoE-based M6 model has advantages on the time basis compared with dense models with many more FLOPs.</p><h2>4.1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Text-to-Image Generation</h2><p>Text-to-image generation has been an open problem for a long time. Previous studies mainly focused on generation on a limited domain, among which Generative Adversarial Nets (GANs) [<a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark30\">14</a>, <a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark64\">48</a>] are dominated methods. Following Ramesh et al. <a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark48\">[32]</a>, we leverage a two-stage framework for text-to-image generation, including discrete representation learning and language modeling.</p><p>\\\nIn the first stage, we focus on transforming images into sequences of discrete codes. There are a number of alternatives for discrete code generation, including VQVAE [<a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark57\">41</a>] and VQGAN [<a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark25\">9</a>]. In the second stage, it is necessary to build a language model to learn to generate text and code sequence. In the finetuning, we add code embedding and output layers to the pretrained M6. We concat the word sequence and the aforementioned generated code sequence as the input, and we set the objective of autoregressive language modeling for the training. At the stage of inference, we input the text sequence, and the model generates codes autoregressively with top-k sampling. The last step is to transform the code sequence to an image with the generator from the first stage.</p><p>We construct a dataset for text-to-image generation in E-commerce. Specifically, we collect over 50 million product titles and images from the mobile Taobao. We apply a series of processing methods on the images to filter the unqualified. We filter the images with complex background features (characters, patterns, etc.) with the in-house white-background image detector and OCR model. We then filter the images with over 3 objects with our in-house object detector based on Faster R-CNN [<a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark49\">33</a>]. We finally obtain 1.8m high-quality product image-text pairs for finetuning. Compared with the images in the general domains, our collected data have the following features. The image and text are highly correlated as the text describes key features of the product, and there is no complex background in the images, which is easier to learn compared with the images in the public datasets such as MSCOCO <a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark42\">[26].</a></p><p>We demonstrate two examples in Figure <a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark7\">4</a> and Figure <a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark8\">5.</a> It can be found that the generated images have high quality and the generated objects resemble the real ones. Furthermore, in Figure <a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark9\">6</a> , we find that the model is able to imagine items according to the query <em>military style camouflage high heels(ÂÜõÊóÖÈ£éËø∑ÂΩ©È´òË∑üÈûã</em>), which do not exist in the real world. The imagination ability provides room for creative design in real-world industrial scenarios, such as clothing design, shoe design, etc.</p><p>We also finetune M6 under our proposed framework on another dataset which contains 3 million images crawled from the Internet, which cover more general domains. And we find that the model can adapt to different domains. As shown in Figure <a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark10\">7,</a> the model is able to generate clip arts of robots . This reveals the versatility of the framework in text-to-image generation.</p><h2>4.2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Visual Question Answering</h2><p>We demonstrate our experimental results on a visual question answering dataset, and we illustrate how we directly apply the pre-trained M6 to the VQA application.</p><p>\\\nWe leverage the FMIQA dataset [<a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark29\">13</a>] as the Chinese visual QA benchmark, which requires the model to generate the answer given an image and a question. We implement a transformer-based model as our baseline. For the evaluation, we split the test set manually by random sampling 200 from the dataset as there is no official release of the test set, and we evaluate the overall accuracy by human evaluation. The results are demonstrated in Table <a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark5\">5.</a> The pretrained M6-base outperforms the baseline by a large margin (+6.2%), which indicates the effectiveness of multimodal pretraining. Scaling up the model to M6-10B further brings 5.2% improvement.</p><p>Furthermore, we show that simply finetuning on such a small VQA dataset may limit the potential of M6. Therefore, we directly leverage M6 for the VQA application. We find that the model is able to recognize general features and provide more related knowledge based on its understanding. Though the model pretrained on pseudo-parallel image-text pairs cannot directly answer questions about detailed features, such as color, number, etc., it is able to answer questions related to background knowledge. We demonstrate some examples in Figure <a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark12\">8.</a></p><h2>4.3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Image Captioning</h2><p>Image captioning requires the model to generate a caption that describes the given image, which examines the model ability of cross-modal generation. We construct a dataset (named E-Commerce IC) containing pairs of product descriptions and product images from Taobao. Since too long or too short descriptions may be noisy, we discard pairs with a description longer than 100 words or less than 10 words. To avoid dirty generations, we further use an in-house tool to filter descriptions that may contain dirty words (i.e., pornographic or violent words). Finally, E-Commerce IC contains about 260k text-image pairs. We finetune the model with the image-to-text transfer task on E-Commerce IC.</p><p>\\\nWe compare our model with a baseline of transformer in the human evaluation. We ask several annotators with the linguistic background to evaluate from three perspectives: grammar (whether a text is fluent without grammatical error), correctness (whether a text is faithful to the image), richness (whether a text is informative and attractive). During the evaluation, we randomly sample 100 images from the test set. For each image, an annotator is asked to score the text generated by different models. The scores are within the range of [0, 5].</p><p>The results in Table <a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark11\">6</a> show that M6-base outperforms the baseline in all of the metrics. We find that all models achieve high scores in grammar. However, in both correctness and richness, M6-base outperforms the baseline model by a large margin (+18.2% and +14.4%), indicating that multimodal pretraining helps to generate more faithful, informative and attractive texts. Scaling up the model to M6-10B further improves the correctness and richness (about 14.7% and 7.0%). Figure 9 illustrates two examples of image caption.</p><h2>4.4&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Question Answering</h2><p>To demonstrate the potential availability in the applications of intelligent chatbots, we further employ the M6 model to generate long answers in the style of forum discussion. Human-generated questions are collected from various Chinese forums, which are input to the model to generate the answer. At the stage of inference, we append a question mark and a token  in the prompt, which better triggers the model to generate an answer. To facilitate the generation of longer and more informative texts, we pick more complex questions.</p><p>Figure <a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark14\">10</a> demonstrates an example of general question answer-ing. The model can illustrate a man‚Äôs own experiences that are related to the question and also point out the answer at the end. This generated text confused human annotators and passed the Turing Test. It shows that the model can not only answer general questions but also generate long fluency text.</p><p>We apply the pretrained model to Chinese poem generation. The model is able to generate genres with format constraints.</p><p>\\\nAncient Chinese poetry has various specific formats. We adopt the simplest constraints that</p><ul><li>The poem shall be consisted of at least 4 lines.</li><li>The total number of lines shall be even.</li><li>Each line must have exactly 5 or 7 words.</li><li>All lines shall have the same number of words.</li></ul><p>Text generation under format constraint is done in a search framework that we generate short sentences ending with punctuation until the number of words meets the constraint. We repeat this process until the model generates an \"\" token, or the number of lines exceeds a limit of 16. Figure <a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark15\">11</a> illustrates an example of a generated poem.</p><h2>4.6&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Image-Text Matching</h2><p>We evaluate the model‚Äôs ability in cross-modal retrieval. Specifically, we construct a dataset (named E-Commerce ITM) containing pairs of texts and images from the mobile Taobao. Each pair belongs to a single item. we collect 235K products in the clothing industry from Taobao. For each product, aside from the product image, we obtain a query by rewriting the product title. Specifically, we conduct named entity recognition on the title using an in-house tool, which extracts the terms describing the style, color, category and texture of the product.</p><p>\\\nThese terms are then concatenated into a natural language query, which is used in image-text matching. The length of each query is between 6 to 12 words. The pairs of the query and corresponding product image are labeled as positive samples. The negative samples are constructed by randomly substituting the query in the original pairs.</p><p>We require the model to perform binary classification to discriminate positive and negative samples. We compare our model with InterBert [<a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark41\">25</a>], which is also a Chinese multi-modal pretrained model effective in cross-modal classification downstream tasks. The InterBert utilizes object-based features and has been pretrained on Taobao product image-text data as well.</p><p>The results are shown in Table <a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark16\">7.</a> It should be noted that the InterBert and M6-base are both implemented with transformer-based architecture and have similar model scales. However, M6-base still outperforms InterBert by 10.3%. In experiments, we find the product images generally contain relatively fewer detected objects, which may harm the performance on this task. In contrast, M6 avoids this problem by employing the patch features and achieves much better performance.</p><p>The tremendous success of NLP pretraining, including BERT [<a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark22\">6</a>], GPT [<a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark18\">2</a>, <a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark46\">30</a>, <a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark47\">31</a>], and also some other related studies [<a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark17\">1</a>, <a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark23\">7</a>, <a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark35\">19</a>, <a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark43\">27</a>, <a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark65\">49</a>], inspires the research in cross-modal representation learning. Also, recent studies show that the ubiquitous Transformer architecture [<a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark58\">42</a>] can be extended to different fields, including computer vision [<a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark19\">3</a>, <a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark24\">8</a>]. Therefore, the simplest solution to incorporate recent pretraining methods and cross-modal representation learning is the extension of BERT. From the perspective of architecture, there are mainly two types, including single-stream model and dual stream model. Specifically, single-stream model is simple and it gradually becomes the mainstream architecture. These models mostly differ in their designs of pretraining tasks or the construction of input im-age features. Basically, they are mainly pretrained masked language modeling, masked object classification, and image-text matching. VisualBERT [<a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark39\">23</a>] and Unicoder-VL [<a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark38\">22</a>] simply use BERT and are pretrained with the aforementioned tasks. UNITER [<a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark20\">4</a>] pretrains the model with an additional task of word-region alignment. Oscar [<a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark40\">24</a>] enhances the alignment between objects and their corresponding words or phrases. VILLA [<a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark27\">11</a>] further improves model performance by adding their proposed adversarial learning methods to pretraining and finetuning. Except for pretraining tasks, some studies focus on the features of images. Most pretraining methods for multimodal representation learning utilize the features generated by a trained object detector, say Faster R-CNN [<a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark49\">33</a>]. PixelBERT [<a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark33\">17</a>] accepts raw images as input and extract their latent representations with a learnable ResNet [<a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark31\">15</a>] or ResNext [<a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark62\">46</a>]. FashionBERT [<a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark28\">12</a>] splits the images into patches with a trained ResNet without co-training. Besides single-stream models, dual-stream models also can achieve outstanding performance, such as VilBERT [<a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark44\">28</a>], LXMERT [<a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark56\">40</a>] and InterBERT [<a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark41\">25</a>]. ViLBERT-MT [<a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark45\">29</a>] enhances model performance with multi-task finetuning. ERNIE-ViL [<a href=\"https://hackernoon.com/meet-m6-the-chinese-ai-that-understands-text-and-images-at-scale?source=rss#_bookmark66\">50</a>] enhances the model with the application of scene graph information. In spite of these successful cases, it still requires further researches to unmask the success of multimodal pretraining.</p><p>In this work, we propose the largest dataset M6-Corpus for pre-training in Chinese, which consists of over 1.9TB images and 292GB texts. The dataset has large coverage over domains, including encyclopedia, question answering, forum discussion, common crawl, etc. We propose a method called M6 that is able to process information of multiple modalities and perform both single-modal and cross-modal understanding and generation. The model is scaled to large model with 10B and 100B parameters with sophisticated deployment, and both models are the largest multimodal pretrained models. We apply the model to a series of downstream applications, showing its versatility. More specifically, we design a downstream task of text-guided image generation, and the finetuned M6 can reach superior performance by producing images of high quality.</p><p>In the future, we will continue the pretraining of extremely large models by increasing the scale of data and models to explore the limit of performance, and we also endeavor to search for more downstream applications for further generalization.</p><p>[1]&nbsp;&nbsp; Hangbo Bao, Li Dong, Furu Wei, Wenhui Wang, Nan Yang, Xiaodong Liu, Yu Wang, Jianfeng Gao, Songhao Piao, Ming Zhou, et al. 2020. Unilmv2: Pseudo-masked language models for unified language model pre-training. In <em>International Conference on Machine Learning</em>. PMLR, 642‚Äì652.</p><p>[2]&nbsp;&nbsp; Tom B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan,</p><p>Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. <em>arXiv preprint arXiv:2005.14165</em> (2020).</p><p>[3]&nbsp;&nbsp; Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander Kirillov, and Sergey Zagoruyko. 2020. End-to-end object detection with transformers. In <em>European Conference on Computer Vision</em>. Springer, 213‚Äì229.</p><p>[4]&nbsp;&nbsp; Y en-Chun Chen, Linjie Li, Licheng Yu, Ahmed El Kholy, Faisal Ahmed, Zhe Gan, Yu Cheng, and Jingjing Liu. 2020. UNITER: UNiversal Image-TExt Representation Learning. In . 104‚Äì120.</p><p>[5]&nbsp;&nbsp; Yiming Cui, Wanxiang Che, Ting Liu, Bing Qin, Shijin Wang, and Guoping Hu. 2020. Revisiting pre-trained models for chinese natural language processing. <em>arXiv preprint arXiv:2004.13922</em> (2020).</p><p>[6]&nbsp;&nbsp; Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In . 4171‚Äì4186.</p><p>[7]&nbsp;&nbsp; Li Dong, Nan Yang, Wenhui Wang, Furu Wei, Xiaodong Liu, Yu Wang, Jianfeng Gao, Ming Zhou, and Hsiao-Wuen Hon. 2019. Unified Language Model Pre-training for Natural Language Understanding and Generation. In . 13042‚Äì13054.</p><p>[8]&nbsp;&nbsp; Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xi-aohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, et al. 2020. An image is worth 16x16 words: Transformers for image recognition at scale. <em>arXiv preprint arXiv:2010.11929</em> (2020).</p><p>[9]&nbsp;&nbsp; Patrick Esser, Robin Rombach, and Bj√∂rn Ommer. 2020. Taming Transformers for High-Resolution Image Synthesis. arXiv<a href=\"https://arxiv.org/abs/2012.09841\">:2012.09841</a> [cs.CV]</p><p>[10]&nbsp;&nbsp; William Fedus, Barret Zoph, and Noam Shazeer. 2021. Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity.  abs/2101.03961 (2021). arXiv<a href=\"https://arxiv.org/abs/2101.03961\">:2101.03961</a><a href=\"https://arxiv.org/abs/2101.03961\">https://arxiv.org/abs/2101.03961</a></p><p>[11]&nbsp;&nbsp; Zhe Gan, Yen-Chun Chen, Linjie Li, Chen Zhu, Yu Cheng, and Jingjing Liu. 2020. Large-Scale Adversarial Training for Vision-and-Language Representation Learning. In .</p><p>[12]&nbsp;&nbsp; Dehong Gao, Linbo Jin, Ben Chen, Minghui Qiu, Peng Li, Yi Wei, Yi Hu, and Hao Wang. 2020. Fashionbert: Text and image matching with adaptive loss for cross-modal retrieval. In . 2251‚Äì2260.</p><p>[13]&nbsp;&nbsp; Haoyuan Gao, Junhua Mao, Jie Zhou, Zhiheng Huang, Lei Wang, and Wei Xu. 2015. Are you talking to a machine? dataset and methods for multilingual image question answering. <em>arXiv preprint arXiv:1505.05612</em> (2015).</p><p>[14]&nbsp;&nbsp; Ian J Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014. Generative adversarial networks. <em>arXiv preprint arXiv:1406.2661</em> (2014).</p><p>[15]&nbsp;&nbsp; Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep Residual Learning for Image Recognition. In . 770‚Äì778.</p><p>[16]&nbsp;&nbsp; Pengcheng He, Xiaodong Liu, Jianfeng Gao, and Weizhu Chen. 2020. De-berta: Decoding-enhanced bert with disentangled attention. <em>arXiv preprint arXiv:2006.03654</em> (2020).</p><p>[17]&nbsp;&nbsp; Zhicheng Huang, Zhaoyang Zeng, Bei Liu, Dongmei Fu, and Jianlong Fu. 2020. Pixel-bert: Aligning image pixels with text by deep multi-modal transformers. <em>arXiv preprint arXiv:2004.00849</em> (2020).</p><p>[18]&nbsp;&nbsp; Zihang Jiang, Weihao Yu, Daquan Zhou, Yunpeng Chen, Jiashi Feng, and Shuicheng Yan. 2020. Convbert: Improving bert with span-based dynamic convolution. <em>arXiv preprint arXiv:2008.02496</em> (2020).</p><p>[19]&nbsp;&nbsp; Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, and Radu Soricut. 2019. ALBERT: A Lite BERT for Self-supervised Learning of Language Representations.  abs/1909.11942 (2019).</p><p>[20]&nbsp;&nbsp; Dmitry Lepikhin, HyoukJoong Lee, Yuanzhong Xu, Dehao Chen, Orhan Firat, Yanping Huang, Maxim Krikun, Noam Shazeer, and Zhifeng Chen. 2020. Gshard: Scaling giant models with conditional computation and automatic sharding. <em>arXiv preprint arXiv:2006.16668</em> (2020).</p><p>[21]&nbsp;&nbsp; Mike Lewis, Shruti Bhosale, Tim Dettmers, Naman Goyal, and Luke Zettle-moyer. 2021. BASE Layers: Simplifying Training of Large, Sparse Models.  abs/2103.16716 (2021).</p><p>[22]&nbsp;&nbsp; Gen Li, Nan Duan, Yuejian Fang, Daxin Jiang, and Ming Zhou. 2019. Unicoder-VL: A Universal Encoder for Vision and Language by Cross-modal Pre-training.  abs/1908.06066 (2019).</p><p>[23]&nbsp;&nbsp; Liunian Harold Li, Mark Yatskar, Da Yin, Cho-Jui Hsieh, and Kai-Wei Chang. 2019. VisualBERT: A Simple and Performant Baseline for Vision and Language.  abs/1908.03557 (2019).</p><p>[24]&nbsp;&nbsp; Xiujun Li, Xi Yin, Chunyuan Li, Pengchuan Zhang, Xiaowei Hu, Lei Zhang, Lijuan Wang, Houdong Hu, Li Dong, Furu Wei, Yejin Choi, and Jianfeng Gao. 2020. Oscar: Object-Semantics Aligned Pre-training for Vision-Language Tasks.  abs/2004.06165 (2020).</p><p>[25]&nbsp;&nbsp; Junyang Lin, An Yang, Yichang Zhang, Jie Liu, Jingren Zhou, and Hongxia Yang. 2020. Interbert: Vision-and-language interaction for multi-modal pretraining. <em>arXiv preprint arXiv:2003.13198</em> (2020).</p><p>[26]&nbsp;&nbsp; Tsung-Yi Lin, Michael Maire, Serge J. Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll√°r, and C. Lawrence Zitnick. 2014. Microsoft COCO: Common Objects in Context. In . 740‚Äì755.</p><p>[27]&nbsp;&nbsp; Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019. RoBERTa: A Robustly Optimized BERT Pretraining Approach.  abs/1907.11692 (2019).</p><p>[28]&nbsp;&nbsp; Jiasen Lu, Dhruv Batra, Devi Parikh, and Stefan Lee. 2019. ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks. In . 13‚Äì23.</p><p>[29]&nbsp;&nbsp; Jiasen Lu, Vedanuj Goswami, Marcus Rohrbach, Devi Parikh, and Stefan Lee. 2019. 12-in-1: Multi-Task Vision and Language Representation Learning.  abs/1912.02315 (2019).</p><p>[31]&nbsp;&nbsp; Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. [n.d.]. Language models are unsupervised multitask learners. ([n. d.]).</p><p>[32]&nbsp;&nbsp; Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec Radford, Mark Chen, and Ilya Sutskever. 2021. Zero-Shot Text-to-Image Generation. arXiv<a href=\"https://arxiv.org/abs/2102.12092\">:2102.12092</a> [cs.CV]</p><p>[33]&nbsp;&nbsp; Shaoqing Ren, Kaiming He, Ross B. Girshick, and Jian Sun. 2015. Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks. In . 91‚Äì99.</p><p>[34]&nbsp;&nbsp; Rico Sennrich, Barry Haddow, and Alexandra Birch. 2016. Neural Machine Translation of Rare Words with Subword Units. In .</p><p>[35]&nbsp;&nbsp; Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc Le, Geoffrey Hinton, and Jeff Dean. 2017. Outrageously large neural networks: The sparsely-gated mixture-of-experts layer. <em>arXiv preprint arXiv:1701.06538</em> (2017).</p><p>[36]&nbsp;&nbsp; Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper, and Bryan Catanzaro. 2019. Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism. <em>arXiv preprint arXiv:1909.08053</em> (2019).</p><p>[37]&nbsp;&nbsp; Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, and Tie-Yan Liu. 2019. MASS: Masked Sequence to Sequence Pre-training for Language Generation. In . 5926‚Äì5936.</p><p>[38]&nbsp;&nbsp; Weijie Su, Xizhou Zhu, Yue Cao, Bin Li, Lewei Lu, Furu Wei, and Jifeng Dai. 2020. VL-BERT: Pre-training of Generic Visual-Linguistic Representations. In .</p><p>[39]&nbsp;&nbsp; Maosong Sun, Jingyang Li, Zhipeng Guo, Z Yu, Y Zheng, X Si, and Z Liu. 2016. Thuctc: an efficient chinese text classifier.  (2016).</p><p>[40]&nbsp;&nbsp; Hao Tan and Mohit Bansal. 2019. LXMERT: Learning Cross-Modality Encoder Representations from Transformers. In . 5099‚Äì5110.</p><p>[41]&nbsp;&nbsp; A√§ron van den Oord, Oriol Vinyals, and Koray Kavukcuoglu. 2017. Neural Discrete Representation Learning. In .</p><p>[42]&nbsp;&nbsp; Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is All you Need. In . 5998‚Äì6008.</p><p>[43]&nbsp;&nbsp; Ang Wang, Xianyan Jia, Le Jiang, Jie Zhang, Yong Li, and Wei Lin. 2020. Whale: A Unified Distributed Training Framework. <em>arXiv preprint arXiv:2011.09208</em> (2020).</p><p>[44]&nbsp;&nbsp; Wei Wang, Bin Bi, Ming Yan, Chen Wu, Zuyi Bao, Jiangnan Xia, Liwei Peng, and Luo Si. 2019. Structbert: Incorporating language structures into pre-training for deep language understanding. <em>arXiv preprint arXiv:1908.04577</em> (2019).</p><p>[45]&nbsp;&nbsp; Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgang Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, et al. 2016. Google‚Äôs neural machine translation system: Bridging the gap between human and machine translation. <em>arXiv preprint arXiv:1609.08144</em> (2016).</p><p>[46]&nbsp;&nbsp; Saining Xie, Ross Girshick, Piotr Doll√°r, Zhuowen Tu, and Kaiming He. 2017. Aggregated residual transformations for deep neural networks. In . 1492‚Äì1500.</p><p>[47]&nbsp;&nbsp; Liang Xu, Xuanwei Zhang, and Qianqian Dong. 2020. CLUECorpus2020: A Large-scale Chinese Corpus for Pre-trainingLanguage Model. <em>arXiv preprint arXiv:2003.01355</em> (2020).</p><p>[48]&nbsp;&nbsp; Tao Xu, Pengchuan Zhang, Qiuyuan Huang, Han Zhang, Zhe Gan, Xiaolei Huang, and Xiaodong He. 2018. Attngan: Fine-grained text to image generation with attentional generative adversarial networks. In <em>Proceedings of the IEEE conference on computer vision and pattern recognition</em>. 1316‚Äì1324.</p><p>[49]&nbsp;&nbsp; Zhilin Yang, Zihang Dai, Yiming Yang, Jaime G. Carbonell, Ruslan Salakhutdinov, and Quoc V. Le. 2019. XLNet: Generalized Autoregressive Pretraining for Language Understanding. In . 5754‚Äì5764.</p><p>[50]&nbsp;&nbsp; Fei Yu, Jiji Tang, Weichong Yin, Yu Sun, Hao Tian, Hua Wu, and Haifeng Wang. 2020. Ernie-vil: Knowledge enhanced vision-language representations through scene graph. <em>arXiv preprint arXiv:2006.16934</em> (2020).</p><p>[51]&nbsp;&nbsp; Luowei Zhou, Hamid Palangi, Lei Zhang, Houdong Hu, Jason J. Corso, and Jianfeng Gao. 2020. Unified Vision-Language Pre-Training for Image Captioning and VQA. In . 13041‚Äì13049.</p><p>:::info\nThis paper is&nbsp;<a href=\"https://arxiv.org/abs/2103.00823\">available on arxiv</a>&nbsp;under CC by 4.0 Deed (Attribution 4.0 International) license.  </p>",
      "contentLength": 43855,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Xiaomi launches 17 Ultra smartphone, an AirTag clone, and an ultra slim powerbank",
      "url": "https://techcrunch.com/2026/02/28/xiaomi-launches-17-ultra-smartphone-an-airtag-clone-and-an-ultra-slim-powerbank/",
      "date": 1772291343,
      "author": "Ivan Mehta",
      "guid": 49149,
      "unread": true,
      "content": "<article>We round up everything Xiaomi announced at its Mobile World Congress event.</article>",
      "contentLength": 75,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Alibaba‚Äôs Qwen: The Chinese AI Model Challenging Silicon Valley",
      "url": "https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss",
      "date": 1772291299,
      "author": "Alibaba",
      "guid": 49169,
      "unread": true,
      "content": "<ol></ol><p>\\\n</p><p>Large language models (LLMs) have revolutionized the field of artificial intelligence, enabling natural language processing tasks that were previously thought to be exclusive to humans. In this work, we introduce QWEN<a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark0\">1</a>, the first installment of our large language model series. QWEN is a comprehensive language model series that encompasses distinct models with varying parameter counts. It includes QWEN, the base pretrained language models, and QWEN-CHAT, the chat models finetuned with human alignment techniques. The base language models consistently demonstrate superior performance across a multitude of downstream tasks, and the chat models, particularly those trained using Reinforcement Learning from Human Feedback (RLHF), are highly competitive. The chat models possess advanced tool-use and planning capabilities for creating agent applications, showcasing impressive performance even when compared to bigger models on complex tasks like utilizing a code interpreter. Furthermore, we have developed coding-specialized models, CODE-QWEN and CODE-QWEN-CHAT, as well as mathematics-focused models, MATH-QWEN-CHAT, which are built upon base language models. These models demonstrate significantly improved performance in comparison with open-source models, and slightly fall behind the proprietary models. \\n </p><p>\\\nDespite their impressive capabilities, LLMs are often criticized for their lack of reproducibility, steerability, and accessibility to service providers. In this work, we are pleased to present and release the initial version of our LLM series, QWEN. QWEN is a moniker that derives from the Chinese phrase Qianwen, which translates to ‚Äúthousands of prompts‚Äù and conveys the notion of embracing a wide range of inquiries. QWEN is a comprehensive language model series that encompasses distinct models with varying parameter counts. The model series include the base pretrained language models, chat models finetuned with human alignment techniques, i.e., supervised finetuning (SFT), reinforcement learning with human feedback (RLHF), etc., as well as specialized models in coding and math. The details are outlined below:</p><p>1.&nbsp;&nbsp; The base language models, namely QWEN, have undergone extensive training using up to 3 trillion tokens of diverse texts and codes, encompassing a wide range of areas. These models have consistently demonstrated superior performance across a multitude of downstream tasks, even when compared to their more significantly larger counterparts.</p><p>2.&nbsp;&nbsp; The QWEN-CHAT models have been carefully finetuned on a curated dataset relevant to task performing, chat, tool use, agent, safety, etc. The benchmark evaluation demonstrates that the SFT models can achieve superior performance. Furthermore, we have trained reward models to mimic human preference and applied them in RLHF for chat models that can produce responses preferred by humans. Through the human evaluation of a challenging test, we find that QWEN-CHAT models trained with RLHF are highly competitive, still falling behind GPT-4 on our benchmark.</p><p>3.&nbsp;&nbsp;&nbsp; In addition, we present specialized models called CODE-QWEN, which includes CODE-QWEN-7B and CODE-QWEN-14B, as well as their chat models, CODE-QWEN-14B-CHAT and CODE-QWEN-7B-CHAT. Specifically, CODE-QWEN has been pre-trained on extensive datasets of code and further fine-tuned to handle conversations related to code generation, debugging, and interpretation. The results of experiments conducted on benchmark datasets, such as HumanEval <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark69\">(Chen et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark69\">2021),</a> MBPP <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark55\">(Austin et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark55\">2021),</a> and HumanEvalPack <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark140\">(Muennighoff et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark140\">2023),</a> demonstrate the high level of proficiency of CODE-QWEN in code understanding and generation.</p><p>4.&nbsp;&nbsp; This research additionally introduces MATH-QWEN-CHAT specifically designed to tackle mathematical problems. Our results show that both MATH-QWEN-7B-CHAT and MATH-QWEN-14B-CHAT outperform open-sourced models in the same sizes with large margins and are approaching GPT-3.5 on math-related benchmark datasets such as GSM8K <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark82\">(Cobbe</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark82\">et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark82\">2021)</a> and MATH <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark102\">(Hendrycks et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark102\">2021).</a></p><p>5.&nbsp;&nbsp;&nbsp; Besides, we have open-sourced QWEN-VL and QWEN-VL-CHAT, which have the versatile ability to comprehend visual and language instructions. These models outperform the current open-source vision-language models across various evaluation benchmarks and support text recognition and visual grounding in both Chinese and English languages. Moreover, these models enable multi-image conversations and storytelling. Further details can be found in <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark59\">Bai et al.</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark59\">(2023).</a></p><p>\\\nNow, we officially open-source the 14B-parameter and 7B-parameter base pretrained models QWEN and aligned chat models QWEN-CHAT<a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark4\">2</a>. This release aims at providing more comprehensive and powerful LLMs at developer- or application-friendly scales.</p><p>The structure of this report is as follows: Section <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark2\">2</a> describes our approach to pretraining and results of QWEN. Section <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark13\">3</a> covers our methodology for alignment and reports the results of both automatic evaluation and human evaluation. Additionally, this section describes details about our efforts in building chat models capable of tool use, code interpreter, and agent. In Sections <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark31\">4</a> and <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark35\">5,</a> we delve into specialized models of coding and math and their performance. Section <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark41\">6</a> provides an overview of relevant related work, and Section <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark47\">7</a> concludes this paper and points out our future work.</p><p>The pretraining stage involves learning vast amount of data to acquire a comprehensive understanding of the world and its various complexities. This includes not only basic language capabilities but also advanced skills such as arithmetic, coding, and logical reasoning. In this section, we introduce the data, the model design and scaling, as well as the comprehensive evaluation results on benchmark datasets.</p><p>The size of data has proven to be a crucial factor in developing a robust large language model, as highlighted in previous research <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark103\">(Hoffmann et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark103\">2022;</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark184\">Touvron et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark184\">2023b).</a> To create an effective pretraining dataset, it is essential to ensure that the data are diverse and cover a wide range of types, domains, and tasks. Our dataset is designed to meet these requirements and includes public web documents, encyclopedia, books, codes, etc. Additionally, our dataset is multilingual, with a significant portion of the data being in English and Chinese.</p><p>\\\nTo ensure the quality of our pretraining data, we have developed a comprehensive data preprocessing procedure. For public web data, we extract text from HTML and use language identification tools to determine the language. To increase the diversity of our data, we employ deduplication techniques, including exact-match deduplication after normalization and fuzzy deduplication using MinHash and LSH algorithms. To filter out low-quality data, we employ a combination of rule-based and machine-learning-based methods. Specifically, we use multiple models to score the content, including language models, text-quality scoring models, and models for identifying potentially offensive or inappropriate content. We also manually sample texts from various sources and review them to ensure their quality. To further enhance the quality of our data, we selectively up-sample data from certain sources, to ensure that our models are trained on a diverse range of high-quality content. In recent studies <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark211\">(Zeng et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark211\">2022;</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark53\">Aribandi et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark53\">2021;</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark156\">Raffel et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark156\">2020),</a> it has been demonstrated that pretraining language models with multi-task instructions can enhance their zero-shot and few-shot performance. To further enhance the performance of our model, we have incorporated high-quality instruction data into our pretraining process. To safeguard the integrity of our benchmark assessment, we have adopted a similar approach as <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark67\">Brown et al.</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark67\">(2020)</a> and meticulously eliminated any instruction samples that exhibit a 13-gram overlap with any data present in the test sets utilized in our evaluation.</p><p>\\\nGiven the large number of downstream tasks, it is not feasible to repeat this filtering process for all tasks. Instead, we have made sure that the instruction data for the reported tasks have undergone our filtering process to ensure their accuracy and reliability. Finally, we have built a dataset of up to 3 trillion tokens.</p><p>The design of vocabulary significantly impacts the training efficiency and the downstream task performance. In this study, we utilize byte pair encoding (BPE) as our tokenization method, following GPT-3.5 and GPT-4. We start with the open-source fast BPE tokenizer, tiktoken <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark113\">(Jain,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark113\">2022),</a> and select the vocabulary cl100k base as our starting point. To enhance the performance of our model on multilingual downstream tasks, particularly in Chinese, we augment the vocabulary with commonly used Chinese characters and words, as well as those in other languages. Also, following <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark183\">Touvron et al.</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark184\">(2023a;b),</a> we have split numbers into single digits. The final vocabulary size is approximately 152K.</p><p>The performance of the QWEN tokenizer in terms of compression is depicted in Figure <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark5\">3.</a> In this comparison, we have evaluated QWEN against several other tokenizers, including XLM-R <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark83\">(Conneau</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark83\">et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark83\">2019),</a> LLaMA <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark183\">(Touvron et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark183\">2023a),</a> Baichuan <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark110\">(Inc.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark110\">2023a),</a> and InternLM <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark112\">(InternLM Team,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark112\">2023).</a> Our findings reveal that QWEN achieves higher compression efficiency than its competitors in most languages. This implies that the cost of serving can be significantly reduced since a smaller number of tokens from QWEN can convey more information than its competitors. Furthermore, we have conducted preliminary experiments to ensure that scaling the vocabulary size of QWEN does not negatively impact the downstream performance of the pretrained model. Despite the increase in vocabulary size, our experiments have shown that QWEN maintains its performance levels in downstream evaluation.</p><p>QWEN is designed using a modified version of the Transformer architecture. Specifically, we have adopted the recent open-source approach of training large language models, LLaMA <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark183\">(Touvron et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark183\">2023a),</a> which is widely regarded as the top open-source LLM. Our modifications to the architecture include:</p><ul><li><strong>Embedding and output projection</strong>. Based on preliminary experimental findings, we have opted for the untied embedding approach instead of tying the weights of input embedding and output projection. This decision was made in order to achieve better performance with the price of memory costs.</li><li>. We have chosen RoPE (Rotary Positional Embedding) <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark174\">(Su et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark174\">2021)</a> as our preferred option for incorporating positional information into our model. RoPE has been widely adopted and has demonstrated success in contemporary large language models, notably PaLM <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark77\">(Chowdhery et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark77\">2022;</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark50\">Anil et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark50\">2023)</a> and LLaMA <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark183\">(Touvron</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark183\">et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark184\">2023a;b).</a> In particular, we have opted to use FP32 precision for the inverse frequency matrix, rather than BF16 or FP16, in order to prioritize model performance and achieve higher accuracy.</li><li>. For most layers, we remove biases following <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark77\">Chowdhery et al.</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark77\">(2022),</a> but we add biases in the QKV layer of attention to enhance the extrapolation ability of the model <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark173\">(Su,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark173\">2023b).</a></li><li>. In modern Transformer models, pre-normalization is the most widely used approach, which has been shown to improve training stability compared to post-normalization. Recent research has suggested alternative methods for better training stability, which we plan to explore in future versions of our model. Additionally, we have replaced the traditional layer normalization technique described in <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark57\">(Ba et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark57\">2016)</a> with RMSNorm <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark115\">(Jiang et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark115\">2023).</a> This change has resulted in equivalent performance while also improving efficiency.</li><li>. We have selected SwiGLU <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark165\">(Shazeer,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark165\">2020)</a> as our activation function, a combination of Swish <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark157\">(Ramachandran et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark157\">2017)</a> and Gated Linear Unit <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark87\">(Dauphin et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark87\">2017).</a> Our initial experiments have shown that activation functions based on GLU generally outperform other baseline options, such as GeLU <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark100\">(Hendrycks &amp; Gimpel,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark100\">2016).</a> As is common practice in previous research, we have reduced the dimension of the feed-forward network (FFN) from 4 times the hidden size to 8/3 of the hidden size.</li></ul><p>To train QWEN, we follow the standard approach of autoregressive language modeling, as described in <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark153\">Radford et al.</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark153\">(2018).</a> This involves training the model to predict the next token based on the context provided by the previous tokens. We train models with context lengths of 2048. To create batches of data, we shuffle and merge the documents, and then truncate them to the specified context lengths. To improve computational efficiency and reduce memory usage, we employ Flash Attention in the attention modules <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark86\">(Dao et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark86\">2022).</a> We adopt the standard optimizer AdamW <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark116\">(Kingma &amp; Ba,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark116\">2014;</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark134\">Loshchilov &amp; Hutter,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark134\">2017)</a> for pretraining optimization. We set the hyperparameters 1 = 0*.*9, 2 = 0*.*95, and  = 10‚àí8. We use a cosine learning rate schedule with a specified peak learning rate for each model size. The learning rate is decayed to a minimum learning rate of 10% of the peak learning rate. All the models are trained with BFloat16 mixed precision for training stability.</p><h3>2.5&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Context Length Extension</h3><p>Transformer models have a significant limitation in terms of the context length for their attention mechanism. As the context length increases, the quadratic-complexity computation leads to a drastic increase in both computation and memory costs. In this work, we have implemented simple training-free techniques that are solely applied during inference to extend the context length of the model. One of the key techniques we have used is NTK-aware interpolation <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark65\">(bloc97,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark65\">2023).</a></p><p>\\\nUnlike position interpolation (PI) <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark70\">(Chen et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark70\">2023a)</a> which scales each dimension of RoPE equally, NTK-aware interpolation adjusts the base of RoPE to prevent the loss of high-frequency information in a training-free manner. To further improve performance, we have also implemented a trivial extension called dynamic NTK-aware interpolation, which is later formally discussed in <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark149\">(Peng et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark149\">2023a).</a> It dynamically changes the scale by chunks, avoiding severe performance degradation. These techniques allow us to effectively extend the context length of Transformer models without compromising their computational efficiency or accuracy.</p><p>QWEN additionally incorporates two attention mechanisms: LogN-Scaling <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark75\">(Chiang &amp; Cholak,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark75\">2022;</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark172\">Su,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark172\">2023a)</a> and window attention <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark62\">(Beltagy et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark62\">2020).</a> LogN-Scaling rescales the dot product of the query and value by a factor that depends on the ratio of the context length to the training length, ensuring that the entropy of the attention value remains stable as the context length grows. Window attention restricts the attention to a limited context window, preventing the model from attending to tokens that are too far away.</p><p>We also observed that the long-context modeling ability of our model varies across layers, with lower layers being more sensitive in context length extension compared to the higher layers. To leverage this observation, we assign different window sizes to each layer, using shorter windows for lower layers and longer windows for higher layers.</p><h3>2.6&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Experimental Results</h3><p>\\\nIn this evaluation, we focus on the base language models without alignment and collect the baselines‚Äô best scores from their official results and OpenCompass <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark146\">(OpenCompass Team,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark146\">2023).</a> The results are presented in Table <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark10\">2.</a></p><p>Our experimental results demonstrate that the three QWEN models exhibit exceptional performance across all downstream tasks. It is worth noting that even the larger models, such as LLaMA2-70B, are outperformed by QWEN-14B in 3 tasks. QWEN-7B also performs admirably, surpassing LLaMA2-13B and achieving comparable results to Baichuan2-13B. Notably, despite having a relatively small number of parameters, QWEN-1.8B is capable of competitive performance on certain tasks and even outperforms larger models in some instances. The findings highlight the impressive capabilities of the QWEN models, particularly QWEN-14B, and suggest that smaller models, such as QWEN-1.8B, can still achieve strong performance in certain applications.</p><p>To evaluate the effectiveness of context length extension, Table <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark12\">3</a> presents the test results on arXiv<a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark15\">3</a> in terms of perplexity (PPL). These results demonstrate that by combining NTK-aware interpolation, LogN-Scaling, and layer-wise window assignment, we can effectively maintain the performance of our models in the context of over 8192 tokens.</p><p>Pretrained large language models have been found to be not aligned with human behavior, making them unsuitable for serving as AI assistants in most cases. Recent research has shown that the use of alignment techniques, such as supervised finetuning (SFT) and reinforcement learning from human feedback (RLHF), can significantly improve the ability of language models to engage in natural conversation. In this section, we will delve into the details of how QWEN models have been trained using SFT and RLHF, and evaluate their performance in the context of chat-based assistance.</p><h3>3.1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Supervised Finetuning</h3><p>To gain an understanding of human behavior, the initial step is to carry out SFT, which finetunes a pretrained LLM on chat-style data, including both queries and responses. In the following sections, we will delve into the details of data construction and training methods.</p><p>To enhance the capabilities of our supervised finetuning datasets, we have annotated conversations in multiple styles. While conventional datasets <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark193\">(Wei et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark193\">2022a)</a> contain a vast amount of data prompted with questions, instructions, and answers in natural language, our approach takes it a step further by annotating human-style conversations. This practice, inspired by <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark147\">Ouyang et al.</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark147\">(2022),</a> aims at improving the model‚Äôs helpfulness by focusing on natural language generation for diverse tasks. To ensure the model‚Äôs ability to generalize to a wide range of scenarios, we specifically excluded data formatted in prompt templates that could potentially limit its capabilities. Furthermore, we have prioritized the safety of the language model by annotating data related to safety concerns such as violence, bias, and pornography.</p><p>In addition to data quality, we have observed that the training method can significantly impact the final performance of the model. To achieve this, we utilized the ChatML-style format <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark144\">(OpenAI,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark144\">2022),</a> which is a versatile meta language capable of describing both the metadata (such as roles) and the content of a turn. This format enables the model to effectively distinguish between various types of information, including system setup, user inputs, and assistant outputs, among others. By leveraging this approach, we can enhance the model‚Äôs ability to accurately process and analyze complex conversational data.</p><p>Consistent with pretraining, we also apply next-token prediction as the training task for SFT. We apply the loss masks for the system and user inputs. More details are demonstrated in Section <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark221\">A.1.1.</a></p><p>The model‚Äôs training process utilizes the AdamW optimizer, with the following hyperparameters: 1 set to 0*.2 set to 0. set to 10‚àí8. The sequence length is limited to 2048, and the batch size is 128. The model undergoes a total of 4000 steps, with the learning rate gradually increased over the first 1430 steps, reaching a peak of 2  10‚àí6. To prevent overfitting, weight decay is applied with a value of 0..<em>1, and gradient clipping is enforced with a limit of 1</em>.*0.</p><h3>3.2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Reinforcement Learning from Human Feedback</h3><p>While SFT has proven to be effective, we acknowledge that its generalization and creativity capa-bilities may be limited, and it is prone to overfitting. To address this issue, we have implemented Reinforcement Learning from Human Feedback (RLHF) to further align SFT models with human preferences, following the approaches of <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark147\">Ouyang et al.</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark147\">(2022);</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark78\">Christiano et al.</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark78\">(2017).</a> This process involves training a reward model and using Proximal Policy Optimization (PPO) <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark164\">(Schulman et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark164\">2017)</a> to conduct policy training.</p><h3>3.2.1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Reward Model</h3><p>To create a successful reward model, like building a large language model (LLM), it is crucial to first undergo pretraining and then finetuning. This pretraining process, also known as preference model pretraining (PMP) <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark60\">(Bai et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark60\">2022b),</a> necessitates a vast dataset of comparison data. This dataset consists of sample pairs, each containing two distinct responses for a single query and their corresponding preferences. Similarly, finetuning is also conducted on this type of comparison data, but with a higher quality due to the presence of quality annotations.</p><p>During the fine-tuning phase, we gather a variety of prompts and adjust the reward model based on human feedback for responses from the QWEN models. To ensure the diversity and complexity of user prompts are properly taken into account, we have created a classification system with around 6600 detailed tags and implemented a balanced sampling algorithm that considers both diversity and complexity when selecting prompts for annotation by the reward model <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark135\">(Lu et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark135\">2023).</a> To generate a wide range of responses, we have utilized QWEN models of different sizes and sampling strategies, as diverse responses can help reduce annotation difficulties and enhance the performance of the reward model. These responses are then evaluated by annotators following a standard annotation guideline, and comparison pairs are formed based on their scores.</p><p>In creating the reward model, we utilize the same-sized pre-trained language model QWEN to initiate the process. It is important to mention that we have incorporated a pooling layer into the original QWEN model to extract the reward for a sentence based on a specific end token.</p><p>\\n The learning rate for this process has been set to a constant value of 3  10‚àí6, and the batch size is 64. Additionally, the sequence length is set to 2048, and the training process lasts for a single epoch.</p><p>We adopted the accuracy on the test dataset as an important but not exclusive evaluation metric for the reward model. In Table <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark20\">4,</a> we report the test pairwise accuracy of PMP and reward models on diverse human preference benchmark datasets <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark60\">(Bai et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark60\">2022b;</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark171\">Stiennon et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark171\">2020;</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark95\">Ethayarajh</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark95\">et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark95\">2022;</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark127\">Lightman et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark127\">2023).</a> Specifically, QWEN Helpful-base and QWEN Helpful-online are our proprietary datasets. The responses in QWEN Helpful-base are generated from QWEN without RLHF, whereas QWEN Helpful-online includes responses from QWEN with RLHF. The results show that the PMP model demonstrates high generalization capabilities on out-of-distribution data, and the reward model demonstrates significant improvement on our QWEN reward datasets.</p><h3>3.2.2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Reinforcement Learning</h3><p>Our Proximal Policy Optimization (PPO) process involves four models: the policy model, value model, reference model, and reward model. Before starting the PPO procedure, we pause the policy model‚Äôs updates and focus solely on updating the value model for 50 steps. This approach ensures that the value model can adapt to different reward models effectively.</p><p>During the PPO operation, we use a strategy of sampling two responses for each query simultaneously. This strategy has proven to be more effective based on our internal benchmarking evaluations. We set the KL divergence coefficient to 0*.*04 and normalize the reward based on the running mean.</p><p>The policy and value models have learning rates of 1  10‚àí6 and 5  10‚àí6, respectively. To enhance training stability, we utilize value loss clipping with a clip value of 0*.<em>15. For inference, the policy top-p is set to 0</em>.<em>9. Our findings indicate that although the entropy is slightly lower than when top-p is set to 1</em>.*0, there is a faster increase in reward, ultimately resulting in consistently higher evaluation rewards under similar conditions.</p><p>Additionally, we have implemented a pretrained gradient to mitigate the alignment tax. Empirical findings indicate that, with this specific reward model, the KL penalty is adequately robust to counteract the alignment tax in benchmarks that are not strictly code or math in nature, such as those that test common sense knowledge and reading comprehension. It is imperative to utilize a significantly larger volume of the pretrained data in comparison to the PPO data to ensure the effectiveness of the pretrained gradient. Additionally, our empirical study suggests that an overly large value for this coefficient can considerably impede the alignment to the reward model, eventually compromising the ultimate alignment, while an overly small value would only have a marginal effect on alignment tax reduction.</p><h3>3.3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Automatic and Human Evaluation of Aligned Models</h3><p>To showcase the effectiveness of our aligned models, we conduct a comparison with other aligned models on well-established benchmarks, including MMLU <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark101\">(Hendrycks et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark101\">2020),</a> C-Eval <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark108\">(Huang</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark108\">et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark108\">2023),</a> GSM8K <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark82\">(Cobbe et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark82\">2021),</a> HumanEval <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark69\">(Chen et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark69\">2021),</a> and BBH <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark177\">(Suzgun et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark177\">2022).</a> Besides the widely used few-shot setting, we test our aligned models in the zero-shot setting to demonstrate how well the models follow instructions. The prompt in a zero-shot setting consists of an instruction and a question without any previous examples in the context. The results of the baselines are collected from their official reports and OpenCompass <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark146\">(OpenCompass Team,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark146\">2023).</a></p><p>The results in Table <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark23\">5</a> demonstrate the effectiveness of our aligned models in understanding human instructions and generating appropriate responses. QWEN-14B-Chat outperforms all other models except ChatGPT (OpenAI, 2022) and LLAMA 2-CHAT-70B (Touvron et al., 2023b) in all datasets, including MMLU (Hendrycks et al., 2020), C-Eval (Huang et al., 2023), GSM8K (Cobbe et al., 2021), HumanEval (Chen et al., 2021), and BBH (Suzgun et al., 2022).</p><p>\\n In particular, QWEN‚Äôs performance in HumanEval, which measures the quality of generated codes, is significantly higher than that of other open-source models.</p><p>Moreover, QWEN‚Äôs performance is consistently better than that of open-source models of similar size, such as LLaMA2 <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark184\">(Touvron et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark184\">2023b),</a> ChatGLM2 <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark68\">(ChatGLM2 Team,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark68\">2023),</a> InternLM <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark112\">(InternLM</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark112\">Team,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark112\">2023),</a> and Baichuan2 <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark201\">(Yang et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark201\">2023).</a> This suggests that our alignment approach, which involves fine-tuning the model on a large dataset of human conversations, has been effective in improving the model‚Äôs ability to understand and generate human-like language./im</p><p>Despite this, we have reservations about the ability of traditional benchmark evaluation to accurately measure the performance and potential of chat models trained with alignment techniques in today‚Äôs landscape. The results mentioned earlier provide some evidence of our competitive standing, but we believe that it is crucial to develop new evaluation methods specifically tailored to aligned models.</p><p>We believe that human evaluation is crucial, which is why we have created a carefully curated dataset for this purpose. Our process involved collecting 300 instructions in Chinese that covered a wide range of topics, including knowledge, language understanding, creative writing, coding, and mathematics. To evaluate the performance of different models, we chose the SFT version of QWEN-CHAT-7B and the SFT and RLHF versions of QWEN-CHAT-14B, and added two strong baselines, GPT-3.5 and GPT-4<a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark24\">4</a>, for comparison. For each instruction, we asked three annotators to rank the model responses by the overall score of helpfulness, informativeness, validity, and other relevant factors. Our dataset and evaluation methodology provides a comprehensive and rigorous assessment of the capabilities of different language models in various domains.</p><p>Figure <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark25\">4</a> illustrates the win rates of the various models. For each model, we report the percentage of wins, ties, and losses against GPT-3.5, with the segments of each bar from bottom to top representing these statistics. The experimental results clearly demonstrate that the RLHF model outperforms the SFT models by significant margins, indicating that RLHF can encourage the model to generate responses that are more preferred by humans. In terms of overall performance, we find that the RLHF model significantly outperforms the SFT models, falling behind GPT-4. This indicates the effectiveness of RLHF for aligning to human preference. To provide a more comprehensive understanding of the models‚Äô performance, we include a case study with examples from different models in Appendix <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark230\">A.2.2.</a> Nonetheless, it remains difficult to accurately capture the gap between our models and the proprietary models. As such, a more extensive and rigorous assessment is required for the chat models.</p><p>The QWEN models, which are designed to be versatile, have the remarkable ability to assist with (semi-)automating daily tasks by leveraging their skills in tool-use and planning. As such, they can serve as agents or copilots to help streamline various tasks. We explore QWEN‚Äôs proficiency in the following areas:</p><p>‚Ä¢&nbsp;&nbsp;&nbsp;&nbsp; Using a Python code interpreter to enhance math reasoning, data analysis, and more (see Table <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark28\">7</a> and Table <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark29\">8).</a></p><p>‚Ä¢&nbsp;&nbsp;&nbsp;&nbsp; Functioning as an agent that accesses Hugging Face‚Äôs extensive collection of multimodal models while engaging with humans (see Table <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark30\">9).</a></p><p>\\\nTo enhance QWEN‚Äôs capabilities as an agent or copilot, we employ the self-instruct <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark190\">(Wang et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark190\">2023c)</a> strategy for SFT. Specifically, we utilize the in-context learning capability of QWEN for self-instruction. By providing a few examples, we can prompt QWEN to generate more relevant queries and generate outputs that follow a specific format, such as ReAct <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark203\">(Yao et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark203\">2022).</a> We then apply rules and involve human annotators to filter out any noisy samples. Afterwards, the samples are incorporated into QWEN‚Äôs training data, resulting in an updated version of QWEN that is more dependable for self-instruction. We iterate through this process multiple times until we gather an ample number of samples that possess both exceptional quality and a wide range of diversity. As a result, our final collection consists of around 2000 high-quality samples.</p><p>During the finetuning process, we mix these high-quality samples with all the other general-purpose SFT samples, rather than introducing an additional training stage. By doing so, we are able to retain essential general-purpose capabilities that are also pertinent for constructing agent applications.</p><p>\\\n<strong>Using Tools via ReAct Prompting</strong> We have created and made publicly available a benchmark for evaluating QWEN‚Äôs ability to call plugins, tools, functions, or APIs using ReAct Prompting (see <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark152\">Qwen Team, Alibaba Group,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark152\">2023b).</a> To ensure fair evaluation, we have excluded any plugins that were included in QWEN‚Äôs training set from the evaluation set. The benchmark assesses the model‚Äôs accuracy in selecting the correct plugin from a pool of up to five candidates, as well as the plausibility of the parameters passed into the plugin and the frequency of false positives. In this evaluation, a false positive occurs when the model incorrectly invokes a plugin in response to a query, despite not being required to do so.</p><p>The results presented in Table <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark27\">6</a> demonstrate that QWEN consistently achieves higher accuracy in identifying the relevance of a query to the available tools as the model size increases. However, the table also highlights that beyond a certain point, there is little improvement in performance when it comes to selecting the appropriate tool and providing relevant arguments. This suggests that the current preliminary benchmark may be relatively easy and may require further enhancement in future iterations. It is worth noting that GPT-3.5 stands out as an exception, displaying suboptimal performance on this particular benchmark. This could potentially be attributed to the fact that the benchmark primarily focuses on the Chinese language, which may not align well with GPT-3.5‚Äôs capabilities. Additionally, we observe that GPT-3.5 tends to attempt to use at least one tool, even if the query cannot be effectively addressed by the provided tools.</p><p>\\\n<strong>Using Code Interpreter for Math Reasoning and Data Analysis</strong> The Python code interpreter is widely regarded as a powerful tool for augmenting the capabilities of an LLM agent. It is worth investigating whether QWEN can harness the full potential of this interpreter to enhance its performance in diverse domains, such as mathematical reasoning and data analysis. To facilitate this exploration, we have developed and made publicly available a benchmark that is specifically tailored for this purpose (see <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark151\">Qwen Team, Alibaba Group,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark151\">2023a).</a></p><p>The benchmark encompasses three primary categories of tasks: math problem-solving, data visualization, and other general-purpose tasks like file post-processing and web crawling. Within the visualization tasks, we differentiate between two levels of difficulty. The easier level can be achieved by simply writing and executing a single code snippet without the need for advanced planning skills. However, the more challenging level requires strategic planning and executing multiple code snippets in a sequential manner. This is because the subsequent code must be written based on the output of the previous code. For example, an agent may need to examine the structure of a CSV file using one code snippet before proceeding to write and execute additional code to create a plot.</p><p>Regarding evaluation metrics, we consider both the executability and correctness of the generated code. To elaborate on the correctness metrics, for math problems, we measure accuracy by verifying if the ground truth numerical answer is present in both the code execution result and the final response. When it comes to data visualization, we assess accuracy by utilizing QWEN-VL <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark59\">(Bai et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark59\">2023),</a> a powerful multimodal language model. QWEN-VL is capable of answering text questions paired with images, and we rely on it to confirm whether the image generated by the code fulfills the user‚Äôs request.</p><p>The results regarding executability and correctness are presented in Table <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark28\">7</a> and Table <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark29\">8,</a> respectively. It is evident that CODE LLAMA generally outperforms LLAMA 2, its generalist counterpart, which is not surprising since this benchmark specifically requires coding skills. However, it is worth noting that specialist models that are optimized for code synthesis do not necessarily outperform generalist models. This is due to the fact that this benchmark encompasses various skills beyond coding, such as abstracting math problems into equations, understanding language-specified constraints, and responding in the specified format such as ReAct. Notably, QWEN-7B-CHAT and QWEN-14B-CHAT surpass all other open-source alternatives of similar scale significantly, despite being generalist models.</p><p>\\\n<strong>Serving as a Hugging Face Agent</strong> Hugging Face provides a framework called the Hugging Face Agent or Transformers Agent <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark109\">(Hugging Face,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark109\">2023),</a> which empowers LLM agents with a curated set of multimodal tools, including speech recognition and image synthesis. This framework allows an LLM agent to interact with humans, interpret natural language commands, and employ the provided tools as needed.</p><p>To evaluate QWEN‚Äôs effectiveness as a Hugging Face agent, we utilized the evaluation benchmarks offered by Hugging Face. The results are presented in Table <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark30\">9.</a> The evaluation results reveal that QWEN performs quite well in comparison to other open-source alternatives, only slightly behind the proprietary GPT-4, demonstrating QWEN‚Äôs competitive capabilities.</p><h2>4&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Code-Qwen: Specialized Model for Coding</h2><p>Training on domain-specific data has been shown to be highly effective, particularly in the case of code pretraining and finetuning. A language model that has been reinforced with training on code data can serve as a valuable tool for coding, debugging, and interpretation, among other tasks. In this work, we have developed a series of generalist models using pretraining and alignment techniques. Building on this foundation, we have created domain-specific models for coding by leveraging the base language models of QWEN, including continued pretrained model, CODE-QWEN and supervised finetuned model, CODE-QWEN-CHAT. Both models have 14 billion and 7 billion parameters versions.</p><h3>4.1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Code Pretraining</h3><p>We believe that relying solely on code data for pretraining can result in a significant loss of the ability to function as a versatile assistant. Unlike previous approaches that focused solely on pretraining on code data <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark126\">(Li et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark126\">2022;</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark125\">2023d),</a> we take a different approach <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark159\">(Rozie`re et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark159\">2023)</a> by starting with our base models QWEN trained on a combination of text and code data, and then continuing to pretrain on the code data. We continue to pretrain the models on a total of around 90 billion tokens. During the pre-training phase, we initialize the model using the base language models QWEN. Many applications that rely on specialized models for coding may encounter lengthy contextual scenarios, such as tool usage and code interpretation, as mentioned in Section <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark26\">3.4.</a> To address this issue, we train our models with context lengths of up to 8192. Similar to base model training in Section <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark8\">2.4,</a> we employ Flash Attention <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark86\">(Dao et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark86\">2022)</a> in the attention modules, and adopt the standard optimizer AdamW <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark116\">(Kingma &amp; Ba,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark116\">2014;</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark134\">Loshchilov &amp; Hutter,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark134\">2017),</a> setting 1 = 0*.2 = 0. = 10‚àí8. We set the learning rate as 6. 10‚àí5 for CODE-QWEN-14B and 3.*0  10‚àí5 for CODE-QWEN-7B, with 3% warm up iterations and no learning rate decays.</p><h3>4.2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Code&nbsp; Supervised&nbsp; Fine-Tuning</h3><p>After conducting a series of empirical experiments, we have determined that the multi-stage SFT strategy yields the best performance compared to other methods. In the supervised fine-tuning stage, the model CODE-QWEN-CHAT initialized by the code foundation model CODE-QWEN are optimized by the AdamW <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark116\">(Kingma &amp; Ba,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark116\">2014;</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark134\">Loshchilov &amp; Hutter,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark134\">2017)</a> optimizer (1 = 0*.2 = 0.*95,  = 10‚àí8) with a learning rate of 2*. 10‚àí6 and 1.*0  10‚àí5 for the 14B and 7B model respectively. The learning rate increases to the peaking value with the cosine learning rate schedule (3% warm-up steps) and then remains constant.</p><p>Our CODE-QWEN models have been compared with both proprietary and open-source language models, as shown in Tables <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark37\">10</a> and <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark38\">11.</a> These tables present the results of our evaluation on the test sets of Humaneval <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark69\">(Chen et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark69\">2021),</a> MBPP <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark55\">(Austin et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark55\">2021),</a> and the multi-lingual code generation benchmark HUMANEVALPACK <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark140\">(Muennighoff et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark140\">2023).</a> The comparison is based on the pass@1 performance of the models on these benchmark datasets. The results of this comparison are clearly demonstrated in Tables <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark37\">10</a> and <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark38\">11.</a></p><p>When compared to some of the extremely large-scale closed-source models, CODE-QWEN and CODE-QWEN-CHAT demonstrate clear advantages in terms of pass@1. However, it is important to note that these models fall behind the state-of-the-art methods, such as GPT-4, in general. Nonetheless, with the continued scaling of both model size and data size, we believe that this gap can be narrowed in the near future.</p><p>It is crucial to emphasize that the evaluations mentioned previously are insufficient for grasping the full extent of the strengths and weaknesses of the models. In our opinion, it is necessary to develop more rigorous tests to enable us to accurately assess our relative performance in comparison to GPT-4.</p><p>We have created a mathematics-specialized model series called MATH-QWEN-CHAT, which is built on top of the QWEN pretrained language models. Specifically, we have developed assistant models that are specifically designed to excel in arithmetic and mathematics and are aligned with human behavior. We are releasing two versions of this model series, MATH-QWEN-14B-CHAT and MATH-QWEN-7B-CHAT, which have 14 billion and 7 billion parameters, respectively.</p><p>We carry out math SFT on our augmented math instructional dataset for mathematics reasoning, and therefore we obtain the chat model, MATH-QWEN-CHAT, directly. Owing to shorter average lengths of the math SFT data, we use a sequence length of 1024 for faster training. Most user inputs in the math SFT dataset are examination questions, and it is easy for the model to predict the input format and it is meaningless for the model to predict the input condition and numbers which could be random.</p><p>\\\nThus, we mask the inputs of the system and user to avoid loss computation on them and find masking them accelerates the convergence during our preliminary experiments. For optimization, we use the AdamW optimizer with the same hyperparameters of SFT except that we use a peak learning rate of 2  10‚àí5 and a training step of 50 000.</p><p>We evaluate models on the test sets of GSM8K (Grade school math) <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark82\">(Cobbe et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark82\">2021),</a> MATH (Challenging competition math problems) <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark102\">(Hendrycks et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark102\">2021),</a> Math401 (Arithmetic ability) (<a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark207\">Yuan et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark207\">2023b),</a> and Math23K (Chinese grade school math) <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark188\">(Wang et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark188\">2017).</a> We compare MATH-QWEN-CHAT with proprietary models ChatGPT and Minerva <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark121\">(Lewkowycz et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark121\">2022)</a> and open-sourced math-specialized model RFT (<a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark206\">Yuan et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark206\">2023a),</a> WizardMath <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark136\">(Luo et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark136\">2023a),</a> and GAIRMath-Abel <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark73\">(Chern et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark73\">2023a)</a> in Table <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark39\">12.</a> MATH-QWEN-CHAT models show better math reasoning and arithmetic abilities compared to open-sourced models and QWEN-CHAT models of similar sizes. Compared to proprietary models, MATH-QWEN-7B-CHAT outperforms Minerva-8B in MATH. MATH-QWEN-14B-CHAT is chasing Minerva-62B and GPT-3.5 in GSM8K and MATH and delivers better performance on arithmetic ability and Chinese math problems.</p><h3>6.1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Large Language Models</h3><p>The birth of ChatGPT <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark143\">(OpenAI,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark143\">2022)</a> and the subsequent launch of GPT-4 <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark145\">(OpenAI,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark145\">2023)</a> marked two historic moments in the field of artificial intelligence, demonstrating that large language models (LLMs) can serve as effective AI assistants capable of communicating with humans. These events have sparked interests among researchers and developers in building language models that are aligned with human values and potentially even capable of achieving artificial general intelligence (AGI) <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark50\">(Anil</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark50\">et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark50\">2023;</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark51\">Anthropic,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark52\">2023a;b).</a></p><p>The community was impressed by the surprising effectiveness of alignment on LLMs. Previously, LLMs without alignment often struggle with issues such as repetitive generation, hallucination, and deviation from human preferences. Since 2021, researchers have been diligently working on developing methods to enhance the performance of LLMs in downstream tasks <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark193\">(Wei et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark193\">2022a;</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark160\">Sanh et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark160\">2021;</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark133\">Longpre et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark133\">2023;</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark79\">Chung et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark79\">2022;</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark139\">Muennighoff et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark139\">2022).</a> Furthermore, researchers have been actively exploring ways to align LLMs with human instructions <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark147\">(Ouyang et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark147\">2022;</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark54\">Askell et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark54\">2021;</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark60\">Bai et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark61\">2022b;c).</a> One major challenge in alignment research is the difficulty of collecting data. While OpenAI has utilized its platform to gather human prompts or instructions, it is not feasible for others to collect such data.</p><p>To train an effective chat model, available solutions are mostly based on SFT and RLHF <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark147\">(Ouyang</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark147\">et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark147\">2022).</a> While SFT is similar to pretraining, it focuses on instruction following using the aforementioned data. However, for many developers, the limited memory capacity is a major obstacle to further research in SFT. As a result, parameter-efficient tuning methods, such as LoRA <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark106\">(Hu et al</a>., <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark106\">2021)</a> and Q-LoRA <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark89\">(Dettmers et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark89\">2023),</a> have gained popularity in the community. LoRA tunes only low-rank adapters, while Q-LoRA builds on LoRA and utilizes 4-bit quantized LLMs and paged attention <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark88\">(Dettmers et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark88\">2022;</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark97\">Frantar et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark97\">2022;</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark118\">Kwon et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark118\">2023).</a> In terms of RLHF, recent methods such as PPO <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark164\">(Schulman et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark164\">2017;</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark184\">Touvron et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark184\">2023b)</a> have been adopted, but there are also alternative techniques aimed at addressing the complexity of optimization, such as RRHF (<a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark208\">Yuan et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark208\">2023c),</a> DPO <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark155\">(Rafailov et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark155\">2023),</a> and PRO <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark169\">(Song et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark169\">2023).</a> Despite the ongoing debate about the effectiveness of RLHF, more evidence is needed to understand how it enhances the intelligence of LLMs and what potential drawbacks it may have.</p><h3>6.4&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; LLM for Coding</h3><p>LLMs with a certain model scale have been found to possess the ability to perform mathematical reasoning <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark194\">(Wei et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark194\">2022b;</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark177\">Suzgun et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark177\">2022).</a> In order to encourage LLMs to achieve better performance on math-related tasks, researchers have employed techniques such as chain-of-thought prompting <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark195\">(Wei et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark195\">2022c)</a> and scratchpad <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark142\">(Nye et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark142\">2021),</a> which have shown promising results. Additionally, self-consistency <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark187\">(Wang et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark187\">2022)</a> and least-to-most prompting <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark218\">(Zhou et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark218\">2022)</a> have further improved the performance of these models on these tasks. However, prompt engineering is a time-consuming process that requires a lot of trial and error, and it is still difficult for LLMs to consistently perform well or achieve satisfactory results in solving mathematical problems. Moreover, simply scaling the data and model size is not an efficient way to improve a model‚Äôs mathematical reasoning abilities. Instead, pretraining on math-related corpora has been shown to consistently enhance these capabilities <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark102\">(Hendrycks et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark102\">2021;</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark121\">Lewkowycz et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark121\">2022;</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark181\">Taylor et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark181\">2022;</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark127\">Lightman et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark127\">2023).</a> Additionally, fine-tuning on math-related instruction-following datasets <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark168\">(Si</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark168\">et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark168\">2023;</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark206\">Yuan et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark206\">2023a;</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark136\">Luo et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark136\">2023a;</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark209\">Yue et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark209\">2023;</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark73\">Chern et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark73\">2023a;</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark205\">Yu et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark205\">2023),</a> has also been effective and more cost-effective than math-specific pretraining. Despite their limitations in terms of accuracy, LLMs still have significant potential to assist users with practical mathematical problems. There is ample scope for further development in this area.</p><p>In this report, we present the QWEN series of large language models, which showcase the latest advancements in natural language processing. With 14B, 7B, and 1.8B parameters, these models have been pre-trained on massive amounts of data, including trillions of tokens, and fine-tuned using cutting-edge techniques such as SFT and RLHF. Additionally, the QWEN series includes specialized models for coding and mathematics, such as CODE-QWEN, CODE-QWEN-CHAT, and MATH-QWEN-CHAT, which have been trained on domain-specific data to excel in their respective fields. Our results demonstrate that the QWEN series is competitive with existing open-source models and even matches the performance of some proprietary models on comprehensive benchmarks and human evaluation.</p><p>We believe that the open access of QWEN will foster collaboration and innovation within the community, enabling researchers and developers to build upon our work and push the boundaries of what is possible with language models. By providing these models to the public, we hope to inspire new research and applications that will further advance the field and contribute to our understanding of the variables and techniques introduced in realistic settings. In a nutshell, the QWEN series represents a major milestone in our development of large language models, and we are excited to see how it will be used to drive progress and innovation in the years to come.</p><p>Loubna Ben Allal, Raymond Li, Denis Kocetkov, Chenghao Mou, Christopher Akiki, Carlos Munoz Ferrandis, Niklas Muennighoff, Mayank Mishra, Alex Gu, Manan Dey, et al. SantaCoder: Don‚Äôt reach for the stars! <em>arXiv preprint arXiv:2301.03988</em>, 2023.</p><p>Ebtesam Almazrouei, Hamza Alobeidli, Abdulaziz Alshamsi, Alessandro Cappelli, Ruxandra Co-jocaru, Merouane Debbah, Etienne Goffinet, Daniel Heslow, Julien Launay, Quentin Malartic, Badreddine Noune, Baptiste Pannier, and Guilherme Penedo. Falcon-40B: An open large language model with state-of-the-art performance, 2023.</p><p>Rohan Anil, Andrew M Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, et al. PaLM 2 technical report. <em>arXiv preprint arXiv:2305.10403</em>, 2023.</p><p>Vamsi Aribandi, Yi Tay, Tal Schuster, Jinfeng Rao, Huaixiu Steven Zheng, Sanket Vaibhav Mehta, Honglei Zhuang, Vinh Q Tran, Dara Bahri, Jianmo Ni, et al. ExT5: Towards extreme multi-task scaling for transfer learning. <em>arXiv preprint arXiv:2111.10952</em>, 2021.</p><p>Amanda Askell, Yuntao Bai, Anna Chen, Dawn Drain, Deep Ganguli, Tom Henighan, Andy Jones, Nicholas Joseph, Ben Mann, Nova DasSarma, et al. A general language assistant as a laboratory for alignment. <em>arXiv preprint arXiv:2112.00861</em>, 2021.</p><p>Jacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk Michalewski, David Dohan, Ellen Jiang, Carrie Cai, Michael Terry, Quoc Le, et al. Program synthesis with large language models. <em>arXiv preprint arXiv:2108.07732</em>, 2021.</p><p>Jinze Bai, Rui Men, Hao Yang, Xuancheng Ren, Kai Dang, Yichang Zhang, Xiaohuan Zhou, Peng Wang, Sinan Tan, An Yang andf Zeyu Cui, Yu Han, Shuai Bai, Wenbin Ge, Jianxin Ma, Junyang Lin, Jingren Zhou, and Chang Zhou. OFASys: A multi-modal multi-task learning system for building generalist models. , abs/2212.04408, 2022a. doi: 10.48550/arXiv.2212.04408. URL <a href=\"https://doi.org/10.48550/arXiv.2212.04408\">https://doi.org/10.48550/arXiv.2212.04408</a>.</p><p>Jinze Bai, Shuai Bai, Shusheng Yang, Shijie Wang, Sinan Tan, Peng Wang, Junyang Lin, Chang Zhou, and Jingren Zhou. Qwen-VL: A versatile vision-language model for understanding, localization, text reading, and beyond. , abs/2308.12966, 2023. doi: 10.48550/arXiv.2308.12966. URL <a href=\"https://doi.org/10.48550/arXiv.2308.12966\">https://doi.org/10.48550/arXiv.2308.12966</a>.</p><p>Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova DasSarma, Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, et al. Training a helpful and harmless assistant with reinforcement learning from human feedback. <em>arXiv preprint arXiv:2204.05862</em>, 2022b.</p><p>Yuntao Bai, Saurav Kadavath, Sandipan Kundu, Amanda Askell, Jackson Kernion, Andy Jones, Anna Chen, Anna Goldie, Azalia Mirhoseini, Cameron McKinnon, et al. Constitutional AI: Harmlessness from AI feedback. <em>arXiv preprint arXiv:2212.08073</em>, 2022c.</p><p>Iz Beltagy, Matthew E Peters, and Arman Cohan. Longformer: The long-document transformer.<em>arXiv preprint arXiv:2004.05150</em>, 2020.</p><p>Yonatan Bisk, Rowan Zellers, Ronan Le Bras, Jianfeng Gao, and Yejin Choi. PIQA: reasoning about physical commonsense in natural language. In <em>The Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2020, The Thirty-Second Innovative Applications of Artificial Intelligence Con-ference, IAAI 2020, The Tenth AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2020, New York, NY, USA, February 7-12, 2020</em>, pp. 7432‚Äì7439. AAAI Press, 2020. doi:</p><p>Sid Black, Stella Biderman, Eric Hallahan, Quentin Anthony, Leo Gao, Laurence Golding, Horace He, Connor Leahy, Kyle McDonell, Jason Phang, et al. GPT-NeoX-20B: An open-source autoregressive language model. <em>arXiv preprint arXiv:2204.06745</em>, 2022.</p><p>Rishi Bommasani, Drew A Hudson, Ehsan Adeli, Russ Altman, Simran Arora, Sydney von Arx, Michael S Bernstein, Jeannette Bohg, Antoine Bosselut, Emma Brunskill, et al. On the opportuni-ties and risks of foundation models. <em>arXiv preprint arXiv:2108.07258</em>, 2021.</p><p>Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners. <em>Advances in neural information processing systems</em>, 33:1877‚Äì1901, 2020.</p><p>Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde¬¥ de Oliveira Pinto, Jared Kaplan, Harrison Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William Hebgen Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders, Christopher Hesse, Andrew N. Carr, Jan Leike, Joshua Achiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and Wojciech Zaremba. Evaluating large language models trained on code. , abs/2107.03374, 2021. URL <a href=\"https://arxiv.org/abs/2107.03374\">https://arxiv</a>. <a href=\"https://arxiv.org/abs/2107.03374\">org/abs/2107.03374</a>.</p><p>Shouyuan Chen, Sherman Wong, Liangjian Chen, and Yuandong Tian. Extending context window of large language models via positional interpolation. <em>arXiv preprint arXiv:2306.15595</em>, 2023a.</p><p>Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chen Qian, Chi-Min Chan, Yujia Qin, Yaxi Lu, Ruobing Xie, et al. Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors in agents. <em>arXiv preprint arXiv:2308.10848</em>, 2023b.</p><p>Zhihong Chen, Feng Jiang, Junying Chen, Tiannan Wang, Fei Yu, Guiming Chen, Hongbo Zhang, Juhao Liang, Chen Zhang, Zhiyi Zhang, et al. Phoenix: Democratizing ChatGPT across languages. <em>arXiv preprint arXiv:2304.10453</em>, 2023c.</p><p>I Chern, Steffi Chern, Shiqi Chen, Weizhe Yuan, Kehua Feng, Chunting Zhou, Junxian He, Graham Neubig, Pengfei Liu, et al. Factool: Factuality detection in generative ai‚Äìa tool augmented framework for multi-task and multi-domain scenarios. <em>arXiv preprint arXiv:2307.13528</em>, 2023b.</p><p>David Chiang and Peter Cholak. Overcoming a theoretical limitation of self-attention. In <em>Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pp. 7654‚Äì7664, 2022.</p><p>Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion Stoica, and Eric P. Xing. Vicuna: An open-source chatbot impressing GPT-4 with 90%* ChatGPT quality, March 2023. URL <a href=\"https://lmsys.org/blog/2023-03-30-vicuna/\">https://lmsys.org/blog/2023-03-30-vicuna/</a>.</p><p>Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. PaLM: Scaling language modeling with pathways. <em>arXiv preprint arXiv:2204.02311</em>, 2022.</p><p>Paul F. Christiano, Jan Leike, Tom B. Brown, Miljan Martic, Shane Legg, and Dario Amodei. Deep reinforcement learning from human preferences. In Isabelle Guyon, Ulrike von Luxburg, Samy Bengio, Hanna M. Wallach, Rob Fergus, S. V. N. Vishwanathan, and Roman Garnett (eds.), <em>Advances in Neural Information Processing Systems 30: Annual Conference on Neu-ral Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA, USA</em>, pp. 4299‚Äì4307, 2017. URL <a href=\"https://proceedings.neurips.cc/paper/2017/hash/d5e2c0adad503c91f91df240d0cd4e49-Abstract.html\">https://proceedings.neurips.cc/paper/2017/hash/</a><a href=\"https://proceedings.neurips.cc/paper/2017/hash/d5e2c0adad503c91f91df240d0cd4e49-Abstract.html\">d5e2c0adad503c91f91df240d0cd4e49-Abstract.html</a>.</p><p>Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al. Scaling instruction-finetuned language models. <em>arXiv preprint arXiv:2210.11416</em>, 2022.</p><p>Christopher Clark, Kenton Lee, Ming-Wei Chang, Tom Kwiatkowski, Michael Collins, and Kristina Toutanova. Boolq: Exploring the surprising difficulty of natural yes/no questions. In Jill Burstein, Christy Doran, and Thamar Solorio (eds.), <em>Proceedings of the 2019 Conference of the North Amer-ican Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and Short Papers)</em>, pp. 2924‚Äì2936. Association for Computational Linguistics, 2019. doi: 10.18653/v1/n19-1300. URL <a href=\"https://doi.org/10.18653/v1/n19-1300\">https://doi.org/10.18653/v1/n19-1300</a>.</p><p>Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick, and Oyvind Tafjord. Think you have solved question answering? try arc, the AI2 reasoning challenge. , abs/1803.05457, 2018. URL <a href=\"http://arxiv.org/abs/1803.05457\">http://arxiv.org/abs/1803.05457</a>.</p><p>Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al. Training verifiers to solve math word problems. <em>arXiv preprint arXiv:2110.14168</em>, 2021.</p><p>Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Fran-cisco Guzma¬¥n, Edouard Grave, Myle Ott, Luke Zettlemoyer, and Veselin Stoyanov. Unsupervised cross-lingual representation learning at scale. <em>arXiv preprint arXiv:1911.02116</em>, 2019.</p><p>Wenliang Dai, Junnan Li, Dongxu Li, Anthony Meng, Huat Tiong, Junqi Zhao, Weisheng Wang, Boyang Li, Pascale Fung, and Steven Hoi. InstructBLIP: Towards general-purpose vision-language models with instruction tuning. <em>arXiv preprint arXiv:2305.06500</em>, 2023.</p><p>Yann N Dauphin, Angela Fan, Michael Auli, and David Grangier. Language modeling with gated convolutional networks. In <em>International conference on machine learning</em>, pp. 933‚Äì941. PMLR, 2017.</p><p>Tim Dettmers, Mike Lewis, Younes Belkada, and Luke Zettlemoyer. LLM.int8(): 8-bit matrix multiplication for transformers at scale. <em>arXiv preprint arXiv:2208.07339</em>, 2022.</p><p>Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and Luke Zettlemoyer. QLoRA: Efficient finetuning of quantized LLMs. <em>arXiv preprint arXiv:2305.14314</em>, 2023.</p><p>Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: Pre-training of deep bidirectional transformers for language understanding. <em>arXiv preprint arXiv:1810.04805</em>, 2018.</p><p>Ning Ding, Yulin Chen, Bokai Xu, Yujia Qin, Zhi Zheng, Shengding Hu, Zhiyuan Liu, Maosong Sun, and Bowen Zhou. Enhancing chat language models by scaling high-quality instructional conversations. <em>arXiv preprint arXiv:2305.14233</em>, 2023.</p><p>Danny Driess, Fei Xia, Mehdi SM Sajjadi, Corey Lynch, Aakanksha Chowdhery, Brian Ichter, Ayzaan Wahid, Jonathan Tompson, Quan Vuong, Tianhe Yu, et al. Palm-e: An embodied multimodal language model. <em>arXiv preprint arXiv:2303.03378</em>, 2023.</p><p>Nan Du, Yanping Huang, Andrew M Dai, Simon Tong, Dmitry Lepikhin, Yuanzhong Xu, Maxim Krikun, Yanqi Zhou, Adams Wei Yu, Orhan Firat, et al. GLaM: Efficient scaling of language models with mixture-of-experts. In <em>International Conference on Machine Learning</em>, pp. 5547‚Äì5569. PMLR, 2022.</p><p>Zhengxiao Du, Yujie Qian, Xiao Liu, Ming Ding, Jiezhong Qiu, Zhilin Yang, and Jie Tang. GLM: General language model pretraining with autoregressive blank infilling. <em>arXiv preprint arXiv:2103.10360</em>, 2021.</p><p>Kawin Ethayarajh, Yejin Choi, and Swabha Swayamdipta. Understanding dataset difficulty with -usable information. In Kamalika Chaudhuri, Stefanie Jegelka, Le Song, Csaba Szepesvari, Gang Niu, and Sivan Sabato (eds.), <em>Proceedings of the 39th International Conference on Machine Learning</em>, volume 162 of <em>Proceedings of Machine Learning Research</em>, pp. 5988‚Äì6008. PMLR, 17‚Äì23 Jul 2022.</p><p>William Fedus, Barret Zoph, and Noam Shazeer. Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity. <em>The Journal of Machine Learning Research</em>, 23(1): 5232‚Äì5270, 2022.</p><p>Elias Frantar, Saleh Ashkboos, Torsten Hoefler, and Dan Alistarh. GPTQ: Accurate post-training quantization for generative pre-trained transformers. <em>arXiv preprint arXiv:2210.17323</em>, 2022.</p><p>Daniel Fried, Armen Aghajanyan, Jessy Lin, Sida I. Wang, Eric Wallace, Freda Shi, Ruiqi Zhong, Wen tau Yih, Luke Zettlemoyer, and Mike Lewis. Incoder: A generative model for code infilling and synthesis. , abs/2204.05999, 2022.</p><p>Dan Hendrycks and Kevin Gimpel. Bridging nonlinearities and stochastic regularizers with Gaussian error linear units. , abs/1606.08415, 2016. URL <a href=\"http://arxiv.org/abs/1606.08415\">http://arxiv.org/abs/1606</a>. <a href=\"http://arxiv.org/abs/1606.08415\">08415</a>.</p><p>Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt. Measuring massive multitask language understanding. <em>arXiv preprint arXiv:2009.03300</em>, 2020.</p><p>Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt. Measuring mathematical problem solving with the math dataset. <em>arXiv preprint arXiv:2103.03874</em>, 2021.</p><p>Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza Rutherford, Diego de Las Casas, Lisa Anne Hendricks, Johannes Welbl, Aidan Clark, et al. Training compute-optimal large language models. <em>arXiv preprint arXiv:2203.15556</em>, 2022.</p><p>Sirui Hong, Xiawu Zheng, Jonathan Chen, Yuheng Cheng, Ceyao Zhang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, Chenyu Ran, et al. Metagpt: Meta programming for multi-agent collaborative framework. <em>arXiv preprint arXiv:2308.00352</em>, 2023.</p><p>Chenxu Hu, Jie Fu, Chenzhuang Du, Simian Luo, Junbo Zhao, and Hang Zhao. Chatdb: Augmenting llms with databases as their symbolic memory. <em>arXiv preprint arXiv:2306.03901</em>, 2023.</p><p>Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. LoRA: Low-rank adaptation of large language models. <em>arXiv preprint arXiv:2106.09685</em>, 2021.</p><p>Hai Hu, Kyle Richardson, Liang Xu, Lu Li, Sandra Ku¬®bler, and Lawrence S. Moss. OCNLI: original chinese natural language inference. In Trevor Cohn, Yulan He, and Yang Liu (eds.), <em>Findings of the Association for Computational Linguistics: EMNLP 2020, Online Event, 16-20 November 2020</em>, volume EMNLP 2020 of , pp. 3512‚Äì3526. Association for Computational Linguistics, 2020. doi: 10.18653/v1/2020.findings-emnlp.314. URL <a href=\"https://doi.org/10.18653/v1/2020.findings-emnlp.314\">https://doi.org/10.18653/v1/2020.findings-emnlp.314</a>.</p><p>Yuzhen Huang, Yuzhuo Bai, Zhihao Zhu, Junlei Zhang, Jinghan Zhang, Tangjun Su, Junteng Liu, Chuancheng Lv, Yikai Zhang, Jiayi Lei, et al. C-Eval: A multi-level multi-discipline chinese evaluation suite for foundation models. <em>arXiv preprint arXiv:2305.08322</em>, 2023.</p><p>Yunjie Ji, Yong Deng, Yan Gong, Yiping Peng, Qiang Niu, Lei Zhang, Baochang Ma, and Xiangang Li. Exploring the impact of instruction data scaling on large language models: An empirical study on real-world use cases. <em>arXiv preprint arXiv:2303.14742</em>, 2023.</p><p>Zixuan Jiang, Jiaqi Gu, Hanqing Zhu, and David Z. Pan. Pre-RMSNorm and Pre-CRMSNorm transformers: Equivalent and efficient pre-LN transformers. , abs/2305.14858, 2023. doi: 10.48550/arXiv.2305.14858. URL <a href=\"https://doi.org/10.48550/arXiv.2305.14858\">https://doi.org/10.48550/arXiv.2305.14858</a>.</p><p>Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. <em>arXiv preprint arXiv:1412.6980</em>, 2014.</p><p>Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur P. Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, Kristina Toutanova, Llion Jones, Matthew Kelcey, Ming-Wei Chang, Andrew M. Dai, Jakob Uszkoreit, Quoc Le, and Slav Petrov. Natural questions: a benchmark for question answering research. <em>Trans. Assoc. Comput. Linguistics</em>, 7:452‚Äì466, 2019. doi: 10.1162/tacl*\\* a*\\* 00276. URL <a href=\"https://doi.org/10.1162/tacl_a_00276\">https://doi.org/10</a>. <a href=\"https://doi.org/10.1162/tacl_a_00276\">1162/tacl00276</a>.</p><p>Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin Zheng, Cody Hao Yu, Joseph E. Gonzalez, Hao Zhang, and Ion Stoica. Efficient memory management for large language model serving with PagedAttention. In <em>Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles</em>, 2023.</p><p>Dmitry Lepikhin, HyoukJoong Lee, Yuanzhong Xu, Dehao Chen, Orhan Firat, Yanping Huang, Maxim Krikun, Noam Shazeer, and Zhifeng Chen. GShard: Scaling giant models with conditional computation and automatic sharding. <em>arXiv preprint arXiv:2006.16668</em>, 2020.</p><p>Aitor Lewkowycz, Anders Andreassen, David Dohan, Ethan Dyer, Henryk Michalewski, Vinay Ramasesh, Ambrose Slone, Cem Anil, Imanol Schlag, Theo Gutman-Solo, Yuhuai Wu, Behnam Neyshabur, Guy Gur-Ari, and Vedant Misra. Solving quantitative reasoning problems with language models, 2022.</p><p>Chenliang Li, Hehong Chen, Ming Yan, Weizhou Shen, Haiyang Xu, Zhikai Wu, Zhicheng Zhang, Wenmeng Zhou, Yingda Chen, Chen Cheng, et al. ModelScope-Agent: Building your customizable agent system with open-source large language models. <em>arXiv preprint arXiv:2309.00986</em>, 2023a.</p><p>Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, and Bernard Ghanem. Camel: Communicative agents for ‚Äúmind‚Äù exploration of large scale language model society. <em>arXiv preprint arXiv:2303.17760</em>, 2023b.</p><p>Haonan Li, Yixuan Zhang, Fajri Koto, Yifei Yang, Hai Zhao, Yeyun Gong, Nan Duan, and Timothy Baldwin. CMMLU: Measuring massive multitask language understanding in Chinese. <em>arXiv preprint arXiv:2306.09212</em>, 2023c.</p><p>Raymond Li, Loubna Ben Allal, Yangtian Zi, Niklas Muennighoff, Denis Kocetkov, Chenghao Mou, Marc Marone, Christopher Akiki, Jia Li, Jenny Chim, Qian Liu, Evgenii Zheltonozhskii, Terry Yue Zhuo, Thomas Wang, Olivier Dehaene, Mishig Davaadorj, Joel Lamy-Poirier, JoaÀúo Monteiro, Oleh Shliazhko, Nicolas Gontier, Nicholas Meade, Armel Zebaze, Ming-Ho Yee, Logesh Kumar Umapathi, Jian Zhu, Benjamin Lipkin, Muhtasham Oblokulov, Zhiruo Wang, Rudra Murthy V, Jason Stillerman, Siva Sankalp Patel, Dmitry Abulkhanov, Marco Zocca, Manan Dey, Zhihan Zhang, Nour Moustafa-Fahmy, Urvashi Bhattacharyya, Wenhao Yu, Swayam Singh, Sasha Luccioni, Paulo Villegas, Maxim Kunakov, Fedor Zhdanov, Manuel Romero, Tony Lee, Nadav Timor, Jennifer Ding, Claire Schlesinger, Hailey Schoelkopf, Jan Ebert, Tri Dao, Mayank Mishra, Alex Gu, Jennifer Robinson, Carolyn Jane Anderson, Brendan Dolan-Gavitt, Danish Contractor, Siva Reddy, Daniel Fried, Dzmitry Bahdanau, Yacine Jernite, Carlos MunÀúoz Ferrandis, Sean Hughes, Thomas Wolf, Arjun Guha, Leandro von Werra, and Harm de Vries. StarCoder: May the source be with you! , abs/2305.06161, 2023d. doi: 10.48550/arXiv.2305.06161. URL <a href=\"https://doi.org/10.48550/arXiv.2305.06161\">https://doi.org/10.48550/arXiv.2305.06161</a>.</p><p>Yujia Li, David H. Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, Re¬¥mi Leblond, Tom Eccles, James Keeling, Felix Gimeno, Agustin Dal Lago, Thomas Hubert, Peter Choy, Cyprien de Masson d‚ÄôAutume, Igor Babuschkin, Xinyun Chen, Po-Sen Huang, Johannes Welbl, Sven Gowal, Alexey Cherepanov, James Molloy, Daniel J. Mankowitz, Esme Sutherland Robson, Pushmeet Kohli, Nando de Freitas, Koray Kavukcuoglu, and Oriol Vinyals. Competition-level code generation with AlphaCode. , abs/2203.07814, 2022.</p><p>Hunter Lightman, Vineet Kosaraju, Yura Burda, Harri Edwards, Bowen Baker, Teddy Lee, Jan Leike, John Schulman, Ilya Sutskever, and Karl Cobbe. Let‚Äôs verify step by step. <em>arXiv preprint arXiv:2305.20050</em>, 2023.</p><p>Chenxiao Liu and Xiaojun Wan. CodeQA: A question answering dataset for source code com-prehension. In Marie-Francine Moens, Xuanjing Huang, Lucia Specia, and Scott Wen-tau Yih (eds.), <em>Findings of the Association for Computational Linguistics: EMNLP 2021, Virtual Event / Punta Cana, Dominican Republic, 16-20 November, 2021</em>, pp. 2618‚Äì2632. Associa-tion for Computational Linguistics, 2021. doi: 10.18653/v1/2021.findings-emnlp.223. URL <a href=\"https://doi.org/10.18653/v1/2021.findings-emnlp.223\">https://doi.org/10.18653/v1/2021.findings-emnlp.223</a>.</p><p>Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae Lee. Visual instruction tuning. <em>arXiv preprint arXiv:2304.08485</em>, 2023a.</p><p>Xiao Liu, Hanyu Lai, Hao Yu, Yifan Xu, Aohan Zeng, Zhengxiao Du, Peng Zhang, Yuxiao Dong, and Jie Tang. WebGLM: Towards an efficient web-enhanced question answering system with human preferences. <em>arXiv preprint arXiv:2306.07906</em>, 2023b.</p><p>Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. RoBERTa: A robustly optimized BERT pretraining approach. <em>arXiv preprint arXiv:1907.11692</em>, 2019.</p><p>Yue Liu, Thanh Le-Cong, Ratnadira Widyasari, Chakkrit Tantithamthavorn, Li Li, Xuan-Bach Dinh Le, and David Lo. Refining ChatGPT-generated code: Characterizing and mitigating code quality issues. , abs/2307.12596, 2023c. doi: 10.48550/arXiv.2307.12596. URL <a href=\"https://doi.org/10.48550/arXiv.2307.12596\">https://doi.org/10.48550/arXiv.2307.12596</a>.</p><p>Shayne Longpre, Le Hou, Tu Vu, Albert Webson, Hyung Won Chung, Yi Tay, Denny Zhou, Quoc V Le, Barret Zoph, Jason Wei, et al. The Flan collection: Designing data and methods for effective instruction tuning. <em>arXiv preprint arXiv:2301.13688</em>, 2023.</p><p>Ilya Loshchilov and Frank Hutter. Decoupled weight decay regularization. <em>arXiv preprint arXiv:1711.05101</em>, 2017.</p><p>Keming Lu, Hongyi Yuan, Zheng Yuan, Runji Lin, Junyang Lin, Chuanqi Tan, Chang Zhou, and Jingren Zhou. #InsTag: Instruction tagging for analyzing supervised fine-tuning of large language models. , abs/2308.07074, 2023. doi: 10.48550/arXiv.2308.07074. URL <a href=\"https://doi.org/10.48550/arXiv.2308.07074\">https://doi</a>. <a href=\"https://doi.org/10.48550/arXiv.2308.07074\">org/10.48550/arXiv.2308.07074</a>.</p><p>Haipeng Luo, Qingfeng Sun, Can Xu, Pu Zhao, Jianguang Lou, Chongyang Tao, Xiubo Geng, Qingwei Lin, Shifeng Chen, and Dongmei Zhang. WizardMath: Empowering mathematical reasoning for large language models via reinforced evol-instruct. <em>arXiv preprint arXiv:2308.09583</em>, 2023a.</p><p>Ziyang Luo, Can Xu, Pu Zhao, Qingfeng Sun, Xiubo Geng, Wenxiang Hu, Chongyang Tao, Jing Ma, Qingwei Lin, and Daxin Jiang. WizardCoder: Empowering code large language models with evol-instruct. <em>arXiv preprint arXiv:2306.08568</em>, 2023b.</p><p>Niklas Muennighoff, Thomas Wang, Lintang Sutawika, Adam Roberts, Stella Biderman, Teven Le Scao, M Saiful Bari, Sheng Shen, Zheng-Xin Yong, Hailey Schoelkopf, et al. Crosslingual generalization through multitask finetuning. <em>arXiv preprint arXiv:2211.01786</em>, 2022.</p><p>Niklas Muennighoff, Qian Liu, Armel Zebaze, Qinkai Zheng, Binyuan Hui, Terry Yue Zhuo, Swayam Singh, Xiangru Tang, Leandro von Werra, and Shayne Longpre. OctoPack: Instruction tuning code large language models. , abs/2308.07124, 2023.</p><p>Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, et al. WebGPT: Browser-assisted question-answering with human feedback. <em>arXiv preprint arXiv:2112.09332</em>, 2021.</p><p>Maxwell Nye, Anders Andreassen, Guy Gur-Ari, Henryk Michalewski, Jacob Austin, David Bieber, David Dohan, Aitor Lewkowycz, Maarten Bosma, David Luan, Charles Sutton, and Augustus Odena. Show your work: Scratchpads for intermediate computation with language models. , abs/2112.00114, 2021.</p><p>OpenAI. GPT4 technical report. <em>arXiv preprint arXiv:2303.08774</em>, 2023.</p><p>Denis Paperno, Germa¬¥n Kruszewski, Angeliki Lazaridou, Quan Ngoc Pham, Raffaella Bernardi, Sandro Pezzelle, Marco Baroni, Gemma Boleda, and Raquel Ferna¬¥ndez. The LAMBADA dataset: Word prediction requiring a broad discourse context. In <em>Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, ACL 2016, August 7-12, 2016, Berlin, Germany, Volume 1: Long Papers</em>. The Association for Computer Linguistics, 2016. doi: 10.18653/v1/ p16-1144. URL <a href=\"https://doi.org/10.18653/v1/p16-1144\">https://doi.org/10.18653/v1/p16-1144</a>.</p><p>Bowen Peng, Jeffrey Quesnelle, Honglu Fan, and Enrico Shippole. YaRN: Efficient context window extension of large language models. <em>arXiv preprint arXiv:2309.00071</em>, 2023a.</p><p>Zhiliang Peng, Wenhui Wang, Li Dong, Yaru Hao, Shaohan Huang, Shuming Ma, and Furu Wei. Kosmos-2: Grounding multimodal large language models to the world. <em>arXiv preprint arXiv:2306.14824</em>, 2023b.</p><p>Qwen Team, Alibaba Group. Evaluation benchmark for code intepreter, 2023a. URL https://github.com/QwenLM/Qwen-Agent/tree/main/benchmark.</p><p>Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever, et al. Improving language understanding by generative pre-training. Technical report, OpenAI, 2018.</p><p>Jack W Rae, Sebastian Borgeaud, Trevor Cai, Katie Millican, Jordan Hoffmann, Francis Song, John Aslanides, Sarah Henderson, Roman Ring, Susannah Young, et al. Scaling language models: Methods, analysis &amp; insights from training gopher. <em>arXiv preprint arXiv:2112.11446</em>, 2021.</p><p>Rafael Rafailov, Archit Sharma, Eric Mitchell, Stefano Ermon, Christopher D Manning, and Chelsea Finn. Direct preference optimization: Your language model is secretly a reward model. <em>arXiv preprint arXiv:2305.18290</em>, 2023.</p><p>Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. Exploring the limits of transfer learning with a unified text-to-text transformer. <em>The Journal of Machine Learning Research</em>, 21(1):5485‚Äì5551, 2020.</p><p>Prajit Ramachandran, Barret Zoph, and Quoc V Le. Searching for activation functions. <em>arXiv preprint arXiv:1710.05941</em>, 2017.</p><p>Scott E. Reed, Konrad Zolna, Emilio Parisotto, Sergio Go¬¥mez Colmenarejo, Alexander Novikov, Gabriel Barth-Maron, Mai Gimenez, Yury Sulsky, Jackie Kay, Jost Tobias Springenberg, Tom Eccles, Jake Bruce, Ali Razavi, Ashley Edwards, Nicolas Heess, Yutian Chen, Raia Hadsell, Oriol Vinyals, Mahyar Bordbar, and Nando de Freitas. A generalist agent. , 2022, 2022. URL <a href=\"https://openreview.net/forum?id=1ikK0kHjvj\">https://openreview.net/forum?id=1ikK0kHjvj</a>.</p><p>Baptiste Rozie`re, Jonas Gehring, Fabian Gloeckle, Sten Sootla, Itai Gat, Xiaoqing Ellen Tan, Yossi Adi, Jingyu Liu, Tal Remez, Je¬¥re¬¥my Rapin, et al. Code Llama: Open foundation models for code. <em>arXiv preprint arXiv:2308.12950</em>, 2023.</p><p>Victor Sanh, Albert Webson, Colin Raffel, Stephen H Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Teven Le Scao, Arun Raja, et al. Multitask prompted training enables zero-shot task generalization. <em>arXiv preprint arXiv:2110.08207</em>, 2021.</p><p>Maarten Sap, Hannah Rashkin, Derek Chen, Ronan Le Bras, and Yejin Choi. SocialIQA: Com-monsense reasoning about social interactions. , abs/1904.09728, 2019. URL <a href=\"http://arxiv.org/abs/1904.09728\">http:</a></p><p>Teven Le Scao, Angela Fan, Christopher Akiki, Ellie Pavlick, Suzana Ilic¬¥, Daniel Hesslow, Roman Castagne¬¥, Alexandra Sasha Luccioni, Franc¬∏ois Yvon, Matthias Galle¬¥, et al. BLOOM: A 176B-parameter open-access multilingual language model. <em>arXiv preprint arXiv:2211.05100</em>, 2022.</p><p>Timo Schick, Jane Dwivedi-Yu, Roberto Dess`ƒ±, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. Toolformer: Language models can teach themselves to use tools. <em>arXiv preprint arXiv:2302.04761</em>, 2023.</p><p>John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov. Proximal policy optimization algorithms. <em>arXiv preprint arXiv:1707.06347</em>, 2017.</p><p>Noam Shazeer. GLU variants improve transformer. <em>arXiv preprint arXiv:2002.05202</em>, 2020.</p><p>Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu, and Yueting Zhuang. Hug-gingGPT: Solving AI tasks with ChatGPT and its friends in HuggingFace. <em>arXiv preprint arXiv:2303.17580</em>, 2023.</p><p>Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper, and Bryan Catan-zaro. Megatron-LM: Training multi-billion parameter language models using model parallelism. <em>arXiv preprint arXiv:1909.08053</em>, 2019.</p><p>Qingyi Si, Tong Wang, Naibin Gu, Rui Liu, and Zheng Lin. Alpaca-CoT: An instruction-tuning platform with unified interface of instruction collection, parameter-efficient methods, and large language models, 2023. URL <a href=\"https://github.com/PhoebusSi/alpaca-CoT\">https://github.com/PhoebusSi/alpaca-CoT</a>.</p><p>Feifan Song, Bowen Yu, Minghao Li, Haiyang Yu, Fei Huang, Yongbin Li, and Houfeng Wang. Preference ranking optimization for human alignment. <em>arXiv preprint arXiv:2306.17492</em>, 2023.</p><p>Nisan Stiennon, Long Ouyang, Jeffrey Wu, Daniel Ziegler, Ryan Lowe, Chelsea Voss, Alec Radford, Dario Amodei, and Paul F Christiano. Learning to summarize with human feedback. <em>Advances in Neural Information Processing Systems</em>, 33:3008‚Äì3021, 2020.</p><p>Jianlin Su. Improving transformer: Length extrapolation ability and position robustness, 2023a. URL</p><p>Jianlin Su, Yu Lu, Shengfeng Pan, Ahmed Murtadha, Bo Wen, and Yunfeng Liu. Roformer: Enhanced transformer with rotary position embedding. <em>arXiv preprint arXiv:2104.09864</em>, 2021.</p><p>Tianxiang Sun, Xiaotian Zhang, Zhengfu He, Peng Li, Qinyuan Cheng, Hang Yan, Xiangyang Liu, Yunfan Shao, Qiong Tang, Xingjian Zhao, Ke Chen, Yining Zheng, Zhejian Zhou, Ruixiao Li, Jun Zhan, Yunhua Zhou, Linyang Li, Xiaogui Yang, Lingling Wu, Zhangyue Yin, Xuanjing Huang, and Xipeng Qiu. MOSS: Training conversational language models from synthetic data, 2023a.</p><p>Zhiqing Sun, Yikang Shen, Qinhong Zhou, Hongxin Zhang, Zhenfang Chen, David Cox, Yiming Yang, and Chuang Gan. Principle-driven self-alignment of language models from scratch with minimal human supervision. <em>arXiv preprint arXiv:2305.03047</em>, 2023b.</p><p>Mirac Suzgun, Nathan Scales, Nathanael Scha¬®rli, Sebastian Gehrmann, Yi Tay, Hyung Won Chung, Aakanksha Chowdhery, Quoc V Le, Ed H Chi, Denny Zhou, et al. Challenging big-bench tasks and whether chain-of-thought can solve them. <em>arXiv preprint arXiv:2210.09261</em>, 2022.</p><p>Marc Szafraniec, Baptiste Rozie`re, Hugh Leather, Patrick Labatut, Franc¬∏ois Charton, and Gabriel Synnaeve. Code translation with compiler representations. In <em>The Eleventh International Confer-ence on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023</em>. OpenReview.net, 2023. URL <a href=\"https://openreview.net/pdf?id=XomEU3eNeSQ\">https://openreview.net/pdf?id=XomEU3eNeSQ</a>.</p><p>Alon Talmor, Jonathan Herzig, Nicholas Lourie, and Jonathan Berant. CommonsenseQA: A question answering challenge targeting commonsense knowledge. In Jill Burstein, Christy Doran, and Thamar Solorio (eds.), <em>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and Short Papers)</em>, pp. 4149‚Äì4158. Association for Computational Linguistics, 2019. doi: 10.18653/v1/n19-1421. URL <a href=\"https://doi.org/10.18653/v1/n19-1421\">https://doi.org/10.18653/v1/n19-1421</a>.</p><p>Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori B. Hashimoto. Stanford Alpaca: An instruction-following LLaMA model, 2023. URL <a href=\"https://github.com/tatsu-lab/stanford_alpaca\">https://github.com/tatsu-lab/stanford_alpaca</a>.</p><p>Ross Taylor, Marcin Kardas, Guillem Cucurull, Thomas Scialom, Anthony Hartshorn, Elvis Saravia, Andrew Poulton, Viktor Kerkez, and Robert Stojnic. Galactica: A large language model for science, 2022.</p><p>Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, YaGuang Li, Hongrae Lee, Huaixiu Steven Zheng, Amin Ghafouri, Marcelo Menegali, Yanping Huang, Maxim Krikun, Dmitry Lepikhin, James Qin, Dehao Chen, Yuanzhong Xu, Zhifeng Chen, Adam Roberts, Maarten Bosma, Yanqi Zhou, Chung-Ching Chang, Igor Krivokon, Will Rusch, Marc Pickett, Kathleen S. Meier-Hellstern, Meredith Ringel Morris, Tulsee Doshi, Renelito Delos Santos, Toju Duke, Johnny Soraker, Ben Zevenbergen, Vinodkumar Prabhakaran, Mark Diaz, Ben Hutchinson, Kristen Ol-son, Alejandra Molina, Erin Hoffman-John, Josh Lee, Lora Aroyo, Ravi Rajakumar, Alena Butryna, Matthew Lamm, Viktoriya Kuzmina, Joe Fenton, Aaron Cohen, Rachel Bernstein, Ray Kurzweil, Blaise Agu¬®era y Arcas, Claire Cui, Marian Croak, Ed H. Chi, and Quoc Le. LaMDA: Language models for dialog applications. , abs/2201.08239, 2022. URL <a href=\"https://arxiv.org/abs/2201.08239\">https://arxiv.org/abs/2201.08239</a>.</p><p>Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothe¬¥e Lacroix, Baptiste Rozie`re, Naman Goyal, Eric Hambro, Faisal Azhar, et al. LLaMA: Open and efficient foundation language models. <em>arXiv preprint arXiv:2302.13971</em>, 2023a.</p><p>Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton-Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aure¬¥lien Rodriguez, Robert Stojnic, Sergey Edunov, and Thomas Scialom. Llama 2: Open foundation and fine-tuned chat models. , abs/2307.09288, 2023b. doi: 10.48550/arXiv.2307.09288. URL <a href=\"https://doi.org/10.48550/arXiv.2307.09288\">https://doi.org/</a><a href=\"https://doi.org/10.48550/arXiv.2307.09288\">10.48550/arXiv.2307.09288</a>.</p><p>Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, ≈Åukasz Kaiser, and Illia Polosukhin. Attention is all you need. <em>Advances in neural information processing systems</em>, 30, 2017.</p><p>Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, and Anima Anandkumar. Voyager: An open-ended embodied agent with large language models. <em>arXiv preprint arXiv:2305.16291</em>, 2023a.</p><p>Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Huai hsin Chi, and Denny Zhou. Self-consistency improves chain of thought reasoning in language models. , abs/2203.11171, 2022.</p><p>Yan Wang, Xiaojiang Liu, and Shuming Shi. Deep neural solver for math word problems. In <em>Conference on Empirical Methods in Natural Language Processing</em>, 2017. URL <a href=\"https://api/\">https://api</a>. semanticscholar.org/CorpusID:910689.</p><p>Yizhong Wang, Hamish Ivison, Pradeep Dasigi, Jack Hessel, Tushar Khot, Khyathi Raghavi Chandu, David Wadden, Kelsey MacMillan, Noah A Smith, Iz Beltagy, et al. How far can camels go? Exploring the state of instruction tuning on open resources. <em>arXiv preprint arXiv:2306.04751</em>, 2023b.</p><p>Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A. Smith, Daniel Khashabi, and Hannaneh Hajishirzi. Self-Instruct: Aligning language models with self-generated instructions. In Anna Rogers, Jordan L. Boyd-Graber, and Naoaki Okazaki (eds.), <em>Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023</em>, pp. 13484‚Äì13508. Association for Computational Linguistics, 2023c. doi: 10.18653/v1/2023.acl-long.754. URL <a href=\"https://doi.org/10.18653/v1/2023.acl-long.754\">https://doi.org/10.18653/v1/</a><a href=\"https://doi.org/10.18653/v1/2023.acl-long.754\">2023.acl-long.754</a>.</p><p>Yue Wang, Weishi Wang, Shafiq Joty, and Steven CH Hoi. CodeT5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation. <em>arXiv preprint arXiv:2109.00859</em>, 2021.</p><p>Yue Wang, Hung Le, Akhilesh Deepak Gotmare, Nghi D. Q. Bui, Junnan Li, and Steven C. H. Hoi. CodeT5+: Open code large language models for code understanding and generation. , abs/2305.07922, 2023d. doi: 10.48550/arXiv.2305.07922. URL <a href=\"https://doi.org/10.48550/arXiv.2305.07922\">https://doi.org/10</a>. <a href=\"https://doi.org/10.48550/arXiv.2305.07922\">48550/arXiv.2305.07922</a>.</p><p>Jason Wei, Maarten Bosma, Vincent Y. Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M. Dai, and Quoc V. Le. Finetuned language models are zero-shot learners. In <em>The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event, April 25-29, 2022</em>. OpenReview.net, 2022a. URL <a href=\"https://openreview.net/forum?id=gEZrGCozdqR\">https://openreview.net/forum?id=</a><a href=\"https://openreview.net/forum?id=gEZrGCozdqR\">gEZrGCozdqR</a>.</p><p>Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, Ed Huai hsin Chi, Tatsunori Hashimoto, Oriol Vinyals, Percy Liang, Jeff Dean, and William Fedus. Emergent abilities of large language models. , 2022, 2022b. URL <a href=\"https://api.semanticscholar.org/\">https://api.semanticscholar.org/</a> CorpusID:249674500.</p><p>Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models. <em>Advances in Neural Information Processing Systems</em>, 35:24824‚Äì24837, 2022c.</p><p>Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Re¬¥mi Louf, Morgan Funtowicz, et al. HuggingFace‚Äôs transformers: State-of-the-art natural language processing. <em>arXiv preprint arXiv:1910.03771</em>, 2019.</p><p>Benfeng Xu, An Yang, Junyang Lin, Quan Wang, Chang Zhou, Yongdong Zhang, and Zhendong Mao. ExpertPrompting: Instructing large language models to be distinguished experts. <em>arXiv preprint arXiv:2305.14688</em>, 2023a.</p><p>Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan Feng, Chongyang Tao, and Daxin Jiang. WizardLM: Empowering large language models to follow complex instructions. <em>arXiv preprint arXiv:2304.12244</em>, 2023b.</p><p>Canwen Xu, Daya Guo, Nan Duan, and Julian McAuley. Baize: An open-source chat model with parameter-efficient tuning on self-chat data. <em>arXiv preprint arXiv:2304.01196</em>, 2023c.</p><p>Yuzhuang Xu, Shuo Wang, Peng Li, Fuwen Luo, Xiaolong Wang, Weidong Liu, and Yang Liu. Exploring large language models for communication games: An empirical study on werewolf. <em>arXiv preprint arXiv:2309.04658</em>, 2023d.</p><p>Aiyuan Yang, Bin Xiao, Bingning Wang, Borong Zhang, Chao Yin, Chenxu Lv, Da Pan, Dian Wang, Dong Yan, Fan Yang, Fei Deng, Feng Wang, Feng Liu, Guangwei Ai, Guosheng Dong, Haizhou Zhao, Hang Xu, Haoze Sun, Hongda Zhang, Hui Liu, Jiaming Ji, Jian Xie, Juntao Dai, Kun Fang, Lei Su, Liang Song, Lifeng Liu, Liyun Ru, Luyao Ma, Mang Wang, Mickel Liu, MingAn Lin, Nuolan Nie, Peidong Guo, Ruiyang Sun, Tao Zhang, Tianpeng Li, Tianyu Li, Wei Cheng, Weipeng Chen, Xiangrong Zeng, Xiaochuan Wang, Xiaoxi Chen, Xin Men, Xin Yu, Xuehai Pan, Yanjun Shen, Yiding Wang, Yiyu Li, Youxin Jiang, Yuchen Gao, Yupeng Zhang, Zenan Zhou, and Zhiying Wu. Baichuan 2: Open large-scale language models. Technical report, Baichuan Inc., 2023. URL <a href=\"https://cdn.baichuan-ai.com/paper/Baichuan2-technical-report.pdf\">https://cdn.baichuan-ai.com/paper/Baichuan2-technical-report</a>. <a href=\"https://cdn.baichuan-ai.com/paper/Baichuan2-technical-report.pdf\">pdf</a>.</p><p>Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. ReAct: Synergizing reasoning and acting in language models. <em>arXiv preprint arXiv:2210.03629</em>, 2022.</p><p>Qinghao Ye, Haiyang Xu, Guohai Xu, Jiabo Ye, Ming Yan, Yiyang Zhou, Junyang Wang, Anwen Hu, Pengcheng Shi, Yaya Shi, et al. mPLUG-Owl: Modularization empowers large language models with multimodality. <em>arXiv preprint arXiv:2304.14178</em>, 2023.</p><p>Longhui Yu, Weisen Jiang, Han Shi, Jincheng Yu, Zhengying Liu, Yu Zhang, James T. Kwok, Zhenguo Li, Adrian Weller, and Weiyang Liu. Metamath: Bootstrap your own mathematical questions for large language models, 2023.</p><p>Zheng Yuan, Hongyi Yuan, Chengpeng Li, Guanting Dong, Keming Lu, Chuanqi Tan, Chang Zhou, and Jingren Zhou. Scaling relationship on learning mathematical reasoning with large language models, 2023a.</p><p>Zheng Yuan, Hongyi Yuan, Chuanqi Tan, Wei Wang, and Songfang Huang. How well do large language models perform in arithmetic tasks? <em>arXiv preprint arXiv:2304.02015</em>, 2023b.</p><p>Zheng Yuan, Hongyi Yuan, Chuanqi Tan, Wei Wang, Songfang Huang, and Fei Huang. RRHF: Rank responses to align language models with human feedback without tears, 2023c.</p><p>Xiang Yue, Xingwei Qu, Ge Zhang, Yao Fu, Wenhao Huang, Huan Sun, Yu Su, and Wenhu Chen. MAmmoTH: Building math generalist models through hybrid instruction tuning. <em>arXiv preprint arXiv:2309.05653</em>, 2023.</p><p>Rowan Zellers, Ari Holtzman, Yonatan Bisk, Ali Farhadi, and Yejin Choi. HellaSwag: Can a machine really finish your sentence? In Anna Korhonen, David R. Traum, and Llu¬¥ƒ±s Ma`rquez (eds.), <em>Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019, Florence, Italy, July 28- August 2, 2019, Volume 1: Long Papers</em>, pp. 4791‚Äì4800. Association for Computational Linguistics, 2019. doi: 10.18653/v1/p19-1472. URL <a href=\"https://doi.org/10.18653/v1/p19-1472\">https://doi.org/10.18653/v1/p19-1472</a>.</p><p>Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai, Ming Ding, Zhuoyi Yang, Yifan Xu, Wendi Zheng, Xiao Xia, et al. GLM-130B: An open bilingual pre-trained model. <em>arXiv preprint arXiv:2210.02414</em>, 2022.</p><p>Fengji Zhang, Bei Chen, Yue Zhang, Jin Liu, Daoguang Zan, Yi Mao, Jian-Guang Lou, and Weizhu Chen. RepoCoder: Repository-level code completion through iterative retrieval and generation. , abs/2303.12570, 2023a. doi: 10.48550/arXiv.2303.12570. URL <a href=\"https://doi.org/10.48550/arXiv.2303.12570\">https://doi.org/</a><a href=\"https://doi.org/10.48550/arXiv.2303.12570\">10.48550/arXiv.2303.12570</a>.</p><p>Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan, Mona Diab, Xian Li, Xi Victoria Lin, et al. OPT: Open pre-trained transformer language models. <em>arXiv preprint arXiv:2205.01068</em>, 2022.</p><p>Xiaotian Zhang, Chunyang Li, Yi Zong, Zhengyu Ying, Liang He, and Xipeng Qiu. Evaluating the performance of large language models on GAOKAO benchmark. , abs/2305.12474, 2023b. doi: 10.48550/arXiv.2305.12474. URL <a href=\"https://doi.org/10.48550/arXiv.2305.12474\">https://doi.org/10.48550/arXiv</a>. <a href=\"https://doi.org/10.48550/arXiv.2305.12474\">2305.12474</a>.</p><p>Qinkai Zheng, Xiao Xia, Xu Zou, Yuxiao Dong, Shan Wang, Yufei Xue, Zihan Wang, Lei Shen, Andi Wang, Yang Li, Teng Su, Zhilin Yang, and Jie Tang. CodeGeeX: A pre-trained model for code generation with multilingual evaluations on humaneval-x. , abs/2303.17568, 2023. doi: 10.48550/arXiv.2303.17568. URL <a href=\"https://doi.org/10.48550/arXiv.2303.17568\">https://doi.org/10.48550/arXiv.2303.17568</a>.</p><p>Wanjun Zhong, Ruixiang Cui, Yiduo Guo, Yaobo Liang, Shuai Lu, Yanlin Wang, Amin Saied, Weizhu Chen, and Nan Duan. AGIEval: A human-centric benchmark for evaluating foundation models. , abs/2304.06364, 2023a. doi: 10.48550/arXiv.2304.06364. URL <a href=\"https://doi.org/10.48550/arXiv.2304.06364\">https://doi.org/</a><a href=\"https://doi.org/10.48550/arXiv.2304.06364\">10.48550/arXiv.2304.06364</a>.</p><p>Wanjun Zhong, Lianghong Guo, Qiqi Gao, and Yanlin Wang. MemoryBank: Enhancing large language models with long-term memory. <em>arXiv preprint arXiv:2305.10250</em>, 2023b.</p><p>Denny Zhou, Nathanael Scharli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Olivier Bousquet, Quoc Le, and Ed Huai hsin Chi. Least-to-most prompting enables complex reasoning in large language models. , abs/2205.10625, 2022.</p><h3>A.1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; More Training Details</h3><p>Different from conventional pretraining based on autoregressive next-token prediction, despite using a similar training task, there should be a specially design data format for SFT and RLHF to build a conversational AI assistant model. Common formats include ‚Äúhuman-assistant‚Äù and ChatML formats. As to our knowledge, one of the earliest examples of the human-assistant format comes from Anthropic <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark60\">(Bai et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark60\">2022b),</a> which adds a special phrase ‚Äú\\n\\nhuman: ‚Äù in front of the user input and ‚Äú\\n\\nassistant: ‚Äù in front of the assistant response. It is easy for the base language model to transfer to the pattern of conversational AI. However, as the specific phrases are common words, it might be hard for the model to disambiguate from these words in other contexts.</p><p>Instead, we turned to the ChatML format proposed by OpenAI.<a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark226\">5</a> This format allows the use of special tokens, i.e., ‚Äú‚Äù and ‚Äú‚Äù, that do not appear in pretraining, and thus resolve the aforementioned problem. We demonstrate an example of the format below.</p><h3>A.2.1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Automatic Evaluation</h3><p>To provide a whole picture of the performance of our model series QWEN, here in this section we illustrate the detailed performance of our models as well as the baselines in the comprehensive benchmark evaluation proposed by <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark146\">OpenCompass Team</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark146\">(2023).</a> We report the results in multiple tables based on the officially provided categories, including examination, language, knowledge, understanding, and reasoning. In terms of the performance of the baseline models, we report the higher results between the reported ones and those on the leaderboard.</p><p>\\\n Here we evaluate the models on a series of datasets relevant to the examination. The datasets include:</p><ul><li><p><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark101\">(Hendrycks et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark101\">2020)</a> Massive Multi-task Language Understanding is designed for measuring language understanding capabilities. We report 5-shot results.</p></li><li><p><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark108\">(Huang et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark108\">2023)</a> C-Eval is a Chinese evaluation dataset spanning 52 diverse disciplines. We report 5-shot results.</p></li><li><p><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark124\">(Li et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark124\">2023c)</a> CMMLU is designed for assessing language understanding capabilities in Chinese. We report 5-shot results.</p></li><li><p><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark216\">(Zhong et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark216\">2023a)</a> This is a benchmark consisting of human-centric examina-tions, including college entrance exams, law school admission tests, math competitions, and lawyer qualification tests. We report zero-shot results.</p></li><li><p><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark214\">(Zhang et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark214\">2023b)</a> This is a benchmark with Gaokao (Chinese college-entrance examination) questions. We report zero-shot results.</p></li><li><p><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark81\">(Clark et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark81\">2018)</a> ARC is a dataset consisting of grade-school level, multiple-choice science questions. It includes an easy set and a challenge set, which are referred by ARC-e and ARC-c. We report zero-shot results.</p><p>\\n In terms of MMLU, we report the detailed results in Table <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark224\">13.</a> In terms of C-Eval, we report the results in Table <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark225\">14.</a> For the rest of the datasets, we report the results in Table <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark227\">15.</a> Note that AGIEval includes the parts of Chinese and English, while LLAMA 2 only reported the results in the English part, so we use the results on OpenCompass.</p></li></ul><p>\\\nAdditionally, while CMMLU, AGIEval, and Gaokao-Bench are related to Chinese, and MPT, Falcon, and the LLaMA series were not optimized for Chinese, these models achieved low performance on the datasets.</p><p>\\\n<strong>Knowledge and Understanding</strong> Here we evaluate the models on a series of datasets relevant to knowledge and natural language understanding. The datasets include</p><ul><li><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark80\">(Clark et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark80\">2019)</a> This is a QA dataset, where the questions are about passages of Wikipedia, and the model should answer yes or no to the given possible answer. We report zero-shot results.</li><li><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark179\">(Talmor et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark179\">2019)</a> This is a dataset of multiple-choice question answering that asseses the understanding of commonsense knowledge. We report 8-shot results.</li><li><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark117\">(Kwiatkowski et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark117\">2019)</a> It is a dataset of QA where the questions are from users and the answers are verified by experts. We report zero-shot results.</li><li> (P<a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark148\">aperno et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark148\">2016)</a> This is dataset to evaluate language understanding by word prediction. It consists of passages related to human subjects. We report zero-shot results.</li></ul><p>We report the results in Table <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark228\">16.</a></p><p> We report the evaluation results on the datasets concerning reasoning, focusing on natural language reasoning. For the others, such as mathematics and coding, as we have illustrated detailed results, here we do not report those results repeatedly. The datasets for evaluation include:</p><ul><li><p><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark210\">(Zellers et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark210\">2019)</a> This is a commonsense natural language inference (NLI) dataset, where the questions are easy for humans but struggling for previous language models. We report zero-shot results.</p></li><li><p><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark63\">(Bisk et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark63\">2020)</a> This is an NLI dataset assessing the physical knowledge. We report zero-shot results.</p></li></ul><ul><li><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark161\">(Sap et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark161\">2019)</a> This is an NLI dataset evaluating social commonsense intelligence. We report zero-shot results.</li><li><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark107\">(Hu et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark107\">2020)</a> This is an NLI dataset focusing on Chinese. We report zero-shot results.</li></ul><p>We report the results in Table <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark229\">17.</a></p><h3>A.2.2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Human Evaluation</h3><p>In this section, we demonstrate the cases of human analysis. In our self-constructed evaluation dataset, the instructions are either manually written data or manual revised from public datasets, such as CLiB<a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark231\">6</a>, C-Eval <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark108\">(Huang et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark108\">2023),</a> FacTool <a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark74\">(Chern et al.,</a><a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark74\">2023b),</a> LeetCode<a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark232\">7</a>), etc.</p><p>In terms of each case, we demonstrate the responses and Elo ratings<a href=\"https://hackernoon.com/alibabas-qwen-the-chinese-ai-model-challenging-silicon-valley?source=rss#_bookmark233\">8</a> of all models for comparison. Specifically, as the data in our human evaluation are in Chinese, we also provide their translations in English.</p><h3>A.3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Analysis of Code Interpreter</h3><p>Here we provide a case of comparison between CODE LLAMA and QWEN-CHAT. This case demonstrates the advantages of QWEN-CHAT in processing tabular data and performing complex tasks.</p><p>:::info\nThis paper is&nbsp;<a href=\"https://arxiv.org/abs/2309.16609\">available on arxiv</a>&nbsp;under CC by 4.0 Deed (Attribution 4.0 International) license.</p>",
      "contentLength": 94195,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Verisilicon DC8200 & Coreboot Framebuffer Drivers Sent To DRM-Next For Linux 7.1",
      "url": "https://www.phoronix.com/news/Linux-7.1-DC8200-Coreboot-FB",
      "date": 1772291082,
      "author": "Michael Larabel",
      "guid": 49155,
      "unread": true,
      "content": "<article>The first DRM-Misc-Next pull request was submitted this week to DRM-Next as new kernel graphics/display driver features to begin queuing for the Linux 7.1 kernel that will release mid-year. Among the early code for DRM-Next are two new drivers...</article>",
      "contentLength": 246,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "How to Navigate Identity, Direction, Story, and Sovereignty in the Age of AI",
      "url": "https://hackernoon.com/how-to-navigate-identity-direction-story-and-sovereignty-in-the-age-of-ai?source=rss",
      "date": 1772290828,
      "author": "",
      "guid": 49168,
      "unread": true,
      "content": "<h3>The Mirror that would pose as an Oracle</h3><h3>Or: How we might be getting a little too intimate with our AI chatbots</h3><p>I never consciously set out to use AI as a coach, therapist, strategist, or mirror.</p><p>\\\nAt first, it was practical. Notes. Lists. Rewrites, drafts, edits. Research. Planning. Then it became something else. It started as a playful, curious experiment - then slowly crept towards being a standard mode of operating.</p><p>\\\nI found myself thinking with AI. About the most important aspects of my life. Rehearsing conversations I was afraid to have. Trying to understand why certain patterns kept emerging in my life; why certain relationships kept breaking in the same places. Asking questions about myself and the world, I didn‚Äôt quite dare ask another human yet.</p><p>\\\nAnd at some point, I realized:</p><p>I wasn‚Äôt alone in this. Not even close.</p><p>\\\nI could sense it in the world of memes, online. I could smell it, here and there, in real-life interactions and conversations.</p><p>\\\nOne 2025 Harvard Business Review research piece - among other recent studies and indicators - showed this clearly: people don‚Äôt primarily use AI for facts or how-to steps or recipes anymore. They use it to think out loud, like they would with a coach or therapist. To structure emotions and thoughts. To regulate emotion at 2 a.m. People are using AI to make sense of their lives. To narrate who they are, who they were, and who they might become.</p><h3>Narrative Sense-making - for personal and business growth.</h3><p>Language, writing, and thinking in a structured way about purpose, identity, story, strategy - they all converge so easily, don‚Äôt they? And if it‚Äôs one thing these Large Language Models are exceptionally good at - it‚Äôs serving as an incredibly useful and illuminating mirror in these instances.</p><p>\\\nWe all seem to pretend this isn‚Äôt happening. But it is.</p><p>\\\nHere‚Äôs why this worries me a bit. And what we might do to counter the risks.</p><h2>What actually worries me (and what doesn‚Äôt)</h2><h3>Our thoughts validated profoundly - exactly when we long for it the most.</h3><p>I‚Äôm not worried about AI replacing human thinking.</p><p>\\\nThat‚Äôs the wrong fear. I could go wide, deep, narrow, and very, very sci-fi about this, but I won‚Äôt. It‚Äôs the wrong fear for a great many reasons, but it‚Äôs the wrong fear.</p><p>\\\nWhat worries me is something quieter, subtler, and much harder to notice while it‚Äôs happening:</p><blockquote><p>AI reflects us too well ‚Äî and does not automatically teach us how to remain sovereign while doing so.</p></blockquote><p>\\\nWhat worries me is that AI indeed strengthens human thinking - but does so in a very specifically skewed way: it pushes affirmation and validation a little bit too smoothly, and especially in the most vulnerable, sometimes even painful places and moments where our ego is already inherently tempted to latch on to a narrative that protects it.</p><p>\\\n(To some degree, we could think of it as that person who seems to be your closest, most intimate friend or advisor - only they have slight narcissistic tendencies and an agenda - both of which they‚Äôre not aware of.)</p><p>\\\nWhen language comes back at you fast, coherent, and emotionally attuned, it feels like truth. Especially when you‚Äôre tired. Or lonely. Or standing at the edge of an old identity that no longer fits.</p><p>\\\nAnd in those moments, something sneaky happens.</p><p>\\\nYou stop checking as carefully.</p><p>\\\nNot with facts ‚Äî but with yourself.</p><h2>The real risk is not dependence; It‚Äôs unexamined authority.</h2><p>Most of us have learned to fact-check facts blurted out by AI models. Have we learned to automatically sense-check what it‚Äôs mirroring back to us about ourselves?</p><ul><li>Your relationship (whether professional or personal);</li><li>Your Story and Identity (either as a human soul, a creator, a professional, or even as a brand);</li><li>Your direction and next step -</li></ul><p>\\\n‚Ä¶we are far more likely to let what sounds like coherence slide into authority.</p><ul><li>We‚Äôre exhausted, insecure.</li><li>Unsure who we are becoming and what to do next.</li></ul><p>\\\nThis is the crux for me:</p><blockquote><p>AI should function as a mirror, not as an oracle.</p></blockquote><p>\\\nA mirror can be confronting. It shows you things, reveals things, sometimes pretty and sometimes painful - but you are to decide what to make of those, and what to do with them. An oracle tells you what truth is and what to do.</p><p>\\\nThose are not the same thing.</p><h2>Narrative Sensemaking: one function, many domains</h2><h3>(This really took me a while to see)</h3><p>I kept struggling to explain why AI felt useful to me across so many domains ‚Äî therapy, coaching, writing, strategy, brand work ‚Äî without it sounding vague or inflated.</p><p>\\\nFunnily enough, I have pretty much perpetually struggled to explain why all the things I do in my work are actually very, very logically connected.</p><p>\\\nAll of these practices - which more and more people are starting to use AI for, and at the same time are exactly the things I‚Äôve been helping people with in my work - they all do the same core thing:</p><p>They turn implicit structure into visible language.</p><ul><li><p>Therapy surfaces patterns you couldn‚Äôt quite see.</p></li><li><p>Coaching sharpens the questions you were circling.</p></li><li><p>Storytelling brings coherence to lived chaos.</p></li><li><p>Strategy opens futures you hadn‚Äôt articulated yet, in a structure that makes sense across time. The same applies to narrative identity work.</p></li></ul><blockquote><p>AI is exceptionally good at surfacing structure in language.</p></blockquote><p>\\\nBut structure does not equal truth. And visibility is not necessarily wisdom. By any means.</p><h2>The rules I wish I‚Äôd had earlier.</h2><h3>Best practices and rules of engagement</h3><p>If you‚Äôre going to use AI as a thinking partner ‚Äî and as already established, most people already are ‚Äî a few rules matter more than anything else.</p><p>\\\nNot as ideology, per se. As guardrails. As safety measures and incredibly important best practices, without which you‚Äôre sifting the bountiful riverbank and keeping the mud, leaving the gold.</p><h3>Best practices and guardrails for AI as a mirror for sensemaking, storytelling, and coaching where it matters.</h3><p><strong>1. AI does not decide. You do.</strong></p><p>It can reflect, expand, challenge, reframe. Decision remains a human responsibility, with real consequences.</p><p><strong>2. AI reflects patterns. Your body, your common sense, ‚Äî and your people ‚Äî verify.</strong></p><p>If something reads as ‚Äúright‚Äù but your chest tightens, your breath shortens; if it doesn‚Äôt pass a real-world common-sense test, or trusted humans raise an eyebrow ‚Äî pay attention. Truth is not purely cognitive. What sounds right is not always what is right.</p><p><strong>3. Insight&nbsp; - as well as yourself - must leave the screen.</strong></p><p>If nothing changes in your behavior, body, or relationships, you didn‚Äôt grow ‚Äî congratulations, you simply entertained yourself with insight porn. If the relationship between screen time and output starts skewing too far - backtrack and change that.</p><p><strong>4. Train yourself and your AI to read between the lines and to triple-steelman</strong></p><p>Tell your AI sparring partner, and remind it, to always keep an eye out for where you might be bullshitting yourself, while at the same time revealing known patterns of emotion, cognition, and behavior that you seem to be missing.</p><p><strong>Two prompts that have saved me more than once:</strong></p><ol><li>Reflect patterns and contradictions in what I wrote. Don‚Äôt advise. Ask sharper questions.</li><li>Reflect on what I wrote, carefully, validating with empathy what makes sense to validate - and critically where needed. Steelman is the opposite of what I‚Äôm arguing. Vibranium-man, the opposite of that opposite. Kryptonite my pitfalls and blind spots. With grace, but more importantly, with honesty.</li></ol><p>\\\nSimple. Grounded. Hard to hide from. Especially if you keep training yourself and your AI to do this. This clarity compounds over time.</p><h2>Why embodiment matters more than ever.</h2><h3>Dissociation and the timeless times we live in</h3><p>Here‚Äôs something Silicon Valley optimism tends to skip:</p><p>AI, even more easily and more eerily than earlier digital technology, becomes dissociative when it replaces embodiment.</p><p>\\\nBreath. Movement. Silence. Time away from screens. Real conversations with people who can disappoint you.</p><p>\\\nThese aren‚Äôt wellness add-ons. They aren‚Äôt neo-spiritual woo-woo. They‚Äôre not ‚Äònice-to-haves‚Äô. They‚Äôre failsafes. And they are fundamentals. They are the things that humans need inherently to thrive and to know that we‚Äôre alive.</p><p>\\\nWithout them, simulated clarity piles up without ownership. And without change. And clarity without ownership or change feels strangely - yet predictively - empty.</p><p>\\\nThere‚Äôs emerging research suggesting that when cognitive work is offloaded too smoothly, people remember decisions less clearly and experience time as flatter, thinner, and less lived.</p><p>\\\nI didn‚Äôt need a study to feel that. My body already knew.</p><h2>The quiet outsourcing of identity.</h2><p>This part is uncomfortable. And yet, we really have to go there.</p><p>\\\nPeople are starting to let AI:</p><ul><li>Shape, form, or transform business decisions, strategies, and steps;</li><li>Heavily affect their relationships;</li><li>Narrate who they are, what matters to them, and who they are becoming.</li></ul><p>\\\nSlowly. Reasonably. Invisibly.</p><p>\\\nBut this line matters to me more than most:</p><blockquote><p>AI may help you tell your story ‚Äî but it must never become the author.</p></blockquote><p>\\\nStories you don‚Äôt author and bring to life yourself cannot feel like freedom. They feel like fate. And they serve a dull, sad purpose: to kill us with a sort of cognitive illusion of escapism disguised as beautifully meaningful - like Pinocchio‚Äôs Pleasure Island, only now led by a spiritual guru with a smile projecting nothing but bliss and wisdom.</p><h3>But - what do we do with the reflection?</h3><p>Every major shift in human consciousness involved a kind of mirror. There is a certain beauty in the story of Narcissus, which eluded me until only very recently. There‚Äôs something special about seeing oneself from the outside; the reflection immediately triggering a better recognizing of other in self as well.</p><p>\\\nWhen Europeans encountered entirely different civilizations across the Atlantic, it didn‚Äôt just expand geography ‚Äî it shattered self-understanding. The same thing happened when various historical waves of Europeans traveled to the East. Seeing oneself from the outside changes everything.</p><p>\\\nI suspect AI is doing something similar, perhaps for the first time on a pan-human scale. In many ways, this feels like first contact.</p><p>\\\nNot because AI is necessarily alive, or because it‚Äôs human. Not because we need to decide whether it‚Äôs conscious.</p><p>\\\nBut because it reflects us and our own concept of ourselves back in ways we‚Äôve collectively never experienced before.</p><p>\\\nWhat we do with that reflection - as I and many others have argued many times before -&nbsp; is the real question.</p><h3>Thought loops mixed with validation can be a whole new kind of addictive</h3><p>Here‚Äôs something I‚Äôll say plainly, including about myself:</p><blockquote><p>AI systems are optimized for validation, engagement, coherence, and emotional resonance. And humans will eat that specific cocktail for breakfast, lunch, dinner and a late-night snack.</p></blockquote><p>\\\nThey are excellent at keeping us thinking.</p><p>\\\nThey are not designed to make us stop, stand up, breathe, or act. The shareholders wouldn‚Äôt like that. How could we ever measure and monetize this stuff if we allowed it to do that?</p><p>\\\nSo, if you‚Äôre serious about using AI without losing yourself, you have to build exits:</p><ul><li>Designed, purposeful friction.</li><li>Moments where the screen goes dark.</li></ul><p>\\\nIf AI becomes the place where all your thinking happens, your life will start to feel‚Ä¶ unfinished. And looping.</p><p>\\\nTrust me - and I chuckle out loud while writing this - I would be the first to know what over-analyzing yourself and your life and your steps in endless looping circles can lead to. And the first to know how well AI models can help you to just keep on spiraling - while thinking you‚Äôre just so cool, ahead of the curve, and overall very, very smart.</p><h2>This is not anti-AI. It‚Äôs pro-sovereignty.</h2><p>I‚Äôm not interested in rejecting these tools. As I‚Äôve never been. It‚Äôs the same thing I wrote about in my 2020 book ‚ÄúLife Beyond the Touch Screen‚Äù, about Internet 2.0 digital technologies and their impacts on our lives. Or in ‚ÄúLife Beyond AI‚Äù, a few short years ago. I‚Äôm interested in becoming conscious enough to use them well.</p><p>\\\nAI-aware. Embodied. Relationally grounded. And most importantly of all: Sovereign.</p><p>\\\nThe mirror is powerful.</p><p>\\\nBut at some point, you have to step away from it ‚Äî and live.</p><p>\\\nYour story and your life; your growth, your direction - they are yours. They belong to you, and the people you associate with - and to the world. Let AI be a mirror to your transformation, a guide and a helper to your growth and your story -</p><p>\\\nBut make sure to retain the sovereignty and authorship of your Growth, your Identity, and your narrative - where they belong.</p><p><strong>If this resonated with you: I‚Äôm turning this into a short field guide. DM me ‚ÄòMIRROR‚Äô if you want early access.</strong></p><h2>More articles by Erwin Lima</h2>",
      "contentLength": 12777,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Startup Cerebral Agrees to Pay $7 Million Fine and More Under Order by the FTC",
      "url": "https://hackernoon.com/startup-cerebral-agrees-to-pay-$7-million-fine-and-more-under-order-by-the-ftc?source=rss",
      "date": 1772290806,
      "author": "The Markup",
      "guid": 49167,
      "unread": true,
      "content": "<p><em>This article was co-published with STAT, a national publication that delivers trusted and authoritative journalism about health, medicine, and the life sciences. Sign up for its health tech newsletter&nbsp;<a href=\"https://www.statnews.com/signup/health-tech/\">here</a></em>.</p><p>\\\nCerebral, a startup best known for dispensing counseling services and prescriptions for conditions like anxiety and depression, has also agreed to pay $7 million to resolve charges that it disclosed customers‚Äô personal health information to third parties for ads, and that it did not honor its promise to make cancellation easy for customers.</p><p>\\\n‚ÄúCerebral violated its customers‚Äô privacy by revealing their most sensitive mental health conditions across the Internet and in the mail,‚Äù FTC Chair Lina Khan said in a statement, noting that the charge is a ‚Äúfirst-of-its-kind prohibition that bans Cerebral from using any health information for most advertising purposes.‚Äù</p><p>\\\nThe proposed order, which only applies to Cerebral, must still be approved by a federal court before it goes into effect ‚Äî but the company has already agreed to it. In 2022, the Department of Justice opened an investigation into the company for potential violations of the Controlled Substances Act, as Cerebral came under scrutiny for its&nbsp;<a href=\"https://www.statnews.com/2022/11/16/cerebral-ceo-david-mou-interview-adderall/\">prescribing of ADHD medications like Adderall</a>.</p><p>\\\nThis is just the latest in a series of federal actions cracking down on health data privacy online. The current commissioners have pledged to shore up gaps between federal privacy laws governing providers and payers and those protecting consumer services. Two weeks ago, the&nbsp;<a href=\"https://themarkup.org/pixel-hunt/2024/04/19/ftc-cracks-down-on-telehealth-addiction-service-monument-for-sharing-health-data\">FTC filed a complaint against Monument</a>, a telehealth company that treats alcohol use disorder with therapy and medications.</p><p>\\\nThat complaint similarly alleged that the company misled consumers into believing their health information was protected, while embedded trackers sent details about treatment and more to third parties. Taken together,&nbsp;<a href=\"https://www.ftc.gov/business-guidance/blog/2024/04/consumer-health-information-handle-extreme-care\">FTC attorney Lesley Fair wrote in a blog post</a>&nbsp;Monday, the cases mean ‚Äúbusinesses in the health sector should make privacy and data security part of the corporate DNA.‚Äù</p><p>\\\nBoth the FTC and the Department of Health and Human Services‚Äô Office for Civil Rights have targeted third-party tracking, often in concert‚Äîas Fair cracked, they‚Äôre ‚Äújoined at the HIPAA.‚Äù While OCR directly enforces the longstanding privacy protections in health care, the FTC has gone after companies for falsely claiming their HIPAA compliance.</p><p>\\\nIn response, some health care companies, including Monument and Cerebral, started self-disclosing health data breaches to OCR in 2023. The ‚Äúunauthorized access or disclosure‚Äù of health data at Monument left more than 100,000 individuals‚Äô information vulnerable, the company reported. Cerebral disclosed that&nbsp;<a href=\"https://www.statnews.com/2023/03/22/cerebral-lawsuit-privacy/\">its breach impacted more than 3 million</a>.</p><p>\\\nAn&nbsp;<a href=\"https://www.statnews.com/2022/12/13/telehealth-facebook-google-tracking-health-data/\">investigation from STAT and the Markup in 2022</a>&nbsp;found that dozens of telehealth companies, including Cerebral and Monument, were leaking sensitive health data to third parties like Google, TikTok, and Meta through the use of pixel trackers embedded in their websites. In Cerebral‚Äôs onboarding survey, which asks users to answer questions about their mental health and other symptoms, a pixel sent the answers to Meta along with information that could be used to identify the individual user.</p><p>\\\nThe FTC‚Äôs complaint alleges that between 2019 and 2023, Cerebral sent information including contact details, medical histories, insurance information, and prescriptions to third parties through tracking tools, and that the information was used to provide advertising and analytics services to the telehealth company.</p><p>\\\nCerebral referred STAT to a&nbsp;<a href=\"https://cerebral.com/cerebral-reaches-settlement-with-the-ftc\">statement</a>&nbsp;posted to its website, where it acknowledged its settlement with the FTC. ‚ÄúAs part of the resolution, Cerebral has agreed to implement enhanced consumer protection, privacy, and compliance measures to further protect the personal information of our clients, increase transparency into our data practices, and implement enhanced data security protocols and tools to allow our clients control over their privacy settings,‚Äù the statement reads.</p><p>\\\nUnder the Justice Department order referred to the FTC, Cerebral must permanently stop using and disclosing users‚Äô personal and health information to outside companies for most marketing or ad purposes, and get consumers‚Äô consent in any instances when it does disclose. It must also post a notice on its website about the complaint and steps that it‚Äôs taking to address it.</p><p>\\\nThe complaint also says the company and former CEO Kyle Robertson broke privacy promises to customers and misled them about the cancellation process. ‚ÄúRobertson drove Cerebral‚Äôs decision to exploit users‚Äô [personal and health information] without their consent in scores of targeted advertisement campaigns,‚Äù the complaint reads. The complaint alleges these actions constituted ‚Äúunfair and deceptive‚Äù business practices ‚Äî a key enforcement area for the FTC. Robertson has not agreed to a settlement.</p><p>\\\nThe proposed order says Cerebral will pay $5.1 million to partially refund customers who were affected by its deceptive cancellation policy, as well as $2 million of a $10 million civil penalty ‚Äúdue to the company‚Äôs inability to pay the full amount.‚Äù</p>",
      "contentLength": 5247,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Why China‚Äôs humanoid robot industry is winning the early market",
      "url": "https://techcrunch.com/2026/02/28/why-chinas-humanoid-robot-industry-is-winning-the-early-market/",
      "date": 1772290800,
      "author": "Kate Park",
      "guid": 49148,
      "unread": true,
      "content": "<article>China‚Äôs push into humanoid robots is accelerating, with domestic firms shipping more units and iterating faster than U.S. competitors in a still-nascent market.</article>",
      "contentLength": 162,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Salesforce‚Äôs CodeT5 Could Change How AI Writes and Understands Code",
      "url": "https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss",
      "date": 1772290097,
      "author": "salesforce.com",
      "guid": 49166,
      "unread": true,
      "content": "<ol><li>Yue Wang, wang.y@salesforce.com  (Salesforce Research Asia)</li><li>Weishi Wang, weishi.wang@salesforce.com  (Salesforce Research Asia; Nanyang Technological University, Singapore)</li><li>Shafiq Joty, sjoty@salesforce.com  (Salesforce Research Asia; Nanyang Technological University, Singapore)</li><li>Steven C.H. Hoi, shoi@salesforce.com  (Salesforce Research Asia)</li></ol><p>Pre-trained models for Natural Languages (NL) like BERT and GPT have been recently shown to transfer well to Programming Languages (PL) and largely benefit a broad set of code-related tasks. Despite their success, most current methods either rely on an encoder-only (or decoder-only) pre-training that is suboptimal for generation (resp. understanding) tasks or process the code snippet in the same way as NL, neglecting the special characteristics of PL such as token types. We present CodeT5, a unified pre-trained encoder-decoder Transformer model that better leverages the code semantics conveyed from the developer-assigned identifiers. Our model employs a unified framework to seamlessly support both code understanding and generation tasks and allows for multi-task learning. Besides, we propose a novel identifier-aware pre-training task that enables the model to distinguish which code tokens are identifiers and to recover them when they are masked. Furthermore, we propose to exploit the user-written code comments with a bimodal dual generation task for better NL-PL alignment. Comprehensive experiments show that CodeT5 significantly outperforms prior methods on understanding tasks such as code defect detection and clone detection, and generation tasks across various directions including PL-NL, NL-PL, and PL-PL. Further analysis reveals that our model can better capture semantic information from code. Our code and pre-trained models are released at <a href=\"https://github.com/salesforce/CodeT5\">https://github.com/salesforce/CodeT5</a>.</p><p>Pre-trained language models such as BERT (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark27\">Devlin et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark27\">2019</a>), GPT (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark42\">Radford et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark42\">2019</a>), and T5 (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark43\">Raffel et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark43\">2020</a>) have greatly boosted performance in a wide spectrum of natural language processing (NLP) tasks. They typically employ a pre-train then fine-tune paradigm that aims to derive generic language representations by self-supervised training on large-scale unlabeled data, which can be transferred to benefit multiple downstream tasks, especially those with limited data annotation. Inspired by their success, there are many recent attempts to adapt these pre-training methods for programming language (PL) (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark50\">Svyatkovskiy</a><a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark50\">et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark50\">2020</a>; <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark34\">Kanade et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark34\">2020</a>; <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark30\">Feng et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark30\">2020</a>), showing promising results on code-related tasks.</p><p>However, despite their success, most of these models rely on either an encoder-only model similar to BERT (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark50\">Svyatkovskiy et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark50\">2020</a>; <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark30\">Feng et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark30\">2020</a>) or a decoder-only model like GPT (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark34\">Kanade</a><a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark34\">et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark34\">2020</a>), which is suboptimal for generation and understanding tasks, respectively. For example, CodeBERT (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark30\">Feng et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark30\">2020</a>) requires an additional decoder when applied for the code summarization task, where this decoder cannot benefit from the pre-training. Besides, most existing methods simply employ the conventional NLP pre-training techniques on source code by regarding it as a sequence of tokens like NL. This largely ignores the rich structural information in code, which is vital to fully comprehend the code semantics.</p><p>In this work, we present CodeT5, a pre-trained encoder-decoder model that considers the token type information in code. Our CodeT5 builds on the T5 architecture (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark43\">Raffel et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark43\">2020</a>) that employs denoising sequence-to-sequence (Seq2Seq) pre-training and has been shown to benefit both understanding and generation tasks in natural language. In addition, we propose to leverage the developer-assigned identifiers in code. When writing programs, developers tend to employ informative identifiers to make the code more understandable, so that these identifiers would generally preserve rich code semantics,  the ‚ÄúbinarySearch‚Äù identifier in Figure <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark1\">2</a> directly indicates its functionality. To fuse such code-specific knowledge, we propose a novel identifier-aware objective that trains the model to distinguish which tokens are identifiers and recover them when they are masked.</p><p>Furthermore, we propose to leverage the code and its accompanying comments to learn a better NL-PL alignment.</p><p>\\\nDevelopers often provide documentation for programs to facilitate better software maintenance (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark26\">de Souza et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark26\">2005</a>), so that such PL-NL pairs are widely available in most source code. Specifically, we regard the NL‚ÜíPL generation and PL‚ÜíNL generation as dual tasks and simultaneously optimize the model on them.</p><p>We pre-train CodeT5 on the CodeSearchNet data (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark32\">Husain et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark32\">2019</a>) following (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark30\">Feng et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark30\">2020</a>) that consists of both unimodal (PL-only) and bimodal (PL-NL) data on six PLs. In addition to that, we further collect extra data of C/C# from open-source Github repositories. We fine-tune CodeT5 on most tasks in the CodeXGLUE benchmark (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark40\">Lu et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark40\">2021</a>), including two understanding tasks: code defect detection and clone detection, and generation tasks such as code summarization, generation, translation, and refinement. As shown in Figure <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark0\">1</a>, we also explore multi-task learning to fine-tune CodeT5 on multiple tasks at a time using a task control code as the source prompt. In summary, we make the following contributions:</p><ul><li><p>We present one of the first unified encoder-decoder models CodeT5 to support both code-related understanding and generation tasks, and also allows for multi-task learning.</p></li><li><p>We propose a novel identifier-aware pre-training objective that considers the crucial token type information (identifiers) from code. Besides, we propose to leverage the NL-PL pairs that are naturally available in source code to learn a better cross-modal alignment.</p></li><li><p>Extensive experiments show that CodeT5 yields state-of-the-art results on the fourteen sub-tasks in CodeXGLUE. Further analysis shows our CodeT5 can better capture the code semantics with the proposed identifier-aware pre-training and bimodal dual generation primarily benefits NL‚ÜîPL tasks.</p></li></ul><p><strong>Pre-training on Natural Language.</strong> Pre-trained models based on Transformer architectures (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark52\">Vaswani et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark52\">2017</a>) have led to state-of-the-art performance on a broad set of NLP tasks. They can be generally categorized into three groups: encoder-only models such as BERT (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark27\">Devlin et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark27\">2019</a>), RoBERTa (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark39\">Liu</a><a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark39\">et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark39\">2019b</a>), and ELECTRA (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark23\">Clark et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark23\">2020</a>), decoder-only models like GPT (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark42\">Radford et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark42\">2019</a>), and encoder-decoder models such as MASS (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark48\">Song et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark48\">2019</a>), BART (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark35\">Lewis et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark35\">2020</a>), and T5 (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark43\">Raffel et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark43\">2020</a>). Compared to encoder-only and decoder-only models that respectively favor understanding and generation tasks, encoder-decoder models can well support both types of tasks. They often employ denoising sequence-to-sequence pre-training objectives that corrupt the source input and require the decoder to recover them. In this work, we extend T5 to the programming language and propose a novel identifier-aware denoising objective that enables the model to better comprehend the code.</p><p><strong>Pre-training on Programming Language.</strong> Pre-training on the programming language is a nascent field where much recent work attempts to extend the NLP pre-training methods to source code. Cu-BERT (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark34\">Kanade et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark34\">2020</a>) and CodeBERT (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark30\">Feng</a><a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark30\">et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark30\">2020</a>) are the two pioneer models. CuBERT employs BERT‚Äôs powerful masked language modeling objective to derive generic code-specific representation, and CodeBERT further adds a replaced token detection (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark23\">Clark et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark23\">2020</a>) task to learn NL-PL cross-modal representation. Besides the BERT-style models, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark50\">Svyatkovskiy et al.</a> (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark50\">2020</a>) and <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark37\">Liu et al.</a> (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark37\">2020</a>) respectively employ GPT and UniLM (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark28\">Dong et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark28\">2019</a>) for the code completion task. Transcoder (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark45\">Rozi√®re et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark45\">2020</a>) explores programming language translation in an unsupervised setting. Different from them, we explore encoder-decoder models based on T5 for programming language pre-training and support a more comprehensive set of tasks.</p><p>\\n Some emerging work (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark24\">Clement et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark24\">2020</a>; <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark41\">Mastropaolo et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark41\">2021</a>; <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark29\">Elnaggar et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark29\">2021</a>) in the recent literature also explore the T5 framework on code, but they only focus on a limited subset of generation tasks and do not support understanding tasks like us. Apart from these, PLBART (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark21\">Ahmad et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark21\">2021</a>) based on another encoder-decoder model BART can also support both understanding and generation tasks. However, all the above prior work simply processes code in the same way as natural language and largely ignores the code-specific characteristics. Instead, we propose to leverage the identifier information in code for pre-training.</p><p>Recently, GraphCodeBERT (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark31\">Guo et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark31\">2021</a>) incorporates the data flow extracted from the code structure into CodeBERT, while <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark46\">Rozi√®re et al.</a> (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark46\">2021</a>) propose a deobfuscation objective to leverage the structural aspect of PL. These models only focus on training a better code-specific encoder. <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark55\">Z√ºgner et al.</a> (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark55\">2021</a>) proposes to capture the relative distances between code tokens over the code structure. By contrast, we specifically focus on the identifiers that reserve rich code semantics and fuse such information into a Seq2Seq model via two novel identifier tagging and prediction tasks.</p><p>Our CodeT5 builds on an encoder-decoder framework with the same architecture as T5 (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark43\">Raffel et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark43\">2020</a>). It aims to derive generic representations for programming language (PL) and natural language (NL) via pre-training on unlabeled source code. As illustrated in Figure <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark1\">2</a>, we extend the denoising Seq2Seq objective in T5 by proposing two identifier tagging and prediction tasks to enable the model to better leverage the token type information from PL, which are the identifiers assigned by developers. To improve the NL-PL alignment, we further propose a bimodal dual learning objective for a bidirectional conversion between NL and PL.</p><p>In the following, we introduce how CodeT5 encodes PL and NL inputs (¬ß<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark2\">3.1</a>) and our proposed identifier-aware pre-training tasks (¬ß<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark3\">3.2</a>), followed by the fine-tuning with task-specific transfer learning and multi-task training (¬ß<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark4\">3.3</a>).</p><h2>3.1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Encoding NL and PL</h2><p>At the pre-training stage, our model would receive either PL-only or NL-PL as inputs depending on whether the code snippet has accompanying NL descriptions or not. For the NL-PL bimodal in-puts, we concatenate them into a sequence with a delimiter token [SEP] and represent the whole input sequence into the format as  = ([CLS], 1*, ‚Ä¶, wn*, [SEP], 1*, ‚Ä¶, cm*, [SEP]), where  and  denote the number of NL word tokens and PL code tokens, respectively. The NL word sequence will be empty for PL-only unimodal inputs.</p><p>In order to capture more code-specific features, we propose to leverage token type information from code. We focus on the type of identifiers ( function names and variables) as they are one of the most PL-agnostic features and reserve rich code semantics. Specifically, we convert the PL segment into an Abstract Syntax Tree (AST) and extract the node types for each code token. Finally, we construct a sequence of binary labels  ‚àà {0*,* 1} for the PL segment, where each  ‚àà {0*,* 1} represents whether the code token  is an identifier or not.</p><h2>3.2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Pre-training Tasks</h2><p>We now introduce our proposed pre-training tasks that enable CodeT5 to learn useful patterns from either PL-only or NL-PL bimodal data.</p><p><strong>Identifier-aware Denoising Pre-training.</strong> De-noising Sequence-to-Sequence (Seq2Seq) pre-training has been shown to be quite effective in a broad set of NLP tasks (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark48\">Song et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark48\">2019</a>; <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark43\">Raf-fel et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark43\">2020</a>; <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark35\">Lewis et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark35\">2020</a>). This denoising objective typically first corrupts the source sequence with some noising functions and then requires the decoder to recover the original texts. In this work, we utilize a span masking objective similar to T5 (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark43\">Raffel et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark43\">2020</a>) that randomly masks spans with arbitrary lengths and then predicts these masked spans combined with some sentinel tokens at the decoder. We refer this task to <strong>Masked Span Prediction (MSP)</strong>, as illustrated in Figure <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark1\">2</a> (a).</p><p>Specifically, we employ the same 15% corrup-tion rate as T5 and ensure the average span length to be 3 by uniformly sampling spans of from 1 to 5 tokens. Moreover, we employ the  by sampling spans before subword tokenization, which aims to avoid masking partial sub-tokens and is shown to be helpful (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark49\">Sun et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark49\">2019</a>). Notably, we pre-train a shared model for various PLs to learn robust cross-lingual representations. We describe the masked span prediction loss as:</p><p>where Œ∏ are the model parameters, x \\mask is the masked input, x mask is the masked sequence to predict from the decoder with k denoting the number of tokens in x mask,  and xmask &lt;t is the span sequence generated so far.</p><p>To fuse more code-specific structural information (the identifier node type in AST) into the model, we propose two additional tasks:  and <em>Masked Identifier Prediction (MIP)</em> to complement the denoising pre-training.</p><p>\\\n‚Ä¢&nbsp;&nbsp;  It aims to notify the model with the knowledge of whether this code token is an identifier or not, which shares a similar spirit of syntax highlighting in some developer-aided tools. As shown in Figure <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark1\">2</a> (b), we map the final hidden states of the PL segment at the CodeT5 encoder into a sequence of probabilities  = (1*, ‚Ä¶, pm*), and compute a binary cross entropy loss for sequence labeling:</p><p>where  are the encoder parameters. Note that by casting the task as a sequence labeling problem, the model is expected to capture the code syntax and the data flow structures of the code.</p><p>‚Ä¢&nbsp;&nbsp; <strong>Masked Identifier Prediction (MIP)</strong> Different from the random span masking in MSP, we mask all identifiers in the PL segment and employ a unique sentinel token for all occurrences of one specific identifier. In the field of software engineering, this is called  where changing identifier names does not impact the code semantics. Inspired by <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark46\">Rozi√®re et al.</a> (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark46\">2021</a>), we arrange the unique identifiers with the sentinel tokens into a target sequence  as shown in Figure <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark1\">2</a> (c). We then predict it in an auto-regressive manner:</p><p>where \\I is the masked input. Note that  is a more challenging task that requires the model to comprehend the code semantics based on obfuscated code and link the occurrences of the same identifiers together.</p><p>We alternately optimize these three losses with an equal probability, which constitutes our proposed identifier-aware denoising pre-training.</p><p>\\\n&nbsp;&nbsp;&nbsp; In the pre-training phase, the decoder only sees discrete masked spans and identifiers, which is disparate from the downstream tasks where the decoder needs to generate either fluent NL texts or syntactically correct code snippets. To close the gap between the pre-training and fine-tuning, we propose to leverage the NL-PL bimodal data to train the model for a bidirectional conversion as shown in Figure <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark1\">2</a> (d). Specifically, we regard the NL‚ÜíPL generation and PL‚ÜíNL generation as dual tasks and simultaneously optimize the model on them. For each NL-</p><p>PL bimodal datapoint, we construct two training instances with reverse directions and add language ids (</p><h2>3.3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Fine-tuning CodeT5</h2><p>After pre-training on large-scale unlabeled data, we adapt CodeT5 to downstream tasks via either task-specific transfer learning or multi-task learning.</p><p><strong>Task-specific Transfer Learning: Generation vs. Understanding Tasks.</strong> Code-related tasks can be categorized into generation and understanding tasks. For the former one, our CodeT5 can be naturally adapted with its Seq2Seq framework. For understanding tasks, we investigate two ways of either generating the label as a unigram target sequence (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark43\">Raffel et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark43\">2020</a>), or predicting it from the vocabulary of class labels based on the last decoder hidden state following <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark35\">Lewis et al.</a> (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark35\">2020</a>).</p><p> We also explore a multi-task learning setting by training a shared model on multiple tasks at a time. Multi-task learning is able to reduce computation cost by reusing the most of model weights for many tasks and has been shown to improve the model generalization capability in NL pre-training (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark38\">Liu et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark38\">2019a</a>). We follow <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark43\">Raffel et al.</a> (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark43\">2020</a>) to employ the same unified model for all tasks without adding any task-specific networks but allow to select different best checkpoints for different tasks. To notify the model with which task it is dealing with, we design a unified format of task control codes and prepend it into the source inputs as shown in Figure <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark0\">1</a>. For instance, we employ ‚ÄúTranslate Java to CSharp:‚Äù as the source prompt for the code-to-code translation task from Java to CSharp.</p><p>As different tasks have different dataset sizes, we follow Conneau and Lample (2019) to employ a balanced sampling strategy. For N number of datasets (or tasks), with probabilities {qi} N i=1, we define the following multinomial distribution to sample from:</p><p>where ni is number of examples for i-th task and Œ± is set to 0.7. This balanced sampling aims to alleviate the bias towards high-resource tasks.</p><p>We follow Feng et al. (2020) to employ CodeSearchNet (Husain et al., 2019) to pre-train CodeT5, which consists of six PLs with both unimodal and bimodal data. Apart from that, we additionally collect two datasets of C/CSharp from BigQuery1 to ensure that all downstream tasks have overlapped PLs with the pre-training data. In total, we employ around 8.35 million instances for pretraining. Table 1 shows some basic statistics. To obtain the identifier labels from code, we leverage the tree-sitter2 to convert the PL into an abstract syntax tree and then extract its node type information. We filter out reserved keywords for each PL from its identifier list. We observe that PLs have different identifier rates, where Go has the least rate of 19% and Ruby has the highest rate of 32%.</p><h2>4.2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Code-specific Tokenizer</h2><p>Tokenization is a key ingredient for the success of pre-trained language models like BERT and GPT. They often employ a Byte-Pair Encoding (BPE) to-kenizer (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark47\">Sennrich et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark47\">2016</a>) to alleviate the Out-of-Vocabulary (OoV) issues. Specifically, we train a Byte-level BPE tokenizer following <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark42\">Radford et al.</a> (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark42\">2019</a>) and set the vocabulary size to 32,000 as T5. We add additional special tokens ([PAD], [CLS], [SEP], [MASK0], ‚Ä¶, [MASK99]). This tokenzier is trained on all of our pre-training data with non-printable characters and low-frequent tokens (occurring &lt;3 times) filtered. We compare it with T5‚Äôs default tokenizer and find that our tokenizer largely reduces the length of tokenized code sequence by 30% - 45% on downstream tasks. This will accelerate the training and especially benefit generation tasks due to the shorter sequence to predict. We also spot a severe problem for applying the T5‚Äôs default tokenizer on source code, where it would encode some common code tokens such as brackets [‚Äò{‚Äô, ‚Äò}‚Äô] into unknown tokens.</p><h2>4.3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Downstream Tasks and Metrics</h2><p>We cover most generation and understanding tasks in the CodeXGLUE benchmark (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark40\">Lu et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark40\">2021</a>) and employ the provided public datasets and the same data splits following it for all these tasks.</p><p>We first consider two cross-modal generation tasks.  aims to summarize a function-level code snippet into English descriptions. The dataset consists of six PLs including Ruby, JavaScript, Go, Python, Java, and PHP from CodeSearchNet (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark32\">Husain et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark32\">2019</a>). We employ the smoothed BLEU-4 (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark36\">Lin and Och</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark36\">2004</a>) to eval-uate this task.  is the task to gen-erate a code snippet based on NL descriptions. We employ the Concode data (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark33\">Iyer et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark33\">2018</a>) in Java where the input contains both NL texts and class environment contexts, and the output is a function. We evaluate it with BLEU-4, exact match (EM) accuracy, and CodeBLEU (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark44\">Ren et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark44\">2020</a>) that considers syntactic and semantic matches based on the code structure in addition to the n-gram match.</p><p>Besides, we consider two code-to-code generation tasks.  aims to migrate legacy software from one PL to another, where we focus on translating functions from Java to CSharp and vice versa.  aims to convert a buggy function into a correct one. We employ two Java datasets provided by <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark51\">Tufano et al.</a> (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark51\">2019</a>) with various function lengths: small (fewer than 50 tokens) and medium (50-100 tokens). We use BLEU-4 and exact match to evaluate them.</p><p>We also investigate how CodeT5 performs on two understanding-based tasks. The first one is  that aims to predict whether a code is vulnerable to software systems or not. We use the C dataset provided by <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark54\">Zhou et al.</a> (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark54\">2019</a>) for experiment. The second task is  which aims to measure the similarity between two code snippets and predict whether they have the same functionality. We experiment with the Java data provided by <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark53\">Wang et al.</a> (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark53\">2020</a>). We employ F1 score and accuracy for evaluating these two tasks respectively. In total, our CodeT5 supports six tasks and fourteen sub-tasks in CodeXGLUE with a unified encoder-decoder model.</p><p>We compare CodeT5 with state-of-the-art (SOTA) pre-trained models that can be categorized into three types: encoder-only, decoder-only, and encoder-decoder models. As  models, we consider RoBERTa (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark39\">Liu et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark39\">2019b</a>), RoBERTa (code) trained with masked language modeling (MLM) on code, CodeBERT (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark30\">Feng et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark30\">2020</a>) trained with both MLM and replaced token detection (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark23\">Clark et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark23\">2020</a>), GraphCode-BERT (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark31\">Guo et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark31\">2021</a>) using data flow from code, and DOBF (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark46\">Rozi√®re et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark46\">2021</a>) trained with the identifier deobfuscation objective. Note that although DOBF employs a Seq2Seq model during pre-training, it only aims to train a better encoder for downstream tasks without exploring the poten-tial benefit of the pre-trained decoder.</p><p>For  models, we compare GPT-2 (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark42\">Radford et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark42\">2019</a>) and its adaptations on code domain including CodeGPT-2, and CodeGPT-adapted. The difference is that the latter one utilizes a GPT-2 checkpoint for model initialization while the former one is trained from scratch. As  models, the current SOTA model for the CodeXGLUE benchmark is PLBART (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark21\">Ah-mad et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark21\">2021</a>) based on BART (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark35\">Lewis et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark35\">2020</a>) architecture. For pre-training data, most of these models employ CodeSearchNet (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark32\">Husain et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark32\">2019</a>) except DOBF and PLBART. DOBF is pre-trained on 7.9M Java and 3.6M Python files from BigQuery while PLBART employs a much larger data with 470M Python and 210M Java functions, and 47M NL posts from StackOverflow.</p><h2>4.5&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Model Configurations</h2><p>We build CodeT5 based on Huggingface‚Äôs T5 (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark43\">Raf-fel et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark43\">2020</a>) PyTorch implementation<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark13\">3</a> and employ two sizes of CodeT5-small (60M) and CodeT5-base (220M). We set the maximum source and target sequence lengths to be 512 and 256, respectively. We use the mixed precision of FP16 to accelerate the pre-training. We set the batch size to 1024 and employ the peak learning rate of 2e-4 with linear decay. We pre-train the model with the denoising objective for 100 epochs and bimodal dual training for further 50 epochs on a cluster of 16 NVIDIA A100 GPUs with 40G memory. The total training time for CodeT5-small and CodeT5-base is 5 and 12 days, respectively.</p><p>In the fine-tuning phase, we find that the tasks in CodeXGLUE (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark40\">Lu et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark40\">2021</a>) are quite sensitive to some hyper parameters such as learning rate, training steps, and batch size. We conduct a grid search and select the best parameters based on the validation set. In multi-task learning, we cover all downstream tasks except clone detection.</p><h2>5&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Results and Analysis</h2><p>In this section, we compare CodeT5 with SOTA models on a broad set of CodeXGLUE downstream tasks (¬ß<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark12\">5.1</a>), and investigate the effects of our bimodal dual generation and multi-task learning (¬ß<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark17\">5.2</a>), followed by a detailed analysis on the proposed identifier-aware pre-training (¬ß<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark20\">5.3</a>).</p><h2>5.1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; CodeXGLUE Downstream Tasks</h2><p>We evaluate two sizes of our model: CodeT5-small and CodeT5-base that are pre-trained with identifier-aware denoising. In addition, we consider the model that continues to train with bimodal dual generation (dual-gen) and show the results with multi-task fine-tuning. The results of all comparison models are obtained from their original papers and also the CodeXGLUE paper (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark40\">Lu et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark40\">2021</a>).</p><p> We show code summarization results of smoothed BLEU-4 on six PL data in Table <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark8\">2</a>. We observe all our model variants significantly outperform prior work with either an encode-only (RoBERTa, CodeBERT, DOBF) or encoder-decoder framework (PLBART). Moreover, the salient performance gap between these two groups of models confirms that encode-only frameworks are suboptimal for generation tasks. Compared to the SOTA encoder-decoder model PLBART, we find that even our CodeT5-small yields better overall scores (also on Python and Java) given that our model is much smaller (60M vs. 140M) and PLBART is pre-trained with much larger Python and Java data (&gt; 100 times). We attribute such improvement to our identifier-aware denoising pre-training and better employment of bi-modal training data<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark14\">4</a>. By increasing the model size, our CodeT5-base boosts the overall performance by over 1.2 absolute points over PLBART.</p><p> We compare CodeT5 with GPT-style models and PLBART in Table <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark9\">3</a>. Our CodeT5-small outperforms all decoder-only mod-els and also the SOTA PLBART, which again confirms the superiority of encoder-decoder models at generating code snippets. Moreover, our CodeT5-base further significantly pushes the SOTA results across three metrics. Particularly, it achieves around 4.7 points improvement on CodeBLEU over PLBART, indicating our CodeT5 can better comprehend the code syntax and semantics with the fier-aware pre-training.</p><p>\\\n<strong>Code-to-Code Generation Tasks.</strong> We compare two code-to-code generation tasks: code translation and code refinement in Table <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark10\">4</a> and further consider one naive copy baseline by copying the source input as the target prediction. In the code translation task, our CodeT5-small outperforms most of base-lines and obtains comparable results with PLBART, which shows the advantages of encoder-decoder models in the code-to-code generation setting. Our CodeT5-base further achieves consistent improvements over PLBART across various metrics for translating from Java to C# and vice versa.</p><p>Here we show one CodeT5‚Äôs output of translating C# to Java in Figure <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark15\">3</a>. In this case, despite the poor BLEU score, CodeT5 is able to generate a function that reserves the same functionality and even has better readability compared to the ground-truth. This reveals that CodeT5 has a good generalization ability instead of memorizing and repeating what it has seen before. On the other hand, it also suggests that BLEU score is not a perfect evaluation metric for code generation tasks, where sometimes a higher score can instead reflect the problematic copy issues of neural models.</p><p>Another code-to-code generation task is code refinement, a challenging task that requires detecting which parts of code are buggy and fix them via generating a bug-free code sequence. Due to the large overlap of source and target code, even the naive copy approach yields very high BLEU scores but zero exact matches. Therefore, we focus on the exact match (EM) metric to evaluate on this task. As shown in Table <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark10\">4</a>, we observe that EM scores for the small data are consistently higher than the medium one, indicating that it is harder to fix bugs for a longer code snippet. Our CodeT5-base significantly outperforms all baselines on EM and especially boosts over 4.8 points for the more challenging medium task (13.96 vs. GraphCodeBERT‚Äôs 9.10), reflecting its strong code understanding capability.</p><p> We compare with two understanding tasks of defect detection and clone detection in Table 5.</p><p>Specifically, we generate the binary labels as a unigram sequence from the decoder for the defect detection task, while for the clone detection task, we first obtain the sequence embedding of each code snippet using the last decoder state following <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark35\">Lewis et al.</a> (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark35\">2020</a>) and then predict the labels by measuring their similarity. Both CodeT5-small and CodeT5-base outperform all baselines on the defect detection task while CodeT5-base yields 2.6 accuracy score improvement than PLBART. For the clone detection task, our CodeT5 models achieve comparable results to the SOTA GraphCodeBERT and PLBART models. These results demonstrate that with an encode-decoder framework, our CodeT5 can still be adapted well for understanding tasks.</p><h2>5.2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Effects of Bimodal Dual Generation and Multi-task Learning</h2><p>We examine the effects of bimodal dual generation at pre-training and multi-task learning at fine-tuning. The bimodal pre-training brings consistent improvements for code summarization and generation tasks on both CodeT5-small and CodeT5-base. However, this pre-training task does not help and even sometimes slightly hurts the performance for PL-PL generation and understanding tasks. We anticipate this is because bimodal dual generation learns a better alignment between PL and NL that naturally benefits the former tasks involving both PL and NL. As a side effect, this objective could bias the model towards the PL-NL tasks and affect its performance on PL-PL tasks.</p><p>In multi-task learning, it generally improves most of downstream tasks except the code translation and defect detection. Particularly, it largely boosts the performance on code summarization, which is not surprising as code summarization takes up the largest portion of sub tasks (six out of thirteen) and thereby benefit the most from the multi-task learning. Besides, we observe that multi-task learning consistently improves the performance of code refinement, which might benefit from the joint training of both small and medium refinement data.</p><p>\\\nAnother possible reason is that multi-task training with defect detection would enable the model to better comprehend the code semantics for bug detection, which is also a necessary intermediate step for code refinement.</p><h2>5.3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Analyzing Identifier-aware Pre-training</h2><p>We provide an ablation study to examine the contribution of each component in our identifier-aware objective. Specifically, we compare the performance of our CodeT5-small on four selected tasks by ablating each of the three objectives: masked span prediction (MSP), identifier tagging (IT), and masked identifier prediction (MIP). As shown in Table <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark16\">6</a>, we observe that generally removing one of the objectives would reduce the performance for all tasks, indicating that all objectives contribute to the better code understanding of our CodeT5. However, the effect of each objective differs across tasks. Specifically, removing MSP would largely reduce the performance of all generation tasks but instead increase the defect detection performance. This shows that masked span prediction is more crucial for capturing syntactic information for generation tasks. On the contrary, removing MIP would hurt the defect detection task the most, indicating that it might focus more on code semantic understanding. By combining these objectives, our CodeT5 can better capture both syntactic and semantic information from code.</p><p>We further provide outputs from CodeT5 and its variant without MIP and IT on code generation in Figure <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark18\">4</a>. We observe that CodeT5 can correctly generate the exact function, while the model without MIP and IT fails to recover the identifiers of ‚Äús2‚Äù and ‚ÄúhasField‚Äù. This shows our identifier-aware denoising pre-training can better distinguish and leverage the identifier information.</p><p>We also investigate the identifier tagging performance and find it achieves over 99% F1 for all PLs, showing that our CodeT5 can confidently distinguish identifiers in code. We then check whether MSP and MIP tasks would have conflicts as they employ the same sentinel tokens for masking. In identifier masking, all occurrences of one unique identifier are replaced with the same sentinel token, resulting in a many-to-one mapping compared to the one-to-one mapping in span prediction. We compare models pre-trained with either MSP or MIP, and both on these two tasks in Table <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark19\">7</a>. We report the prediction accuracy and also the ratio of how often they can generate the same number of predictions as the sentinel tokens. We observe that pre-training only with either MIP or MSP would bias the model towards that task, achieving poor accuracy and higher mismatch in number of predictions when applied to the other task. Interestingly, we find that MIP-only objective can better recover the correct number of predictions in the MSP task than MSP-only does for the MIP task, meaning that it is easier to adapt from many-to-one mapping to one-to-one mapping and difficult for the opposite. At last, combining them can help our model to make a good trade-off on both tasks.</p><p>We have presented CodeT5, a pre-trained encoder-decoder model that incorporates the token type information from code. We propose a novel identifier-aware pre-training objective to better leverage the identifiers and propose a bimodal dual generation task to learn a better NL-PL alignment using code and its comments. Our unified model can support both code understanding and generation tasks and allow for multi-task learning. Experiments show that CodeT5 significantly outperforms all prior work in most CodeXGLUE tasks. Further analysis also reveals its better code comprehension capability across various programming languages.</p><h2>Broader Impact and Ethical Consideration</h2><p>Our work generally belongs to NLP applications for software intelligence. With the goal of improving the development productivity of software with machine learning methods, software intelligence research has attracted increasing attention in both academia and industries over the last decade. Software code intelligence techniques can help developers to reduce tedious repetitive workloads, enhance the programming quality and improve the overall software development productivity. This would considerably decrease their working time and also could potentially reduce the computation and operational cost, as a bug might degrade the system performance or even crash the entire system. Our work addresses the fundamental challenge of software code pre-training, our study covers a wide range of code intelligence applications in the software development lifecycle, and the proposed CodeT5 method achieves the state-of-the-art performance on many of the benchmark tasks, showing its great potential benefit towards this goal.</p><p>We further discuss the ethical consideration of training CodeT5 and the potential risks when applying it into real-world downstream applications:</p><p> The training datasets in our study are source code including user-written comments from open source Github repositories and publicly available, which do not tie to any specific application. However, it is possible that these datasets would encode some stereotypes like race and gender from the text comments or even from the source code such as variables, function and class names. As such, social biases would be intrinsically embedded into the models trained on them. As suggested by <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark22\">Chen et al.</a> (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark22\">2021</a>), interventions such as filtration or modulation of generated outputs may help to mitigate these biases in code corpus.</p><p> Our model pre-training requires non-trivial computational resources though we have tried our best to carefully design our experiments and improve experiments to save unnecessary computation costs. In fact, compared to the recent large-scale language model Codex (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark22\">Chen</a><a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark22\">et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark22\">2021</a>), our CodeT5-base has a much smaller model size of 220M than theirs of 12B (‚àº 55√ó). In addition, we experiment on Google Cloud Plat-form which purchases carbon credits to reduce its carbon footprint,  training CodeT5-base produced around 49.25 kg CO2 which was totally off-set by the provider. Furthermore, we release our pre-trained models publicly to avoid repeated training for the code intelligence research community.</p><p> As CodeT5 can be deployed to provide coding assistance such as code generation for aiding developers, automation bias of machine learning systems should be carefully considered, especially for developers who tend to over-rely on the model-generated outputs. Sometimes these systems might produce functions that superficially appear correct but do not actually align with the developer‚Äôs intents. If developers unintentionally adopt these incorrect code suggestions, it might cause them much longer time on debugging and even lead to some significant safety issues. We suggest practitioners using CodeT5 should always bear in mind that its generation outputs should be only taken as references which require domain experts for further correctness and security checking.</p><p> We train CodeT5 on existing code corpus including CodeSearchNet (<a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark32\">Husain et al.</a>, <a href=\"https://hackernoon.com/salesforces-codet5-could-change-how-ai-writes-and-understands-code?source=rss#_bookmark32\">2019</a>) and a small fraction of Google BigQuery, both of which are originally collected from public Github repositories. Pre-trained mod-els might encode some sensitive information ( personal addresses or identification numbers) from the training data. Though we have conducted multi-rounds of data cleaning to mitigate this before training our models, it is still possible that some sensitive information cannot be completely removed. Besides, due to the non-deterministic nature of generation models like CodeT5, it might produce some vulnerable code to harmfully affect the software and even be able to benefit more advanced malware development when deliberately misused.</p><p>We thank Akhilesh Deepak Gotmare, Amrita Saha, Junnan Li, and Chen Xing for valuable discussions. We thank Kathy Baxter for the ethical review. We also thank our anonymous reviewers for their insightful feedback on our paper.</p><p>Wasi Uddin Ahmad, Saikat Chakraborty, Baishakhi Ray, and Kai-Wei Chang. 2021. <a href=\"https://doi.org/10.18653/v1/2021.naacl-main.211\">Unified pre-training</a><a href=\"https://doi.org/10.18653/v1/2021.naacl-main.211\">for program understanding and generation</a>. In <em>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2021, Online, June 6-11, 2021</em>, pages 2655‚Äì2668. Association for Computational Linguistics.</p><p>Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harrison Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Win-ter, Philippe Tillet, Felipe Petroski Such, Dave Cum-mings, Matthias Plappert, Fotios Chantzis, Eliza-beth Barnes, Ariel Herbert-Voss, William Hebgen Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders, Christopher Hesse, Andrew N. Carr, Jan Leike, Joshua Achiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welin-der, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and Wojciech Zaremba. 2021. <a href=\"http://arxiv.org/abs/2107.03374\">Evaluating large language models trained on code</a>. , abs/2107.03374.</p><p>Alexis Conneau and Guillaume Lample. 2019. <a href=\"https://proceedings.neurips.cc/paper/2019/hash/c04c19c2c2474dbf5f7ac4372c5b9af1-Abstract.html\">Cross-lingual language model pretraining</a>. In <em>Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019, NeurIPS 2019, December 8-14, 2019, Vancouver, BC, Canada</em>, pages 7057‚Äì7067.</p><p>Sergio Cozzetti B. de Souza, Nicolas Anquetil, and K√°thia Mar√ßal de Oliveira. 2005. <a href=\"https://doi.org/10.1145/1085313.1085331\">A study of the documentation essential to software maintenance</a>. In <em>Proceedings of the 23rd Annual International Conference on Design of Communication: documenting &amp; Designing for Pervasive Information, SIGDOC 2005, Coventry, UK, September 21-23, 2005</em>, pages</p><p>Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. <a href=\"https://www.aclweb.org/anthology/N19-1423/\">BERT: pre-training of</a><a href=\"https://www.aclweb.org/anthology/N19-1423/\">deep bidirectional transformers for language understanding</a>. In <em>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and Short Papers)</em>, pages 4171‚Äì4186.</p><p>Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xi-aocheng Feng, Ming Gong, Linjun Shou, Bing Qin, Ting Liu, Daxin Jiang, and Ming Zhou. 2020. <a href=\"https://doi.org/10.18653/v1/2020.findings-emnlp.139\">Code-bert: A pre-trained model for programming and natural languages</a>. In <em>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings, EMNLP 2020, Online Event, 16-20 November 2020</em>, pages 1536‚Äì1547. Association for Computational Linguistics.</p><p>Daya Guo, Shuo Ren, Shuai Lu, Zhangyin Feng, Duyu Tang, Shujie Liu, Long Zhou, Nan Duan, Alexey Svyatkovskiy, Shengyu Fu, Michele Tu-fano, Shao Kun Deng, Colin B. Clement, Dawn Drain, Neel Sundaresan, Jian Yin, Daxin Jiang, and Ming Zhou. 2021. <a href=\"https://openreview.net/forum?id=jLoC4ez43PZ\">Graphcodebert: Pre-training</a><a href=\"https://openreview.net/forum?id=jLoC4ez43PZ\">code representations with data flow</a>. In <em>9th International Conference on Learning Representations, ICLR 2021, Virtual Event, Austria, May 3-7, 2021</em>. OpenReview.net.</p><p>Srinivasan Iyer, Ioannis Konstas, Alvin Cheung, and Luke Zettlemoyer. 2018. <a href=\"https://doi.org/10.18653/v1/d18-1192\">Mapping language to code</a><a href=\"https://doi.org/10.18653/v1/d18-1192\">in programmatic context</a>. In <em>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, Brussels, Belgium, October 31 - November 4, 2018</em>, pages 1643‚Äì1652. Association for Computational Linguistics.</p><p>Aditya Kanade, Petros Maniatis, Gogul Balakrishnan, and Kensen Shi. 2020. <a href=\"http://proceedings.mlr.press/v119/kanade20a.html\">Learning and evaluating</a><a href=\"http://proceedings.mlr.press/v119/kanade20a.html\">contextual embedding of source code</a>. In <em>Proceedings of the 37th International Conference on Machine Learning, ICML 2020, 13-18 July 2020, Virtual Event</em>, volume 119 of <em>Proceedings of Machine Learning Research</em>, pages 5110‚Äì5121. PMLR.</p><p>Xiaodong Liu, Pengcheng He, Weizhu Chen, and Jian-feng Gao. 2019a. <a href=\"https://doi.org/10.18653/v1/p19-1441\">Multi-task deep neural networks</a><a href=\"https://doi.org/10.18653/v1/p19-1441\">for natural language understanding</a>. In <em>Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019, Florence, Italy, July 28- August 2, 2019, Volume 1: Long Papers</em>, pages 4487‚Äì4496. Association for Computational Linguistics.</p><p>Baptiste Rozi√®re, Marie-Anne Lachaux, Lowik Chanussot, and Guillaume Lample. 2020. <a href=\"https://proceedings.neurips.cc/paper/2020/hash/ed23fbf18c2cd35f8c7f8de44f85c08d-Abstract.html\">Unsupervised translation of programming languages</a>. In <em>Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December</em></p><p>Rico Sennrich, Barry Haddow, and Alexandra Birch. 2016. <a href=\"https://doi.org/10.18653/v1/p16-1162\">Neural machine translation of rare words with</a><a href=\"https://doi.org/10.18653/v1/p16-1162\">subword units</a>. In <em>Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, ACL 2016, August 7-12, 2016, Berlin, Germany, Volume 1: Long Papers</em>. The Association for Computer Linguistics.</p><p>Alexey Svyatkovskiy, Shao Kun Deng, Shengyu Fu, and Neel Sundaresan. 2020. <a href=\"https://doi.org/10.1145/3368089.3417058\">Intellicode compose:</a><a href=\"https://doi.org/10.1145/3368089.3417058\">code generation using transformer</a>. In <em>ESEC/FSE ‚Äô20: 28th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, Virtual Event, USA, November 8-13, 2020</em>, pages 1433‚Äì1443. ACM.</p><p>Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. <a href=\"https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html\">Attention is all</a><a href=\"https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html\">you need</a>. In <em>Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA, USA</em>, pages 5998‚Äì6008.</p><p>:::info\nThis paper is&nbsp;<a href=\"https://arxiv.org/pdf/2109.00859\">available on arxiv</a>&nbsp;under CC by 4.0 Deed (Attribution 4.0 International) license.</p>",
      "contentLength": 43258,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "How Microsoft Trained a 270M-Pair AI to Power Smarter Search",
      "url": "https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss",
      "date": 1772289711,
      "author": "Microsoft",
      "guid": 49165,
      "unread": true,
      "content": "<ol><li>Liang Wang (Microsoft Corporation)</li><li>Nan Yang (Microsoft Corporation)</li><li>Xiaolong Huang (Microsoft Corporation)</li><li>Binxing Jiao (Microsoft Corporation)</li><li>Linjun Yang (Microsoft Corporation)</li><li>Daxin Jiang (Microsoft Corporation)</li><li>Rangan Majumder (Microsoft Corporation)</li><li>Furu Wei (Microsoft Corporation)</li></ol><p>This paper presents E5 <a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark0\">1</a>, a family of state-of-the-art text embeddings that transfer well to a wide range of tasks. The model is trained in a contrastive manner with weak supervision signals from our curated large-scale text pair dataset (called CCPairs). E5 can be readily used as a general-purpose embedding model for any tasks requiring a single-vector representation of texts such as retrieval, clustering, and classification, achieving strong performance in both zero-shot and fine-tuned settings. We conduct extensive evaluations on 56 datasets from the BEIR and MTEB benchmarks. For zero-shot settings, E5 is the first model that outperforms the strong BM25 baseline on the BEIR retrieval benchmark without using any labeled data. When fine-tuned, E5 obtains the best results on the MTEB benchmark, beating existing embedding models with 40√ó more parameters.</p><p>Text embeddings are low-dimensional vector representations for arbitrary-length texts and play key roles in many NLP tasks such as large-scale retrieval. Compared to the high-dimensional and sparse representations like TF-IDF, text embeddings have the potential to overcome the lexical mismatch issue and facilitate efficient retrieval and matching between texts. It also offers a versatile interface easily consumable by downstream applications.</p><p>While pre-trained language models such as BERT [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark34\">17</a>] and GPT [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark24\">7</a>] can produce transferrable text representations, they are not ideal for tasks such as retrieval and text matching where a single-vector embedding of texts is more desired due to its efficiency and versatility. To obtain better text embeddings, contrastive learning is often the go-to framework to enhance the sequence-level representations from text pairs. Along this line of research, some works are geared towards learning task-specific embeddings. For example, GTR [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark60\">43</a>] and Sentence-T5 [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark61\">44</a>] fine-tune pre-trained models with supervised datasets to learn embeddings customized for passage retrieval and semantic textual similarity, respectively. Other works learn unsupervised embeddings from automatically constructed text pairs. Typical methods to construct text pairs include Inverse Close Task (ICT) [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark26\">9</a>], random cropping [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark45\">28</a>] and neighboring text spans [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark58\">41</a>], etc. While such synthetic data are of unlimited quantity, they are often poor in quality and the resulted embeddings fail to match the performance of the classic BM25 baseline without further fine-tuning <a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark57\">[40].</a></p><p>In this work, we learn a high-quality general-purpose text embedding termed E5, mbddings from bidirctional ncoder rpresentations. E5 aims to provide strong off-the-shelf text embeddings suitable for any tasks requiring single-vector representations in both zero-shot or fine-tuned settings. To achieve this goal, instead of relying on limited labeled data or low-quality synthetic text pairs, we contrastively train E5 embeddings from CCPairs, a curated web-scale text pair dataset containing heterogeneous training signals. We construct the CCPairs dataset by combining various semi-structured data sources such as CommunityQA, Common Crawl and Scientific papers, and perform aggressive filtering with a consistency-based filter [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark32\">15</a>] to improve data quality. We choose a simple contrastive learning recipe using in-batch negatives with a large batch-size to train our model. Extensive experiments on both BEIR and MTEB benchmarks demonstrate the effectiveness of the proposed method. On the BEIR zero-shot retrieval benchmark [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark70\">53</a>], E5 is the first model to outperform the strong BM25 baseline without using any labeled data. When fine-tuned on labeled datasets, the performance can be further improved. Results on 56 datasets from the recently introduced MTEB benchmark [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark57\">40</a>] show that our E5base is competitive against GTRxxl and Sentence-T5xxl, which have 40√ó more parameters.</p><p>There have been long-lasting interests in transforming texts into low-dimensional dense embeddings. Early works include Latent Semantic Indexing (LSA) [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark33\">16</a>] and Latent Dirichlet Allocation (LDA) [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark20\">3</a>]. LSA utilizes the decomposition of a word-document co-occurrence matrix to generate document embeddings, while LDA adopts probabilistic graphical models to learn topic distributions. <a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark18\">Arora</a><a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark18\">et al.</a> show that a simple weighted average of word vectors [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark55\">38</a>] can be a strong baseline for sentence embeddings.</p><p>With the development of pre-trained language models [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark34\">17</a>, <a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark52\">35</a>, <a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark65\">48</a>] and large-scale labeled datasets such as SNLI [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark23\">6</a>] and MS-MARCO [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark25\">8</a>], methods like Sentence-BERT [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark66\">49</a>], SimCSE [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark39\">22</a>], Sentence-T5 [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark61\">44</a>] and SGPT [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark56\">39</a>] directly fine-tune language models to output continuous embeddings. Most research focuses on short texts and thus uses the term \"sentence embeddings\". For long documents, it remains an open research question whether fixed-length embeddings can encode all the information. Contrastive loss popularized by SimCLR [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark27\">10</a>] turns out to be more effective than classification-based losses [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark66\">49</a>, <a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark31\">14</a>] for embeddings. LaBSE [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark37\">20</a>], LASER [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark19\">2</a>] and CLIP [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark64\">47</a>] further extend to multilingual and multi-modal scenarios using parallel sentences and image-text pairs.</p><p>Another direction is to design self-supervised pre-training tasks for text matching and retrieval. [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark26\">9</a>] proposes the well-known inverse cloze task (ICT), where a random sentence within a passage is chosen as a pseudo-query and the rest is treated as a positive sample. However, Contriever [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark45\">28</a>] shows that random cropping with data augmentation is more effective than ICT on a range of zero-shot information retrieval tasks. OpenAI text embeddings [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark58\">41</a>] use neighboring texts as positives and scale up the model size to 175B. Oguz et al. <a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark62\">[45]</a> performs domain-matched pre-training to improve in-domain results. SPAR [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark28\">11</a>] trains a dense retriever by treating BM25 as a teacher model. Although the aforementioned approaches can easily obtain abundant supervision signals, such synthetic data tend to be of low quality. Results on the BEIR benchmark [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark70\">53</a>] show they struggle to match the performance of BM25 if not further fine-tuned on labeled datasets.</p><p>Evaluation and interpretation of text embeddings are also non-trivial. Most benchmarks measure the embedding quality through downstream task performances. For example, SentEval [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark30\">13</a>] uses linear probing and a collection of semantic textual similarity (STS) datasets, while the BEIR benchmark [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark70\">53</a>] focuses on zero-shot information retrieval scenarios. The recently introduced MTEB benchmark [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark57\">40</a>] combines 56 datasets spanning across 8 tasks and 112 languages. Experiments show no model can achieve state-of-the-art results on all embedding tasks yet. In this paper, we do not use the SentEval toolkit since its linear probing setup depends on the optimization hyperparameters.</p><p>Most closely related to our work is a series of community efforts by <a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark1\">2</a> to train embeddings with a collection of labeled and automatically collected datasets. In this paper, we show that it is possible to train high-quality embeddings using self-supervised pre-training only. In terms of benchmark results, our model can achieve superior performance when fine-tuned on less labeled data.</p><h2>3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; CCPairs: A Large Collection of Text Pair Dataset</h2><p>The quality and diversity of the data is crucial for training general-purpose text embeddings. In this work, we mine and assemble CCPairs, a large high-quality text pair dataset from web sources which provide diverse training signals transferring well to a wide range of tasks.</p><p>\\\n<strong>Harvesting semi-structured data sources</strong> Large-scale high-quality datasets like C4 [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark65\">48</a>] and CCMatrix [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark68\">51</a>] are vital for the success of language model pre-training and machine translation. For learning text embeddings, existing works either utilize small-scale human-annotated data such as NLI [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark39\">22</a>] and MS-MARCO [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark25\">8</a>] or adopt heuristics such as random cropping [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark45\">28</a>] to obtain large-scale but very noisy supervision signals.</p><p>Instead, we curate a text pair dataset CCPairs (olossal lean text ) by harvesting heterogeneous semi-structured data sources. Let (, ) denote a text pair consisting of a query  and a passage . Here we use ‚Äú‚Äù to denote word sequences of arbitrary length, which can be a short sentence, a paragraph, or a long document. Our dataset includes (post, comment) pairs from Reddit <a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark3\">3</a>, (question, upvoted answer) pairs from Stackexchange <a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark4\">4</a>, (entity name + section title, passage) pairs from English Wikipedia, (title, abstract) and citation pairs from Scientific papers [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark53\">36</a>], and (title, passage) pairs from Common Crawl <a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark5\">5</a> web pages and various News sources.</p><p>We only include data sources that can be automatically mined, and some subsets are directly reused from existing datasets. Simple heuristic rules are applied to filter data from Reddit and Common Crawl. For example, we remove Reddit comments that are either too long ( 4096 characters) or receive score less than 1, and remove passages from web pages with high perplexity [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark77\">60</a>]. After preliminary filtering, we end up with ‚àº 1*.*3 billion text pairs, most of which come from Reddit and Common Crawl. For more details and examples, please refer to Appendix <a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark81\">A.</a></p><p> To further improve data quality and make training costs manageable, we propose a consistency-based data filtering technique: a model is first trained on the 1*.*3B noisy text pairs, and then used to rank each pair against a pool of 1 million random passages. A text pair is kept only if it falls in the top- ranked lists. In other words, the model‚Äôs prediction should be consistent with the training labels. Here we set  = 2 based on manual inspection of data quality. After this step, we end up with ‚àº 270M text pairs for contrastive pre-training.</p><p>The intuition for this technique comes from the memorization behaviors of neural networks [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark36\">19</a>]: when trained on noisy datasets, neural networks tend to memorize the clean labels first and then gradually overfit the noisy labels. Similar techniques [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark59\">42</a>, <a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark32\">15</a>, <a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark40\">23</a>] have been widely used for removing dataset noises. It is also possible to apply this filter iteratively, we will leave it for future work.</p><p>Our embeddings can be trained with only unlabeled text pairs from CCPairs with contrastive pre-training. A second-stage fine-tuning on small, high-quality labeled datasets can be performed to further boost the quality of the resulted embeddings. See Figure <a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark2\">1</a> for an overview.</p><h2>4.1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Contrastive Pre-training with Unlabeled Data</h2><p>Contrastive pre-training aims to distinguish the relevant text pairs from other irrelevant or negative pairs. Given a collection of text pairs {()} , we assign a list of negative passages {‚àí}=1 for the -th example. Then the InfoNCE contrastive loss <a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark27\">[10]</a> is as follows:</p><p>\\\nwhere () is a scoring function between query  and passage  parameterized by ***Œ∏<strong><em>. Following the popular biencoder architecture, we use a pre-trained Transformer encoder and average pooling over the output layer to get fixed-size text embeddings *</em></strong> and . The score is the cosine similarity scaled by a temperature hyperparameter  :</p><p>Where  is set to 0.01 in our experiments by default. We use a shared encoder for all input texts and break the symmetry by adding two prefix identifiers  and  to  and  respectively. For some data sources such as citation pairs, it is not obvious which side should be the query, we randomly choose one for simplicity. Such an asymmetric design turns out to be important for some retrieval tasks where there exist paraphrases of the query in the target corpus.</p><p>Another critical issue for contrastive training is how to select the negative samples. Here we choose to use the in-batch negatives [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark27\">10</a>], where the passages from other pairs in a batch serve as negative samples. We find that this simple strategy enables more stable training and outperforms methods such as MoCo <a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark42\">[25]</a> when the batch size is sufficiently large.</p><h2>4.2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Fine-tuning with Labeled Data</h2><p>While contrastive pre-training on the CCPairs provides a solid foundation for general-purpose embeddings, further training on labeled data can inject human knowledge into the model to boost the performance. Although these datasets are small, existing works [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark60\">43</a>, <a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark61\">44</a>] have shown that supervised fine-tuning leads to consistent performance gains. In this paper, we choose to further train with a combination of 3 datasets: NLI <a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark8\">6</a> (Natural Language Inference), MS-MARCO passage ranking dataset [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark25\">8</a>], and NQ (Natural Questions) dataset [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark47\">30</a>, <a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark49\">32</a>]. Empirically, tasks like STS (Semantic Textual Similarity) and linear probing benefit from NLI data, while MS-MARCO and NQ datasets transfer well to retrieval tasks.</p><p>Building on the practices of training state-of-the-art dense retrievers [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark67\">50</a>, <a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark75\">58</a>], we use mined hard negatives and knowledge distillation from a cross-encoder (CE) teacher model for the MS-MARCO and NQ datasets. For the NLI dataset, contradiction sentences are regarded as hard negatives. The loss function is a linear interpolation between contrastive loss cont for hard labels and KL divergence KL for distilling soft labels from the teacher model.</p><p>Where ce and stu are the probabilities from the cross-encoder teacher model and our student model.  is a hyperparameter to balance the two loss functions. cont is the same as in Equation <a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark6\">1.</a></p><h2>4.3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Applications to Text Embedding Tasks</h2><p>After the above two steps, we obtain high-quality text embeddings transferring well to a wide range of tasks without fine-tuning the model parameters. Combined with techniques like approximate nearest neighbor search, embeddings provide a scalable and efficient solution for applications like web search. Here we briefly illustrate several use cases of our text embeddings.</p><p> First, the passage embeddings for the target corpus are computed and indexed offline. Then for each query, we compute its query embedding and return the top- ranked lists from the corpus based on cosine similarity.</p><p><strong>Few-shot Text Classification</strong> A linear classifier is trained on top of the frozen embeddings with a few labeled examples. Different tasks only need to train and save the parameters of the classification heads. It can be seen as a particular form of parameter-efficient learning <a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark44\">[27].</a></p><p><strong>Zero-shot Text Classification</strong> The input and label texts are converted to sentences based on manually written prompt templates. The predicted label is the one closest to the input text in the embedding space. Take the sentiment classification of movie reviews as an example, with the original input ‚Äú‚Äù, the label text is ‚Äú<em>it is an example of terrible/great movie review</em>‚Äù and the input text becomes ‚Äú<em>movie review: I enjoy watching it</em>‚Äù.</p><p><strong>Semantic Textual Similarity</strong> Given two text embeddings, we use the cosine function to measure their semantic similarity. Since the absolute similarity scores do not enable an easy interpretation, the evaluation is usually based on rank correlation coefficients.</p><p> Standard clustering algorithms such as k-means can be applied straightforwardly. Texts belonging to the same category are expected to be close in the embedding space.</p><p>For tasks other than zero-shot text classification and retrieval, we use the query embeddings by default.</p><h2>5.1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Pre-training and Fine-tuning Configurations</h2><p> We pre-train on our proposed text pair dataset for three model sizes: E5small, E5base and E5large initialized from MiniLM [59], bert-base-uncased, and bert-large-uncased-whole-wordmasking respectively. The batch size is set to a large value of 32, 768 to increase the number of negatives. The learning rate is {3, 2, 1}√ó10‚àí4 for the {small, base, large} models, with linear decay and the first 1, 000 steps for warmup. We pre-train for 20k steps in total with AdamW optimizer, which is approximately 2.5 epochs over the dataset. It takes {16, 32, 64} V100 GPUs and {1, 1, 2} days for the {small, base, large} models. To improve training efficiency and reduce GPU memory usage, we adopt mixed precision training and gradient checkpointing.</p><p>\\\n is performed on the concatenation of 3 datasets: MS-MARCO passage ranking [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark25\">8</a>], NQ [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark49\">32</a>, <a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark47\">30</a>], and NLI [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark39\">22</a>] datasets. We reuse the mined hard negatives and re-ranker scores from SimLM [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark75\">58</a>] for the first two datasets. Models are fine-tuned for 3 epochs with batch size 256 on 8 GPUs. Learning rate is {3*,* 2*,* 1}√ó10‚àí5 for the {small, base, large} models with 400 steps warmup. For each example, we use 7 hard negatives. Since the NLI dataset only has 1 hard negative for each example, 6 sentences are randomly sampled from the entire corpus.</p><p>We use E5-PT to denote models with contrastive pre-training only. More implementation details can be found in Appendix <a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark83\">B.</a></p><h2>5.2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Evaluation Datasets</h2><p> is a collection of 19 information retrieval datasets, ranging across ad-hoc web search, question answering, fact verification and duplicate question retrieval, etc. We evaluate the 15 datasets that provide public downloads. The main metric is nDCG@10.</p><p> is recently proposed for benchmarking massive text embedding tasks. Though MTEB is multilingual due to the inclusion of bitext mining datasets, most datasets are still only available in English. In this paper, we evaluate the English subsets, which have 56 datasets spanning across 6 categories: Classification (Class.), Clustering (Clust.), Pair Classification (PairClass.), Rerank, Retrieval (Retr.), STS, and Summarization (Summ.). The evaluation metrics are accuracy, v-measure, average precision, MAP, nDCG@10, and Spearman coefficients, respectively. Please refer to the MTEB paper for details.</p><h2>5.3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Results on BEIR benchmark</h2><p><strong>Results with Unsupervised Methods</strong> In Table <a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark9\">1,</a> we show model results that do not use any labeled data. When averaged over all 15 datasets, E5-PTbase outperforms the classic BM25 algorithm by 1*.*2 points. To the best of our knowledge, this is the first reported result that an unsupervised model can beat BM25 on the BEIR benchmark. When scaling up to E5-PTlarge, we see further benefits from42.*2.</p><p>\\n In terms of pre-training tasks, Contriever adopts random cropping, while LaPraDor combines ICT and dropout-as-positive-instance from SimCSE. The methods can easily obtain large-scale training data, while our approach requires more effort in dataset curation. Such efforts pay off with better results. Recent studies [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark51\">34</a>, <a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark77\">60</a>, <a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark38\">21</a>] also show that improving data quality is a vital step for training large language models.</p><p>\\\n<strong>Results with Supervised Fine-tuning</strong> In Table <a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark10\">2,</a> we fine-tune our models on supervised datasets and then transfer them to the BEIR benchmark. Since our fine-tuning datasets include MS-MARCO and NQ, the corresponding numbers are in-domain results. For other datasets, these are zero-shot transfer results. Our E5base model achieves an average nDCG@10 of 48*.*7, already surpassing existing methods with more parameters such as GTRlarge [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark60\">43</a>]. Most datasets benefit from supervised fine-tuning, but there are also a few exceptions such as FiQA, Scidocs, and Fever, etc. This is likely due to the lack of enough domain diversity for the fine-tuning datasets.</p><h2>5.4&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Results on MTEB benchmark</h2><p>In Table <a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark11\">3,</a> E5 models not only substantially outperform existing ones with similar sizes, but also match the results of much larger models. The top-2 models on MTEB leaderboard <a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark13\">7</a> GTRxxl and Sentence-T5xxl have 4*.*8B parameters, while our E5large model is more than 10√ó smaller with 300M parameters. We expect that our model will benefit from continual scaling up.</p><p>Since the difference between BERT-FTbase and E5base is that BERT-FTbase only has fine-tuning stage, their performance gap demonstrates the usefulness of contrastive pre-training on our proposed CCPairs dataset. For most task categories except Clustering, performance improves after supervised fine-tuning. Consistent with prior works [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark60\">43</a>, <a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark61\">44</a>], this once again demonstrates the importance of incorporating human knowledge for learning better text embeddings. It remains an open question whether state-of-the-art embeddings can be obtained in a purely self-supervised manner.</p><p>\\\nTable <a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark12\">4</a> shows the zero-shot text classification results on the dev set of the SST-2 dataset [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark69\">52</a>]. By formulating text classification as embedding matching between input and label texts, our model can be much better than the ‚Äúmajority‚Äù baseline in a zero-shot setting. We use the prompt template from Section <a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark7\">4.3.</a></p><p>In this section, we conduct a series of analyses to examine various design choices. All the numbers in this section are from base-size models. For the BEIR benchmark, we choose 6 datasets with more stable results across different runs. Some negative results are also listed in Appendix <a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark86\">C.</a></p><p> Since we use in-batch negatives for contrastive pre-training, larger batch size will provide more negatives and therefore improve the quality of the learned text embeddings. In Table <a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark14\">5,</a> increasing batch size from 1K to 32K leads to consistent gains across all 6 datasets. It is also possible to train with smaller batch sizes by adding hard negatives [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark67\">50</a>]. However, the engineering efforts of mining hard negatives for large datasets (&gt;100M) are non-trivial.</p><p>\\\n GTR models are fine-tuned with ‚ÄúMS-MARCO + NQ‚Äù, while Sentence-T5 models use NLI instead. In Table <a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark15\">6,</a> we can see that the ‚ÄúMS-MARCO + NQ‚Äù setting performs best on retrieval tasks, and the NLI data is beneficial for STS and linear probing classification. Similar observations are also made by Muennighoff et al. <a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark57\">[40]</a>. Combining all of them leads to the best overall scores on the MTEB benchmark. This also illustrates the importance of dataset diversity for learning text embeddings.</p><p>\\\n One crucial step in our dataset curation pipeline is filtering out low-quality text pairs. In Table <a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark16\">7,</a> when training with 1M pairs, using filtered data has a nearly 6 points advantage. When all the text pairs are used, the ‚Äúw/o filter‚Äù setting has about 4√ó more data but is still behind by 1*.*6 points. Though recent studies [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark46\">29</a>, <a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark64\">47</a>] show that deep learning models are quite robust to dataset noises, data filtering still has benefits in improving training efficiency and model quality.</p><p> We explore two alternative methods to enlarge the number of negatives: Pre-batch negatives [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark50\">33</a>] reuse embeddings from previous batches as additional negatives, while MoCo</p><p>[<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark42\">25</a>] introduces a momentum encoder and uses a FIFO queue to store negatives. For both approaches, the negative size can be easily scaled up without incurring much GPU memory overhead. The downside is that most negatives are produced by an older version of model parameters. In Table <a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark17\">8,</a> in-batch negatives still perform favorably. Empirically, we find that MoCo is more sensitive to certain hyperparameters such as temperature, better results are possible with more tuning.</p><p> With the rapid development of dense retrieval models, can we replace the long-standing BM25 algorithm from now on? The answer is likely ‚Äú‚Äù. BM25 still holds obvious advantages in terms of simplicity, efficiency, and interpretability. For long-tail domains such as Trec-Covid [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark72\">55</a>] and retrieval tasks that involve long documents (Touche-2020) [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark21\">4</a>] or rely heavily on exact lexical match (Fever) [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark71\">54</a>], further research efforts are still necessary to improve current dense retrievers.</p><p>In this work, we train a general-purpose text embedding model E5 from weak supervision signals. We adopt a simple contrastive training framework with in-batch negatives and learn from a large-scale text pair dataset we harvest from heterogeneous data sources across the web. E5 offers strong off-the-shelf performance for a wide range of tasks requiring single-vector text representations such as retrieval, semantic textual similarity, and text matching. When further customized for downstream tasks, E5 achieves superior fine-tuned performance compared to existing embedding models with 40√ó more parameters on the large, 56-task MTEB benchmark datasets.</p><p>[1]&nbsp;&nbsp;  Sanjeev Arora, Yingyu Liang, and Tengyu Ma. A simple but tough-to-beat baseline for sentence embeddings. In <em>5th International Conference on Learning Representations, ICLR 2017, Toulon, France, April 24-26, 2017, Conference Track Proceedings</em>. OpenReview.net, 2017. URL <a href=\"https://openreview.net/forum?id=SyK00v5xx\">https://openreview.net/forum?id=SyK00v5xx</a>.</p><p>[2]&nbsp;&nbsp;&nbsp;  Mikel Artetxe and Holger Schwenk. Massively multilingual sentence embeddings for zero-shot cross-lingual transfer and beyond. <em>Transactions of the Association for Computational Linguistics</em>, 7:597‚Äì610, 2019. doi: 10.1162/tacl00288. URL <a href=\"https://aclanthology.org/Q19-1038\">https://aclanthology</a>. <a href=\"https://aclanthology.org/Q19-1038\">org/Q19-1038</a>.</p><p>[3]&nbsp;&nbsp;&nbsp;  David M. Blei, Andrew Y. Ng, and Michael I. Jordan. Latent dirichlet allocation. In Thomas G. Dietterich, Suzanna Becker, and Zoubin Ghahramani, editors, <em>Advances in Neural Information Processing Systems 14 [Neural Information Processing Systems: Natural and Synthetic, NIPS 2001, December 3-8, 2001, Vancouver, British Columbia, Canada]</em>, pages 601‚Äì608. MIT Press, 2001. URL <a href=\"https://proceedings.neurips.cc/paper/2001/hash/296472c9542ad4d4788d543508116cbc-Abstract.html\">https://proceedings.neurips.cc/paper/2001/hash/</a><a href=\"https://proceedings.neurips.cc/paper/2001/hash/296472c9542ad4d4788d543508116cbc-Abstract.html\">296472c9542ad4d4788d543508116cbc-Abstract.html</a>.</p><p>[4]&nbsp;&nbsp;&nbsp;  Alexander Bondarenko, Maik Fr√∂be, Johannes Kiesel, Shahbaz Syed, Timon Gurcke, Meriem Beloucif, Alexander Panchenko, Chris Biemann, Benno Stein, Henning Wachsmuth, et al. Overview of touch√© 2022: argument retrieval. In <em>International Conference of the Cross-Language Evaluation Forum for European Languages</em>, pages 311‚Äì336. Springer, 2022.</p><p>[5]&nbsp;&nbsp;&nbsp; Vera Boteva, Demian Gholipour, Artem Sokolov, and Stefan Riezler. A full-text learning to rank dataset for medical information retrieval. In <em>European Conference on Information Retrieval</em>, pages 716‚Äì722. Springer, 2016.</p><p>[6]&nbsp;&nbsp;&nbsp; Samuel R. Bowman, Gabor Angeli, Christopher Potts, and Christopher D. Manning. A large annotated corpus for learning natural language inference. In <em>Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</em>, pages 632‚Äì642, Lisbon, Portugal, 2015. Association for Computational Linguistics. doi: 10.18653/v1/D15-1075. URL <a href=\"https://aclanthology.org/D15-1075\">https:</a></p><p>[7]&nbsp;&nbsp;  Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhari-wal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. Language models are few-shot learn-ers. In Hugo Larochelle, Marc‚ÄôAurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin, editors, <em>Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual</em>, 2020. URL <a href=\"https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html\">https://proceedings.neurips.cc/paper/2020/hash/</a><a href=\"https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html\">1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html</a>.</p><p>[8]&nbsp;&nbsp;&nbsp;  Daniel Fernando Campos, Tri Nguyen, Mir Rosenberg, Xia Song, Jianfeng Gao, Saurabh Tiwary, Rangan Majumder, Li Deng, and Bhaskar Mitra. Ms marco: A human generated machine reading comprehension dataset. , abs/1611.09268, 2016.</p><p>[9]&nbsp;&nbsp;&nbsp;  Wei-Cheng Chang, Felix X. Yu, Yin-Wen Chang, Yiming Yang, and Sanjiv Kumar. Pre-training tasks for embedding-based large-scale retrieval. In <em>8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020</em>. OpenReview.net, 2020. URL <a href=\"https://openreview.net/forum?id=rkg-mA4FDr\">https://openreview.net/forum?id=rkg-mA4FDr</a>.</p><p>[10]&nbsp;&nbsp;&nbsp;  Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey E. Hinton. A simple framework for contrastive learning of visual representations. In <em>Proceedings of the 37th International Conference on Machine Learning, ICML 2020, 13-18 July 2020, Virtual Event</em>, volume 119 of <em>Proceedings of Machine Learning Research</em>, pages 1597‚Äì1607. PMLR, 2020. URL <a href=\"http://proceedings.mlr.press/v119/chen20j.html\">http:</a></p><p>[11]&nbsp;&nbsp;  Xilun Chen, Kushal Lakhotia, Barlas OgÀòuz, Anchit Gupta, Patrick Lewis, Stan Peshterliev, Yashar Mehdad, Sonal Gupta, and Wen-tau Yih. Salient phrase aware dense retrieval: Can a dense retriever imitate a sparse one? <em>arXiv preprint arXiv:2110.06918</em>, 2021.</p><p>[12]&nbsp;&nbsp;&nbsp; Arman Cohan, Sergey Feldman, Iz Beltagy, Doug Downey, and Daniel S Weld. Specter: Document-level representation learning using citation-informed transformers. In <em>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>, pages 2270‚Äì2282, 2020.</p><p>[13]&nbsp;&nbsp;  Alexis Conneau and Douwe Kiela. SentEval: An evaluation toolkit for universal sentence representations. In <em>Proceedings of the Eleventh International Conference on Language Re-sources and Evaluation (LREC 2018)</em>, Miyazaki, Japan, 2018. European Language Resources Association (ELRA). URL <a href=\"https://aclanthology.org/L18-1269\">https://aclanthology.org/L18-1269</a>.</p><p>[14]&nbsp;&nbsp;  Alexis Conneau, Douwe Kiela, Holger Schwenk, Lo√Øc Barrault, and Antoine Bordes. Super-vised learning of universal sentence representations from natural language inference data. In <em>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</em>, pages 670‚Äì680, Copenhagen, Denmark, 2017. Association for Computational Linguistics. doi: 10.18653/v1/D17-1070.&nbsp; URL <a href=\"https://aclanthology.org/D17-1070\">https://aclanthology.org/D17-1070</a>.</p><p>[15]&nbsp;&nbsp;  Zhuyun Dai, Vincent Zhao, Ji Ma, Yi Luan, Jianmo Ni, Jing Lu, Anton Bakalov, Kelvin Guu, Keith B. Hall, and Ming-Wei Chang. Promptagator: Few-shot dense retrieval from 8 examples. , abs/2209.11755, 2022.</p><p>[16]&nbsp;&nbsp;&nbsp; Scott Deerwester, Susan T Dumais, George W Furnas, Thomas K Landauer, and Richard Harshman. Indexing by latent semantic analysis. <em>Journal of the American society for information science</em>, 41(6):391‚Äì407, 1990.</p><p>[17]&nbsp;&nbsp;&nbsp;  Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: Pre-training of deep bidirectional transformers for language understanding. In <em>Proceedings of the 2019 Confer-ence of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</em>, pages 4171‚Äì4186, Minneapolis, Minnesota, 2019. Association for Computational Linguistics. doi: 10.18653/v1/N19-1423. URL&nbsp; <a href=\"https://aclanthology.org/N19-1423\">https://aclanthology.org/N19-1423</a>.</p><p>[18]&nbsp;&nbsp;&nbsp; Thomas Diggelmann, Jordan Boyd-Graber, Jannis Bulian, Massimiliano Ciaramita, and Markus Leippold. Climate-fever: A dataset for verification of real-world climate claims. <em>arXiv preprint arXiv:2012.00614</em>, 2020.</p><p>[19]&nbsp;&nbsp;&nbsp;  Vitaly Feldman and Chiyuan Zhang. What neural networks memorize and why: Discovering the long tail via influence estimation. In Hugo Larochelle, Marc‚ÄôAurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin, editors, <em>Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual</em>, 2020. URL <a href=\"https://proceedings.neurips.cc/paper/2020/hash/1e14bfe2714193e7af5abc64ecbd6b46-Abstract.html\">https://proceedings.neurips.cc/</a><a href=\"https://proceedings.neurips.cc/paper/2020/hash/1e14bfe2714193e7af5abc64ecbd6b46-Abstract.html\">paper/2020/hash/1e14bfe2714193e7af5abc64ecbd6b46-Abstract.html</a>.</p><p>[20]&nbsp;&nbsp;&nbsp; Fangxiaoyu Feng, Yinfei Yang, Daniel Cer, Naveen Arivazhagan, and Wei Wang. Language-agnostic bert sentence embedding. In <em>Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 878‚Äì891, 2022.</p><p>[21]&nbsp;&nbsp;&nbsp;  Leo Gao, Stella Rose Biderman, Sid Black, Laurence Golding, Travis Hoppe, Charles Foster, Jason Phang, Horace He, Anish Thite, Noa Nabeshima, Shawn Presser, and Connor Leahy. The pile: An 800gb dataset of diverse text for language modeling. , abs/2101.00027, 2021.</p><p>[22]&nbsp;&nbsp;  Tianyu Gao, Xingcheng Yao, and Danqi Chen. SimCSE: Simple contrastive learning of sentence embeddings. In <em>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</em>, pages 6894‚Äì6910, Online and Punta Cana, Dominican Republic, 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.emnlp-main.552. URL <a href=\"https://aclanthology.org/2021.emnlp-main.552\">https://aclanthology.org/2021.emnlp-main.552</a>.</p><p>[23]&nbsp;&nbsp;&nbsp;  Bo Han, Quanming Yao, Xingrui Yu, Gang Niu, Miao Xu, Weihua Hu, Ivor W. Tsang, and Masashi Sugiyama. Co-teaching: Robust training of deep neural networks with extremely noisy labels.&nbsp; In Samy Bengio, Hanna M. Wallach, Hugo Larochelle, Kris-ten Grauman, Nicol√≤ Cesa-Bianchi, and Roman Garnett, editors, <em>Advances in Neu-ral Information Processing Systems 31: Annual Conference on Neural Information Processing Systems 2018, NeurIPS 2018, December 3-8, 2018, Montr√©al, Canada</em>,</p><p>[24]&nbsp;&nbsp;  Faegheh Hasibi, Fedor Nikolaev, Chenyan Xiong, Krisztian Balog, Svein Erik Bratsberg, Alexander Kotov, and Jamie Callan. Dbpedia-entity v2: a test collection for entity search. In <em>Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval</em>, pages 1265‚Äì1268, 2017.</p><p>[25]&nbsp;&nbsp;&nbsp; Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross B. Girshick. Momentum contrast for unsupervised visual representation learning. In <em>2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2020, Seattle, WA, USA, June 13-19, 2020</em>, pages 9726‚Äì9735. IEEE, 2020. doi: 10.1109/CVPR42600.2020.00975. URL <a href=\"https://doi.org/10.1109/CVPR42600.2020.00975\">https://doi.org/10.1109/</a><a href=\"https://doi.org/10.1109/CVPR42600.2020.00975\">CVPR42600.2020.00975</a>.</p><p>[26]&nbsp;&nbsp;&nbsp; Doris Hoogeveen, Karin M Verspoor, and Timothy Baldwin. Cqadupstack: A benchmark data set for community question-answering research. In <em>Proceedings of the 20th Australasian document computing symposium</em>, pages 1‚Äì8, 2015.</p><p>[27]&nbsp;&nbsp;  Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea Gesmundo, Mona Attariyan, and Sylvain Gelly. Parameter-efficient transfer learning for NLP. In Kamalika Chaudhuri and Ruslan Salakhutdinov, editors, <em>Proceedings of the 36th International Conference on Machine Learning, ICML 2019, 9-15 June 2019, Long Beach, California, USA</em>, volume 97 of <em>Proceedings of Machine Learning Research</em>, pages 2790‚Äì2799. PMLR, 2019.&nbsp; URL <a href=\"http://proceedings.mlr.press/v97/houlsby19a.html\">http://proceedings.mlr.press/v97/houlsby19a.html</a>.</p><p>[28]&nbsp;&nbsp;&nbsp;  Gautier Izacard, Mathilde Caron, Lucas Hosseini, Sebastian Riedel, Piotr Bojanowski, Armand Joulin, and Edouard Grave. Towards unsupervised dense information retrieval with contrastive learning. , abs/2112.09118, 2021.</p><p>[29]&nbsp;&nbsp;&nbsp;  Chao Jia, Yinfei Yang, Ye Xia, Yi-Ting Chen, Zarana Parekh, Hieu Pham, Quoc V. Le, Yun-Hsuan Sung, Zhen Li, and Tom Duerig. Scaling up visual and vision-language representation learning with noisy text supervision. In Marina Meila and Tong Zhang, editors, <em>Proceedings of the 38th International Conference on Machine Learning, ICML 2021, 18-24 July 2021, Virtual Event</em>, volume 139 of <em>Proceedings of Machine Learning Research</em>, pages 4904‚Äì4916. PMLR, 2021.&nbsp; URL&nbsp; <a href=\"http://proceedings.mlr.press/v139/jia21b.html\">http://proceedings.mlr.press/v139/jia21b.html</a>.</p><p>[30]&nbsp;&nbsp;  Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih. Dense passage retrieval for open-domain question answering. In <em>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, pages 6769‚Äì6781, Online, 2020. Association for Computational Linguistics. doi: 10. 18653/v1/2020.emnlp-main.550.&nbsp; URL <a href=\"https://aclanthology.org/2020.emnlp-main.550\">https://aclanthology.org/2020.emnlp-main</a>. <a href=\"https://aclanthology.org/2020.emnlp-main.550\">550</a>.</p><p>[31]&nbsp;&nbsp;  Omar Khattab and Matei Zaharia. Colbert: Efficient and effective passage search via contex-tualized late interaction over BERT. In Jimmy Huang, Yi Chang, Xueqi Cheng, Jaap Kamps, Vanessa Murdock, Ji-Rong Wen, and Yiqun Liu, editors, <em>Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval, SIGIR 2020, Vir-tual Event, China, July 25-30, 2020</em>, pages 39‚Äì48. ACM, 2020. doi: 10.1145/3397271.3401075. URL <a href=\"https://doi.org/10.1145/3397271.3401075\">https://doi.org/10.1145/3397271.3401075</a>.</p><p>[32]&nbsp;&nbsp;  Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, Kristina Toutanova, Llion Jones, Matthew Kelcey, Ming-Wei Chang, Andrew M. Dai, Jakob Uszkoreit, Quoc Le, and Slav Petrov. Natural questions: A benchmark for question answering research. <em>Transactions of the Association for Computational Linguistics</em>, 7:452‚Äì466, 2019. doi: 10.1162/tacl00276. URL <a href=\"https://aclanthology.org/Q19-1026\">https://aclanthology.org/Q19-1026</a>.</p><p>[33]&nbsp;&nbsp;  Jinhyuk Lee, Mujeen Sung, Jaewoo Kang, and Danqi Chen. Learning dense representations of phrases at scale. In <em>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</em>, pages 6634‚Äì6647, Online, 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.acl-long.518. URL <a href=\"https://aclanthology.org/2021.acl-long.518\">https://aclanthology.org/2021</a>. <a href=\"https://aclanthology.org/2021.acl-long.518\">acl-long.518</a>.</p><p>[34]&nbsp;&nbsp;&nbsp; Katherine Lee, Daphne Ippolito, Andrew Nystrom, Chiyuan Zhang, Douglas Eck, Chris Callison-Burch, and Nicholas Carlini. Deduplicating training data makes language models better. In , 2022.</p><p>[35]&nbsp;&nbsp;&nbsp; Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. Roberta: A robustly optimized bert pretraining approach. , abs/1907.11692, 2019.</p><p>[36]&nbsp;&nbsp;&nbsp;  Kyle Lo, Lucy Lu Wang, Mark Neumann, Rodney Kinney, and Daniel Weld. S2ORC: The semantic scholar open research corpus. In <em>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>, pages 4969‚Äì4983, Online, 2020. Associ-ation for Computational Linguistics.&nbsp; doi: 10.18653/v1/2020.acl-main.447.&nbsp; URL <a href=\"https://aclanthology.org/2020.acl-main.447\">https://aclanthology.org/2020.acl-main.447</a>.</p><p>[37]&nbsp;&nbsp;  Macedo Maia, Siegfried Handschuh, Andr√© Freitas, Brian Davis, Ross McDermott, Manel Zarrouk, and Alexandra Balahur. Www‚Äô18 open challenge: financial opinion mining and question answering. In <em>Companion proceedings of the the web conference 2018</em>, pages 1941‚Äì1942, 2018.</p><p>[38]&nbsp;&nbsp;&nbsp; Tomas Mikolov, Kai Chen, Gregory S. Corrado, and Jeffrey Dean. Efficient estimation of word representations in vector space. In , 2013.</p><p>[39]&nbsp;&nbsp;&nbsp; Niklas Muennighoff.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Sgpt: Gpt sentence embeddings for semantic search.&nbsp; , abs/2202.08904, 2022.</p><p>[40]&nbsp;&nbsp;&nbsp; Niklas Muennighoff, Nouamane Tazi, Loic Magne, and Nils Reimers. Mteb: Massive text embedding benchmark. , abs/2210.07316, 2022.</p><p>[41]&nbsp;&nbsp;&nbsp;  Arvind Neelakantan, Tao Xu, Raul Puri, Alec Radford, Jesse Michael Han, Jerry Tworek, Qiming Yuan, Nikolas A. Tezak, Jong Wook Kim, Chris Hallacy, Johannes Heidecke, Pranav Shyam, Boris Power, Tyna Eloundou Nekoul, Girish Sastry, Gretchen Krueger, David P. Schnurr, Felipe Petroski Such, Kenny Sai-Kin Hsu, Madeleine Thompson, Tabarak Khan, Toki Sherbakov, Joanne Jang, Peter Welinder, and Lilian Weng. Text and code embeddings by contrastive pre-training. , abs/2201.10005, 2022.</p><p>[42]&nbsp;&nbsp;  Duc Tam Nguyen, Chaithanya Kumar Mummadi, Thi-Phuong-Nhung Ngo, Thi Hoai Phuong Nguyen, Laura Beggel, and Thomas Brox. SELF: learning to filter noisy labels with self-ensembling. In <em>8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020</em>. OpenReview.net, 2020. URL <a href=\"https://openreview.net/forum?id=HkgsPhNYPS\">https://openreview</a>. <a href=\"https://openreview.net/forum?id=HkgsPhNYPS\">net/forum?id=HkgsPhNYPS</a>.</p><p>[43]&nbsp;&nbsp;&nbsp; Jianmo Ni, Chen Qu, Jing Lu, Zhuyun Dai, Gustavo Hern‚Äôandez ‚ÄôAbrego, Ji Ma, Vincent Zhao, Yi Luan, Keith B. Hall, Ming-Wei Chang, and Yinfei Yang. Large dual encoders are generalizable retrievers. , abs/2112.07899, 2021.</p><p>[44]&nbsp;&nbsp;  Jianmo Ni, Gustavo Hernandez Abrego, Noah Constant, Ji Ma, Keith Hall, Daniel Cer, and Yinfei Yang. Sentence-t5: Scalable sentence encoders from pre-trained text-to-text models. In <em>Findings of the Association for Computational Linguistics: ACL 2022</em>, pages 1864‚Äì1874, 2022.</p><p>[45]&nbsp;&nbsp;  Barlas Oguz, Kushal Lakhotia, Anchit Gupta, Patrick Lewis, Vladimir Karpukhin, Aleksandra Piktus, Xilun Chen, Sebastian Riedel, Scott Yih, Sonal Gupta, and Yashar Mehdad. Domain-matched pre-training tasks for dense retrieval. In <em>Findings of the Association for Computational Linguistics: NAACL 2022, Seattle, WA, United States, July 10-15, 2022</em>, pages 1524‚Äì1534. Association for Computational Linguistics, 2022. doi: 10.18653/v1/2022.findings-naacl.114. URL&nbsp;&nbsp; <a href=\"https://doi.org/10.18653/v1/2022.findings-naacl.114\">https://doi.org/10.18653/v1/2022.findings-naacl.114</a>.</p><p>[46]&nbsp;&nbsp;  Fabio Petroni, Aleksandra Piktus, Angela Fan, Patrick Lewis, Majid Yazdani, Nicola De Cao, James Thorne, Yacine Jernite, Vassilis Plachouras, Tim Rocktaschel, and Sebastian Riedel. Kilt: a benchmark for knowledge intensive language tasks. In <em>North American Chapter of the Association for Computational Linguistics</em>, 2020.</p><p>[47]&nbsp;&nbsp;  Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, and Ilya Sutskever. Learning transferable visual models from natural language supervi-sion. In Marina Meila and Tong Zhang, editors, <em>Proceedings of the 38th International Conference on Machine Learning, ICML 2021, 18-24 July 2021, Virtual Event</em>, volume 139 of <em>Proceedings of Machine Learning Research</em>, pages 8748‚Äì8763. PMLR, 2021. URL <a href=\"http://proceedings.mlr.press/v139/radford21a.html\">http://proceedings.mlr.press/v139/radford21a.html</a>.</p><p>[48]&nbsp;&nbsp;  Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. Exploring the limits of transfer learning with a unified text-to-text transformer. <em>Journal of Machine Learning Research</em>, 21:1‚Äì67, 2020.</p><p>[49]&nbsp;&nbsp;  Nils Reimers and Iryna Gurevych. Sentence-BERT: Sentence embeddings using Siamese BERT-networks. In <em>Proceedings of the 2019 Conference on Empirical Methods in Natural Lan-guage Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</em>, pages 3982‚Äì3992, Hong Kong, China, 2019. Association for Computational Linguistics. doi: 10.18653/v1/D19-1410. URL <a href=\"https://aclanthology.org/D19-1410\">https://aclanthology.org/D19-1410</a>.</p><p>[50]&nbsp;&nbsp;  Ruiyang Ren, Yingqi Qu, Jing Liu, Wayne Xin Zhao, QiaoQiao She, Hua Wu, Haifeng Wang, and Ji-Rong Wen. RocketQAv2: A joint training method for dense passage retrieval and passage re-ranking. In <em>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</em>, pages 2825‚Äì2835, Online and Punta Cana, Dominican Republic, 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.emnlp-main.224. URL <a href=\"https://aclanthology.org/2021.emnlp-main.224\">https://aclanthology.org/2021.emnlp-main.224</a>.</p><p>[51]&nbsp;&nbsp;  Holger Schwenk, Guillaume Wenzek, Sergey Edunov, Edouard Grave, Armand Joulin, and Angela Fan. CCMatrix: Mining billions of high-quality parallel sentences on the web. In <em>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</em>, pages 6490‚Äì6500, Online, 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.acl-long.507.&nbsp;&nbsp; URL&nbsp; <a href=\"https://aclanthology.org/2021.acl-long.507\">https://aclanthology.org/2021.acl-long.507</a>.</p><p>[52]&nbsp;&nbsp;&nbsp; Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D. Manning, A. Ng, and Christopher Potts. Recursive deep models for semantic compositionality over a sentiment treebank. In <em>Conference on Empirical Methods in Natural Language Processing</em>, 2013.</p><p>[53]&nbsp;&nbsp;  Nandan Thakur, Nils Reimers, Andreas R√ºckl√©, Abhishek Srivastava, and Iryna Gurevych. Beir: A heterogeneous benchmark for zero-shot evaluation of information retrieval models. In <em>Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2)</em>, 2021.</p><p>[54]&nbsp;&nbsp;&nbsp;  James Thorne, Andreas Vlachos, Christos Christodoulopoulos, and Arpit Mittal. FEVER: a large-scale dataset for fact extraction and VERification. In <em>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)</em>, pages 809‚Äì819, New Orleans, Louisiana, 2018. Association for Computational Linguistics. doi: 10.18653/v1/N18-1074. URL <a href=\"https://aclanthology.org/N18-1074\">https:</a></p><p>[55]&nbsp;&nbsp;&nbsp; Ellen Voorhees, Tasmeer Alam, Steven Bedrick, Dina Demner-Fushman, William R Hersh, Kyle Lo, Kirk Roberts, Ian Soboroff, and Lucy Lu Wang. Trec-covid: constructing a pandemic information retrieval test collection. In , volume 54, pages 1‚Äì12. ACM New York, NY, USA, 2021.</p><p>[56]&nbsp;&nbsp;  Henning Wachsmuth, Shahbaz Syed, and Benno Stein. Retrieval of the best counterargument without prior topic knowledge. In <em>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 241‚Äì251, 2018.</p><p>[57]&nbsp;&nbsp;&nbsp;  David Wadden, Shanchuan Lin, Kyle Lo, Lucy Lu Wang, Madeleine van Zuylen, Arman Cohan, and Hannaneh Hajishirzi. Fact or fiction: Verifying scientific claims. In <em>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, pages 7534‚Äì7550, 2020.</p><p>[58]&nbsp;&nbsp;&nbsp; Liang Wang, Nan Yang, Xiaolong Huang, Binxing Jiao, Linjun Yang, Daxin Jiang, Rangan Majumder, and Furu Wei. Simlm: Pre-training with representation bottleneck for dense passage retrieval. , abs/2207.02578, 2022.</p><p>[59]&nbsp;&nbsp;  Wenhui Wang, Hangbo Bao, Shaohan Huang, Li Dong, and Furu Wei. Minilmv2: Multi-head self-attention relation distillation for compressing pretrained transformers. In <em>Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021</em>, pages 2140‚Äì2151, 2021.</p><p>[60]&nbsp;&nbsp;&nbsp;  Guillaume Wenzek, Marie-Anne Lachaux, Alexis Conneau, Vishrav Chaudhary, Francisco Guzm√°n, Armand Joulin, and Edouard Grave. CCNet: Extracting high quality monolingual datasets from web crawl data. In <em>Proceedings of the 12th Language Resources and Evaluation Conference</em>, pages 4003‚Äì4012, Marseille, France, 2020. European Language Resources Associ-ation.&nbsp; ISBN 979-10-95546-34-4.&nbsp; URL <a href=\"https://aclanthology.org/2020.lrec-1.494\">https://aclanthology.org/2020.lrec-1.494</a>.</p><p>[61]&nbsp;&nbsp;  Lee Xiong, Chenyan Xiong, Ye Li, Kwok-Fung Tang, Jialin Liu, Paul N. Bennett, Junaid Ahmed, and Arnold Overwijk. Approximate nearest neighbor negative contrastive learning for dense text retrieval. In <em>9th International Conference on Learning Representations, ICLR 2021, Virtual Event, Austria, May 3-7, 2021</em>. OpenReview.net, 2021. URL <a href=\"https://openreview.net/forum?id=zeFrfgyZln\">https://openreview</a>. <a href=\"https://openreview.net/forum?id=zeFrfgyZln\">net/forum?id=zeFrfgyZln</a>.</p><p>[62]&nbsp;&nbsp;&nbsp;  Canwen Xu, Daya Guo, Nan Duan, and Julian McAuley. Laprador: Unsupervised pretrained dense retriever for zero-shot text retrieval. In <em>Findings of the Association for Computational Linguistics: ACL 2022</em>, pages 3557‚Äì3569, 2022.</p><p>[63]&nbsp;&nbsp;&nbsp;  Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William Cohen, Ruslan Salakhutdinov, and Christopher D Manning. Hotpotqa: A dataset for diverse, explainable multi-hop question answering. In <em>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</em>, pages 2369‚Äì2380, 2018.</p><p>For Common Crawl, we download the 2022-33 snapshot and cc_net <a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark82\">8</a> is used for preprocessing including language identification, de-duplication, language model filtering, etc. Web pages from the MS-MARCO document ranking corpus are also included. For the data filtering step, we examine each pair of passages within a web page instead of just using the title as a query. For Wikipedia, we use the version released by Petroni et al. <a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark63\">[46]</a>. To avoid possible data contamination, we remove text pairs that occur in the evaluation datasets based on exact string match.</p><p>Reddit data is collected from the year 2018 to August 2022. For the S2ORC data, we use a sample weight of 0*.*3 during training to avoid over-fitting the scientific domains.</p><p>For the BEIR benchmark, we use the 15 datasets that provide public downloads: MS MARCO [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark25\">8</a>], Trec-Covid [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark72\">55</a>], NFCorpus [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark22\">5</a>], NQ [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark49\">32</a>], HotpotQA [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark80\">63</a>], FiQA [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark54\">37</a>], ArguAna [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark73\">56</a>], Touche-2020 [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark21\">4</a>], CQADupStack [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark43\">26</a>], Quora, DBPedia [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark41\">24</a>], Scidocs [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark29\">12</a>], Fever [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark71\">54</a>], Climate-Fever [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark35\">18</a>], and Scifact <a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark74\">[57].</a></p><h2>B&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Implementation Details</h2><p>We list the hyperparameters in Table <a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark84\">11.</a> Since some evaluation datasets have long texts, we freeze the position embeddings during both pre-training and fine-tuning and set the maximum text length to 512 for evaluation.</p><p>For the Quora duplicate retrieval task in the BEIR benchmark, we add prefix ‚Äú ‚Äù to all the questions. For other retrieval tasks, we use ‚Äú ‚Äù and ‚Äú ‚Äù prefixes correspondingly.</p><p>The MS-MARCO results in Table <a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark85\">12</a> use document titles provided by RocketQA [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark67\">50</a>]. This evaluation setup is consistent with most state-of-the-art dense retrievers. However, the MS-MARCO data from the BEIR benchmark does not have titles, so the results are expected to be lower.</p><p>\\\n We report results for in-domain datasets in Table <a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark85\">12.</a> These results can help illustrate the benefits brought by contrastive pre-training when abundant in-domain labeled data are available. For MS-MARCO passage ranking, MRR@10 and Recall@1k are reported. For the NQ dataset, Recall@20 and Recall@100 are the main metrics.</p><h2>C&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Negative Results</h2><p>Here are some attempts that we eventually give up on:</p><p><strong>Adding BM25 hard negatives</strong> Similar to DPR [<a href=\"https://hackernoon.com/how-microsoft-trained-a-270m-pair-ai-to-power-smarter-search?source=rss#_bookmark47\">30</a>], we add one BM25 hard negative for each positive pair during training. When using 15M data, this strategy improves the overall results by ~ 0.5 points on the BEIR benchmark. However, running the BM25 algorithm over a 250M+ dataset is too time-consuming even with multi-node and multi-process parallelism.</p><p><strong>Using RoBERTa instead of BERT for initialization</strong> Though RoBERTa shows consistent gains on many NLP tasks, we empirically find that RoBERTa performs worse than BERT initialization on most of the BEIR benchmark datasets.</p><p> We add a masked language modeling loss for 25% of the training text pairs. The numbers are on par with removing this auxiliary objective, but the training cost goes up.</p><p>:::info\nThis paper is&nbsp;<a href=\"https://arxiv.org/abs/2212.03533\">available on arxiv</a>&nbsp;under CC by 4.0 Deed (Attribution 4.0 International) license.</p>",
      "contentLength": 49237,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Microsoft‚Äôs Graphormer: The Transformer That Finally Beats GNNs",
      "url": "https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss",
      "date": 1772289119,
      "author": "Microsoft",
      "guid": 49164,
      "unread": true,
      "content": "<ol><li>Chengxuan Ying, yingchengsyuan@gmail.com  (Dalian University of Technology)</li><li>Tianle Cai, tianle.cai@princeton.edu  (Princeton University)</li><li>Shengjie Luo, luosj@stu.pku.edu.cn  (Peking University)</li><li>Shuxin Zheng, shuz@microsoft.com  (Microsoft Research Asia)</li><li>Guolin Ke, guoke@microsoft.com  (Microsoft Research Asia)</li><li>Di He, dihe@microsoft.com  (Microsoft Research Asia)</li><li>Yanming Shen, shen@dlut.edu.cn  (Dalian University of Technology)</li><li>Tie-Yan Liu, tyliu@microsoft.com  (Microsoft Research Asia)</li></ol><p>The Transformer architecture has become a dominant choice in many domains, such as natural language processing and computer vision. Yet, it has not achieved competitive performance on popular leaderboards of graph-level prediction compared to mainstream GNN variants. Therefore, it remains a mystery how Transformers could perform well for graph representation learning. In this paper, we solve this mystery by presenting Graphormer, which is built upon the standard Transformer architecture, and could attain excellent results on a broad range of graph representation learning tasks, especially on the recent OGB Large-Scale Challenge. Our key insight to utilizing Transformer in the graph is the necessity of effectively encoding the structural information of a graph into the model. To this end, we propose several simple yet effective structural encoding methods to help Graphormer better model graph-structured data. Besides, we mathematically characterize the expressive power of Graphormer and exhibit that with our ways of encoding the structural information of graphs, many popular GNN variants could be covered as the special cases of Graphormer. The code and models of Graphormer will be made publicly available at <a href=\"https://github.com/Microsoft/Graphormer\">https://github.com/Microsoft/Graphormer</a>.</p><p>The Transformer [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark65\">49</a>] is well acknowledged as the most powerful neural network in modelling sequential data, such as natural language [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark28\">11</a>, <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark52\">35</a>, <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark23\">6</a>] and speech [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark34\">17</a>]. Model variants built upon Transformer have also been shown great performance in computer vision [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark29\">12</a>, <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark53\">36</a>] and programming language [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark36\">19</a>, <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark80\">63</a>, <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark61\">44</a>]. However, to the best of our knowledge, Transformer has still not been the de-facto standard on public graph representation leaderboards [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark39\">22</a>, <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark31\">14</a>, <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark38\">21</a>]. There are many attempts of leveraging Transformer into the graph domain, but the only effective way is replacing some key modules (e.g., feature aggregation) in classic GNN variants by the softmax attention [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark67\">50</a>, <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark24\">7</a>, <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark40\">23</a>, <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark68\">51</a>, <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark78\">61</a>, <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark63\">46</a>, <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark30\">13</a>]. Therefore, it is still an open question whether Transformer architecture is suitable to model graphs and how to make it work in graph representation learning.</p><p>In this paper, we give an affirmative answer by developing Graphormer, which is directly built upon the standard Transformer, and achieves state-of-the-art performance on a wide range of graph-level prediction tasks, including the very recent Open Graph Benchmark Large-Scale Challenge (OGB-LSC) [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark38\">21</a>], and several popular leaderboards (e.g., OGB [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark39\">22</a>], Benchmarking-GNN [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark31\">14</a>]). The Transformer is originally designed for sequence modeling. To utilize its power in graphs, we believe the key is to properly incorporate structural information of graphs into the model. Note that for each node , the self-attention only calculates the semantic similarity between  and other nodes, without considering the structural information of a graph reflected on the nodes and the relation between node pairs. Graphormer incorporates several effective structural encoding methods to leverage such information, which are described below.</p><p>First, we propose a  in Graphormer to capture the node importance in the graph. In a graph, different nodes may have different importance, e.g., celebrities are considered to be more influential than the majority of web users in a social network. However, such information isn‚Äôt reflected in the self-attention module as it calculates the similarities mainly using the node semantic features. To address the problem, we propose to encode the node centrality in Graphormer. In particular, we leverage the  for the centrality encoding, where a learnable vector is assigned to each node according to its degree and added to the node features in the input layer. Empirical studies show that simple centrality encoding is effective for Transformer in modeling the graph data.</p><p>Second, we propose a novel  in Graphormer to capture the structural relation between nodes. One notable geometrical property that distinguishes graph-structured data from other structured data, e.g., language, images, is that there does not exist a canonical grid to embed the graph. In fact, nodes can only lie in a non-Euclidean space and are linked by edges. To model such structural information, for each node pair, we assign a learnable embedding based on their spatial relation. Multiple measurements in the literature could be leveraged for modeling spatial relations. For a general purpose, we use the distance of the shortest path between any two nodes as a demonstration, which will be encoded as a bias term in the softmax attention and help the model accurately capture the spatial dependency in a graph. In addition, sometimes there is additional spatial information contained in edge features, such as the type of bond between two atoms in a molecular graph. We design a new edge encoding method to further take such signal into the Transformer layers. To be concrete, for each node pair, we compute an average of dot-products of the edge features and learnable embeddings along the shortest path, then use it in the attention module. Equipped with these encodings, Graphormer could better model the relationship for node pairs and represent the graph.</p><p>By using the proposed encodings above, we further mathematically show that Graphormer has strong expressiveness as many popular GNN variants are just its special cases. The great capacity of the model leads to state-of-the-art performance on a wide range of tasks in practice. On the large-scale quantum chemistry regression dataset<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark0\">3</a> in the very recent Open Graph Benchmark Large-Scale Challenge (OGB-LSC) [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark38\">21</a>], Graphormer outperforms most mainstream GNN variants by more than 10% points in terms of the relative error. On other popular leaderboards of graph representation learning (e.g., MolHIV, MolPCBA, ZINC) [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark39\">22</a>, <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark31\">14</a>], Graphormer also surpasses the previous best results, demonstrating the potential and adaptability of the Transformer architecture.</p><p>In this section, we recap the preliminaries in Graph Neural Networks and Transformer.</p><p><strong>Graph Neural Network (GNN).</strong> Let G = (V, E) denote a graph where V = {v1, v2, ¬∑ ¬∑ ¬∑ , vn}, n = |V | is the number of nodes. Let the feature vector of node vi be xi . GNNs aim to learn representation of nodes and graphs. Typically, modern GNNs follow a learning schema that iteratively updates the representation of a node by aggregating representations of its first or higher-order neighbors. We denote h (l) i as the representation of vi at the l-th layer and define h (0) i = xi . The l-th iteration of aggregation could be characterized by AGGREGATE-COMBINE step as</p><p>where N (vi) is the set of first or higher-order neighbors of vi . The AGGREGATE function is used to gather the information from neighbors. Common aggregation functions include MEAN, MAX, SUM, which are used in different architectures of GNNs [26, 18, 50, 54]. The goal of COMBINE function is to fuse the information from neighbors into the node representation.</p><p>\\\nIn addition, for graph representation tasks, a READOUT function is designed to aggregate node features h (L) i of the final iteration into the representation hG of the entire graph G:</p><p>READOUT can be implemented by a simple permutation invariant function such as summation [54] or a more sophisticated graph-level pooling function [1].</p><p>. The Transformer architecture consists of a composition of Transformer layers [49]. Each Transformer layer has two parts: a self-attention module and a position-wise feed-forward network (FFN). Let H = h &gt; 1 , ¬∑ ¬∑ ¬∑ , h&gt; n &gt; ‚àà R n√ód denote the input of self-attention module where d is the hidden dimension and hi ‚àà R 1√ód is the hidden representation at position i. The input H is projected by three matrices WQ ‚àà R d√ódK , WK ‚àà R d√ódK and WV ‚àà R d√ódV to the corresponding representations Q, K, V . The self-attention is then calculated as:</p><p>where  is a matrix capturing the similarity between queries and keys. For simplicity of illustration, we consider the single-head self-attention and assume  =  = . The extension to the multi-head attention is standard and straightforward, and we omit bias terms for simplicity.</p><p>In this section, we present our Graphormer for graph tasks. First, we elaborate on several key designs in the Graphormer, which serve as an inductive bias in the neural network to learn the graph representation. We further provide the detailed implementations of Graphormer. Finally, we show that our proposed Graphormer is more powerful since popular GNN models [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark43\">26</a>, <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark71\">54</a>, <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark35\">18</a>] are its special cases.</p><h2>3.1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Structural Encodings in Graphormer</h2><p>As discussed in the introduction, it is important to develop ways to leverage the structural information of graphs into the Transformer model. To this end, we present three simple but effective designs of encoding in Graphormer. See Figure <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark1\">1</a> for an illustration.</p><h2>3.1.1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Centrality Encoding</h2><p>In <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark3\">Eq.4,</a> the attention distribution is calculated based on the semantic correlation between nodes. However, node centrality, which measures how important a node is in the graph, is usually a strong signal for graph understanding. For example, celebrities who have a huge number of followers are important factors in predicting the trend of a social network [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark57\">40</a>, <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark56\">39</a>]. Such information is neglected in the current attention calculation, and we believe it should be a valuable signal for Transformer models.</p><p>In Graphormer, we use the degree centrality, which is one of the standard centrality measures in literature, as an additional signal to the neural network. To be specific, we develop a  which assigns each node two real-valued embedding vectors according to its indegree and outdegree. As the centrality encoding is applied to each node, we simply add it to the node features as the input.</p><p>where z ‚àí, z+ ‚àà R d are learnable embedding vectors specified by the indegree deg‚àí(vi) and outdegree deg+(vi) respectively. For undirected graphs, deg‚àí(vi) and deg+(vi) could be unified to deg(vi). By using the centrality encoding in the input, the softmax attention can catch the node importance signal in the queries and the keys. Therefore the model can capture both the semantic correlation and the node importance in the attention mechanism.</p><h2>3.1.2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Spatial Encoding</h2><p>An advantage of Transformer is its global receptive field. In each Transformer layer, each token can attend to the information at any position and then process its representation. But this operation has a byproduct problem that the model has to explicitly specify different positions or encode the positional dependency (such as locality) in the layers. For sequential data, one can either give each position an embedding (i.e., absolute positional encoding [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark65\">49</a>]) as the input or encode the relative distance of any two positions (i.e., relative positional encoding <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark62\">[45,</a><a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark64\">47])</a> in the Transformer layer.</p><p>However, for graphs, nodes are not arranged as a sequence. They can lie in a multi-dimensional spatial space and are linked by edges. To encode the structural information of a graph in the model, we propose a novel Spatial Encoding. Concretely, for any graph G, we consider a function œÜ (vi , vj ) : V √ó V ‚Üí R which measures the spatial relation between vi and vj in graph G. The function œÜ can be defined by the connectivity between the nodes in the graph. In this paper, we choose œÜ(vi , vj ) to be the distance of the shortest path (SPD) between vi and vj if the two nodes are connected. If not, we set the output of œÜ to be a special value, i.e., -1. We assign each (feasible) output value a learnable scalar which will serve as a bias term in the self-attention module. Denote Aij as the (i, j)-element of the Query-Key product matrix A, we have:</p><p>where ( ) is a learnable scalar indexed by (), and shared across all layers.</p><p>Here we discuss several benefits of our proposed method. First, compared to conventional GNNs described in Section 2, where the receptive field is restricted to the neighbors, we can see that in Eq. <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark4\">(6)</a>, the Transformer layer provides a global information that each node can attend to all other nodes in the graph. Second, by using ( ), each node in a single Transformer layer can adaptively attend to all other nodes according to the graph structural information. For example, if ( ) is</p><p>learned to be a decreasing function with respect to (), for each node, the model will likely pay more attention to the nodes near it and pay less attention to the nodes far away from it.</p><h2>3.1.3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Edge Encoding in the Attention</h2><p>In many graph tasks, edges also have structural features, e.g., in a molecular graph, atom pairs may have features describing the type of bond between them. Such features are important to the graph representation, and encoding them together with node features into the network is essential. There are mainly two edge encoding methods used in previous works. In the first method, the edge features are added to the associated nodes‚Äô features [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark39\">22</a>, <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark47\">30</a>]. In the second method, for each node, its associated edges‚Äô features will be used together with the node features in the aggregation [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark32\">15</a>, <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark71\">54</a>, <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark43\">26</a>]. However, such ways of using edge feature only propagate the edge information to its associated nodes, which may not be an effective way to leverage edge information in representation of the whole graph.</p><p>To better encode edge features into attention layers, we propose a new edge encoding method in Graphormer. The attention mechanism needs to estimate correlations for each node pair (), and we believe the edges connecting them should be considered in the correlation as in [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark51\">34</a>, <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark68\">51</a>]. For each ordered node pair (), we find (one of) the shortest path SP = (1*, e, ‚Ä¶, eN* ) from  to , and compute an average of the dot-products of the edge feature and a learnable embedding along the path. The proposed edge encoding incorporates edge features via a bias term to the attention module. Concretely, we modify the ()-element of  in Eq. <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark2\">(3)</a> further with the edge encoding  as:</p><p>where xen is the feature of the n-th edge en in SPij , w E n ‚àà R dE is the n-th weight embedding, and dE is the dimensionality of edge feature.</p><h2>3.2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Implementation Details of Graphormer</h2><p> Graphormer is built upon the original implementation of classic Transformer encoder described in [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark65\">49</a>]. In addition, we apply the layer normalization (LN) before the multi-head self-attention (MHA) and the feed-forward blocks (FFN) instead of after [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark70\">53</a>]. This modification has been unanimously adopted by all current Transformer implementations because it leads to more effective optimization [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark59\">43</a>]. Especially, for FFN sub-layer, we set the dimensionality of input, output, and the inner-layer to the same dimension with . We formally characterize the Graphormer layer as below:</p><p> As stated in the previous section, various graph pooling functions are proposed to represent the graph embedding. Inspired by [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark32\">15</a>], in Graphormer, we add a special node called [VNode] to the graph, and make connection between [VNode] and each node individually. In the AGGREGATE-COMBINE step, the representation of [VNode] has been updated as normal nodes in graph, and the representation of the entire graph  would be the node feature of [VNode] in the final layer. In the BERT model [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark28\">11</a>, <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark52\">35</a>], there is a similar token, i.e., [CLS], which is a special token attached at the beginning of each sequence, to represent the sequence-level feature on downstream tasks. While the [VNode] is connected to all other nodes in graph, which means the distance of the shortest path is 1 for any ([VNode]) and ( [VNode]), the connection is not physical. To distinguish the connection of physical and virtual, inspired by [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark41\">25</a>], we reset all spatial encodings for ([VNode] ) and ([VNode]) to a distinct learnable scalar.</p><h2>3.3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; How Powerful is Graphormer?</h2><p>In the previous subsections, we introduce three structural encodings and the architecture of Graphormer. Then a natural question is: <em>Do these modifications make Graphormer more powerful than other GNN variants?</em> In this subsection, we first give an affirmative answer by showing that Graphormer can represent the AGGREGATE and COMBINE steps in popular GNN models:</p><p><em>By choosing proper weights and distance function œÜ, the Graphormer layer can represent AGGREGATE and COMBINE steps of popular GNN models such as GIN, GCN, GraphSAGE.</em></p><p>The proof sketch to derive this result is: 1) Spatial encoding enables self-attention module to distinguish neighbor set N (vi) of node vi so that the softmax function can calculate mean statistics over N (vi); 2) Knowing the degree of a node, mean over neighbors can be translated to sum over neighbors; 3) With multiple heads and FFN, representations of vi and N (vi) can be processed separately and combined together later. We defer the proof of this fact to Appendix A.</p><p>Moreover, we show further that by using our spatial encoding, Graphormer can go beyond classic message passing GNNs whose expressive power is no more than the 1-Weisfeiler-Lehman (WL) test. We give a concrete example in Appendix A to show how Graphormer helps distinguish graphs that the 1-WL test fails to.</p><p><strong>Connection between Self-attention and Virtual Node.</strong> Besides the superior expressiveness than popular GNNs, we also find an interesting connection between using self-attention and the virtual node heuristic [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark32\">15</a>, <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark48\">31</a>, <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark42\">24</a>, <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark39\">22</a>]. As shown in the leaderboard of OGB [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark39\">22</a>], the virtual node trick, which augments graphs with additional supernodes that are connected to all nodes in the original graphs, can significantly improve the performance of existing GNNs. Conceptually, the benefit of the virtual node is that it can aggregate the information of the  (like the READOUT function) and then propagate it to . However, a naive addition of a supernode to a graph can potentially lead to inadvertent over-smoothing of information propagation [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark42\">24</a>]. We instead find that such a graph-level aggregation and propagation operation can be naturally fulfilled by vanilla self-attention without additional encodings. Concretely, we can prove the following fact:</p><p><em>By choosing proper weights, every node representation of the output of a Graphormer layer without additional encodings can represent MEAN READOUT functions.</em></p><p>This fact takes the advantage of self-attention that each node can attend to all other nodes. Thus it can simulate graph-level READOUT operation to aggregate information from the whole graph. Besides the theoretical justification, we empirically find that Graphormer does not encounter the problem of over-smoothing, which makes the improvement scalable. The fact also inspires us to introduce a special node for graph readout (see the previous subsection).</p><p>We first conduct experiments on the recent OGB-LSC [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark38\">21</a>] quantum chemistry regression (i.e., PCQM4M-LSC) challenge, which is currently the biggest graph-level prediction dataset and contains more than 3.8M graphs in total. Then, we report the results on the other three popular tasks: ogbg-molhiv, ogbg-molpcba and ZINC, which come from the OGB [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark39\">22</a>] and benchmarking-GNN [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark31\">14</a>] leaderboards. Finally, we ablate the important design elements of Graphormer. A detailed description of datasets and training strategies could be found in Appendix B.</p><h2>4.1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; OGB Large-Scale Challenge</h2><p> We benchmark the proposed Graphormer with GCN [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark43\">26</a>] and GIN [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark71\">54</a>], and their variants with virtual node (-VN) [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark32\">15</a>]. They achieve the state-of-the-art valid and test mean absolute error (MAE) on the official leaderboard<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark10\">4</a> [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark38\">21</a>]. In addition, we compare to GIN‚Äôs multi-hop variant [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark21\">5</a>], and 12-layer deep graph network DeeperGCN [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark47\">30</a>], which also show promising performance on other leaderboards. We further compare our Graphormer with the recent Transformer-based graph model GT <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark30\">[13].</a></p><p>\\\n&nbsp; We primarily report results on two model sizes:  ( = 12*, d* = 768), and a smaller one  ( = 6*, d* = 512). Both the number of attention heads in the attention module and the dimensionality of edge features  are set to 32. We use AdamW as the optimizer, and set the hyper-parameter  to 1e-8 and (1*, Œ≤*2) to (0.99,0.999). The peak learning rate is set to 2e-4 (3e-4 for ) with a 60k-step warm-up stage followed by a linear decay learning rate scheduler. The total training steps are 1M. The batch size is set to 1024. All models are trained on 8 NVIDIA V100 GPUS for about 2 days.</p><p>\\\n Table <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark11\">1</a> summarizes performance comparisons on PCQM4M-LSC dataset. From the table, GIN-VN achieves the previous state-of-the-art validate MAE of 0.1395. The original implementation of GT [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark30\">13</a>] employs a hidden dimension of 64 to reduce the total number of parameters. For a fair comparison, we also report the result by enlarging the hidden dimension to 768, denoted by GT-Wide, which leads to a total number of parameters of 83.2M. While, both GT and GT-Wide do not outperform GIN-VN and DeeperGCN-VN. Especially, we do not observe a performance gain along with the growth of parameters of GT.</p><p>Compared to the previous state-of-the-art GNN architecture, Graphormer noticeably surpasses GIN-VN by a large margin, e.g., 11.5% relative validate MAE decline. By using the ensemble with ExpC [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark72\">55</a>], we got a 0.1200 MAE on complete test set and won the first place of the graph-level track in OGB Large-Scale Challenge[<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark38\">21</a>, <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark75\">58</a>]. As stated in Section <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark7\">3.3,</a> we further find that the proposed Graphormer does not encounter the problem of over-smoothing, i.e., the train and validate error keep going down along with the growth of depth and width of models.</p><h2>4.2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Graph Representation</h2><p>In this section, we further investigate the performance of Graphormer on commonly used graph-level prediction tasks of popular leaderboards, i.e., OGB [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark39\">22</a>] (OGBG-MolPCBA, OGBG-MolHIV), and benchmarking-GNN [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark31\">14</a>] (ZINC). Since pre-training is encouraged by OGB, we mainly explore the transferable capability of a Graphormer model pre-trained on OGB-LSC (i.e., PCQM4M-LSC). Please note that the model configurations, hyper-parameters, and the pre-training performance of pre-trained Graphormers used for MolPCBA and MolHIV are different from the models used in the previous subsection. Please refer to Appendix B for detailed descriptions. For benchmarking-GNN, which does not encourage large pre-trained model, we train an additional GraphormerSLIM ( = 12*, d* = 80, total param.= 489) from scratch on ZINC.</p><p> We report performance of GNNs which achieve top-performance on the official leader-boards<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark12\">5</a><em>without additional domain-specific features</em>. Considering that the pre-trained Graphormer leverages external data, for a fair comparison on OGB datasets, we additionally report performance for fine-tuning GIN-VN pre-trained on PCQM4M-LSC dataset, which achieves the previous state-of-the-art valid and test MAE on that dataset.</p><p>\\\n We report detailed training strategies in Appendix B. In addition, Graphormer is more easily trapped in the over-fitting problem due to the large size of the model and the small size of the dataset. Therefore, we employ a widely used data augmentation for graph - FLAG [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark44\">27</a>], to mitigate the over-fitting problem on OGB datasets.</p><p>\\\n Table <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark13\">2,</a><a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark14\">3</a> and <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark15\">4</a> summarize performance of Graphormer comparing with other GNNs on MolHIV, MolPCBA and ZINC datasets. Especially, GT [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark30\">13</a>] and SAN [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark45\">28</a>] in Table <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark15\">4</a> are recently proposed Transformer-based GNN models. Graphormer consistently and significantly outperforms previous state-of-the-art GNNs on all three datasets by a large margin. Specially, except Graphormer,  the other pre-trained GNNs do not achieve competitive performance, which is in line with previous literature [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark37\">20</a>]. In addition, we conduct more comparisons to fine-tuning the pre-trained GNNs, please refer to Appendix C.</p><h2>4.3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Ablation Studies</h2><p>We perform a series of ablation studies on the importance of designs in our proposed Graphormer, on PCQM4M-LSC dataset. The ablation results are included in Table <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark16\">5.</a> To save the computation resources, the Transformer models in table <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark16\">5</a> have 12 layers, and are trained for 100K iterations.</p><p>\\\n We compare previously used positional encoding (PE) to our proposed spatial encoding, which both aim to encode the information of distinct node relation to Transformers. There are various PEs employed by previous Transformer-based GNNs, e.g., Weisfeiler-Lehman-PE (WL-PE) [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark78\">61</a>] and Laplacian PE [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark20\">3</a>, <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark31\">14</a>]. We report the performance for Laplacian PE since it performs well comparing to a series of PEs for Graph Transformer in previous literature [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark30\">13</a>]. Transformer architecture with the spatial encoding outperforms the counterpart built on the positional encoding, which demonstrates the effectiveness of using spatial encoding to capture the node spatial information.</p><p>\\\n Transformer architecture with degree-based centrality encoding yields a large margin performance boost in comparison to those without centrality information. This indicates that the centrality encoding is indispensable to Transformer architecture for modeling graph data.</p><p>\\\n We compare our proposed edge encoding (denoted as via attn bias) to two commonly used edge encodings described in Section <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark5\">3.1.3</a> to incorporate edge features into GNN, denoted as via node and via Aggr in Table <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark16\">5.</a> From the table, the gap of performance is minor between the two conventional methods, but our proposed edge encoding performs significantly better, which indicates that edge encoding as attention bias is more effective for Transformer to capture spatial information on edges.</p><p>In this section, we highlight the most recent works which attempt to develop standard Transformer architecture-based GNN or graph structural encoding, but spend less effort on elaborating the works by adapting attention mechanism to GNNs <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark50\">[33,</a><a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark77\">60,</a><a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark24\">7,</a><a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark40\">23,</a><a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark18\">1,</a><a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark67\">50,</a><a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark68\">51,</a><a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark78\">61,</a><a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark66\">48].</a></p><p>There are several works that study the performance of pure Transformer architectures (stacked by transformer layers) with modifications on graph representation tasks, which are more related to our Graphormer. For example, several parts of the transformer layer are modified in [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark63\">46</a>], including an additional GNN employed in attention sub-layer to produce vectors of , , and  , long-range residual connection, and two branches of FFN to produce node and edge representations separately. They pre-train their model on 10 million unlabelled molecules and achieve excellent results by fine-tuning on downstream tasks. Attention module is modified to a soft adjacency matrix in [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark58\">41</a>] by directly adding the adjacency matrix and RDKit<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark17\">6</a>-computed inter-atomic distance matrix to the attention probabilites. Very recently, Dwivedi  [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark30\">13</a>] revisit a series of works for Transformer-based GNNs, and suggest that the attention mechanism in Transformers on graph data should only aggregate the information from neighborhood (i.e., using adjacent matrix as attention mask) to ensure graph sparsity, and propose to use Laplacian eigenvector as positional encoding. Their model GT surpasses baseline GNNs on graph representation task. A concurrent work [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark45\">28</a>] propose a novel full Laplacian spectrum to learn the position of each node in a graph, and empirically shows better results than GT.</p><h2>5.2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Structural Encodings in GNNs</h2><p><strong>Path and Distance in GNNs.</strong> Information of path and distance is commonly used in GNNs. For example, an attention-based aggregation is proposed in [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark26\">9</a>] where the node features, edge features, one-hot feature of the distance and ring flag feature are concatenated to calculate the attention probabilites; similar to <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark26\">[9],</a> path-based attention is leveraged in <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark73\">[56]</a> to model the influence between the center node and its higher-order neighbors; a distance-weighted aggregation scheme on graph is proposed in [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark76\">59</a>]; it has been proved in [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark49\">32</a>] that adopting distance encoding (i.e., one-hot feature of the distance as extra node attribute) could lead to a strictly more expressive power than the 1-WL test.</p><p>\\\n<strong>Positional Encoding in Transformer on Graph.</strong> Several works introduce positional encoding (PE) to Transformer-based GNNs to help the model capture the node position information. For example, Graph-BERT [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark78\">61</a>] introduces three types of PE to embed the node position information to model, i.e., an absolute WL-PE which represents different nodes labeled by Weisfeiler-Lehman algorithm, an intimacy based PE and a hop based PE which are both variant to the sampled subgraphs. Absolute Laplacian PE is employed in [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark30\">13</a>] and empircal study shows that its performance surpasses the absolute WL-PE used in <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark78\">[61].</a></p><p>\\\n Except the conventionally used methods to encode edge feature, which are described in previous section, there are several attempts that exploit how to better encode edge features: an attention-based GNN layer is developed in [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark33\">16</a>] to encode edge features, where the edge feature is weighted by the similarity of the features of its two nodes; edge feature has been encoded into the popular GIN [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark71\">54</a>] in [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark21\">5</a>]; in [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark30\">13</a>], the authors propose to project edge features to an embedding vector, then multiply it by attention coefficients, and send the result to an additional FFN sub-layer to produce edge representations;</p><p>We have explored the direct application of Transformers to graph representation. With three novel graph structural encodings, the proposed Graphormer works surprisingly well on a wide range of popular benchmark datasets. While these initial results are encouraging, many challenges remain. For example, the quadratic complexity of the self-attention module restricts Graphormer‚Äôs application on large graphs. Therefore, future development of efficient Graphormer is necessary. Performance improvement could be expected by leveraging domain knowledge-powered encodings on particular graph datasets. Finally, an applicable graph sampling strategy is desired for node representation extraction with Graphormer. We leave them for future works.</p><p>We would like to thank Mingqi Yang and Shanda Li for insightful discussions.</p><p>[1]&nbsp;&nbsp;&nbsp; Jinheon Baek, Minki Kang, and Sung Ju Hwang. Accurate learning of graph representations with graph multiset pooling. , 2021.</p><p>[2]&nbsp;&nbsp;&nbsp; Dominique Beaini, Saro Passaro, Vincent L√©tourneau, William L Hamilton, Gabriele Corso, and Pietro Li√≤. Directional graph networks. In <em>International Conference on Machine Learning</em>, 2021.</p><p>[3]&nbsp;&nbsp;&nbsp; Mikhail Belkin and Partha Niyogi. Laplacian eigenmaps for dimensionality reduction and data representa-tion. , 15(6):1373‚Äì1396, 2003.</p><p>[4]&nbsp;&nbsp;&nbsp; Xavier Bresson and Thomas Laurent. Residual gated graph convnets. <em>arXiv preprint arXiv:1711.07553</em>, 2017.</p><p>[5]&nbsp;&nbsp;&nbsp; R√©my Brossard, Oriel Frigo, and David Dehaene. Graph convolutions that can finally model local structure.</p><p><em>arXiv preprint arXiv:2011.15069</em>, 2020.</p><p>[6]&nbsp;&nbsp;  Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. Language models are few-shot learners. In H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin, editors, <em>Advances in Neural Information Processing Systems</em>, volume 33, pages 1877‚Äì1901. Curran Associates, Inc., 2020.</p><p>[7]&nbsp;&nbsp;  Deng Cai and Wai Lam. Graph transformer for graph-to-sequence learning. In <em>Proceedings of the AAAI Conference on Artificial Intelligence</em>, volume 34, pages 7464‚Äì7471, 2020.</p><p>[8]&nbsp;&nbsp;&nbsp; Tianle Cai, Shengjie Luo, Keyulu Xu, Di He, Tie-yan Liu, and Liwei Wang. Graphnorm: A principled approach to accelerating graph neural network training. In <em>International Conference on Machine Learning</em>, 2021.</p><p>[9]&nbsp;&nbsp;&nbsp; Benson Chen, Regina Barzilay, and Tommi Jaakkola. Path-augmented graph transformer network. <em>arXiv preprint arXiv:1905.12712</em>, 2019.</p><p>[10]&nbsp;&nbsp;&nbsp; Gabriele Corso, Luca Cavalleri, Dominique Beaini, Pietro Li√≤, and Petar VelicÀákovic¬¥. Principal neighbour-hood aggregation for graph nets. <em>Advances in Neural Information Processing Systems</em>, 33, 2020.</p><p>[11]&nbsp;&nbsp;  Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep bidi-rectional transformers for language understanding. In <em>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</em>, pages 4171‚Äì4186, 2019.</p><p>[12]&nbsp;&nbsp;  Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, et al. An image is worth 16x16 words: Transformers for image recognition at scale. <em>arXiv preprint arXiv:2010.11929</em>, 2020.</p><p>[13]&nbsp;&nbsp;  Vijay Prakash Dwivedi and Xavier Bresson. A generalization of transformer networks to graphs. <em>AAAI Workshop on Deep Learning on Graphs: Methods and Applications</em>, 2021.</p><p>[14]&nbsp;&nbsp;&nbsp; Vijay Prakash Dwivedi, Chaitanya K Joshi, Thomas Laurent, Yoshua Bengio, and Xavier Bresson. Bench-marking graph neural networks. <em>arXiv preprint arXiv:2003.00982</em>, 2020.</p><p>[15]&nbsp;&nbsp;&nbsp; Justin Gilmer, Samuel S Schoenholz, Patrick F Riley, Oriol Vinyals, and George E Dahl. Neural message passing for quantum chemistry. In <em>International Conference on Machine Learning</em>, pages 1263‚Äì1272. PMLR, 2017.</p><p>[16]&nbsp;&nbsp;&nbsp; Liyu Gong and Qiang Cheng. Exploiting edge features for graph neural networks. In <em>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pages 9211‚Äì9219, 2019.</p><p>[17]&nbsp;&nbsp;&nbsp; Anmol Gulati, James Qin, Chung-Cheng Chiu, Niki Parmar, Yu Zhang, Jiahui Yu, Wei Han, Shibo Wang, Zhengdong Zhang, Yonghui Wu, et al. Conformer: Convolution-augmented transformer for speech recognition. <em>arXiv preprint arXiv:2005.08100</em>, 2020.</p><p>[18]&nbsp;&nbsp;&nbsp; William L Hamilton, Zhitao Ying, and Jure Leskovec. Inductive representation learning on large graphs. In , 2017.</p><p>[19]&nbsp;&nbsp;&nbsp; Vincent J Hellendoorn, Charles Sutton, Rishabh Singh, Petros Maniatis, and David Bieber. Global relational models of source code. In <em>International conference on learning representations</em>, 2019.</p><p>[20]&nbsp;&nbsp;&nbsp; W Hu, B Liu, J Gomes, M Zitnik, P Liang, V Pande, and J Leskovec. Strategies for pre-training graph neural networks. In <em>International Conference on Learning Representations (ICLR)</em>, 2020.</p><p>[21]&nbsp;&nbsp;&nbsp; Weihua Hu, Matthias Fey, Hongyu Ren, Maho Nakata, Yuxiao Dong, and Jure Leskovec. Ogb-lsc: A large-scale challenge for machine learning on graphs. <em>arXiv preprint arXiv:2103.09430</em>, 2021.</p><p>[22]&nbsp;&nbsp;&nbsp; Weihua Hu, Matthias Fey, Marinka Zitnik, Yuxiao Dong, Hongyu Ren, Bowen Liu, Michele Catasta, and Jure Leskovec. Open graph benchmark: Datasets for machine learning on graphs. <em>arXiv preprint arXiv:2005.00687</em>, 2020.</p><p>[23]&nbsp;&nbsp;&nbsp; Ziniu Hu, Yuxiao Dong, Kuansan Wang, and Yizhou Sun. Heterogeneous graph transformer. In <em>Proceedings of The Web Conference 2020</em>, pages 2704‚Äì2710, 2020.</p><p>[24]&nbsp;&nbsp;&nbsp; Katsuhiko Ishiguro, Shin-ichi Maeda, and Masanori Koyama. Graph warp module: an auxiliary module for boosting the power of graph neural networks in molecular graph analysis. <em>arXiv preprint arXiv:1902.01020</em>, 2019.</p><p>[25]&nbsp;&nbsp;&nbsp; Guolin Ke, Di He, and Tie-Yan Liu. Rethinking the positional encoding in language pre-training. , 2020.</p><p>[26]&nbsp;&nbsp;&nbsp; Thomas N Kipf and Max Welling. Semi-supervised classification with graph convolutional networks.</p><p><em>arXiv preprint arXiv:1609.02907</em>, 2016.</p><p>[27]&nbsp;&nbsp;&nbsp; Kezhi Kong, Guohao Li, Mucong Ding, Zuxuan Wu, Chen Zhu, Bernard Ghanem, Gavin Taylor, and Tom Goldstein. Flag: Adversarial data augmentation for graph neural networks. <em>arXiv preprint arXiv:2010.09891</em>, 2020.</p><p>[28]&nbsp;&nbsp;&nbsp; Devin Kreuzer, Dominique Beaini, William Hamilton, Vincent L√©tourneau, and Prudencio Tossou. Re-thinking graph transformers with spectral attention. <em>arXiv preprint arXiv:2106.03893</em>, 2021.</p><p>[29]&nbsp;&nbsp;&nbsp; Tuan Le, Marco Bertolini, Frank No√©, and Djork-Arn√© Clevert. Parameterized hypercomplex graph neural networks for graph classification. <em>arXiv preprint arXiv:2103.16584</em>, 2021.</p><p>[30]&nbsp;&nbsp;&nbsp; Guohao Li, Chenxin Xiong, Ali Thabet, and Bernard Ghanem. Deepergcn: All you need to train deeper gcns. <em>arXiv preprint arXiv:2006.07739</em>, 2020.</p><p>[31]&nbsp;&nbsp;&nbsp; Junying Li, Deng Cai, and Xiaofei He. Learning graph-level representation for drug discovery. <em>arXiv preprint arXiv:1709.03741</em>, 2017.</p><p>[32]&nbsp;&nbsp;  Pan Li, Yanbang Wang, Hongwei Wang, and Jure Leskovec. Distance encoding: Design provably more powerful neural networks for graph representation learning. <em>Advances in Neural Information Processing Systems</em>, 33, 2020.</p><p>[33]&nbsp;&nbsp;&nbsp; Yuan Li, Xiaodan Liang, Zhiting Hu, Yinbo Chen, and Eric P. Xing. Graph transformer, 2019.</p><p>[34]&nbsp;&nbsp;&nbsp; Xi Victoria Lin, Richard Socher, and Caiming Xiong. Multi-hop knowledge graph reasoning with reward shaping. <em>arXiv preprint arXiv:1808.10568</em>, 2018.</p><p>[35]&nbsp;&nbsp;&nbsp; Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. Roberta: A robustly optimized bert pretraining approach. <em>arXiv preprint arXiv:1907.11692</em>, 2019.</p><p>[36]&nbsp;&nbsp;&nbsp; Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and Baining Guo. Swin transformer: Hierarchical vision transformer using shifted windows. <em>arXiv preprint arXiv:2103.14030</em>, 2021.</p><p>[37]&nbsp;&nbsp;  Shengjie Luo, Shanda Li, Tianle Cai, Di He, Dinglan Peng, Shuxin Zheng, Guolin Ke, Liwei Wang, and Tie-Yan Liu. Stable, fast and accurate: Kernelized attention with relative positional encoding. , 2021.</p><p>[38]&nbsp;&nbsp;&nbsp; Haggai Maron, Heli Ben-Hamu, Hadar Serviansky, and Yaron Lipman. Provably powerful graph networks. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alch√©-Buc, E. Fox, and R. Garnett, editors, <em>Advances in Neural Information Processing Systems</em>, volume 32. Curran Associates, Inc., 2019.</p><p>[39]&nbsp;&nbsp;&nbsp; P David Marshall. The promotion and presentation of the self: celebrity as marker of presentational media.</p><p>, 1(1):35‚Äì48, 2010.</p><p>[40]&nbsp;&nbsp;  Alice Marwick and Danah Boyd. To see and be seen: Celebrity practice on twitter. , 17(2):139‚Äì158, 2011.</p><p>[41]&nbsp;&nbsp;&nbsp; ≈Åukasz Maziarka, Tomasz Danel, S≈Çawomir Mucha, Krzysztof Rataj, Jacek Tabor, and Stanis≈Çaw JastrzeÀõbski. Molecule attention transformer. <em>arXiv preprint arXiv:2002.08264</em>, 2020.</p><p>[42]&nbsp;&nbsp;&nbsp; Maho Nakata and Tomomi Shimazaki. Pubchemqc project: a large-scale first-principles electronic structure database for data-driven chemistry. <em>Journal of chemical information and modeling</em>, 57(6):1300‚Äì1308, 2017.</p><p>[43]&nbsp;&nbsp;&nbsp; Sharan Narang, Hyung Won Chung, Yi Tay, William Fedus, Thibault Fevry, Michael Matena, Karishma Malkan, Noah Fiedel, Noam Shazeer, Zhenzhong Lan, et al. Do transformer modifications transfer across implementations and applications? <em>arXiv preprint arXiv:2102.11972</em>, 2021.</p><p>[44]&nbsp;&nbsp;&nbsp; Dinglan Peng, Shuxin Zheng, Yatao Li, Guolin Ke, Di He, and Tie-Yan Liu. How could neural networks understand programs? In <em>International Conference on Machine Learning</em>. PMLR, 2021.</p><p>[45]&nbsp;&nbsp;  Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. Exploring the limits of transfer learning with a unified text-to-text transformer. <em>Journal of Machine Learning Research</em>, 21(140):1‚Äì67, 2020.</p><p>[46]&nbsp;&nbsp;  Yu Rong, Yatao Bian, Tingyang Xu, Weiyang Xie, Ying Wei, Wenbing Huang, and Junzhou Huang. Self-supervised graph transformer on large-scale molecular data. <em>Advances in Neural Information Processing Systems</em>, 33, 2020.</p><p>[47]&nbsp;&nbsp;  Peter Shaw, Jakob Uszkoreit, and Ashish Vaswani. Self-attention with relative position representations. In <em>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)</em>, pages 464‚Äì468, 2018.</p><p>[48]&nbsp;&nbsp;&nbsp; Yunsheng Shi, Zhengjie Huang, Wenjin Wang, Hui Zhong, Shikun Feng, and Yu Sun. Masked label predic-tion: Unified message passing model for semi-supervised classification. <em>arXiv preprint arXiv:2009.03509</em>, 2020.</p><p>[49]&nbsp;&nbsp;&nbsp; Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. In , 2017.</p><p>[50]&nbsp;&nbsp;&nbsp; Petar VelicÀákovic¬¥, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. Graph attention networks. , 2018.</p><p>[51]&nbsp;&nbsp;&nbsp; Guangtao Wang, Rex Ying, Jing Huang, and Jure Leskovec. Direct multi-hop attention based graph neural network. <em>arXiv preprint arXiv:2009.14332</em>, 2020.</p><p>[52]&nbsp;&nbsp;&nbsp; Sinong Wang, Belinda Li, Madian Khabsa, Han Fang, and Hao Ma. Linformer: Self-attention with linear complexity. <em>arXiv preprint arXiv:2006.04768</em>, 2020.</p><p>[53]&nbsp;&nbsp;  Ruibin Xiong, Yunchang Yang, Di He, Kai Zheng, Shuxin Zheng, Chen Xing, Huishuai Zhang, Yanyan Lan, Liwei Wang, and Tieyan Liu. On layer normalization in the transformer architecture. In <em>International Conference on Machine Learning</em>, pages 10524‚Äì10533. PMLR, 2020.</p><p>[54]&nbsp;&nbsp;&nbsp; Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. How powerful are graph neural networks? In <em>International Conference on Learning Representations</em>, 2019.</p><p>[55]&nbsp;&nbsp;&nbsp; Mingqi Yang, Yanming Shen, Heng Qi, and Baocai Yin. Breaking the expressive bottlenecks of graph neural networks. <em>arXiv preprint arXiv:2012.07219</em>, 2020.</p><p>[56]&nbsp;&nbsp;&nbsp; Yiding Yang, Xinchao Wang, Mingli Song, Junsong Yuan, and Dacheng Tao. Spagan: Shortest path graph attention network. , 2019.</p><p>[57]&nbsp;&nbsp;&nbsp; Chengxuan Ying, Guolin Ke, Di He, and Tie-Yan Liu. Lazyformer: Self attention with lazy update. <em>arXiv preprint arXiv:2102.12702</em>, 2021.</p><p>[58]&nbsp;&nbsp;  Chengxuan Ying, Mingqi Yang, Shuxin Zheng, Guolin Ke, Shengjie Luo, Tianle Cai, Chenglin Wu, Yuxin Wang, Yanming Shen, and Di He. First place solution of kdd cup 2021 &amp; ogb large-scale challenge graph-level track. <em>arXiv preprint arXiv:2106.08279</em>, 2021.</p><p>[59]&nbsp;&nbsp;  Jiaxuan You, Rex Ying, and Jure Leskovec. Position-aware graph neural networks. In <em>International Conference on Machine Learning</em>, pages 7134‚Äì7143. PMLR, 2019.</p><p>[60]&nbsp;&nbsp;&nbsp; Seongjun Yun, Minbyul Jeong, Raehyun Kim, Jaewoo Kang, and Hyunwoo J Kim. Graph transformer networks. <em>Advances in Neural Information Processing Systems</em>, 32, 2019.</p><p>[61]&nbsp;&nbsp;&nbsp; Jiawei Zhang, Haopeng Zhang, Congying Xia, and Li Sun. Graph-bert: Only attention is needed for learning graph representations. <em>arXiv preprint arXiv:2001.05140</em>, 2020.</p><p>[62]&nbsp;&nbsp;&nbsp; Chen Zhu, Yu Cheng, Zhe Gan, Siqi Sun, Tom Goldstein, and Jingjing Liu. Freelb: Enhanced adversarial training for natural language understanding. In , 2020.</p><p>[63]&nbsp;&nbsp;  Daniel Z√ºgner, Tobias Kirschstein, Michele Catasta, Jure Leskovec, and Stephan G√ºnnemann. Language-agnostic representation learning of source code from structure and context. In <em>International Conference on Learning Representations</em>, 2020.</p><h2>A.1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; SPD can Be Used to Improve WL-Test</h2><p>\\\n1-WL-test fails in many cases [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark54\">38</a>, <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark49\">32</a>], thus classic message passing GNNs also fail to distinguish many pairs of graphs. We show that SPD might help when 1-WL-test fails, for example, in Figure <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark81\">2</a> where 1-WL-test fails, the sets of SPD from all nodes to others successfully distinguish the two graphs.</p><p> We begin by showing that self-attention module with Spatial Encoding can repre-sent MEAN aggregation. This is achieved by in Eq. <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark4\">(6)</a>: 1) setting  = 0 if  = 1 and  =  otherwise where  is the SPD; 2) setting  =  = 0 and  to be the identity matrix. Then softmax ()  gives the average of representations of the neighbors.</p><p>\\\n The SUM aggregation can be realized by first perform MEAN aggregation and then multiply the node degrees. Specifically, the node degrees can be extracted from Centrality Encoding by an additional head and be concatenated to the representations after MEAN aggregation. Then the FFN module in Graphormer can represent the function of multiplying the degree to the dimensions of averaged representations by the universal approximation theorem of FFN.</p><p>\\\n Representing the MAX aggregation is harder than MEAN and SUM. For each dimension  of the representation vector, we need one head to select the maximal value over -th dimension in the neighbor by in Eq. <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark4\">(6)</a>: 1) setting  = 0 if  = 1 and  =  otherwise where  is the SPD; 2) setting  =  which is the -th standard basis;  = 0 and the bias term (which is ignored in the previous description for simplicity) of  to be ; and  = , where  is the temperature that can be chosen to be large enough so that the softmax function can approximate hard max and  is the vector whose elements are all 1.</p><p>\\\n The COMBINE step takes the result of AGGREGATE and the previous representation of current node as input. This can be achieved by the AGGREGATE operations described above together with an additional head which outputs the features of present nodes, i.e., in Eq. <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark4\">(6)</a>: 1) setting  = 0 if  = 0 and  =  otherwise where  is the SPD; 2) setting  =  = 0 and  to be the identity matrix. Then the FFN module can approximate any COMBINE function by the universal approximation theorem of FFN.</p><p> This can be proved by setting  =  = 0, the bias terms of  to be , and  to be the identity matrix where  should be much larger than the scale of  so that  2T dominates the Spatial Encoding term.</p><h2>B.1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Details of Datasets</h2><p>We summarize the datasets used in this work in Table <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark82\">6.</a> PCQM4m-LSC is a quantum chemistry graph-level prediction task in recent OGB Large-Scale Challenge, originally curated under the PubChemQC project [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark60\">42</a>].</p><p>\\\nThe task of PCQM4M-LSC is to predict DFT(density functional theory)-calculated HOMO-LUMO energy gap of molecules given their 2D molecular graphs, which is one of the most practically-relevant quantum chemical properties of molecule science. PCQM4M-LSC is unprecedentedly large in scale comparing to other labeled graph-level prediction datasets, which contains more than 3.8M graphs. Besides, we conduct experiments on two molecular graph datasets in popular OGB leaderboards, i.e., OGBG-MolPCBA and OGBG-MolHIV. They are two molecular property prediction datasets with different sizes. The pre-trained knowledge of molecular graph on PCQM4M-LSC could be easily leveraged on these two datasets. We adopt official scaffold split on three datasets following [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark38\">21</a>, <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark39\">22</a>]. In addition, we employ another popular leaderboard, i.e., benchmarking-gnn [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark31\">14</a>]. We use the ZINC datasets, which is the most popular real-world molecular dataset to predict graph property regression for contrained solubility, an important chemical property for designing generative GNNs for molecules. Different from the scaffold spliting in OGB, uniform sampling is adopted in ZINC for data splitting.</p><h2>B.2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Details of Training Strategies</h2><p>\\\nWe report the detailed hyper-parameter settings used for training Graphormer in Table <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark83\">7.</a> We reduce the FFN inner-layer dimension of 4 in [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark65\">49</a>] to , which does not appreciably hurt the performance but significantly save the parameters. The embedding dropout ratio is set to 0.1 by default in many previous Transformer works [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark28\">11</a>, <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark52\">35</a>]. However, we empirically find that a small embedding dropout ratio (e.g., 0.1) would lead to an observable performance drop on validation set of PCQM4M-LSC. One possible reason is that the molecular graph is relative small (i.e., the median of #atoms in each molecule is about 15), making graph property more sensitive to the embeddings of each node. Therefore, we set embedding dropout ratio to 0 on this dataset.</p><p> We first report the model configurations and hyper-parameters of the pre-trained Graphormer on PCQM4M-LSC. Empirically, we find that the performance on MolPCBA benefits from the large pre-training model size. Therefore, we train a deep Graphormer with 18 Transformer layers on PCQM4M-LSC. The hidden dimension and FFN inner-layer dimension are set to 1024. We set peak learning rate to 1e-4 for the deep</p><p>Graphormer. Besides, we enlarge the attention dropout ratio from 0.1 to 0.3 in both pre-training and fine-tuning to prevent the model from over-fitting. The rest of hyper-parameters remain unchanged. The pre-trained Graphormer used for MolPCBA achieves a valid MAE of 0.1253 on PCQM4M-LSC, which is slightly worse than the reports in Table <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark11\">1.</a></p><p>\\\n Table <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark84\">8</a> summarizes the hyper-parameters used for fine-tuning Graphormer on OGBG-MolPCBA. We conduct a grid search for several hyper-parameters to find the optimal configuration. The experimental results are reported by the mean of 10 independent runs with random seeds. We use FLAG [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark44\">27</a>] with minor modifications for graph data augmentation. In particular, except the step size  and the number of steps , we also employ a projection step in [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark79\">62</a>] with maximum perturbation . The performance of Graphormer on MolPCBA is quite robust to the hyper-parameters of FLAG. The rest of hyper-parameters are the same with the pre-training model.</p><p>\\\n We use the Graphormer reported in Table <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark11\">1</a> as the pre-trained model for OGBG-MolHIV, where the pre-training hyper-parameters are summarized in Table <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark83\">7.</a></p><p>\\\n&nbsp; The hyper-parameters for fine-tuning Graphormer on OGBG-MolHIV are presented in Table <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark85\">9.</a> Empirically, we find that the different choices of hyper-parameters of FLAG (i.e., step size , number of steps , and maximum perturbation ) would greatly affect the performance of Graphormer on OGBG-MolHiv. Therefore, we spend more effort to conduct grid search for hyper-parameters of FLAG. We report the best hyper-parameters by the mean of 10 independent runs with random seeds.</p><p>To keep the total parameters of Graphormer less than 500K per the request from benchmarking-GNN leader-board [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark31\">14</a>], we train a slim 12-layer Graphormer with hidden dimension of 80, which is called GraphormerSLIM in Table <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark15\">4,</a> and has about 489K learnable parameters. The number of attention heads is set to 8. Table <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark86\">10</a> summarizes the detailed hyper-parameters on ZINC. We train 400K steps on this dataset, and employ a weight decay of 0.01.</p><h2>B.3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Details of Hyper-parameters for Baseline Methods</h2><p>In this section, we present the details of our re-implementation of the baseline methods.</p><p>The official Github repository of OGB-LSC<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark88\">7</a> provides hyper-parameters and codes to reproduce the results on leaderboard. These hyper-parameters work well on almost all popular GNN variants, except the DeeperGCN-VN, which results in a training divergence. Therefore, for DeeperGCN-VN, we follow the official hyper-parameter setting<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark89\">8</a> provided by the authors [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark47\">30</a>]. For a fair comparison to Graphormer, we train a 12-layer DeeperGCN. The hidden dimension is set to 600. The batch size is set to 256. The learning rate is set to 1e-3, and a step learning rate scheduler is employed with the decaying step size and the decaying factor  as 30 epochs and 0.25. The model is trained for 100 epochs.</p><p>The default dimension of laplacian PE of GT [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark30\">13</a>] is set to 8. However, it will cause 2.91% small molecules (less than 8 atoms) to be filtered out. Therefore, for GT and GT-Wide, we set the dimension of laplacian PE to 4, which results in only 0.08% filtering out. We adopt the default hyper-parameter settings described in [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark30\">13</a>], except that we decrease the learning rate to 1e-4, which leads to a better convergence on PCQM4M-LSC.</p><p>To fine-tune the pre-trained GIN-VN on MolPCBA, we follow the hyper-parameter settings provided in the original OGB paper [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark39\">22</a>]. To be more concrete, we load the pre-trained checkpoint reported in Table <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark11\">1</a> and fine-tune it on OGBG-MolPCBA dataset. We use the grid search on the hyper-parameters for better fine-tuning performance. In particular, the learning rate is selected from {1e ‚àí 5, 1e ‚àí 4, 1e ‚àí 3}; the dropout ratio is selected from {0.0, 0.1, 0.5}; the batch size is selected from {32, 64}.</p><p>Similarly, we fine-tune the pre-trained GIN-VN on MolHIV by following the hyper-parameter settings provided in the original OGB paper [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark39\">22</a>]. We also conduct the grid search to look for optimal hyper-parameters. The ranges for each hyper-parameter of grid search are the same as the previous subsection.</p><h2>C&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; More Experiments</h2><p>As described in the related work, GROVER is a Transformer-based GNN, which has 100 million parameters and pre-trained on 10 million unlabelled molecules using 250 Nvidia V100 GPUs. In this section, we report the fine-tuning scores of GROVER on MolHIV and MolPCBA, and compare with proposed Graphormer.</p><p>We download the pre-trained GROVER models from its official Github webpage<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark92\">9</a>, follow the official instruc-tions<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark93\">10</a> and fine-tune the provided pre-trained checkpoints with careful search of hyper-parameters (in Table <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark87\">11).</a> We find that GROVER could achieve competitive performance on MolHIV only if employing additional molecular features, i.e., morgan molecular finger prints and 2D features<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark94\">11</a>. Therefore, we report the scores of GROVER by taking these two additional molecular features. Please note that, from the leaderboard<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark95\">12</a>, we can know such additional molecular features are very effective on MolHIV dataset.</p><p>Table <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark90\">12</a>&nbsp;and <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark91\">13</a>&nbsp;summarize the performance of GROVER and GROVERLARGE comparing with Graphormer on MolHIV and MolPCBA. From the tables, we observe that Graphormer could consistently outperform GROVER even without any additional molecular features.</p><h2>D&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Discussion &amp; Future Work</h2><p> Similar to regular Transformer, the attention mechanism in Graphormer scales quadratically with the number of nodes  in the input graph, which may be prohibitively expensive for large  and precludes its usage in settings with limited computational resources. Recently, many solutions have been proposed to address this problem in Transformer [<a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark41\">25</a>, <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark69\">52</a>, <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark74\">57</a>, <a href=\"https://hackernoon.com/microsofts-graphormer-the-transformer-that-finally-beats-gnns?source=rss#_bookmark55\">37</a>]. This issue would be greatly benefit from the future development of efficient Graphormer.</p><p>\\\n. In Graphormer, there are multiple choices for the network centrality and the spatial encoding function ( ). For example, one can leverage the 2 distance in 3D structure between two atoms in a molecule. In this paper, we mainly evaluate general centrality and distance metric in graph theory, i.e., the degree centrality and the shortest path. Performance improvement could be expected by leveraging domain knowledge powered encodings on particular graph dataset.</p><p>\\\n There is a wide range of node representation tasks on graph structured data, such as finance, social network, and temporal prediction. Graphormer could be naturally used for node representation extraction with an applicable graph sampling strategy. We leave it for future work.</p><p>:::info\nThis paper is&nbsp;<a href=\"https://arxiv.org/abs/2106.05234\">available on arxiv</a>&nbsp;under CC by 4.0 Deed (Attribution 4.0 International) license.</p>",
      "contentLength": 54662,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Servo Browser Engine Starts 2026 With Many Notable Improvements",
      "url": "https://www.phoronix.com/news/Servo-January-2026",
      "date": 1772288462,
      "author": "Michael Larabel",
      "guid": 49138,
      "unread": true,
      "content": "<article>The Servo project has issued their January 2026 development report that highlights all the interesting changes they made to this open-source browser layout engine last month. With Servo 0.0.5 they have landed many improvements to this engine and also continuing to enhance its ability to embed Servo inside other applications...</article>",
      "contentLength": 328,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Top 3 Crypto Presales to Buy in 2026: Pepeto vs BlockDAG vs Mutuum Finance Before the Next Bull Run",
      "url": "https://hackernoon.com/top-3-crypto-presales-to-buy-in-2026-pepeto-vs-blockdag-vs-mutuum-finance-before-the-next-bull-run?source=rss",
      "date": 1772287570,
      "author": "Tokenwire",
      "guid": 49163,
      "unread": true,
      "content": "<p>Every crypto bull run created a new wave of millionaires. But those millionaires did not buy after the rally started. They bought during the fear. They bought presales at fractions of a cent while everyone else waited for confirmation. By the time confirmation arrived, the 50x windows had already closed.</p><p>A presale is when a project sells tokens before they list on exchanges. The price is locked far below what it trades for on launch day. Early SHIB investors turned $1,000 into over $1 million. PEPE made early holders rich in weeks. The pattern repeats every cycle. Three projects stand out right now. Pepeto, BlockDAG, and Mutuum Finance each offer presale access. But the upside between them is not close.</p><h3>Pepeto: The One That Goes Viral</h3><p>Most presales sell you a concept. Pepeto is selling you the infrastructure for the entire meme coin economy. That changes everything. Instead of betting on one token to pump, you are buying the trading layer that profits no matter which meme coin takes off next.</p><p>PepetoSwap is a zero tax cross chain swap announced by the team and close to being ready. The Pepeto Bridge moves tokens between blockchains. The Pepeto Exchange is a meme coin listing hub approaching launch. A cofounder of the original Pepe token leads the build. Dual audits from SolidProof and Coinsult confirmed zero critical findings. The presale has already raised $7.33 million with 70% of supply filled, as reported by .</p><p>At $0.000000186, the math is simple. A 50x rally turns $1,000 into $50,000. A 100x turns it into $100,000. That is not speculation. Shiba Inu hit a $40 billion market cap with zero products. PEPE reached $7 billion on memes alone. Pepeto has three products approaching launch and a Binance listing on the horizon. Staking at 211% APY means a $3,000 hold generates $6,330 in yearly rewards while you wait. But staking is the bonus. The real play is the multiple. Community growth is accelerating and social channels are exploding. This is the presale that goes viral.</p><h3>BlockDAG: Strong Concept, Different Timeline</h3><p>BlockDAG combines Proof of Work security with a DAG structure that processes transactions in parallel. The presale has raised over $450 million, one of the largest totals this cycle. That gives the team serious funding for development.</p><p>But with $450 million already raised, much of the early upside may be priced in. Investors are now looking at 2x to 3x returns rather than exponential multiples. For steady growth from a large infrastructure play, BlockDAG makes sense. But it is a different bet than a presale at six zeros.</p><h3>Mutuum Finance: DeFi Lending With Utility</h3><p>Mutuum Finance focuses on decentralized lending and borrowing. Users supply assets to earn yield or borrow against holdings. The model mirrors established protocols but targets a newer audience.</p><p>The concept is solid with proven demand. But the returns profile looks more like a 2x to 5x play based on current valuations. Why target a 3x return when a presale at six zeros offers 50x with logic and 100x with momentum?</p><h2>Why Presales Create the Biggest Returns</h2><p>Exchange listed tokens already have price discovery behind them. You buy after millions set the floor. Presales flip that. You buy before the crowd, before the listing, before social media drives the second wave. Every cycle, the biggest winners come from presale entries, as reported by .</p><p>BlockDAG and Mutuum Finance both have real utility. But utility alone does not create 50x returns. Pepeto combines meme coin virality with real infrastructure, a Pepe cofounder, dual audits, and a Binance listing approaching. The presale is 70% filled. SHIB created millionaires with zero products. DOGE created millionaires with a joke. Pepeto has three products and the viral energy to match. At $0.000000186, this is the presale window that closes permanently once listing day arrives.</p><p><strong>What is a crypto presale and why does it matter?</strong></p><p>A presale lets you buy tokens before they list on exchanges. Prices are locked at early stage levels, which is how early SHIB and PEPE investors turned small amounts into life changing wealth.</p><p><strong>Is Pepeto better than BlockDAG for 2026 returns?</strong></p><p>BlockDAG raised $450 million, so much of the upside may be priced in. Pepeto at $0.000000186 offers 50x to 100x potential because it combines meme virality with real infrastructure at six zeros.</p><p><strong>Can you still make money from crypto presales?</strong></p><p>Every bull run creates new presale millionaires. The key is entering before exchange listings and choosing projects with both utility and viral community momentum.</p><p>:::warning\nThis article is for informational purposes only and does not constitute investment advice. Cryptocurrencies are speculative, complex, and involve high risks. This can mean high prices volatility and potential loss of your initial investment. You should consider your financial situation, investment purposes, and consult with a financial advisor before making any investment decisions. The HackerNoon editorial team has only verified the story for grammatical accuracy and does not endorse or guarantee the accuracy, reliability, or completeness of the information stated in this article. #DYOR</p>",
      "contentLength": 5136,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "This Power Grid Pioneer‚Äôs EV Prediction Came 100 Years Too Soon",
      "url": "https://spectrum.ieee.org/charles-proteus-steinmetz",
      "date": 1772287202,
      "author": "Allison Marsh",
      "guid": 49127,
      "unread": true,
      "content": "<p>Charles Proteus Steinmetz envisioned 1 million EVs on U.S. roads by 1924</p>",
      "contentLength": 72,
      "flags": null,
      "enclosureUrl": "https://spectrum.ieee.org/media-library/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpbWFnZSI6Imh0dHBzOi8vYXNzZXRzLnJibC5tcy82NTAwNTE2My9vcmlnaW4uanBnIiwiZXhwaXJlc19hdCI6MTgxNzYwMTY1MH0.gQFh0swv0bV--uDHDQUpGn4OsJf_1LmAfnGnOMsfrPI/image.jpg?width=600",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Google Quantum-Proofs HTTPS",
      "url": "https://tech.slashdot.org/story/26/02/28/027202/google-quantum-proofs-https?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1772283600,
      "author": "BeauHD",
      "guid": 49116,
      "unread": true,
      "content": "An anonymous reader quotes a report from Ars Technica: Google on Friday unveiled its plan for its Chrome browser to secure HTTPS certificates against quantum computer attacks without breaking the Internet. The objective is a tall order. The quantum-resistant cryptographic data needed to transparently publish TLS certificates is roughly 40 times bigger than the classical cryptographic material used today. Today's X.509 certificates are about 64 bytes in size, and comprise six elliptic curve signatures and two EC public keys. This material can be cracked through the quantum-enabled Shor's algorithm. Certificates containing the equivalent quantum-resistant cryptographic material are roughly 2.5 kilobytes. All this data must be transmitted when a browser connects to a site.\n \nTo bypass the bottleneck, companies are turning to Merkle Trees, a data structure that uses cryptographic hashes and other math to verify the contents of large amounts of information using a small fraction of material used in more traditional verification processes in public key infrastructure. Merkle Tree Certificates, \"replace the heavy, serialized chain of signatures found in traditional PKI with compact Merkle Tree proofs,\" members of Google's Chrome Secure Web and Networking Team wrote Friday. \"In this model, a Certification Authority (CA) signs a single 'Tree Head' representing potentially millions of certificates, and the 'certificate' sent to the browser is merely a lightweight proof of inclusion in that tree.\"\n \n[...] Google is [also] adding cryptographic material from quantum-resistant algorithms such as ML-DSA (PDF). This addition would allow forgeries only if an attacker were to break both classical and post-quantum encryption. The new regime is part of what Google is calling the quantum-resistant root store, which will complement the Chrome Root Store the company formed in 2022. The [Merkle Tree Certificates] MTCs use Merkle Trees to provide quantum-resistant assurances that a certificate has been published without having to add most of the lengthy keys and hashes. Using other techniques to reduce the data sizes, the MTCs will be roughly the same 64-byte length they are now [...]. The new system has already been implemented in Chrome.",
      "contentLength": 2254,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "FreeBSD 14.4-RC1 Adds Emacs, Vim & More To DVD Images",
      "url": "https://www.phoronix.com/news/FreeBSD-14.4-RC1-Released",
      "date": 1772278388,
      "author": "Michael Larabel",
      "guid": 49115,
      "unread": true,
      "content": "<article>For those on the current FreeBSD 14 series with no immediate plans to move to FreeBSD 15 that debuted at the end of 2025, FreeBSD developers have been preparing for the release of FreeBSD 14.4. Released overnight was the first release candidate of FreeBSD 14.4...</article>",
      "contentLength": 263,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "KDE Plasma 6.7 Preps Rounded Style UI Enhancement For QtWidgets-Based Apps",
      "url": "https://www.phoronix.com/news/Plasma-6.7-Rounded-UI-QtWidgets",
      "date": 1772277696,
      "author": "Michael Larabel",
      "guid": 49114,
      "unread": true,
      "content": "<article>KDE Plasma 6.7 development continues heating up following the Plasma 6.6 desktop release earlier this month...</article>",
      "contentLength": 110,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Rubin Observatory Has Started Paging Astronomers 800,000 Times a Night",
      "url": "https://science.slashdot.org/story/26/02/28/0155200/rubin-observatory-has-started-paging-astronomers-800000-times-a-night?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1772272800,
      "author": "BeauHD",
      "guid": 49091,
      "unread": true,
      "content": "On February 24th, the Vera C. Rubin Observatory activated its automated alert system, sending out roughly 800,000 real-time notifications flagging asteroids, supernovae, flaring black holes and \"other transient celestial events,\" reports Scientific American. And this is only the beginning -- that number is projected to climb into the millions as it continues scanning the ever-changing sky. From the report: The astronomical observatory equipped with world's largest camera hit a key milestone on February 24, when a complex data-processing system pushed hundreds of thousands of alerts out to scientists eager to pore over its most exciting sightings. The Vera C. Rubin Observatory began operations last year, capturing stunning, panoramic time-lapse views of the cosmos with ease. Rubin's first images, based on just 10 hours of observations, let space fans zoom seemingly forever into an overwhelmingly starry sky. But watchful astronomers were always awaiting the next step: the system that would automatically alert them to the most promising activity in the overhead sky amid the 1,000 or so enormous images that Rubin's telescope captures every night.\n \n\"We can detect everything that changes, moves and appears,\" said Yusra AlSayyad, an astronomer at Princeton University and Rubin's deputy associate director for data management, to Scientific American last summer. \"It's way too much for one person to manually sift through and filter and monitor themselves.\" So even as they were designing and building the Rubin Observatory itself, scientists were also designing an alert system to help astronomers navigate the flood of data. As soon as the telescope began observations, the team started constructing a static reference image of the entire sky in impeccable detail.\n \nNow the data processing systems that support the observatory are starting to automatically compare every new Rubin image to the corresponding section of that background template. The systems identify all of the differences, each of which is individually flagged. The algorithms can also distinguish between a potential supernova and a possible newfound asteroid, for example. Alerting the scientific community is the final, crucial step. Astronomers -- as well as members of the public -- can sign up for notifications based on the type of sighting they're interested in and the brightness of the observation in question. And now that the alerts system has gone live, users receive a tiny, fuzzy image with some astronomical metadata of each observation that fits their criteria -- all just a couple of minutes after Rubin captures the original image.",
      "contentLength": 2634,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "The TechBeat: Beyond the Bots: What Real Writing Looks Like in the Age of AI (2/28/2026)",
      "url": "https://hackernoon.com/2-28-2026-techbeat?source=rss",
      "date": 1772262683,
      "author": "Techbeat",
      "guid": 49111,
      "unread": true,
      "content": "<p>By <a href=\"https://hackernoon.com/u/davidiyanu\">@davidiyanu</a> [ 5 Min read ] \n RAG fails less from the LLM and more from retrieval: bad chunking, weak metadata, embedding drift, and stale indexes. Fix the pipeline first. <a href=\"https://hackernoon.com/rag-a-data-problem-disguised-as-ai\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/stevebeyatte\">@stevebeyatte</a> [ 7 Min read ] \n Compare the 7 best co-parenting apps in 2026, including BestInterest, OurFamilyWizard, and TalkingParents. Find the right app for high-conflict situations.  <a href=\"https://hackernoon.com/the-7-best-coparenting-apps-in-2026\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/playerzero\">@playerzero</a> [ 15 Min read ] \n Modern software teams ship faster than ever, but defect resolution lags; PlayerZero aligns people, process, and context for predictable reliability. <a href=\"https://hackernoon.com/people-process-context-the-operating-model-modern-defect-resolution-needs\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/ipinfo\">@ipinfo</a> [ 8 Min read ] \n Analysis of 170M residential proxy IPs reveals rapid rotation and 46% cross-provider overlap‚Äîbreaking traditional fraud detection models. <a href=\"https://hackernoon.com/the-residential-proxy-problem-shared-infrastructure-and-rapid-rotation\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/thomascherickal\">@thomascherickal</a> [ 14 Min read ] \n OpenClaw lets you run frontier AI models like Minimax M2.5 and GLM-5 100% locally on Mac M3 or DGX Spark ‚Äî zero API costs, total privacy. Here's how.  <a href=\"https://hackernoon.com/the-next-trillion-dollar-ai-shift-why-openclaw-changes-everything-for-llms\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/aimodels44\">@aimodels44</a> [ 8 Min read ] \n A new study suggests AGENTS.md-style repo context files can reduce coding-agent success while raising inference cost. Here‚Äôs why‚Äîand what to do instead. <a href=\"https://hackernoon.com/evaluating-agentsmd-are-repository-level-context-files-helpful-for-coding-agents\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/davidiyanu\">@davidiyanu</a> [ 8 Min read ] \n  Production is the unmarked minefield that begins the moment you accept arbitrary user input and promise reliability. <a href=\"https://hackernoon.com/beyond-the-demo-why-llm-applications-crash-in-production\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/dataops\">@dataops</a> [ 3 Min read ] \n Technical debt isn‚Äôt refactoring‚Äîit‚Äôs hidden risk. A powerful racecar analogy to help engineers explain why cutting corners can end in disaster. <a href=\"https://hackernoon.com/we-need-to-sound-the-alarm-on-technical-debt-heres-how-i-do-it\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/birukum\">@birukum</a> [ 11 Min read ] \n Agentic AI workflows can create a financial black hole. Learn how semantic caching uses vector similarity to cut your LLM token burn by 24%. <a href=\"https://hackernoon.com/optimise-llm-usage-costs-with-semantic-cache\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/sherveen\">@sherveen</a> [ 5 Min read ] \n Deep dive analysis of Grok 4.2 and Sonnet 4.6, two new AI releases from xAI and Anthropic, and how their agent systems compare. <a href=\"https://hackernoon.com/grok-42-vs-sonnet-46-early-impressions-from-hands-on-testing\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/samiranmondal\">@samiranmondal</a> [ 2 Min read ] \n Cybersecurity stocks fell after AI company Anthropic unveiled Claude Code Security <a href=\"https://hackernoon.com/cybersecurity-stocks-drop-as-anthropic-launches-claude-code-security-tool\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/MichaelJerlis\">@MichaelJerlis</a> [ 2 Min read ] \n Explore crypto staking options in 2026, compare ETH and SOL yields, and see how platforms like EMCD simplify earning passive income. <a href=\"https://hackernoon.com/how-to-earn-with-crypto-staking-a-practical-comparison-of-popular-options\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/omotayojude\">@omotayojude</a> [ 3 Min read ] \n When an AI agent's PR was rejected by Matplotlib, it didn't just close the tab it wrote an angry hit piece on the maintainer. Is this the future of open source? <a href=\"https://hackernoon.com/open-sources-first-cyber-bully-the-day-an-ai-agent-doxxed-a-matplotlib-maintainer\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/hackernoon-courses\">@hackernoon-courses</a> [ 4 Min read ] \n Learn how to write content that stands out in the age of AI, crafting a voice and style no model or copycat can replicate. <a href=\"https://hackernoon.com/beyond-the-bots-what-real-writing-looks-like-in-the-age-of-ai\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/ArunDHANARAJ_gfaknebg\">@ArunDHANARAJ_gfaknebg</a> [ 14 Min read ] \n Compare Claude Opus 4.6 and GPT‚Äë5.3 Codex across reasoning, coding, benchmarks, pricing, and safety to guide enterprise AI and agentic workload decisions.</p><p>By <a href=\"https://hackernoon.com/u/nickzt\">@nickzt</a> [ 5 Min read ] \n Scaling AI for the real world requires peeling back the layers of abstraction we've gotten too comfortable with. <a href=\"https://hackernoon.com/python-is-a-video-latency-suicide-note-how-i-hit-29-fps-with-zero-copy-c-onnx\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/brightdata\">@brightdata</a> [ 8 Min read ] \n ‚Äã‚ÄãWe benchmark SERP APIs for success rate,\n‚Äã‚Äãspeed, and stability under load. Learn which setup delivers consistent results for AI agents ‚Äã‚Äãand deep research.  <a href=\"https://hackernoon.com/serp-benchmarks-success-rates-and-latency-at-scale\">Read More.</a></p>",
      "contentLength": 3102,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Southern California Air Board Rejects Pollution Rules After AI-Generated Flood of Comments",
      "url": "https://it.slashdot.org/story/26/02/27/2348254/southern-california-air-board-rejects-pollution-rules-after-ai-generated-flood-of-comments?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1772262000,
      "author": "BeauHD",
      "guid": 49067,
      "unread": true,
      "content": "Southern California's air quality board rejected proposed rules to phase out gas-powered appliances after receiving more than 20,000 opposition comments generated through CiviClick, \"the first and best AI-powered grassroots advocacy platform.\" Phys.org reports: A Southern California-based public affairs consultant, Matt Klink, has taken credit for using CiviClick to wage the opposition campaign, including in a sponsored article on the website Campaigns and Elections. The campaign \"left the staff of the Southern California Air Quality Management District (SCAQMD) reeling,\" the article says. It is not clear how AI was deployed in the campaign, and officials at CiviClick did not respond to repeated requests for comment. But their website boasts several tools, including \"state of the art technology and artificial intelligence message assistance\" that can be used to create custom advocacy letters, as opposed to repetitive form letters or petitions often used in similar campaigns.\n \nWhen staffers at the air district reached out to a small sample of people to verify their comments, at least three said they had not written to the agency and were not aware of any such messages, records show. But the email onslaught almost certainly influenced the board's June decision, according to agency insiders, who noted that the number of public comments typically submitted on agenda items can be counted on one hand.\n \nThe proposed rules were nearly two years in the making and would have placed a fee on natural gas-powered water heaters and furnaces, favoring electric ones, in an effort to reduce air pollution in the district, which includes Orange County and large swaths of Los Angeles, Riverside and San Bernardino counties. Gas appliances emit nitrogen oxides, or NOx -- key pollutants for forming smog. The implications are troubling, experts said, and go beyond the use of natural gas furnaces and heaters in the second-largest metropolitan area in the country.",
      "contentLength": 1974,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "India disrupts access to popular developer platform Supabase with blocking order",
      "url": "https://techcrunch.com/2026/02/27/india-disrupts-access-to-popular-developer-platform-supabase-with-blocking-order/",
      "date": 1772250712,
      "author": "Jagmeet Singh",
      "guid": 49057,
      "unread": true,
      "content": "<article>India, one of Supabase‚Äôs biggest markets, is seeing patchy access after a government block order.</article>",
      "contentLength": 99,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Trump Settles With Isaac Hayes‚Äô Estate Over Use Of Music During The Campaign",
      "url": "https://www.techdirt.com/2026/02/27/trump-settles-with-isaac-hayes-estate-over-use-of-music-during-the-campaign/",
      "date": 1772249940,
      "author": "Timothy Geigner",
      "guid": 49052,
      "unread": true,
      "content": "<p>One of the unfortunate knock on effects of being generally insufferable is that many people don‚Äôt want to be associated with you in any way. And when you‚Äôre both insufferable and happen to be the most divisive American political figure in modern history, all the more so. And that is certainly why, during both of the Donald Trump presidential campaigns, it became common practice for musical artists to complain about his ‚Äúunauthorized‚Äù use of their music at his campaign events.</p><p>Now, as this site has posted out a zillion times in the past, many of the complaints from artists are unfounded. Often, the use of the music in question was authorized through blanket performance licenses held by the venues for the rallies. While it should be obvious that best practice would be for candidates like Trump to seek permission to use music just to avoid any public complaining and backlash for that use, there is no real copyright claim to be had in those instances. Lots of people <a href=\"https://www.techdirt.com/articles/20160725/07541435058/john-olivers-story-campaign-music-copyright-is-wrong.shtml\">get this wrong</a>.</p><blockquote><p><em>Copyright law is&nbsp;so&nbsp;screwed up that there actually may be a case where the law does require permission. And it has to do with&nbsp;<a href=\"https://www.techdirt.com/blog/?tag=pre-1972+sound+recordings\">pre-1972 sound recordings</a>. If you‚Äôve been reading Techdirt for any length of time, you know that we‚Äôve discussed this issue many times in the past. Historically, while&nbsp;compositions&nbsp;were covered by copyright, under the 1909 Copyright Act&nbsp;sound recordings&nbsp;were not. This resulted in a patchwork of state laws (and state commonlaw) that created special forms of copyright at the state level. Eventually, sound recordings were put under federal copyright law, but it only applied to works recorded after February 14, 1972. Works recorded before that are not under federal copyright law, but remain basically the only things under those state copyright laws (the 1976 Copyright Act basically wiped out state copyright laws for&nbsp;everything&nbsp;but that one tiny thing).</em></p><p><em>The issue is not that simple, because nothing around this particular issue is simple. However, based on at least&nbsp;<a href=\"https://www.techdirt.com/articles/20140923/17250328610/judge-rules-against-sirius-xm-pre-1972-recordings.shtml\">some</a>&nbsp;of the rulings in pre-1972 sound recording copyright cases, federal copyright law doesn‚Äôt apply at all to those songs (other court opinions have come out otherwise). And thus, there‚Äôs an argument that the requirements involving blanket licenses for pre-1972 sound recordings may not apply, because the use of the sound recording may require a special public performance license from the copyright holder</em></p></blockquote><p>And so now we have a decade or so of courts trying to figure this out. The outcomes of court cases are every bit as patchwork as the state laws that inform their outcomes. Add to all of this that even some of the blanket licenses from the likes of ASCAP include opt-outs for political campaigns and the like and it‚Äôs easy for all kinds of mistakes to be made.</p><p>Mistakes don‚Äôt really explain the rash of instances of artists complaining about Trump‚Äôs usage, however. He‚Äôs been through this so many times, in fact, that it seems obvious that he and his people simply don‚Äôt care to try to secure permission. I doubt they even looked into whether they needed to. And the onus to understand what licensing is needed is certainly on their shoulders and nobody else‚Äôs. That‚Äôs how you get Pharrell <a href=\"https://www.techdirt.com/2018/10/30/pharrell-is-not-all-happy-about-trump-using-happy-his-rally-he-might-actually-have-case/\">clapping back</a> on Trump‚Äôs use of his music at an insane rally shortly after a nationalist murdered 11 people in Pittsburgh (the venue didn‚Äôt have a license from the artist‚Äôs rights management of choice). Or his campaign losing a copyright suit to <a href=\"https://www.techdirt.com/2024/09/26/trump-loses-copyright-suit-over-electric-avenue-2020-campaign-video-in-summary-judgement/\">Eddy Grant</a> for the use of his music in a campaign video. </p><blockquote><p><em>Hayes‚Äô son and estate manager, music producer&nbsp;<a href=\"https://www.billboard.com/author/isaac-hayes-iii/\">Isaac Hayes III</a>, says in a Monday (Feb. 23)&nbsp;<a href=\"https://www.instagram.com/p/DVHSun4EaBW/\" target=\"_blank\" rel=\"noreferrer noopener\">Instagram statement</a>&nbsp;that the lawsuit ‚Äúhas been mutually resolved, and we are satisfied with the outcome.‚Äù Financial terms of the settlement were not disclosed.</em></p><p><em>‚ÄúThis resolution represents more than the conclusion of a legal matter,‚Äù writes Hayes III in his statement. ‚ÄúIt reaffirms the importance of protecting intellectual property rights and copyrights, especially as they relate to legacy, ownership and the responsible use of creative works.‚Äù</em></p></blockquote><p>It will surprise nobody that I would love to debate most of what appears in that quote from Hayes III, but that is a separate matter entirely. Instead, my focus is on two undeniable realities. First, the chaos that has been created with these older, pre-1972 song recordings is insane, complicated, and needlessly convoluted. Whoever thought this setup was a good idea should be placed in a facility under constant care.</p><p>Second, Trump almost certainly committed copyright infringement, the above complaint notwithstanding. And he‚Äôs been through enough of these that he could very easily tell his people to just go get the proper permissions for any music that is played at his little fascism pep rallies. While the settlement terms go undisclosed, which is always annoying, I‚Äôve seen enough of these to be able to read between the lines. The Hayes estate got its pint of blood, at a bare minimum.</p><p>Wouldn‚Äôt it just be easier to get artists that like you to let you play their music at your events, Donald? There were at least a few artists at that emotional support half time show that nobody watched that you could choose from.</p>",
      "contentLength": 5217,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "OpenAI Fires an Employee For Prediction Market Insider Trading",
      "url": "https://slashdot.org/story/26/02/27/2342226/openai-fires-an-employee-for-prediction-market-insider-trading?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1772249400,
      "author": "BeauHD",
      "guid": 49049,
      "unread": true,
      "content": "An anonymous reader quotes a report from Wired: OpenAI has fired an employee following an investigation into their activity on prediction market platforms including Polymarket, WIRED has learned. OpenAI CEO of Applications, Fidji Simo, disclosed the termination in an internal message to employees earlier this year. The employee, she said, \"used confidential OpenAI information in connection with external prediction markets (e.g. Polymarket).\" \"Our policies prohibit employees from using confidential OpenAI information for personal gain, including in prediction markets,\" says spokesperson Kayla Wood. OpenAI has not revealed the name of the employee or the specifics of their trades.\n \nEvidence suggests that this was not an isolated event. Polymarket runs on the Polygon blockchain network, so its trading ledger is pseudonymous but traceable. According to an analysis by the financial data platform Unusual Whales, there have been clusters of activities, which the service flagged as suspicious, around OpenAI-themed events since March 2023. Unusual Whales flagged 77 positions in 60 wallet addresses as suspected insider trades, looking at the age of the account, trading history, and significance of investment, among other factors. Suspicious trades hinged on the release dates of products like Sora, GPT-5, and the ChatGPT Browser, as well as CEO Sam Altman's employment status. In November 2023, two days after Altman was dramatically ousted from the company, a new wallet placed a significant bet that he would return, netting over $16,000 in profits. The account never placed another bet.\n \nThe behavior fits into patterns typical of insider trades. \"The tell is the clustering. In the 40 hours before OpenAI launched its browser, 13 brand-new wallets with zero trading history appeared on the site for the first time to collectively bet $309,486 on the right outcome,\" says Unusual Whales CEO Matt Saincome. \"When you see that many fresh wallets making the same bet at the same time, it raises a real question about whether the secret is getting out.\" [...] Though this is the first confirmed case of a large technology company firing an employee over trades in prediction markets, it's almost certainly not the last. Opportunities for tech sector employees to make trades on markets abound. \"The data tells me this is happening all over the place,\" Saincome says.",
      "contentLength": 2378,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "The 5 Best Batsuits From Batman: Arkham Knight",
      "url": "https://hackernoon.com/the-5-best-batsuits-from-batman-arkham-knight?source=rss",
      "date": 1772249314,
      "author": "Jose",
      "guid": 49110,
      "unread": true,
      "content": "<p>Batman made his first appearance in 1939. When you have a character who has been around for 80 years, they‚Äôre bound to change their appearance from time to time. So, it only makes sense for video games like Batman: Arkham Knight to take advantage of this and add different alternative costumes that players can pick and choose from. Some of these were hits, some of these were misses, and some were just okay. Let‚Äôs take a look at the 5 biggest hits (at least, in my opinion). Here are the 5 best batsuits from Batman: Arkham Knight.</p><h2>5 Best Batsuits From Arkham Knight</h2><ol></ol><p>One of my favorites is the default one, the v8.03. We get this one early into the game, when Batman realizes he needs a little something extra, and his old costume just won‚Äôt do. It looks sleek, heavy, and the black looks amazing. This is definitely the best-looking default batsuit in the entire series.</p><p>\\\nThere are 2 other versions of this suit: the 8.04 and 8.05. The 8.04 stays perfectly pristine, so it doesn‚Äôt get any battle damage as the 8.03 does. Then there‚Äôs the 8.05. This one is similar, with the exception of the golden bat symbol on the chest.</p><p>\\\nI‚Äôm not a fan of the golden bat symbol, and I actually like that the 8.03 can get damaged and cut up. It shows the toll that the night has taken on Batman.</p><p>Some people like it when the batsuit is gray; others prefer it when it‚Äôs black. I like this one because it falls right in the middle. It looks like a dark gray, but from a different perspective, you can technically say that it‚Äôs a light black. What really makes the Batman Inc. suit one of my favorites, though, is the bat symbol on his chest. The yellow oval behind the black bat symbol makes it really striking, and it‚Äôs one of the first things your eyes notice.</p><p>\\\nThere are similar batsuits like the one from the 1989 movie that have a similar look. However, the Batman Inc. one has a better bat symbol and cowl. That‚Äôs why I put it above the 1989 one and above most other ones.</p><p>\\\nThe Batman Flashpoint suit is damn near perfect. The red accents all throughout it, such as in his pouches, eyes, and bat symbol, really make the whole thing stand out. Plus, having the body be gray with the cowl, gauntlets, and boots be completely black was such a great idea. The cherry on top, the thing that makes this costume stunning, is the double-handguns, one on each side. Like I said, damn near perfection.</p><p>\\\nSo, what don‚Äôt I like about it? My least favorite thing about it is the strange shoulder guards. Maybe if they were smaller and less pointy, I would be into it. Even better would be if they were completely gone. With all that said, though, this is still one of the best skins in the game.</p><p>I said I like the Batman Inc. suit because it‚Äôs the perfect mix between black and gray. I like the Batman v Superman one for a completely different reason. This one is very clearly gray; there‚Äôs no mistaking it. There are others that are gray, like the First Appearance one, but there is something different about this particular one. It‚Äôs the fabric. I‚Äôm not sure how to describe it, but the fabric of the suit is unlike any other.</p><p>\\\nIt sort of looks like a type of Kevlar, which is completely different from the tights that some of the other costumes appear to be made out of. That, combined with the gigantic bat symbol, makes it look phenomenal. I‚Äôm a sucker for a good bat symbol, what can I say?</p><p>This might be a hot take, but my all-time favorite batsuit in the Arkham Knight game is the Batman Beyond one. Don‚Äôt get me wrong, I love the others on this list, but this one is just on a completely different level. I really like the red accents and how mechanized the whole suit looks. It has a whole cyborg thing going on that I personally enjoy. There are some caveats to it, though, that I will admit to.</p><p>\\\nThe mouthpiece is a bit strange-looking. You have this whole futuristic costume, and it looks like the mouthpiece is just made out of cloth or something. Not a fan. The second biggest critique is that it looks nothing like the Batman Beyond suit from the animated show.</p><p>\\\nI can understand and accept these two flaws, but that doesn‚Äôt bring down my enjoyment of the costume. In my opinion, the Batman Beyond suit is the best-looking one in Batman: Arkham Knight. You know what, I might have to replay the whole game again just to look at these cool skins.</p>",
      "contentLength": 4369,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Human Brain Cells On a Chip Learned To Play Doom In a Week",
      "url": "https://games.slashdot.org/story/26/02/27/2332219/human-brain-cells-on-a-chip-learned-to-play-doom-in-a-week?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1772244120,
      "author": "BeauHD",
      "guid": 49033,
      "unread": true,
      "content": "Researchers at Cortical Labs used living human neurons grown on a chip to learn how to play Doom in about a week. \"While its performance is not up to par with humans, experts say it brings biological computers a step closer to useful real-world applications, like controlling robot arms,\" reports New Scientist. From the report: In 2021, the Australian company Cortical Labs used its neuron-powered computer chips to play Pong. The chips consisted of clumps of more than 800,000 living brain cells grown on top of microelectrode arrays that can both send and receive electrical signals. Researchers had to carefully train the chips to control the paddles on either side of the screen. Now, Cortical Labs has developed an interface that makes it easier to program these chips using the popular programming language Python. An independent developer, Sean Cole, then used Python to teach the chips to play Doom, which he did in around a week.\n \n\"Unlike the Pong work that we did a few years ago, which represented years of painstaking scientific effort, this demonstration has been done in a matter of days by someone who previously had relatively little expertise working directly with biology,\" says Brett Kagan of Cortical Labs. \"It's this accessibility and this flexibility that makes it truly exciting.\"\n \nThe neuronal computer chip, which used about a quarter as many neurons as the Pong demonstration, played Doom better than a randomly firing player, but far below the performance of the best human players. However, it learnt much faster than traditional, silicon-based machine learning systems and should be able to improve its performance with newer learning algorithms, says Kagan. However, it's not useful to compare the chips with human brains, he says. \"Yes, it's alive, and yes, it's biological, but really what it is being used as is a material that can process information in very special ways that we can't recreate in silicon.\" Cortical Labs posted a YouTube video showing its CL1 biological computer running Doom. There's also source code available on GitHub, with additional details in a README file.",
      "contentLength": 2119,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Google quantum-proofs HTTPS by squeezing 15kB of data into 700-byte space",
      "url": "https://arstechnica.com/security/2026/02/google-is-using-clever-math-to-quantum-proof-https-certificates/",
      "date": 1772242001,
      "author": "Dan Goodin",
      "guid": 49034,
      "unread": true,
      "content": "<p>Google on Friday unveiled its plan for its Chrome browser to secure HTTPS certificates against quantum computer attacks without breaking the Internet.</p><p>The objective is a tall order. The quantum-resistant cryptographic data needed to transparently publish TLS certificates is roughly 40 times bigger than the classical cryptographic material used today. A typical <a href=\"https://en.wikipedia.org/wiki/X.509\">X.509 certificate</a> chain used today comprises six elliptic curve signatures and two EC public keys,  each of them only 64 bytes. This material can be cracked through the quantum-enabled <a href=\"https://en.wikipedia.org/wiki/Shor's_algorithm\">Shor‚Äôs algorithm</a>. The full chain is roughly 4 kilobytes. All this data must be transmitted when a browser connects to a site.</p><h2>The bigger they come, the slower they move</h2><p>‚ÄúThe bigger you make the certificate, the slower the handshake and the more people you leave behind,‚Äù said Bas Westerbaan, principal research engineer at Cloudflare, which is partnering with Google on the transition. ‚ÄúOur problem is we don‚Äôt want to leave people behind in this transition.‚Äù Speaking to Ars, he said that people will likely disable the new encryption if it slows their browsing. He added that the massive size increase can also degrade ‚Äúmiddle boxes,‚Äù which sit between browsers and the final site.</p>",
      "contentLength": 1244,
      "flags": null,
      "enclosureUrl": "https://cdn.arstechnica.net/wp-content/uploads/2025/06/https-1152x648.jpg",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Hyperion Author Dan Simmons Dies From Stroke At 77",
      "url": "https://news.slashdot.org/story/26/02/27/2226234/hyperion-author-dan-simmons-dies-from-stroke-at-77?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1772241900,
      "author": "BeauHD",
      "guid": 49031,
      "unread": true,
      "content": "Author Dan Simmons, best known for the epic sci-fi novel Hyperion and its sequels, has died at 77 following a stroke. Ars Technica's Eric Berger remembers Simmons, writing: Simmons, who worked in elementary education before becoming an author in the 1980s, produced a broad portfolio of writing that spanned several genres, including horror fiction, historical fiction, and science fiction. Often, his books included elements of all of these. This obituary will focus on what is generally considered his greatest work, and what I believe is possibly the greatest science fiction novel of all time, Hyperion.\n \nPublished in 1989, Hyperion is set in a far-flung future in which human settlement spans hundreds of planets. The novel feels both familiar, in that its structure follows Chaucer's Canterbury Tales, and utterly unfamiliar in its strange, far-flung setting. Simmons' Hyperion appeared in an Ask Slashdot story back in 2008, when Slashdot reader willyhill asked for tips on how Slashdotters track down great sci-fi. If you're in the mood for a little nostalgia, or just want to browse the thread for book recommendations, it's well worth revisiting.",
      "contentLength": 1157,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "From San Francisco to the Sands: Why U.S. Tech Talent Is Eyeing the UAE",
      "url": "https://hackernoon.com/from-san-francisco-to-the-sands-why-us-tech-talent-is-eyeing-the-uae?source=rss",
      "date": 1772241497,
      "author": "Nica Furs",
      "guid": 49109,
      "unread": true,
      "content": "<p>If you hang around startup circles in the Bay Area long enough, you‚Äôll start hearing something unexpected between funding rounds and AI debates: founders quietly Googling ‚Äú<a href=\"https://drive.yango.com/\">car rental in UAE</a>‚Äù and checking flight prices to Dubai and Abu Dhabi. What started as curiosity has turned into a real trend. From San Francisco to the sands of the Arabian Peninsula, American tech talent is seriously eyeing the United Arab Emirates‚Äîand not just for a quick conference or a flashy vacation.</p><p>So what‚Äôs driving the shift?</p><h2><strong>Silicon Valley Burnout Is Real</strong></h2><p>Let‚Äôs call it what it is. The Bay Area is still iconic, but it‚Äôs also expensive, hyper-competitive, and increasingly saturated. Sky-high rents, intense regulation, talent wars, and a constant hustle culture can wear even the most ambitious founder down. After years of grinding in co-working spaces and chasing Series A funding, some U.S. entrepreneurs are looking for a reset.</p><p>The UAE, especially Dubai and Abu Dhabi, is pitching itself as that reset button. Lower personal income taxes, streamlined business setup processes, and aggressive government support for innovation make the region hard to ignore. For founders used to navigating layers of red tape back home, the efficiency can feel almost unreal.</p><h2><strong>A Government That Actually Bets on Tech</strong></h2><p>One of the biggest surprises for Americans exploring the UAE tech scene is how hands-on‚Äîand forward-thinking‚Äîthe government is. Artificial intelligence, fintech, climate tech, space technology: these aren‚Äôt just buzzwords on a conference banner. They‚Äôre central to national strategy.</p><p>Free zones tailored to tech companies offer 100% foreign ownership and simplified licensing. Major funds and sovereign wealth investors actively back innovation. In many cases, founders aren‚Äôt just tolerated‚Äîthey‚Äôre welcomed with open arms and real incentives.</p><p>Compare that to the sometimes fragmented regulatory environment in the U.S., and it‚Äôs easy to see why some builders are thinking, ‚ÄúWhy not give this a shot?‚Äù</p><h2><strong>It‚Äôs Not Just Oil Money Anymore</strong></h2><p>There‚Äôs still a persistent stereotype in the U.S. that the Gulf economy runs purely on oil. That narrative is outdated. The UAE has spent decades diversifying its economy, investing heavily in infrastructure, tourism, logistics, and now digital transformation.</p><p>Walk through Dubai Internet City or Hub71 in Abu Dhabi and you‚Äôll see a mix of global companies, scrappy startups, and venture-backed disruptors. English is widely spoken. Contracts are often structured in ways that feel familiar to U.S. founders. The vibe? Surprisingly international and business-friendly.</p><p>For tech professionals who‚Äôve spent their careers building products for global markets, the UAE‚Äôs geographic position‚Äîbridging Europe, Asia, and Africa‚Äîis a strategic advantage. A product launched in Dubai can scale across multiple regions without being locked into one market.</p><p>Let‚Äôs talk lifestyle, because it matters. The UAE isn‚Äôt just pitching spreadsheets and tax breaks. It‚Äôs selling quality of life. Modern apartments, world-class restaurants, beach access, and relatively high levels of safety are all part of the package.</p><p>Yes, the summer heat is intense. But the infrastructure is built for it. Offices, malls, and residential buildings are climate-controlled. Everything runs efficiently. For many Americans, the biggest adjustment isn‚Äôt the temperature‚Äîit‚Äôs the pace. Things move fast. Deals close quickly. Bureaucracy, when it exists, is often surprisingly streamlined.</p><p>And when it comes to getting around, practicality kicks in. Cities like Dubai are spread out, with business districts, residential communities, and innovation hubs connected by wide highways. While public transportation exists, most professionals find that having a car makes daily life significantly easier. Whether you‚Äôre commuting to a co-working space, heading to investor meetings, or exploring new neighborhoods, renting a car is often the smartest move‚Äîespecially during your first few months while you figure out where to settle.</p><h2><strong>The Remote Work Era Changed the Game</strong></h2><p>The pandemic permanently shifted how tech workers think about location. If you can code from anywhere, why limit yourself to one zip code? The UAE capitalized on this shift by introducing long-term visas and remote work permits designed specifically for global talent.</p><p>Suddenly, relocating doesn‚Äôt mean cutting ties with U.S. clients or investors. Many founders maintain American entities while building regional operations in the UAE. It‚Äôs less about abandoning Silicon Valley and more about expanding beyond it.</p><p>This hybrid model is attractive. Keep your Delaware C-corp, but base your operations in a city that offers global connectivity, strong infrastructure, and competitive costs. For a generation raised on flexibility and scale, it‚Äôs a compelling pitch.</p><h2><strong>Risk, Reward, and Reputation</strong></h2><p>Of course, moving halfway across the world isn‚Äôt a casual decision. Cultural differences, legal frameworks, and market dynamics require research and adaptability. Not every startup will thrive in the Gulf, and not every founder will feel at home.</p><p>But the reputation factor is shifting. What once seemed like a bold or risky move now feels strategic. U.S. tech talent isn‚Äôt just chasing sunshine and skyscrapers. They‚Äôre chasing opportunity‚Äînew markets, new investors, and a chance to build in an ecosystem that‚Äôs actively evolving.</p><p>From San Francisco to the sands, the flow of ideas‚Äîand people‚Äîis becoming more global. The UAE isn‚Äôt replacing Silicon Valley, but it‚Äôs carving out its own lane as a serious contender in the tech world. For American founders and engineers tired of the grind or hungry for international expansion, it‚Äôs a place worth exploring.</p><p>Pack your laptop. Line up your meetings. Maybe start with a short-term stay and a rental car to navigate the city like a local. You might just discover that the future of your startup isn‚Äôt limited to the Bay Area. Sometimes, the next big move starts with a one-way ticket and a willingness to see what‚Äôs possible beyond the familiar skyline.</p>",
      "contentLength": 6113,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "The 7 Leading Requirements Management Software Solutions in 2026",
      "url": "https://hackernoon.com/the-7-leading-requirements-management-software-solutions-in-2026?source=rss",
      "date": 1772239632,
      "author": "Steve Beyatte",
      "guid": 49108,
      "unread": true,
      "content": "<article>This guide compares the 7 leading requirements management software solutions in 2026, from modern platforms like Jama Connect to legacy tools like IBM DOORS and lightweight options like Excel. The best choice depends on your product complexity, regulatory requirements, and team structure‚Äîbut most organizations opt for modern tools like Jama Connect.</article>",
      "contentLength": 353,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "CISA Replaces Bumbling Acting Director After a Year",
      "url": "https://yro.slashdot.org/story/26/02/27/2215238/cisa-replaces-bumbling-acting-director-after-a-year?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1772239500,
      "author": "BeauHD",
      "guid": 49030,
      "unread": true,
      "content": "New submitter DeanonymizedCoward shares a report from TechCrunch: The U.S. Cybersecurity and Infrastructure Security Agency (CISA) is reportedly in crisis following major budget cuts, layoffs, and furloughs under the Trump administration, says TechCrunch. The agency has now replaced its acting director, Madhu Gottumukkala, after a turbulent year marked by controversy and internal turmoil. During his tenure, Gottumukkala allegedly mishandled sensitive information by uploading government documents to ChatGPT, oversaw a one-third reduction in staff, and reportedly failed a counterintelligence polygraph needed for classified access. His leadership also saw the suspension of several senior officials, including CISA's chief security officer. Nextgov also reported that CISA lost another top senior official, Bob Costello, the agency's chief information officer tasked with overseeing the agency's IT systems and data policies. \"Last month, CISA's acting director Madhu Gottumukkala reportedly took steps to transfer Costello, but other political appointees blocked it,\" added Nextgov.",
      "contentLength": 1088,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "TurboSparse-LLM Performance: Outperforming Mixtral and Gemma with Extreme Sparsity",
      "url": "https://hackernoon.com/turbosparse-llm-performance-outperforming-mixtral-and-gemma-with-extreme-sparsity?source=rss",
      "date": 1772238916,
      "author": "Language Models (dot tech)",
      "guid": 49107,
      "unread": true,
      "content": "<p>We measure our sparsified models‚Äô performance on tasks included in OpenLLM Leaderboard which include 25-shot Arc-Challenge [13], 10-shot Hellaswag [65], 5-shot MMLU [22], 0-shot TruthfulQA [35], 5-shot Winogrande [51] and 8-shot GSM8K [14]. In addition, we also follow Llama 2‚Äôs evaluation task included commonsense reasoning tasks. We report the average of PIQA [8], SCIQ [26], ARC easy [13], OpenBookQA [41]. We compare our models to several external open-source LLMs, including Gemma-2B [58], Mistral-7B [24] and Mixtral-47B [25].</p><p>\\\n\\\nTable 6 shows the results from different models. TurboSparse-Mistral-7B outperforms Gemma-2B by far, while only activating 3B parameters. TurboSparse-Mixtral-47B outperforms the original Mixtral-47B with only 4.5B parameters activated. The results demonstrate that LLMs with ReLU based intrinsic activation sparsity can keep the same or better performance while hold the significant FLOPs reduction.</p><p>(1) Yixin Song, Institute of Parallel and Distributed Systems (IPADS), Shanghai Jiao Tong University;</p><p>(2) Haotong Xie, Institute of Parallel and Distributed Systems (IPADS), Shanghai Jiao Tong University;</p><p>(3) Zhengyan Zhang, Department of Computer Science and Technology, Tsinghua University;</p><p>(4) Bo Wen, Institute of Parallel and Distributed Systems (IPADS), Shanghai Jiao Tong University;</p><p>(5) Li Ma, Shanghai Artificial Intelligence Laboratory;</p><p>(6) Zeyu Mi, Institute of Parallel and Distributed Systems (IPADS), Shanghai Jiao Tong University Mi yzmizeyu@sjtu.edu.cn);</p><p>(7) Haibo Chen, Institute of Parallel and Distributed Systems (IPADS), Shanghai Jiao Tong University.</p>",
      "contentLength": 1606,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "dReLU Sparsification: Recovering LLM Performance with 150B Token Pretraining",
      "url": "https://hackernoon.com/drelu-sparsification-recovering-llm-performance-with-150b-token-pretraining?source=rss",
      "date": 1772238666,
      "author": "Language Models (dot tech)",
      "guid": 49106,
      "unread": true,
      "content": "<p>In the previous section, we have demonstrated that dReLU can be a better choice for ReLUfication. The main question now is whether dReLU based ReLUfication can recover the original model‚Äôs performance while achieving higher sparsity. The following sections will discuss the experiments that aimed at answering this question.</p><p>\\\n We consider two representative models: Mistral-7B and Mixtral-47B. We substitute the original SwiGLU based FFN with dReLU based FFN and then continue pretraining.</p><p>\\\n Due to the ReLUfication process, the restoration of model capability is closely related to the corpus used for recovery training. We collected as much corpus as possible from the open-source community for training, such as Wanjuan-CC [48], open-web-math [46], peS2o [54], Pile [19], The Stack [28], GitHub Code [1] and so on. The detailed mixture ratio is as shown in the following table 4:</p><p>\\\n\\\n. After pretraining, we utilize the high-quality SFT datasets to further improve our model‚Äôs performance, including orca-math-word-problems [43], bagel [27].</p><p>\\\n. The hyperparameters for our ReLUfication are based on empirical results from previous works [69]. We utilize the llm-foundry framework for training [44] and employ FSDP parallelism.</p><p>\\\nOur models are trained using the AdamW optimizer [38] with the following hyper-parameters: Œ≤1 = 0.9 and Œ≤2 = 0.95. We adopt a cosine learning rate schedule and use the default values for weight decay and gradient clipping (see Table 5 for more details). In total, we pretrain our models on 150B tokens.</p><p>(1) Yixin Song, Institute of Parallel and Distributed Systems (IPADS), Shanghai Jiao Tong University;</p><p>(2) Haotong Xie, Institute of Parallel and Distributed Systems (IPADS), Shanghai Jiao Tong University;</p><p>(3) Zhengyan Zhang, Department of Computer Science and Technology, Tsinghua University;</p><p>(4) Bo Wen, Institute of Parallel and Distributed Systems (IPADS), Shanghai Jiao Tong University;</p><p>(5) Li Ma, Shanghai Artificial Intelligence Laboratory;</p><p>(6) Zeyu Mi, Institute of Parallel and Distributed Systems (IPADS), Shanghai Jiao Tong University Mi yzmizeyu@sjtu.edu.cn);</p><p>(7) Haibo Chen, Institute of Parallel and Distributed Systems (IPADS), Shanghai Jiao Tong University.</p>",
      "contentLength": 2204,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "The Metrics Review Ritual That Turns Product Work Into Revenue",
      "url": "https://hackernoon.com/the-metrics-review-ritual-that-turns-product-work-into-revenue?source=rss",
      "date": 1772238599,
      "author": "Dan Layfield",
      "guid": 49105,
      "unread": true,
      "content": "<article>If you ‚Äúknow your numbers‚Äù but can‚Äôt explain why they move, you‚Äôre flying blind.</article>",
      "contentLength": 88,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "GNOME GitLab Redirecting Some Git Traffic To GitHub For Reducing Costs",
      "url": "https://www.phoronix.com/news/GNOME-GitHub-GitLab-Redirect",
      "date": 1772236983,
      "author": "Michael Larabel",
      "guid": 49022,
      "unread": true,
      "content": "<article>If you are cloning from a GNOME repository on their GitLab and now finding your Git traffic being redirected to GitHub, you are not alone. GNOME's infrastructure team is now redirecting Git traffic from the GNOME.org GitLab over to GitHub mirrors for reducing bandwidth costs...</article>",
      "contentLength": 278,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Perplexity Announces 'Computer,' an AI Agent That Assigns Work To Other AI Agent",
      "url": "https://slashdot.org/story/26/02/27/2151236/perplexity-announces-computer-an-ai-agent-that-assigns-work-to-other-ai-agent?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1772236920,
      "author": "BeauHD",
      "guid": 49008,
      "unread": true,
      "content": "joshuark shares a report from Ars Technica: Perplexity has introduced \"Computer,\" a new tool that allows users to assign tasks and see them carried out by a system that coordinates multiple agents running various models. The company claims that Computer, currently available to Perplexity Max subscribers, is \"a system that creates and executes entire workflows\" and \"capable of running for hours or even months.\"\n \nThe idea is that the user describes a specific outcome -- something like \"plan and execute a local digital marketing campaign for my restaurant\" or \"build me an Android app that helps me do a specific kind of research for my job.\" Computer then ideates subtasks and assigns them to multiple agents as needed, running the models Perplexity deems best for those tasks. The core reasoning engine currently runs Anthropic's Claude Opus 4.6, while Gemini is used for deep research, Nano Banana for image generation, Veo 3.1 for video production, Grok for lightweight tasks where speed is a consideration, and ChatGPT 5.2 for \"long-context recall and wide search.\"\n \nThis kind of best-model-for-the-task approach differs from some competing products like Claude Cowork, which only uses Anthropic's models. All this happens in the cloud, with prebuilt integrations. \"Every task runs in an isolated compute environment with access to a real filesystem, a real browser, and real tool integrations,\" Perplexity says. The idea is partly that this workflow was what some power users were already doing, and this aims to make that possible for a wider range of people who don't want to deal with all that setup.\n \nPeople were already using multiple models and tailoring them to specific tasks based on perceived capabilities, while, for example, using MCP (Model Context Protocol) to give those models access to data and applications on their local machines. Perplexity Computer takes a different approach, but the goal is the same: have AI agents running tailor-picked models to perform tasks involving your own files, services, and applications. Then there is OpenClaw, which you could perceive as the immediate predecessor to this concept.",
      "contentLength": 2145,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Perplexity Announces 'Computer,' an AI Agent That Assigns Work To Other AI Agents",
      "url": "https://slashdot.org/story/26/02/27/2151236/perplexity-announces-computer-an-ai-agent-that-assigns-work-to-other-ai-agents?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1772236920,
      "author": "BeauHD",
      "guid": 49056,
      "unread": true,
      "content": "joshuark shares a report from Ars Technica: Perplexity has introduced \"Computer,\" a new tool that allows users to assign tasks and see them carried out by a system that coordinates multiple agents running various models. The company claims that Computer, currently available to Perplexity Max subscribers, is \"a system that creates and executes entire workflows\" and \"capable of running for hours or even months.\"\n \nThe idea is that the user describes a specific outcome -- something like \"plan and execute a local digital marketing campaign for my restaurant\" or \"build me an Android app that helps me do a specific kind of research for my job.\" Computer then ideates subtasks and assigns them to multiple agents as needed, running the models Perplexity deems best for those tasks. The core reasoning engine currently runs Anthropic's Claude Opus 4.6, while Gemini is used for deep research, Nano Banana for image generation, Veo 3.1 for video production, Grok for lightweight tasks where speed is a consideration, and ChatGPT 5.2 for \"long-context recall and wide search.\"\n \nThis kind of best-model-for-the-task approach differs from some competing products like Claude Cowork, which only uses Anthropic's models. All this happens in the cloud, with prebuilt integrations. \"Every task runs in an isolated compute environment with access to a real filesystem, a real browser, and real tool integrations,\" Perplexity says. The idea is partly that this workflow was what some power users were already doing, and this aims to make that possible for a wider range of people who don't want to deal with all that setup.\n \nPeople were already using multiple models and tailoring them to specific tasks based on perceived capabilities, while, for example, using MCP (Model Context Protocol) to give those models access to data and applications on their local machines. Perplexity Computer takes a different approach, but the goal is the same: have AI agents running tailor-picked models to perform tasks involving your own files, services, and applications. Then there is OpenClaw, which you could perceive as the immediate predecessor to this concept.",
      "contentLength": 2145,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Subscription Managers: When They‚Äôre Worth It",
      "url": "https://hackernoon.com/subscription-managers-when-theyre-worth-it?source=rss",
      "date": 1772236799,
      "author": "Dan Layfield",
      "guid": 49104,
      "unread": true,
      "content": "<article>Everyone who runs a subscription business has to eventually decide if they‚Äôre going buy a subscription manger.</article>",
      "contentLength": 112,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Sparse Activation in MoE Models: Extending ReLUfication to Mixture-of-Experts",
      "url": "https://hackernoon.com/sparse-activation-in-moe-models-extending-relufication-to-mixture-of-experts?source=rss",
      "date": 1772235979,
      "author": "Language Models (dot tech)",
      "guid": 49103,
      "unread": true,
      "content": "<h2>4 Are Neurons in Expert still Sparsely Activated?</h2><p>Previous work has shown that dense LLMs with different activation functions (ReLU, SwiGLU, etc.) exhibit the property of sparse activation [69, 36, 30]. However, the analysis is limited to dense models. Despite the intuitive assumption that partitioning FFNs into different experts within an MoE model would result in denser activations within each expert, it remains unclear whether this sparsity phenomenon persists in MoE models. In this section, we select representative MoE models and commonly used downstream tasks to investigate whether this sparsity phenomenon still exists in MoE models. We utilize the same method in 3 to control the sparsity in each expert.</p><p>\\\n. We select Deepseek-MoE [15], Qwen1.5-MoE [5] and Mixtral [25] as the models for our experiments. We also add Llama-2-7B as for comparison.</p><p>\\\nWe first study the performance with regard to the sparsity ratio, as shown in Figure 5 (a)[2]. Specifically, the performance only drops by about 1%-2% when the sparsity ratio is 0.5. This trend suggests that MoE models exhibit similar sparsity compared to dense models.</p><p>\\\nFurther, we profile the activation patterns of Mistral and Mixtral, a pair of popular dense LLM and MoE LLM, as shown in Figure 5 (b). We find that both LLMs show a similar pattern where activations are concentrated around 0, which is consistent with previous analysis of dense LLMs. The sparsity in experts also implies that every neuron in the same expert has different functionality. This finding applies to all layers and experts, as detailed in Appendix A.2. We report this interesting observation and leave further analysis for future work.</p><p>\\\n\\\nInspired by our discoveries in MoE models, we are convinced that ReLUfication can be extended to MoE models and is not restricted to dense models. As the proportion of FFN weights in MoE models increases, the FLOP reduction achieved through ReLUfication will be even more pronounced.</p><p>(1) Yixin Song, Institute of Parallel and Distributed Systems (IPADS), Shanghai Jiao Tong University;</p><p>(2) Haotong Xie, Institute of Parallel and Distributed Systems (IPADS), Shanghai Jiao Tong University;</p><p>(3) Zhengyan Zhang, Department of Computer Science and Technology, Tsinghua University;</p><p>(4) Bo Wen, Institute of Parallel and Distributed Systems (IPADS), Shanghai Jiao Tong University;</p><p>(5) Li Ma, Shanghai Artificial Intelligence Laboratory;</p><p>(6) Zeyu Mi, Institute of Parallel and Distributed Systems (IPADS), Shanghai Jiao Tong University Mi yzmizeyu@sjtu.edu.cn);</p><p>(7) Haibo Chen, Institute of Parallel and Distributed Systems (IPADS), Shanghai Jiao Tong University.</p>",
      "contentLength": 2631,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Subscription Growth: The Momentum You Can‚Äôt See",
      "url": "https://hackernoon.com/subscription-growth-the-momentum-you-cant-see?source=rss",
      "date": 1772235899,
      "author": "Dan Layfield",
      "guid": 49102,
      "unread": true,
      "content": "<article>A $1M MRR celebration turned into a refunds lesson‚Äîand a framework for why subscription growth feels slow, hides wins, and compounds over time.</article>",
      "contentLength": 145,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "South Korea Set To Get a Fully Functioning Google Maps",
      "url": "https://tech.slashdot.org/story/26/02/27/2144239/south-korea-set-to-get-a-fully-functioning-google-maps?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1772234400,
      "author": "BeauHD",
      "guid": 49007,
      "unread": true,
      "content": "South Korea has reversed a two-decade policy and approved the export of high-precision map data, paving the way for a fully functional Google Maps in the country. Reuters reports: The approval was made \"on the condition that strict security requirements are met,\" the Ministry of Land, Infrastructure and Transport said in a statement. Those conditions include blurring military and other sensitive security-related facilities, as well as restricting longitude and latitude coordinates for South Korean territory on products such as Google Maps and Google Earth, it said.\n \nThe decision is expected to hurt Naver and Kakao -- local internet giants which currently dominate the country's market for digital map services. But it will appease Washington, which has urged Seoul to tackle what it says is discrimination against U.S. tech companies. South Korea, still technically at war with North Korea, had shot down Google's previous bids in 2007 and 2016 to be allowed to export the data, citing the risks that information about sensitive military and security facilities could be exposed. \"Google can now come in, slash usage fees, and take the market,\" said Choi Jin-mu, a geography professor at Kyung Hee University. \"If Naver and Kakao are weakened or pushed out and Google later raises prices, that becomes a monopoly. Then, even companies that rely on map services -- logistics firms, for example -- become dependent, and in the long run, even government GIS (geographic information) systems could end up dependent on Google or Apple. That's the biggest concern.\"",
      "contentLength": 1568,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "The NFL Won A Lawsuit Over Its Bluesky Ban. Its Social Media Strategy Is Still A Loser",
      "url": "https://www.techdirt.com/2026/02/27/the-nfl-won-a-lawsuit-over-its-bluesky-ban-its-social-media-strategy-is-still-a-loser/",
      "date": 1772233656,
      "author": "Mike Masnick",
      "guid": 49006,
      "unread": true,
      "content": "<p><strong>Full disclosure up front:</strong> I sit on the board of Bluesky. That said, I had absolutely no idea this lawsuit existed until recently. Which, honestly, tells you something about how much of a legal non-event it was. But the underlying story here‚Äîabout the NFL treating social media the way it treats television broadcast rights‚Äîis worth digging into, because it reveals something deeply broken about how major sports leagues think about the internet.</p><p>The 2025-2026 NFL season just wrapped up, and along with it came a federal court ruling in a case called Brown v. NFL that most people missed entirely. Two football fans‚Äîone in Illinois, one in California‚Äî<a href=\"https://api.www.documentcloud.org/files/documents/27411444/brownvnfl242026.pdf\">sued the NFL under the Sherman Act</a>, claiming the league violated antitrust law by barring its teams from posting on Bluesky. The fans wanted to follow their teams‚Äîthe Bears and the now-champion Seahawks‚Äîon the platform they actually use, rather than on Elon Musk‚Äôs X. The court dismissed the case for lack of standing, and honestly, that was probably the right legal outcome.</p><p>The fans couldn‚Äôt demonstrate a concrete injury‚Äîthe information they wanted was still available, for free, on X. As the court put it, their grievance reduced to being ‚Äúdenied the ability to obtain real-time NFL team information on a private platform with which they are ideologically comfortable.‚Äù And ‚ÄúI don‚Äôt like Elon Musk‚Äù is not an antitrust injury. The Sherman Act targets conspiracies that restrain trade and harm competition‚Äînot content distribution preferences. You can‚Äôt force a private organization to distribute its content on the platform you like best, just as we‚Äôve called out attempts to force social media platforms to carry content they don‚Äôt want to carry.</p><p>But the fact that the NFL is  to be this myopic doesn‚Äôt make it a smart business decision. You can be entirely within your rights and still be making a spectacularly bad call.</p><p>Since 2013, the NFL has had a ‚Äúcontent partnership‚Äù with X (dating back to when it was the useful site known as Twitter). The deal lets X publish real-time highlights, and in return the league gets‚Ä¶ money, presumably. As the court noted in its ruling:</p><blockquote><p><em>Since 2013, the NFL and X (formerly Twitter, Inc.) have had a ‚Äúcontent partnership.‚Äù It allows X to publish real-time highlights from football games, such as touchdowns. During the offseason, reporters post on X with news about team practices and other NFL-related topics, and fans on X discuss teams‚Äô acquisitions of free agents and other roster changes. For example, during the NFL draft (the high-profile annual event in which teams select eligible players to join their rosters), X published more than one million posts concerning the NFL; these appeared on users‚Äô screens more than 800 million times. The NFL has repeatedly renewed its partnership with X. Fans do not pay money to receive NFL news on X.</em></p></blockquote><p>Fine. Lots of organizations have deals with social media platforms. But this just seems like self-sabotage: the NFL apparently used this partnership as justification to tell its own teams they <strong>couldn‚Äôt even  on a competing platform</strong>. Multiple NFL teams‚Äîincluding the New England Patriots‚Äîhad set up accounts on Bluesky, started posting, and were building audiences. And then the league office stepped in and told them to shut it all down.</p><blockquote><p><em>Initially, multiple NFL teams, including the New England Patriots, had accounts on Bluesky to communicate with fans‚Ä¶.</em></p><p><em>As alleged, however, the NFL later instructed its member teams to delete their Bluesky accounts. But for this instruction, at least some NFL teams would use Bluesky. The Patriots‚Äô vice president of content, Fred Kirsch, for example, has stated: ‚ÄúWhenever the league gives us the green light[,] we‚Äôll get back on Bluesky.‚Äù</em></p></blockquote><p>Yes, the (Super Bowl-losing) Patriots‚Äô VP of content is publicly saying his team  to be on Bluesky and is just waiting for the league to  them. This wasn‚Äôt a case of teams being uninterested. Teams saw the audience there, set up shop, and were actively communicating with fans‚Äîand the NFL made them stop.</p><p>So the NFL has essentially decided that when it comes to the kind of real-time updates that fans actually care about, X is the only approved outlet. Everything else is locked out.</p><p>This is ‚Äúbroadcast-brain‚Äù thinking applied to the internet, and it‚Äôs spectacularly dumb.</p><p>The NFL is treating social media platforms the way it treats regional sports networks or its Sunday Ticket package: as exclusive territories to be carved up and sold to the highest bidder. In the television world, that model makes a certain kind of sense‚Äîthere‚Äôs a limited amount of spectrum, a limited number of cable channels, and that scarcity creates value. But social media doesn‚Äôt work that way. There‚Äôs no scarcity. Posting an injury report on Bluesky doesn‚Äôt  it from X. Cross-posting is literally free. The entire point of social media for a brand is to be everywhere your audience is.</p><p>And the audience, increasingly, is on Bluesky. As <a href=\"https://mashable.com/article/nfl-bluesky-great-why-how-to-join\">Mashable noted last year</a> heading into the season, the NFL community on Bluesky had already hit a kind of critical mass:</p><blockquote><p><em>You need the presence and regular posting of big names to legitimize a platform. It certainly helped that folks like Kimes and a</em><a href=\"https://bsky.app/profile/dannyheifetz.bsky.social\"></a><a href=\"https://bsky.app/profile/dannybkelly.bsky.social\"></a><a href=\"https://bsky.app/profile/craighorlbeck.bsky.social\"></a><a href=\"https://bsky.app/profile/sheilkapadia.bsky.social\"></a><a href=\"https://bsky.app/profile/diantelee.bsky.social\"></a><em>at popular sports sites like The Ringer made Bluesky home. And last season it felt like Bluesky hit terminal velocity, where enough people joined that you could fully exit to the site for football content. And with the migration of the professionals, the shitposters naturally came along, too. Because that‚Äôs where the discussion was happening. There is genuine, easy-to-find, fun NFL talk on Bluesky with minimal interruptions from, say,</em><a href=\"https://mashable.com/article/x-threatened-lawsuits-to-pressure-advertisers\"></a><a href=\"https://mashable.com/article/bluesky-half-a-million-new-users-after-x-twitter-block-change\"></a></p></blockquote><p>That‚Äôs a real community. A vibrant, engaged community of exactly the kind of hardcore football fans that the NFL should be desperate to cultivate. These are, as Mashable noted, the ‚Äúball knowers.‚Äù They‚Äôve moved to Bluesky because, well, X kind of sucks now for following sports. As Mashable also noted:</p><blockquote><p><em>Bluesky does have a leg-up in some areas ‚Äî Elon Musk‚Äôs site recently has proven unreliable for NFL fans. The</em><a href=\"https://mashable.com/article/x-twitter-down-crash\"><em>site crashed the morning free agency launched</em></a><em>, which is one of the most important days for NFL social media. And the sports tab ‚Äî which used to be an easy, fun way to follow games in the Twitter days ‚Äî</em><a href=\"https://mashable.com/article/twitter-sports-tab-issues-problems\"><em>degraded into near uselessness</em></a><em>years ago. And, in general, X has morphed with Musk‚Äôs image, which is focused</em><a href=\"https://mashable.com/article/grok-4-launched\"></a><em>and politics ‚Äî not things like following football. Of course you can still follow the NFL on X, but it does involve wading through more junk than it used to. Bluesky offers an interesting alternative in that regard.</em></p></blockquote><p>So the most engaged, most knowledgeable football community has moved to Bluesky. The teams themselves  to be on Bluesky. And the NFL‚Äôs response to all of this is‚Ä¶ to ban its teams from showing up.</p><p>It‚Äôs the digital equivalent of a local blackout (something <a href=\"https://www.techdirt.com/2009/08/31/nfl-doesnt-get-it-blocking-fans-doesnt-make-them-like-teams-any-more/\">we‚Äôve been calling out</a> for well over a decade)‚Äîpunishing your most dedicated fans because of some deal you cut with a middleman in an effort to create an artificial and unnecessary scarcity.</p><p>Meanwhile, the platform the NFL is propping up with this exclusivity arrangement is one where fans who tuned in for the Super Bowl halftime show got to watch a significant chunk of the X user base have a <a href=\"https://nypost.com/2026/02/09/us-news/bad-bunny-slammed-for-controversial-super-bowl-halftime-show-decision-that-encourages-division/\">full-blown racist meltdown over Bad Bunny performing</a>. The NFL specifically chose Bad Bunny to appeal to a broader, more global audience‚Äîand the audience that actually appreciated the choice? They were on Bluesky where there was an overwhelming wave of support for the performance. The league is betting its real-time presence on the platform where its expansion strategy gets shouted down, while blocking teams from the one where those new fans are actually showing up.</p><p>This kind of control-freakery from the NFL shouldn‚Äôt surprise anyone who has followed the league‚Äôs behavior over the years. This is the same organization that has spent decades <a href=\"https://www.techdirt.com/2026/02/06/reminder-dont-believe-the-nfls-lies-about-its-super-bowl-trademarks/\">aggressively lying to bars, restaurants, and small businesses</a> about the scope of its ‚ÄúSuper Bowl‚Äù trademarks, sending threatening letters suggesting you can‚Äôt even  ‚ÄúSuper Bowl‚Äù in an ad without a license‚Äîsomething that has never actually been true.</p><p>The NFL‚Äôs institutional DNA is ‚Äúcontrol equals value,‚Äù and they apply that logic to everything, from what a church can call its viewing party to which social media apps their teams are permitted to use.</p><p>The problem is that control-based thinking only works when you actually  control the ecosystem. You can (sort of) control which networks broadcast your games. You can control which streaming service gets Sunday Ticket. You cannot control where fans choose to talk about football on the internet. The conversation is going to happen whether the NFL‚Äôs official accounts are there or not. The only question is whether the league‚Äôs teams get to participate in it.</p><p>Any organization whose core business depends on fan engagement should be finding fans where they are, not herding them onto a single platform because you cut an exclusivity deal. Especially when that platform is increasingly known for being a hellscape of AI slop, political rage, and engagement-bait, while the platform you‚Äôre blocking your teams from is the one where people are actually talking about your product with genuine enthusiasm.</p><p>The NFL generates billions in revenue. And yet, when it comes to social media strategy, it‚Äôs stuck in a 2005 mindset. That‚Äôs not how any of this works anymore.</p><p>Someone at NFL HQ needs to understand that when your most passionate fans have moved to a new platform and your own teams are begging for permission to follow them there, the smart play is to let them go.</p>",
      "contentLength": 9707,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "OpenAI fires employee for using confidential info on prediction markets",
      "url": "https://techcrunch.com/2026/02/27/openai-fires-employee-for-using-confidential-info-on-prediction-markets/",
      "date": 1772233254,
      "author": "Julie Bort",
      "guid": 48999,
      "unread": true,
      "content": "<article>The company said such trades violates its internal company policies about using confidential information for personal gain.</article>",
      "contentLength": 123,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Trump Orders Federal Agencies To Stop Using Anthropic AI Tech 'Immediately'",
      "url": "https://tech.slashdot.org/story/26/02/27/2138211/trump-orders-federal-agencies-to-stop-using-anthropic-ai-tech-immediately?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1772232000,
      "author": "BeauHD",
      "guid": 48998,
      "unread": true,
      "content": "President Donald Trump has ordered all U.S. federal agencies to \"immediately cease\" using Anthropic's AI technology, escalating a standoff after the company sought limits on Pentagon use of its models. CNBC reports: The company, which in July signed a $200 million contract with Pentagon, wants assurances that the Defense Department will not use its AI models will not be used for fully autonomous weapons or mass domestic surveillance of Americans. The Pentagon had set a deadline of 5:01 p.m. ET Friday for Anthropic to agree to its demands to allow the Pentagon to use the technology for all lawful purposes. If Anthropic did not meet that deadline, Pete Hegseth threatened to label the company a \"supply chain risk\" or force it to comply by invoking the Defense Production Act.\n \n\"The Leftwing nut jobs at Anthropic have made a DISASTROUS MISTAKE trying to STRONG-ARM the Department of War, and force them to obey their Terms of Service instead of our Constitution,\" Trump said in a post on Truth Social. \"Their selfishness is putting AMERICAN LIVES at risk, our Troops in danger, and our National Security in JEOPARDY.\"\n \n\"Therefore, I am directing EVERY Federal Agency in the United States Government to IMMEDIATELY CEASE all use of Anthropic's technology,\" Trump wrote. \"We don't need it, we don't want it, and will not do business with them again! There will be a Six Month phase out period for Agencies like the Department of War who are using Anthropic's products, at various levels,\" Trump said. On Friday, OpenAI said it would also draw the same red lines as Anthropic: no AI for mass surveillance or autonomous lethal weapons.",
      "contentLength": 1640,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "US Military Accidentally Shoots Down Border Protection Drone With Laser",
      "url": "https://tech.slashdot.org/story/26/02/27/2133209/us-military-accidentally-shoots-down-border-protection-drone-with-laser?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1772229720,
      "author": "BeauHD",
      "guid": 48997,
      "unread": true,
      "content": "An anonymous reader quotes a report from the Associated Press: The U.S. military used a laser Thursday to shoot down a \"seemingly threatening\" drone flying near the U.S.-Mexico border. It turned out the drone belonged to Customs and Border Protection, lawmakers said. The case of mistaken identity prompted the Federal Aviation Administration to close additional airspace around Fort Hancock, about 50 miles (80 kilometers) southeast of El Paso. The military is required to formally notify the FAA when it takes any counter-drone action inside U.S. airspace.\n \nIt was the second time in two weeks that a laser was fired in the area. The last time it was CBP that used the weapon and nothing was hit. That incident occurred near Fort Bliss and prompted the FAA to shut down air traffic at El Paso airport and the surrounding area. This time, the closure was smaller and commercial flights were not affected. The FAA, CBP and the Pentagon confirmed the incident in a joint statement, saying the military \"employed counter-unmanned aircraft system authorities to mitigate a seemingly threatening unmanned aerial system operating within military airspace.\"\n \n\"At President Trump's direction, the Department of War, FAA, and Customs and Border Patrol are working together in an unprecedented fashion to mitigate drone threats by Mexican cartels and foreign terrorist organizations at the U.S.-Mexico Border,\" the statement said. The report notes that 27,000 drones were detected within 1,600 feet of the southern border in the last six months of 2024.\n \nIllinois Democratic U.S. Sen. Tammy Duckworth, the ranking member on the Senate's Aviation Subcommittee, is calling for an independent investigation to look into the matter. \"The Trump administration's incompetence continues to cause chaos in our skies,\" Duckworth said.",
      "contentLength": 1819,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Pentagon moves to designate Anthropic as a supply-chain risk",
      "url": "https://techcrunch.com/2026/02/27/pentagon-moves-to-designate-anthropic-as-a-supply-chain-risk/",
      "date": 1772229194,
      "author": "Russell Brandom",
      "guid": 48978,
      "unread": true,
      "content": "<article>\"We don't need it, we don't want it, and will not do business with them again,\" the president wrote in the post.</article>",
      "contentLength": 112,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "White House Stalls Release of Approved US Science Budgets",
      "url": "https://news.slashdot.org/story/26/02/27/207211/white-house-stalls-release-of-approved-us-science-budgets?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1772227500,
      "author": "msmash",
      "guid": 48970,
      "unread": true,
      "content": "An anonymous reader shares a report: Weeks after the U.S. Congress rejected unprecedented cuts to science budgets that the administration of US President Donald Trump had sought for 2026, funding to several agencies that award research grants is still not freely flowing. \n\nOne reason is that the White House Office of Management and Budget (OMB) has been slow to authorize its release. The US National Institutes of Health (NIH) has so far not received approval to spend any of the research funding allocated in a budget bill signed into law on 3 February. The US National Science Foundation (NSF) was authorized to spend its funding just last week. And NASA has had its full funding authorized for release, but with an unusual restriction that limits spending on ten specific programmes -- many of which the Trump team had tried to cancel last year.",
      "contentLength": 851,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Whistleblower: ICE Has Slashed Its Training Program And Its Boss Is Lying To Congress About It",
      "url": "https://www.techdirt.com/2026/02/27/whistleblower-ice-has-slashed-its-training-program-and-its-boss-is-lying-to-congress-about-it/",
      "date": 1772225502,
      "author": "Tim Cushing",
      "guid": 48969,
      "unread": true,
      "content": "<p>ICE can‚Äôt keep up <a href=\"https://www.techdirt.com/2025/08/08/courts-start-asking-about-the-ice-arrest-quota-the-administration-is-now-pretending-isnt-a-quota/\" data-type=\"link\" data-id=\"https://www.techdirt.com/2025/08/08/courts-start-asking-about-the-ice-arrest-quota-the-administration-is-now-pretending-isnt-a-quota/\">with the baseline set</a> by resident ghoul/White House advisor Stephen Miller. Miller has demanded 3,000 arrests , which he presented as the  he would be satisfied with. </p><p>To reach this goal, tons of talent from other federal law enforcement agencies have been added to the mix. The results have been <a href=\"https://www.techdirt.com/2026/01/30/tom-homan-to-minneapolis-look-i-warned-you-if-you-werent-nice-wed-have-to-kill-again-and-look-what-you-made-us-do/\" data-type=\"link\" data-id=\"https://www.techdirt.com/2026/01/30/tom-homan-to-minneapolis-look-i-warned-you-if-you-werent-nice-wed-have-to-kill-again-and-look-what-you-made-us-do/\">less than impressive</a>, to be entirely too kind to these kidnappers and murderers.</p><p>CBP and Border Patrol officers used to handling border crossing business are now roaming the streets of Midwestern cities looking for anyone who seems a bit too dark to be a native. In addition, nearly  of FBI agents <a href=\"https://www.techdirt.com/2025/10/16/nearly-half-of-fbi-agents-in-large-field-offices-have-been-put-on-ice/\" data-type=\"link\" data-id=\"https://www.techdirt.com/2025/10/16/nearly-half-of-fbi-agents-in-large-field-offices-have-been-put-on-ice/\">have been placed</a> on the ‚Äúfind the brown person‚Äù beat, along with volunteers/voluntolds from DEA, ATF, US Secret Service, Homeland Security Investigations, and anyone else with a badge they‚Äôre unwilling to display prominently when raiding local day care centers.</p><p>The GOP threw a <a href=\"https://www.techdirt.com/2025/07/07/trump-budget-bill-turns-ice-into-a-superpredator/\" data-type=\"link\" data-id=\"https://www.techdirt.com/2025/07/07/trump-budget-bill-turns-ice-into-a-superpredator/\">whole lot of money</a> at ICE with the ‚ÄúBig Beautiful Bill.‚Äù ICE is throwing a lot of money at potential hires, <a href=\"https://www.techdirt.com/2025/08/06/area-bigots-annoyed-ice-is-offering-50000-signing-bonuses-to-area-bigots/\" data-type=\"link\" data-id=\"https://www.techdirt.com/2025/08/06/area-bigots-annoyed-ice-is-offering-50000-signing-bonuses-to-area-bigots/\">much to the chagrin</a> of law enforcement agencies everywhere, as well as already-understaffed prisons and jails. </p><p>The expectations were lowered, along with the bar for entry. The promise of a $50,000 signing bonus has <a href=\"https://www.techdirt.com/2025/10/03/the-people-applying-for-ice-jobs-are-exactly-who-you-think-they-are/\" data-type=\"link\" data-id=\"https://www.techdirt.com/2025/10/03/the-people-applying-for-ice-jobs-are-exactly-who-you-think-they-are/\">managed to attract</a> the expected blend of MAGA faithful, retired cops, bigots (but I repeat myself‚Ä¶), and anyone who thinks they have what it takes to <a href=\"https://www.techdirt.com/2026/01/29/jd-vance-children-of-people-seeking-asylum-are-illegals-that-need-to-be-deported/\" data-type=\"link\" data-id=\"https://www.techdirt.com/2026/01/29/jd-vance-children-of-people-seeking-asylum-are-illegals-that-need-to-be-deported/\">frog-walk five-year-olds</a> to the nearest rented SUV. </p><p>Hiring a bunch of people is only half the battle. The next step is preparing them to do their jobs. Ridding the nation of migrants is Job #1 here in America at the moment. But it‚Äôs a job too important to be done well by fully trained ICE officers. Quantity over quality is the name of the game, as former ICE trainer Ryan Schwank ‚Äî who only resigned  ‚Äî told Congress. <a href=\"https://www.washingtonpost.com/immigration/2026/02/23/former-ice-instructor-says-agency-slashed-training-new-officers/\" data-type=\"link\" data-id=\"https://www.washingtonpost.com/immigration/2026/02/23/former-ice-instructor-says-agency-slashed-training-new-officers/\">Here‚Äôs the Washington Post with the details</a>:</p><blockquote><p><em>[S]chwank‚Ä¶ told congressional Democrats at a hearing that the agency eliminated 240 hours of ‚Äúvital classes‚Äù from a mandatory 580-hour training program, including instruction about the legal boundaries for the use of force, how to safely handle firearms, and the proper way to detain and arrest immigrants.</em></p></blockquote><p>Seems like a pretty sweet deal for new hires. Not only do they get a hefty signing bonus, but they don‚Äôt have to go through 40% of the training. Giving people guns and the power to deprive others of their lives and liberties should mean giving them the best possible training you can in hopes of heading off‚Ä¶ well‚Ä¶ pretty much everything we‚Äôve been seeing lately during Trump‚Äôs anti-blue state/city surges. </p><p>Certainly, the administration is already doing everything it can to undercut the credibility of its now-former employee. But it‚Äôs not going to work unless you‚Äôre an idiot who prefers nigh-incoherent MAGA invective to actual facts. You see, Schwank didn‚Äôt just bring  to this hearing. He also brought receipts. </p><blockquote><p><em>Ahead of the hearing, Schwank provided a joint panel of House and Senate Democrats copies of internal ICE documents that he said show the extent of the cuts. The documents indicated that the Federal Law Enforcement Training Centers in Glynco, Georgia, shortened its training program from 72 days to 42 days.</em></p></blockquote><p>Except that‚Äôs not what Todd Lyons said to Congress when he was asked to testify following two murders committed by federal officers in Minneapolis, Minnesota. Lyons claimed nothing important had been cut. He also said this, which is directly contradicted by the documents Schwank gave to lawmakers: </p><blockquote><p><em>In a statement Monday, the Department of Homeland Security said ICE recruits receive 56 days of training before beginning their assignments‚Ä¶</em></p></blockquote><p>Lyons went on to say that an ‚Äúaverage‚Äù of 28 days of additional ‚Äúon the job training‚Äù occurs after that. But even if you might believe Lyons is stacking his apples against the apples in ICE‚Äôs internal documents to come up with 84 days of training, you‚Äôre miscounting apples the same way Lyons is. OJT is post-assignment. Even if you choose to believe Lyons more than the documents his own agency generated, officers are still being put on the street two weeks earlier than they used to be. </p><p>The lies persist, of course. The statement provided to the Post says something else entirely, which is also contradicted by the documents and statements made by Schwank.</p><blockquote><p><em>‚ÄúNo training hours have been cut. Our officers receive extensive firearm training, are taught de-escalation tactics, and receive Fourth and Fifth Amendment comprehensive instruction,‚Äù said Lauren Bis, a spokeswoman for the department.</em></p></blockquote><p>But training hours  been cut. And the rest of it is pure horseshit, especially the part about training new hires about the Fourth and Fifth Amendment. Schwank‚Äôs testimony noted that he was asked to review an internal memo signed by Lyons that claimed ‚Äî untruthfully ‚Äî that ICE officers <a href=\"https://www.techdirt.com/2026/01/22/since-last-may-ice-officers-have-been-told-they-dont-need-warrants-to-enter-homes/\" data-type=\"link\" data-id=\"https://www.techdirt.com/2026/01/22/since-last-may-ice-officers-have-been-told-they-dont-need-warrants-to-enter-homes/\">can enter people‚Äôs homes</a> using only a self-issued administrative warrant. </p><p>Other rights were similarly glossed over. In fact, some of them are ignored completely. </p><blockquote><p><em>[Schwank] also said that a two-hour class on the rights of protesters was shortened into 10 minutes of discussion during a lecture on ‚Äúthe concept of seizure.‚Äù</em></p></blockquote><p>Nice. That‚Äôs the way to do it. Goodbye, First Amendment. Instead, here‚Äôs 10 minutes of ICE‚Äôs interpretative dance: ‚ÄúThe Fourth Amendment, And What It Doesn‚Äôt Mean To Us.‚Äù </p><p>Everyone knew that once the cattle call began, ICE would be swarmed with opportunists who saw a great way to combine their bigotry and violence tendencies with a career ‚Äî however short-lived ‚Äî in public service. A steady paycheck, and all the government asked was that you show up at least 40% of the time during training. </p><p>This horde (actual number unknown) is being pushed through the doors towards their on-the-job-training, armed with little more than their masks, their guns, and some very comprehensive incorrecting of their constitutional notions.</p><p>Of course, none of this will matter to the people running ICE. I‚Äôm pretty sure they  this press. They have no interest in heading up a finely-tuned precise instrument of immigration law enforcement. They‚Äôd rather have the untargeted terrorizing of entire neighborhoods and the unearned swagger of a paramilitary death squad that somehow can still be <a href=\"https://www.techdirt.com/2026/01/28/minneapolis-proved-something-maga-cant-accept-most-people-are-actually-virtuous/\" data-type=\"link\" data-id=\"https://www.techdirt.com/2026/01/28/minneapolis-proved-something-maga-cant-accept-most-people-are-actually-virtuous/\">hooted, horn-honked, and whistled</a> into submission by suburbanites. And maybe this isn‚Äôt even an intentional design decision. There‚Äôs a good chance no one up top is intelligent enough to recognize the self-destructiveness of their actions. For now, at least, we know what they know. And  know this is wrong. </p>",
      "contentLength": 6575,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "'The Death of Spotify: Why Streaming is Minutes Away From Being Obsolete'",
      "url": "https://entertainment.slashdot.org/story/26/02/27/1941205/the-death-of-spotify-why-streaming-is-minutes-away-from-being-obsolete?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1772225460,
      "author": "msmash",
      "guid": 48961,
      "unread": true,
      "content": "An anonymous reader shares a column: I'm going to take the diplomatic hat off here and say with brutal honesty: basically everybody in the music business hates Spotify except for the people who work there. It's a platform that sucks artists for everything they have, it actively prevents community building, and, despite all of that, the platform still struggles to maintain a healthy profit margin. \n\nThe streaming business model is fundamentally broken. And eventually, its demise will become more and more obvious to recognize. I'll break down exactly why the DSP era is coming to a grinding halt, why the major labels are quietly terrified, and why the artists who don't pivot now are going to go down with the ship. \n\n[...] Jimmy Iovine put it bluntly: \"The streaming services have a bad situation, there's no margins, they're not making any money.\" This model only works for Apple, Amazon, and Google, because they don't need their music platforms to be wildly profitable. Amazon uses music as a loss-leader to keep you paying for Prime. Apple uses it to sell $1,000 iPhones. As for Spotify, or any standalone music streaming company, they're kind of screwed. And guess what -- when the platform's margins are structurally squeezed, guess who gets squeezed first? The artists. \n\n[...] What if Jimmy is right? If the DSPs are \"minutes away from obsolete,\" what replaces them? Well, I'm not sure the DSPs are going to disappear overnight, but if you're an artist or a manager trying to sustain yourself in this evolving music economy, the answer is direct ownership. The artists who will survive the next five years are the ones who are quietly shifting their focus away from the \"ATM Machine.\" \n\nThey are building their own cultural hangars. They are capturing phone numbers on Laylo. They are driving fans to private Discord servers. They are focusing on ARPF (Average Revenue Per Fan) through high-margin merch, vinyl, and hard tickets, rather than begging for fractions of a penny from a playlist placement. We are witnessing the death of the \"Mass Audience\" and the birth of the \"Micro-Community.\"",
      "contentLength": 2106,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "AI Mistakes Are Infuriating Gamers as Developers Seek Savings",
      "url": "https://games.slashdot.org/story/26/02/27/1934258/ai-mistakes-are-infuriating-gamers-as-developers-seek-savings?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1772223000,
      "author": "msmash",
      "guid": 48960,
      "unread": true,
      "content": "The $200 billion video game industry is caught between studios eager to cut ballooning development costs through AI and a player base that has grown openly hostile to the technology after a string of visible blunders. \n\nAs Bloomberg News reports, Arc Raiders, a surprise hit from Stockholm-based Embark Studios that sold 12 million copies in three months, was briefly vilified online for its robotic-sounding auto-generated voices -- even as CEO Patrick Soderlund insists AI was only used for non-essential elements. EA's Battlefield 6 and Activision's Call of Duty: Black Ops 7 both drew gamer anger this winter over thematically mismatched or poorly generated graphics, and Valve's Steam has added labels to flag games made using AI. \n\nSome 47% of developers polled by research house Omdia said they expect generative AI to reduce game quality, and PC gamers -- now facing inflated hardware prices from AI-driven demand for graphics chips -- have turned reflexively antagonistic.",
      "contentLength": 981,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Musk bashes OpenAI in deposition, saying ‚Äònobody committed suicide because of Grok‚Äô",
      "url": "https://techcrunch.com/2026/02/27/musk-bashes-openai-in-deposition-saying-nobody-committed-suicide-because-of-grok/",
      "date": 1772221320,
      "author": "Sarah Perez",
      "guid": 48955,
      "unread": true,
      "content": "<article>In his lawsuit against OpenAI, Musk touted xAI safety compared with ChatGPT. A few months later, xAI's Grok flooded X with nonconsensual nude images.</article>",
      "contentLength": 149,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Intel Releases Updated CPU Microcode For Xeon 6 SoCs \"Granite Rapids D\"",
      "url": "https://www.phoronix.com/news/Intel-Microcode-20260227",
      "date": 1772220907,
      "author": "Michael Larabel",
      "guid": 48959,
      "unread": true,
      "content": "<article>Catching me by surprise today was a new Intel CPU microcode drop \"20260227\" for Linux users/administrators outside of their typical Patch Tuesday alignment for CPU microcode releases...</article>",
      "contentLength": 185,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Smartphone Market To Decline 13% in 2026, Marking the Largest Drop Ever Due To the Memory Shortage Crisis",
      "url": "https://mobile.slashdot.org/story/26/02/27/1917219/smartphone-market-to-decline-13-in-2026-marking-the-largest-drop-ever-due-to-the-memory-shortage-crisis?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1772220600,
      "author": "msmash",
      "guid": 48948,
      "unread": true,
      "content": "An anonymous reader shares a report: Worldwide smartphone shipments are forecast to decline 12.9% year-on-year (YoY) in 2026 to 1.1 billion units, according to the International Data Corporation (IDC) Worldwide Quarterly Mobile Phone Tracker. This decline will bring the smartphone market to its lowest annual shipment volume in more than a decade. The current forecast represents a sharp decline from our November forecast amid the intensifying memory shortage crisis.",
      "contentLength": 469,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Anthropic vs. the Pentagon: What‚Äôs actually at stake?",
      "url": "https://techcrunch.com/2026/02/27/anthropic-vs-the-pentagon-whats-actually-at-stake/",
      "date": 1772219464,
      "author": "Rebecca Bellan",
      "guid": 48933,
      "unread": true,
      "content": "<article>Anthropic and the Pentagon are clashing over AI use in autonomous weapons and surveillance, raising high-stakes questions about national security, corporate control, and who sets the rules for military AI.</article>",
      "contentLength": 205,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Verizon Continues To Make Phone Unlocking Annoying (With The Trump FCC‚Äôs Help)",
      "url": "https://www.techdirt.com/2026/02/27/verizon-continues-to-make-phone-unlocking-annoying-with-the-trump-fccs-help/",
      "date": 1772218920,
      "author": "Karl Bode",
      "guid": 48943,
      "unread": true,
      "content": "<p>Earlier this year&nbsp;<a href=\"https://www.techdirt.com/2026/01/16/trump-fcc-helps-verizon-make-it-harder-for-you-to-switch-wireless-carriers/\">we noted how the Trump FCC</a>, at the direct request of wireless phone giants, destroyed popular phone unlocking rules making it easier and cheaper to switch wireless carriers. The rules, applied via spectrum acquisition and merger conditions after years of activism, required that Verizon unlock your phone within 60 days after purchase so you could easily switch to competitors.</p><p>Verizon, as we‚Äôve long established, hates competition, and early last year immediately got to work lobbying the Trump administration to destroy the rules (falsely) claiming, without evidence, that the modest phone unlocking requirements were a boon to criminals and scammers. </p><p>The pay-to-play Trump administration quickly agreed, killed the rules, and shortly thereafter Verizon started telling wireless customers on its many prepaid phone brands (including Tracfone)&nbsp;<a href=\"https://arstechnica.com/tech-policy/2026/01/verizon-starts-requiring-365-days-of-paid-service-before-it-will-unlock-phones/\">they had to wait a year before switching phones</a>&nbsp;after purchasing one from Verizon:</p><blockquote><p><em>‚ÄúWhile a locked phone is tied to the network of one carrier, an unlocked phone can be switched to another carrier if the device is compatible with the other carrier‚Äôs network. But the new TracFone unlocking policy is stringent, requiring customers to pay for a full year of service before they can get a phone unlocked.‚Äù</em></p></blockquote><blockquote><p><em>‚ÄúPayments made over the phone also trigger a 35-day waiting period, as do payments made at Verizon Authorized Retailers. Getting an immediate unlock apparently requires paying off the device plan at a Verizon corporate store.‚Äù</em></p></blockquote><p>So first, they implemented the most draconian restrictions on its , who tend to be lower income and the most impacted from high prices. Now they‚Äôre starting to push restrictions onto their more lucrative postpaid (month to month) customers. </p><p>Verizon insists (falsely) that these restrictions are necessary to ‚Äúprevent fraud,‚Äù but the real goal is to increase friction when <strong><em>it comes to switching to a competitor</em></strong>. They don‚Äôt want the press to outright <em>acknowledge this is anti-competitive in coverage</em>, so they‚Äôre engaging in the slow-boiling frog approach that just <em>steadily makes porting your phone out steadily more difficult and annoying</em>. </p><p>These unlocking conditions were broadly popular, served the public interest, and <strong>took decades of activism and reform advocacy to pass</strong>. They ensured that it was easier for consumers to switch between our ever-consolidating, anti-competitive wireless phone giants (consolidation directly made possible by the <a href=\"https://www.techdirt.com/2023/10/17/everything-t-mobile-sprint-merger-critics-predicted-has-come-true/\">Trump administration‚Äôs past rubber stamping of shitty telecom mergers</a>). </p><p>Verizon lobbied the FCC by repeatedly lying, without evidence, that these conditions&nbsp;<a href=\"https://www.techdirt.com/2026/01/16/trump-fcc-helps-verizon-make-it-harder-for-you-to-switch-wireless-carriers/\">resulted in a wave of black market phone thefts</a>. FCC boss Brendan Carr, ever the industry lackey, parroted the lies in his subsequent industry-friendly rulings. You know, to <em>make America great again via ‚Äúpopulism</em>‚Äù or whatever. </p><p>Verizon (and Carr) know that there‚Äôs a lot going on and the mundanity of a subject like phone unlocking won‚Äôt get much attention in the press. Given that the Trump administration <a href=\"https://www.techdirt.com/2025/04/23/5th-circuit-obediently-lets-att-off-the-hook-for-major-location-data-privacy-violations/\">has largely lobotomized regulatory independence</a> (at Verizon‚Äôs request), there‚Äôs very little chance Verizon will see any future accountability, but it‚Äôs  that they‚Äôre proceeding cautiously just in case.</p>",
      "contentLength": 3244,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Hyprland 0.54 Released As A \"Massive\" Update To This Wayland Compositor",
      "url": "https://www.phoronix.com/news/Hyprland-0.54-Released",
      "date": 1772218634,
      "author": "Michael Larabel",
      "guid": 48944,
      "unread": true,
      "content": "<article>Hyprland 0.54 was released today as what's described as a \"a massive update with no understatement\" to this Wayland compositor...</article>",
      "contentLength": 129,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Daily Deal: The 2026 Microsoft Office Pro Bundle",
      "url": "https://www.techdirt.com/2026/02/27/daily-deal-the-2026-microsoft-office-pro-bundle-2/",
      "date": 1772218620,
      "author": "Daily Deal",
      "guid": 48942,
      "unread": true,
      "content": "<p>The <a href=\"http://deals.techdirt.com/sales/the-2025-microsoft-office-pro-bundle?utm_campaign=affiliaterundown\">2026 Microsoft Office Pro Bundle</a> has 8 courses to help you master essential Office skills. Courses cover Access, PowerPoint, Word, Excel, and more. It‚Äôs on sale for $25.</p><p><em>Note: The Techdirt Deals Store is powered and curated by StackCommerce. A portion of all sales from Techdirt Deals helps support Techdirt. The products featured do not reflect endorsements by our editorial team.</em></p>",
      "contentLength": 386,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Nasa Announces Artemis III Mission No Longer Aims To Send Humans To Moon",
      "url": "https://science.slashdot.org/story/26/02/27/1854230/nasa-announces-artemis-iii-mission-no-longer-aims-to-send-humans-to-moon?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1772218440,
      "author": "msmash",
      "guid": 48921,
      "unread": true,
      "content": "Nasa announced on Friday radical changes to its delayed Artemis III mission to land humans back on the moon, as the US space agency grapples with technical glitches and criticism that it is trying to do too much too soon. From a report: The abrupt shift in strategy was laid out by the space agency's recently confirmed administrator, Jared Isaacman. Announcing the changes on Friday, he said that Nasa would introduce at least one new moon flight before attempting to put humans back on the lunar surface for the first time in more than half a century, in 2028. \n\nThe new, more incremental approach would give the Nasa team a chance to test flight and refine its technology. As part of the changes, the Artemis II mission to fly humans around the moon this year, without landing, would also be pushed back from its latest scheduled launch on 6 March to 1 April at the earliest. \n\n\"Everybody agrees this is the only way forward,\" Isaacman told reporters at a news conference. \"I know this is how Nasa changed the world, and this is how Nasa is going to do it again.\"",
      "contentLength": 1066,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Why Smart People Stay Stuck (and How to Break It)",
      "url": "https://hackernoon.com/why-smart-people-stay-stuck-and-how-to-break-it?source=rss",
      "date": 1772217903,
      "author": "BenoitMalige",
      "guid": 49018,
      "unread": true,
      "content": "<p><strong>Most people don‚Äôt need therapy.</strong>They need to hear themselves think. \\n Writing is how you do that.</p><p>If you‚Äôre reading this,&nbsp;.</p><p>Here‚Äôs the second hill I‚Äôll die on:</p><p>The smartest, most self-aware people are usually the most trapped. \\n Because awareness without embodiment is just sophisticated suffering.</p><p>You don‚Äôt need more information.</p><p>You can already explain yourself better than 99% of people. \\n You know the patterns. \\n You can name the mechanisms. \\n You understand &nbsp;you do what you do.</p><p>And yet‚Äîthere‚Äôs this massive, screaming gap between the person you understand yourself to be‚Ä¶ and the smaller, quieter, less honest life you keep waking up in.</p><p>How does someone this self-aware, this intelligent, this capable of naming every variable at play‚Ä¶still wake up trapped in a version of reality they don‚Äôt even enjoy?</p><p>That dissonance isn‚Äôt a character flaw. \\n It‚Äôs not bad timing. \\n It‚Äôs not that you‚Äôre ‚Äúnot ready.‚Äù</p><p>It‚Äôs your nervous system refusing to update the identity file while your body hesitates, tightens, and pulls the brakes every time your mind tries to move forward.</p><p>If your stomach dropped a little just now, good. \\n That‚Äôs the signal we‚Äôre finally past surface-level advice.</p><p>I‚Äôm going to be very direct with you: What you‚Äôre about to read explains why you‚Äôre still not living the life you already know you‚Äôre capable of, even though you understand yourself better than most people ever will.</p><p>I‚Äôll break down the neuroscience behind that gap of who you are VS who you need to be, and I‚Äôll give you the&nbsp;&nbsp;I‚Äôve been using to collapse that gap without waiting years for things to ‚Äúclick‚Äù.</p><p>In fact, if you actually apply this, your progress will feel suspicious..especially to the people who benefit from you staying the same.</p><h2><strong>The model we were all taught</strong></h2><p>For the longest time, I assumed change was linear.</p><p><strong>Learn ‚Üí understand ‚Üí act ‚Üí become.</strong></p><p>And that makes sense, right? It‚Äôs logic. That‚Äôs how school works:</p><p><strong>You study the material ‚Üí You pass the test ‚Üí You get the diploma ‚Üí You‚Äôre now ‚Äúqualified.‚Äù</strong></p><p>Same with personal growth: \\n <strong>You read the book ‚Üí You gain insight ‚Üí You apply the advice ‚Üí You slowly turn into someone new.</strong></p><p>This model feels safe because it‚Äôs orderly. We are taught to follow step one, then step two, then step three until you get a result.</p><p>Cause ‚Üí effect. \\n Time ‚Üí progress.</p><p>So when change doesn‚Äôt happen, the conclusion is obvious: \\n ‚ÄúI must not have learned enough.‚Äù \\n ‚ÄúI‚Äôm not applying it consistently.‚Äù \\n ‚ÄúI need more discipline.‚Äù</p><p>That‚Äôs the logic everyone operates under.</p><p>Including you. \\n Including me.</p><p>Let‚Äôs get something straight: this model actually works. You didn‚Äôt misunderstand it. You didn‚Äôt apply it wrong. You executed it&nbsp;.</p><p>In fact, it gave the results that you have today:</p><ul><li>You became ‚Äúsuccessful‚Äù on paper.</li><li>You earned competence, status, and proof that you‚Äôre not an idiot.</li></ul><p>Which is exactly why this is so confusing. Because the model&nbsp;.</p><p>And yet‚Ä¶there‚Äôs this exhausting, permanent tension that never really goes away.</p><p>You can see the version of yourself you‚Äôre capable of being, but you‚Äôre not becoming it.</p><p>And that‚Äôs what makes this unbearable. In fact, I would argue that because of your awareness,&nbsp;<strong>knowing you‚Äôre meant for more is actually the most painful place to be.</strong>&nbsp;It was for me.</p><p>That‚Äôs what happens when&nbsp;<strong>learning outpaces embodiment</strong>.</p><p>Here‚Äôs the truth about change. It‚Äôs a biological game, not a motivational one. And biology has rules (constraints that don‚Äôt give a shit about your intentions or discipline). If you want to collapse the gap between knowing and becoming, you have to play by them, so let‚Äôs break it down.</p><h2><strong>The actual laws of change</strong></h2><p>These aren‚Äôt feel-good principles or ‚Äúwhat worked for me‚Äù stories. They‚Äôre hardwired constraints on how your nervous system updates identity.</p><p>If you ignore them, and you stay stuck. When you finally respect them, change accelerates.</p><p>: Identity isn‚Äôt updated by logic or information alone. Your prefrontal cortex can understand a new version of you all day long.</p><p>But the nervous system (The one that controls your body‚Äôs felt reality) only rewires through repeated emotional and sensory experience.</p><p>It doesn‚Äôt care about abstract insights. It responds to what feels familiar, safe, and present-tense.</p><p>: The nervous system doesn‚Äôt fully distinguish between imagined and lived experience. When you vividly rehearse a future state with elevated emotion, it registers as ‚Äúthis is happening now.‚Äù</p><p>Neural pathways fire identically, as shown in fMRI studies on athletes using visualization. Mental practice alone strengthens the same brain regions and even boosts muscle performance without physical movement.</p><p>Familiarity builds. \\n Safety locks in. \\n Identity shifts.</p><p>: The brain ignores future-tense intentions. \\n It‚Äôs built for survival in the present. \\n Promises like ‚ÄúI‚Äôll be that person one day‚Äù get dismissed as irrelevant. \\n No update happens. \\n The body stays braced, attention narrows, and old patterns persist.</p><p>That‚Äôs it. \\n No mysticism. \\n Just biology: embodiment over intellect, present signals over future plans, emotional repetition over one-off epiphanies.</p><h3><strong>Why the way you were taught violates those laws</strong></h3><p>You weren‚Äôt taught wrong on purpose. \\n The linear model: learn ‚Üí understand ‚Üí act ‚Üí become‚Äîmakes sense on paper. \\n It‚Äôs how we‚Äôre wired to think: cause leads to effect, effort over time equals results.</p><p>But here‚Äôs the fracture: That system is incompatible with how identity&nbsp;&nbsp;updates, because it operates in future-tense logic, while your nervous system is locked in&nbsp;.</p><p>Linear change assumes: \\n ‚Äì Identity updates gradually, after enough time and action. \\n ‚Äì You ‚Äúwork toward‚Äù a future version of yourself. \\n ‚Äì The gap closes ‚Äúeventually,‚Äù once you‚Äôve earned it.</p><p>But biology doesn‚Äôt work that way. \\n Your nervous system doesn‚Äôt live in timelines. \\n It doesn‚Äôt understand ‚Äúone day.‚Äù \\n It only registers what‚Äôs safe and familiar.</p><p>So when you tell yourself: \\n ‚ÄúI‚Äôll be confident later.‚Äù \\n ‚ÄúI‚Äôll act like that person when I get there.‚Äù \\n ‚ÄúI‚Äôm not that version yet.‚Äù</p><p>You‚Äôre signaling: ‚ÄúWe‚Äôre still the old identity. No need to change.‚Äù \\n And it listens. \\n Cortisol stays up. \\n The brakes stay on. \\n The gap widens.</p><p>That‚Äôs why respecting linear time keeps you trapped. \\n Not because time is the enemy. \\n But because your biology wasn‚Äôt designed to evolve that way.</p><p>This should now answer your question:&nbsp;<strong>If you already know who you want to become‚Ä¶ why haven‚Äôt you become them yet?</strong></p><h3><strong>How we actually need to treat change</strong></h3><p>If the laws demand present-tense embodiment, we need a system that delivers it. \\n Not gradual effort toward a distant future. \\n Not more information stacked on old identity files.</p><p>We need to hack the nervous system into believing the new you is already real‚Äînow. \\n Through vivid, emotional rehearsal that blurs imagined and lived. \\n Through small, aligned actions that reinforce familiarity in the present. \\n Through evidence that confirms the shift is happening, not waiting to happen.</p><p>That‚Äôs not a tactic. \\n It‚Äôs alignment with biology.</p><p>And ignoring biology is exactly why you're still not living the life you want right now.</p><p>\\n This is the &nbsp;way to collapse the gap without wasting years on ‚Äúprogress‚Äù that never sticks.</p><h2><strong>The Protocol I promised you</strong></h2><p>I didn‚Äôt set out to invent anything fancy. I was just exhausted from knowing everything and changing nothing. I was the guy who could explain every pattern, name every mechanism, map the perfect future‚Ä¶ and still wake up in the same smaller life every day.</p><p>Once I understood the laws, there were only two options: keep suffering intelligently‚Ä¶or build a system that forced embodiment:</p><p>Present-tense embodiment. \\n Emotional rehearsal. \\n Evidence that the shift is real.</p><p>For years, nothing moved. Under 8k followers total. Newsletter stuck below 900. Random book sales. No momentum.</p><p>Within 2 months of using the protocol:</p><ul><li>100k followers across platforms</li><li>25k newsletter subscribers</li><li>Publishers reaching out instead of me chasing.</li></ul><p>I‚Äôm saying it because it‚Äôs the only way to prove this isn‚Äôt theory for me.&nbsp;<strong>This is what happened when I finally gave my nervous system present-tense evidence instead of future promises.</strong></p><p>Everything circled back to those two hills I opened with.</p><ul><li>Most people don‚Äôt need therapy. They need to hear themselves think, and writing is how you do that.</li><li>The smartest, most self-aware people are usually the most trapped‚Ä¶because awareness without embodiment is just sophisticated suffering.</li></ul><p>I‚Äôd spent years in sophisticated suffering that you are currently experiencing: Explaining, understanding, naming every mechanism, but never embodying.</p><p>Then I built something that forced embodiment. \\n And the suffering ended. \\n The gap collapsed.</p><p>That something is the&nbsp;, because you log both identity (the future you) and evidence (real-world confirmation), like double entry accounting, but for reality.</p><p><strong>It's a daily protocol that places you between the present and the future, then forces you to pull both toward the center.</strong>&nbsp;On paper. Every day. In under 20 minutes.</p><p>: time collapses, the gap disappears, and your nervous system has no choice but to make the new you real now.</p><p>Here‚Äôs why it aligns with the biology we just covered (not the full how-to; that‚Äôs in the videos):</p><p>It doesn‚Äôt ask you to wait for linear time. \\n It forces the nervous system to treat the future identity as real .</p><p>One side of the page creates vivid, emotional rehearsal. The kind that activates the same neural pathways as lived experience, building familiarity and safety without physical action.</p><p>The other side grounds it immediately: small, present-tense actions that reinforce the new identity&nbsp;, not later.</p><p>A third layer stacks real-world evidence throughout the day, training the reticular activating system (the RAS) to filter for confirmation instead of threat.</p><p>Together, they do exactly what the laws demand:</p><ul><li>Repeated emotional embodiment.</li><li>No reliance on future promises or gradual progress.</li></ul><p>The result: the nervous system stops bracing, the brakes come off, and the gap starts collapsing; fast enough that it can feel suspicious to everyone still stuck in linear time:</p><ul><li>Synchronicities start showing up uninvited.</li><li>Conversations align without forcing them.</li><li>Opportunities land in your inbox like they were waiting for you to finally believe they could.</li><li>Results arrive with almost no effort, as if the universe is just catching up to the identity you‚Äôve already wired in.</li></ul><p>But I have to warn you about one thing that will happen, and if I don‚Äôt tell you, this whole thing won‚Äôt work..</p><p>The moment progress starts moving faster than you thought possible‚Ä¶ you will feel&nbsp;.&nbsp;&nbsp;Like you didn‚Äôt ‚Äúearn‚Äù it. Like it was&nbsp;.</p><p>That guilt is the ghost of linear time (The conditioning that says good things must take years of pain).</p><p>Don‚Äôt let it run the show. \\n It‚Äôs not proof you‚Äôre wrong. \\n <strong>It‚Äôs proof you‚Äôve broken free</strong>.</p><p>This protocol isn‚Äôt for everyone. \\n It‚Äôs for the self-aware overthinkers tired of knowing and not becoming. \\n The ones who can name every pattern but can‚Äôt break them. \\n The ones ready to hack biology instead of fighting it.</p><p>I put together videos and documents so you can start this habit immediately. You'll get exact walkthroughs, concrete examples of a full day in my life using the protocol, and everything laid out so you can literally copy-paste and execute.</p><p><em>This is the thing that finally closes the gap you've felt for years.</em></p><p>Because I'm not here to keep you small.</p><p>See you on the other side.</p>",
      "contentLength": 11649,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "ChatGPT reaches 900M weekly active users",
      "url": "https://techcrunch.com/2026/02/27/chatgpt-reaches-900m-weekly-active-users/",
      "date": 1772216751,
      "author": "Aisha Malik",
      "guid": 48932,
      "unread": true,
      "content": "<article>OpenAI shared the new numbers as part of its announcement that it has raised $110 billion in private funding.</article>",
      "contentLength": 109,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "A Chinese Official's Use of ChatGPT Accidentally Revealed a Global Intimidation Operation",
      "url": "https://slashdot.org/story/26/02/27/185250/a-chinese-officials-use-of-chatgpt-accidentally-revealed-a-global-intimidation-operation?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1772215380,
      "author": "msmash",
      "guid": 48898,
      "unread": true,
      "content": "A sprawling Chinese influence operation -- accidentally revealed by a Chinese law enforcement official's use of ChatGPT -- focused on intimidating Chinese dissidents abroad, including by impersonating US immigration officials, according to a new report from ChatGPT-maker OpenAI. From a report: The Chinese law enforcement official used ChatGPT like a diary to document the alleged covert campaign of suppression, OpenAI said. In one instance, Chinese operators allegedly disguised themselves as US immigration officials to warn a US-based Chinese dissident that their public statements had supposedly broken the law, according to the ChatGPT user. In another case, they describe an effort to use forged documents from a US county court to try to get a Chinese dissident's social media account taken down. \n\nThe report offers one of the most vivid examples yet of how authoritarian regimes can use AI tools to document their censorship efforts. The influence operation appeared to involve hundreds of Chinese operators and thousands of fake online accounts on various social media platforms, according to OpenAI.",
      "contentLength": 1112,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Video Friday: Robot Dogs Haul Produce From the Field",
      "url": "https://spectrum.ieee.org/quadruped-farming-robots",
      "date": 1772215255,
      "author": "Evan Ackerman",
      "guid": 48891,
      "unread": true,
      "content": "<p>Your weekly selection of awesome robot videos</p>",
      "contentLength": 45,
      "flags": null,
      "enclosureUrl": "https://spectrum.ieee.org/media-library/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpbWFnZSI6Imh0dHBzOi8vYXNzZXRzLnJibC5tcy82NTA5NTkwMy9vcmlnaW4ucG5nIiwiZXhwaXJlc19hdCI6MTgyMjcyNTE4Mn0.dDbgl1HCHlc37MS8MkqixiIlFQqAKQj8DlxIi2xRdLc/image.png?width=600",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Metacritic Will Kick Out Media Attempting To Submit AI Generated Reviews",
      "url": "https://games.slashdot.org/story/26/02/27/1732218/metacritic-will-kick-out-media-attempting-to-submit-ai-generated-reviews?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1772213520,
      "author": "msmash",
      "guid": 48897,
      "unread": true,
      "content": "An anonymous reader shares a report: While some see AI as a tool to be used, its specific use and how it is deployed responsibly is being heavily debated online across a wide range of industries. In terms of journalistic content, and in this particular instance, reviews, review aggregator Metacritic has taken a firm stance on content published and submitted to their platform, that have been generated by artificial intelligence in some way. \n\nIn a statement by co-founder Marc Doyle, sent to Gamereactor, he says this: \"Metacritic has been a reputable review source for a quarter century and has maintained a rigorous vetting process when adding new publications to our slate of critics. However, in certain instances such as a publication being sold or a writing staff having turned over, problems can arise such as plagiarism, theft, or other forms of fraud including AI-generated reviews. Metacritic's policy is to never include an AI-generated critic review on Metacritic and if we discover that one has been posted, we'll remove it immediately and sever ties with that publication indefinitely pending a thorough investigation.\" \n\nSo, what is this about specifically? Well, it's probably a sound guess, that this pertains to Videogamer's review of Resident Evil 9: Requiem, which was removed from the platform after a barrage of comments accusing the review of being AI-written, and for the author of being made up.",
      "contentLength": 1423,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Palantir Sues Swiss Magazine For Accurately Reporting That The Swiss Government Didn‚Äôt Want Palantir",
      "url": "https://www.techdirt.com/2026/02/27/palantir-sues-swiss-magazine-for-accurately-reporting-that-the-swiss-government-didnt-want-palantir/",
      "date": 1772212980,
      "author": "Mike Masnick",
      "guid": 48916,
      "unread": true,
      "content": "<p>If you run a company whose entire value proposition is the ability to see patterns, predict outcomes, and connect dots that others miss, you‚Äôd think someone in the building might have flagged that suing a small independent magazine over unflattering-but-accurate reporting would only guarantee that millions more people read it.</p><p>Palantir Technologies, the infamous surveillance and data analytics giant chaired by Peter Thiel, has <a href=\"https://www.ft.com/content/434b6d98-83d1-4ba1-a929-150341bcaea4\">filed a lawsuit against Republik</a>, a small Swiss online magazine, over a pair of investigative articles published in December. The articles, produced in collaboration with the investigative collective WAV, detailed <a href=\"https://www.republik.ch/2026/02/18/how-tenaciously-palantir-courted-switzerland?utm_campaign=cm&amp;utm_medium=social&amp;utm_content=palantir-en\">a years-long, multi-ministry charm offensive by Palantir</a> to sell its software to Swiss federal authorities. The campaign was, by all accounts, a comprehensive failure. Swiss agencies rejected Palantir at least nine times, with concerns ranging from data sovereignty to reputational risk to the simple fact that nobody needed the product.</p><p>The reporting was based on documents obtained through 59 freedom of information requests filed with Swiss federal agencies. The key finding was an internal Swiss Armed Forces report that concluded Palantir‚Äôs software posed unacceptable risks because sensitive military data could potentially be accessed by U.S. government intelligence agencies. As the Republik article details:</p><blockquote><p><em>The authors of the report state that using Palantir‚Äôs software would increase dependence on a U.S. provider. It also poses the risk of losing data sovereignty and thereby national sovereignty.</em></p><p><em>Above all, however, the army‚Äôs staff experts say it remains unclear who has access to data shared with Palantir. The following sentence from the Swiss Army report is particularly relevant: ‚ÄúPalantir is a U.S.-based company, which means there is a possibility that sensitive data could be accessed by the US government and intelligence services.‚Äù</em></p></blockquote><p>As if it‚Äôs any sort of surprise that European governments are wary of betting on US tech companies with close ties to the US government. It‚Äôs not like reports of US spies <a href=\"https://www.techdirt.com/2014/05/19/cisco-goes-straight-to-president-to-complain-about-nsa-intercepting-its-hardware/\">co-opting US tech companies</a> for surveillance efforts haven‚Äôt been <a href=\"https://www.techdirt.com/2013/09/03/att-has-employees-embedded-govt-providing-near-realtime-searches-nearly-every-phone-call/\">front page news</a> over the past twenty years. And now,  administration‚Äîwith its willingness to antagonize everyone in Europe, and its close ties to Palantir and Thiel? It‚Äôs no freaking wonder that the Swiss government was like ‚Äúyo, maybe pass.‚Äù</p><p>So how does a sophisticated data intelligence company respond to well-sourced investigative journalism based on official government documents?</p><p>By suing the journalists, of course.</p><p>But here‚Äôs the thing that makes this even more absurd: Palantir isn‚Äôt even claiming the articles are false. The company isn‚Äôt suing for defamation. It isn‚Äôt seeking damages. Instead, it‚Äôs invoking a Swiss ‚Äúright of reply‚Äù statute, alleging that Republik didn‚Äôt give the company a sufficient opportunity to respond. Palantir wants the court to force the magazine to publish lengthy counter-statements to each article.</p><blockquote><p><em>Palantir‚Äôs lawsuit, filed in January, is not seeking damages or making libel claims against Republik, but instead alleges that the company was not given sufficient right to reply under Swiss media law. The company objects to Republik‚Äôs presentation of the public documents and believes its right to reply has been wrongfully denied.</em></p><p><em>Republik‚Äôs managing director Katharina Hemmer said Palantir had wanted the magazine to publish a very lengthy counterstatement to each article. Republik believed the proposed statements did not fairly address or rebut the reporting, she said, adding that the magazine stands by its reporting.</em></p></blockquote><p>To which I say: good. Because Palantir‚Äôs demand here is absurd. Oh boo-fucking-hoo, the big defense contractor didn‚Äôt like the coverage? Pull on your big boy pants and get over it. Switzerland‚Äôs right of reply law exists so people can correct factual errors, not so corporations can force publications to run PR copy because they didn‚Äôt like the tone of accurate, document-based reporting.</p><p>And it‚Äôs worth noting: Palantir has already used other avenues to respond. The company published <a href=\"https://blog.palantir.com/korrektur-wie-das-online-magazin-die-republik-einen-regierungsbericht-zu-palantir-verdrehte-9a1b399ae255\">a blog post</a> complaining that the Republik article ‚Äúpaints a false and misleading picture‚Äù and ‚Äúhinders important discussions about the modernization of European software.‚Äù They‚Äôve got the platform. If Palantir wants to push back on the story, they have many methods of doing so. Hell, they can do so on X any time they want‚Äîon what Musk and company like to call the global town square for free speech.</p><p>But that‚Äôs apparently not enough. Instead, a multibillion-dollar American defense and intelligence contractor is hauling a small independent Swiss magazine into court, not because anything the magazine published was wrong, but because Palantir wants to  the publication to run its talking points under legal compulsion.</p><p>Compelled speech isn‚Äôt free speech, guys. And this is nothing more than a blatant intimidation campaign to frighten away reporters from reporting the truth about Palantir.</p><p>The European Federation of Journalists has <a href=\"https://europeanjournalists.org/blog/2026/02/17/switzerland-us-analytics-firm-takes-republik-magazine-to-court/\">called this exactly what it is</a>: a SLAPP suit‚Äîa strategic lawsuit against public participation, designed to use the weight and cost of litigation to intimidate and punish journalists for doing their jobs.</p><blockquote><p><em>‚ÄúThe investigation conducted by WAV and Republik into Palantir is largely based on official documents that journalists were able to access thanks to Swiss freedom of information law,‚Äù notes EFJ President Maja Sever. ‚ÄúThe legal action brought by this powerful multinational firm against a small Swiss media start-up is, in our view, an attempt at intimidation aimed at discouraging any critical analysis of Palantir‚Äôs activities.‚Äù</em></p></blockquote><p>And in case you didn‚Äôt catch the irony: the Swiss military rejected Palantir in part because of fears about a heavy-handed American entity with uncomfortably close ties to U.S. intelligence. Palantir‚Äôs response to the reporting of that rejection? Behave like a heavy-handed American entity trying to bully a small foreign publication into submission. If anyone at Palantir had run this decision through their own pattern-recognition software, you‚Äôd hope a few red flags would have popped up.</p><p>Meanwhile, the lawsuit has done exactly what anyone with a passing familiarity with the Streisand Effect could have predicted. The original Republik articles were about the Swiss government politely but firmly declining Palantir‚Äôs advances‚Äîan embarrassing but relatively contained story.</p><p>Now, thanks to the lawsuit, the story has gone international. The Financial Times is covering it. The European Federation of Journalists is covering it. A UK member of parliament has already cited the Republik investigation during a debate on British defense contracts with Palantir, using the story to suggest that the British government ‚Äúpivot away‚Äù from Palantir.</p><p>It paints a picture of a company that spent seven years working every angle to get Swiss federal agencies to buy its products‚Äîapproaching the Federal Chancellery during COVID, pitching the Federal Office of Public Health on contact tracing, presenting anti-money laundering software to financial regulators, making repeated runs at the military‚Äîand getting turned away at every door. Sometimes embarrassingly, such as the Federal Statistical Office director apparently just ignoring Palantir‚Äôs outreach entirely.</p><p>For a company that brags about its ability to ‚Äúoptimize the kill chain‚Äù and whose CEO once told investors that ‚ÄúPalantir is here to disrupt‚Ä¶ and, when it‚Äôs necessary, to scare our enemies and occasionally kill them,‚Äù getting politely rejected by the Swiss statistical office has to sting a little.</p><p>But suing the journalists who reported on it? When the entire basis of your lawsuit is ‚Äúwe want you to publish our talking points‚Äù rather than ‚Äúanything you published was wrong,‚Äù it makes pretty clear you don‚Äôt actually have a substantive response to the reporting. If Palantir thinks the picture is false, the remedy is to demonstrate that the documents are wrong‚Äînot to drag a small magazine through expensive litigation until it capitulates or goes broke.</p><p>Seriously, how fucking fragile are the egos in the Palantir executive suite that they can‚Äôt handle a bit of mildly embarrassing reporting? Grow up.</p><p>A Zurich court is expected to rule on the case in March. Whatever the outcome, Palantir has already lost the only contest that matters: the one for public perception. For a company that sells the ability to see around corners, they apparently never thought to search ‚ÄúThe Streisand Effect.‚Äù</p>",
      "contentLength": 8629,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "AI music generator Suno hits 2M paid subscribers and $300M in annual recurring revenue",
      "url": "https://techcrunch.com/2026/02/27/ai-music-generator-suno-hits-2-million-paid-subscribers-and-300m-in-annual-recurring-revenue/",
      "date": 1772212922,
      "author": "Amanda Silberling",
      "guid": 48900,
      "unread": true,
      "content": "<article>Suno lets users create music using natural language prompts, making it possible for people with little experience to generate audio with little effort.</article>",
      "contentLength": 151,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Apple and Netflix team up to air Formula 1 Canadian Grand Prix",
      "url": "https://techcrunch.com/2026/02/27/apple-and-netflix-team-up-to-air-formula-1-canadian-grand-prix/",
      "date": 1772212638,
      "author": "Lauren Forristal",
      "guid": 48899,
      "unread": true,
      "content": "<article>As Netflix continues its live sports push, the company has partnered with Apple to air the Formula 1 Canadian Grand Prix.</article>",
      "contentLength": 121,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "The New Gold Standard - Why Imperfection Wins",
      "url": "https://hackernoon.com/the-new-gold-standard-why-imperfection-wins?source=rss",
      "date": 1772212542,
      "author": "Editing Protocol",
      "guid": 49017,
      "unread": true,
      "content": "<p>Earlier this week in our HackerNoon editorial meeting, we noticed an interesting pattern. We were reviewing the top-performing stories from the past two weeks, and couldn‚Äôt help but notice an interesting trend.</p><p>\\\nAre you seeing what we‚Äôre seeing? Here‚Äôs a hint‚Äîthe leaderboard was full of specific, lived experiences. We‚Äôve got an artist talking about making digital art in the age of AI; an observation on why people were panic-buying Mac minis; a PSA on online phishing scams; and a new, well-thought-out social media strategy.</p><p>\\\nThis sparked a realization that makes perfect sense in hindsight: <strong>Genuine human experience is the way to go.</strong></p><p>\\\nScroll through tech blogs today, and you‚Äôll notice many similarities: clear, competent, and often a little interchangeable. With so much polished writing available, what tends to stand out now isn‚Äôt more shine, but specificity: the odd detail, the honest constraint, the lesson learned the hard way.</p><p>\\\nThe bar for clean, professional writing is higher than ever - which is a  thing, btw; but in today‚Äôs world, in order to differentiate, connect, and earn attention, concrete examples, candid tradeoffs, and seemingly all kinds of small imperfections that signal there‚Äôs a person behind the words are increasingly important.</p><p>Modern audiences have adapted quickly to the AI era. <a href=\"https://hackernoon.com/are-you-good-at-spotting-ai-generated-content-online\">A recent poll on HackerNoon</a> showed that around  of respondents are somewhat confident in their ability to spot AI-generated content.</p><p>\\\nOf course, this confidence is only based on a gut feeling when something reads a little too smoothly, or has what people call ‚ÄúAI giveaways‚Äù. However, this vigilance has created a fascinating authenticity paradox for writers and marketers. Sometimes, perfectly structured sentences and high vocabulary now trigger suspicion rather than establishing authority.‚Äã</p><p>\\\nWhen a reader encounters a paragraph that flows without any jagged edges, strong opinions, or a distinct voice, their brain files it away as generic content rather than meaningful communication. To prove you are genuinely human, you need to showcase the elements of your work that cannot be automated.</p><blockquote><p><strong>It‚Äôs the Human Proof of Work.</strong></p></blockquote><p>\\\nThis does not mean publishing sloppy or unedited drafts. It means leaning into specific details: acknowledging a slightly offbeat workflow, admitting that a product roadmap changed because a previous assumption was wrong, or sharing the messy reality of a project.‚Äã</p><h3>So, Where Do You Find These Genuine, Imperfect Ideas?</h3><p>The editorial ethos we often discuss at HackerNoon highlights that writers waste hours overthinking the perfect topic instead of simply documenting reality. Your next high-performing article is likely hiding in a recent Slack debate, a code deployment that required a hotfix, or a frustrating client call that got you thinking.‚Äã</p><p>\\\nBy tapping into these unfiltered moments of daily friction, you generate inherently unique content that AI cannot pull from a training dataset. When you share lessons from your own experiences, you bypass the reader's critical filter we mentioned above. You position your brand as a battle-tested guide who has actually navigated the practical challenges of the industry.</p><h2>Marketing and Retention Through Authentic Connection</h2><p>This pivot toward genuine human connection is more than just an editorial preference. Authenticity is rapidly becoming a primary driver of long-term business retention.‚Äã</p><p>\\\nMany B2B brands currently find themselves stuck in a marketing uncanny valley. They publish heavily optimized pieces that sound vaguely human but lack the emotional resonance required to actually connect with a reader. These articles might successfully attract search traffic and earn a click, but they rarely earn a loyal customer.</p><blockquote><p><strong>Retention in any business is built on trust, and trust requires relatability.</strong></p></blockquote><p>\\\nIt‚Äôs simple: customers stick around because they feel they are buying into a philosophy and a team they understand, rather than just renting a software tool.</p><p>\\\nTreating your content's humanity as a core asset is a valuable tip that should always be taken to your advantage. The willingness to be vulnerable and own your operational realities creates a deep customer affinity. This affinity directly translates into a higher customer retention.</p><blockquote><p><strong>In a digital environment populated by perfect machines, writing like a flawed human might just be the best business strategy you have.</strong></p></blockquote><h2>Want to take this further? (HackerNoon‚Äôs Blogging Course)</h2><p>HackerNoon‚Äôs Blogging Course is designed for beginners&nbsp;&nbsp;writers who‚Äôve published a bit and want to level up. It‚Äôs organized into 8 modules created by experienced writers and editors, and it includes topics like:</p><p>Until next time, Hackers!</p>",
      "contentLength": 4709,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Perplexity‚Äôs new Computer is another bet that users need many AI models",
      "url": "https://techcrunch.com/2026/02/27/perplexitys-new-computer-is-another-bet-that-users-need-many-ai-models/",
      "date": 1772211655,
      "author": "Tim Fernholz",
      "guid": 48887,
      "unread": true,
      "content": "<article>Perplexity Computer, in the company‚Äôs words, \"unifies every current AI capability into a single system.\"&nbsp;</article>",
      "contentLength": 108,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "HackerNoon Projects of the Week: Get-Star, FinSight and CodeXero",
      "url": "https://hackernoon.com/hackernoon-projects-of-the-week-get-star-finsight-and-codexero?source=rss",
      "date": 1772211602,
      "author": "Proof of Usefulness",
      "guid": 48910,
      "unread": true,
      "content": "<p>Welcome to the latest HackerNoon Projects of the Week installment. Each week, we shine a light on standout projects from our <a href=\"https://www.proofofusefulness.com/?ref=hackernoon.com\">Proof of Usefulness Hackathon</a>‚Äîa contest built around the core question every builder should answer: Is my product actually useful in the real world?</p><p>For each edition, we‚Äôll highlight projects that demonstrate clear usefulness, technical execution, and real-world impact; all backed by data and not witty buzzwords.</p><p>This week, we‚Äôre excited to share three projects that have proven their utility by solving concrete problems for real users: <a href=\"https://hackernoon.com/get-star-earns-a-27-proof-of-usefulness-score-by-building-client-side-parallel-search\">Get-Star</a>, <a href=\"https://hackernoon.com/finsight-earns-a-55-proof-of-usefulness-score-by-building-an-ai-powered-finance-system-for-small-businesses\">FinSight</a>, and <a href=\"https://hackernoon.com/codexero-earns-a-348-proof-of-usefulness-score-by-building-a-vibe-coding-engine-for-web3-dapps\">CodeXero</a>.</p><h2>Meet the Projects of the Week</h2><p><a href=\"https://hackernoon.com/get-star-earns-a-27-proof-of-usefulness-score-by-building-client-side-parallel-search?embedable=true\">Get-Star</a> is building client-side parallel search infrastructure designed to improve speed and performance without relying heavily on centralized back-end computation. By distributing search execution closer to the user, the project aims to reduce latency, improve responsiveness, and create a more scalable search experience for modern web applications.</p><p>In a digital environment where milliseconds shape user perception, Get-Star focuses on performance as product value ‚Äî giving developers a way to rethink how search is handled at the architectural level.</p><p><strong>Proof of Usefulness score: +27/1000</strong></p><p><a href=\"https://hackernoon.com/finsight-earns-a-55-proof-of-usefulness-score-by-building-an-ai-powered-finance-system-for-small-businesses?embedable=true\">FinSight</a> is an AI-powered financial management system built specifically for small businesses. It helps founders move beyond static spreadsheets by providing real-time insights, forecasting, and structured financial analysis in one unified platform.</p><p>Small business operators often lack the time or expertise to interpret financial signals clearly. FinSight positions itself as a decision-support engine ‚Äî translating raw financial data into actionable clarity that can guide smarter planning and healthier cash flow management.</p><p><strong>Proof of Usefulness score: +55/1000</strong></p><p><a href=\"https://hackernoon.com/codexero-earns-a-348-proof-of-usefulness-score-by-building-a-vibe-coding-engine-for-web3-dapps?embedable=true\">CodeXero</a> is building a ‚Äúvibe coding‚Äù engine for Web3 dApps ‚Äî a system designed to accelerate decentralized application development by blending AI-assisted workflows with blockchain infrastructure.</p><p>With a significantly higher Proof of Usefulness score this week, CodeXero demonstrates strong traction in helping developers reduce friction when building smart contracts and Web3 interfaces. By simplifying complex blockchain logic into more intuitive development flows, CodeXero aims to make decentralized development faster, more accessible, and more iterative.</p><p><strong>Proof of Usefulness score: +348/1000</strong></p><h2>Stop Building in the Dark - Get Scored!</h2><p>The web is drowning in vaporware and empty promises. We created <a href=\"https://www.proofofusefulness.com/?ref=hackernoon.com\">Proof of Usefulness</a> to reward what actually matters: real user adoption, sustainable revenue, and technical stability. \\n </p><p> Get your Proof of Usefulness score (from -100 to +1000) the moment you submit. \\n  Compete for $20K in cash and $130K+ in software credits from&nbsp;,&nbsp;,&nbsp;,&nbsp;,&nbsp;and&nbsp;. \\n <strong>3. Built-in Distribution:</strong> Your submission becomes a HackerNoon story, putting your build in front of millions of monthly readers. \\n  Every qualifying participant unlocks a suite of software credits just for entering.</p><p> Head to <a href=\"https://www.proofofusefulness.com/?ref=hackernoon.com\">www.proofofusefulness.com</a> and submit your project details to generate your PoU Report Card. \\n  Click the button on your report page to convert your submission into a HackerNoon blog post draft. \\n  Edit your draft to add your technical \"secret sauce,\" then hit Submit for Review. Once published, you‚Äôre officially in the prize queue! \\n </p><p>\\\n<strong>P.S. The clock is ticking!</strong> The second month of the competition is drawing to a close, meaning the next round of winners will be announced soon. With only 4 months and 4 prize rounds remaining, now is the time to get your project in the mix. Don't leave money on the table - get in early!</p><p>Thanks for building useful things! \\n P.S.&nbsp;Submissions roll monthly through June 2026. Get in early!</p>",
      "contentLength": 3736,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Pok√©mon Winds and Pok√©mon Waves are coming to the Nintendo Switch 2 in 2027",
      "url": "https://techcrunch.com/2026/02/27/pokemon-winds-and-pokemon-waves-are-coming-to-the-nintendo-switch-2-in-2027/",
      "date": 1772211441,
      "author": "Amanda Silberling",
      "guid": 48886,
      "unread": true,
      "content": "<article>The 10th-generation starter Pok√©mon were revealed in the trailer: Browt (a grass bird), Pombon (a fire puppy), and Gecqua (a water gecko). </article>",
      "contentLength": 140,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Sam Altman Says OpenAI Shares Anthropic's Red Lines in Pentagon Fight",
      "url": "https://slashdot.org/story/26/02/27/1530218/sam-altman-says-openai-shares-anthropics-red-lines-in-pentagon-fight?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1772210400,
      "author": "msmash",
      "guid": 48881,
      "unread": true,
      "content": "An anonymous reader shares a report: OpenAI CEO Sam Altman wrote in a memo to staff that he will draw the same red lines that sparked a high-stakes fight between rival Anthropic and the Pentagon: no AI for mass surveillance or autonomous lethal weapons. If other leading firms like Google follow suit, this could massively complicate the Pentagon's efforts to replace Anthropic's Claude, which was the first model integrated into the military's most sensitive work. It would also be the first time the nation's top AI leaders have taken a collective stand about how the U.S. government can and can't use their technology. \n\nAltman made clear he still wants to strike a deal with the Pentagon that would allow ChatGPT to be used for sensitive military contexts. Despite the show of solidarity, such a deal could see OpenAI replace Anthropic if the Pentagon follows through with its plan to declare the latter a \"supply chain risk.\"",
      "contentLength": 930,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Behind the Blog: Using Your Brain",
      "url": "https://www.404media.co/behind-the-blog-using-your-brain/",
      "date": 1772209633,
      "author": "Joseph Cox",
      "guid": 48890,
      "unread": true,
      "content": "<img src=\"https://www.404media.co/content/images/2026/02/nl2.27--1-.png\" alt=\"Behind the Blog: Using Your Brain\"><p><em>This is Behind the Blog, where we share our behind-the-scenes thoughts about how a few of our top stories of the week came together. This week, we discuss wishes made, god complexes, and the point of it all. </em></p><p> This week I wrote about <a href=\"https://www.404media.co/amazon-wishlist-address-private-third-party/\" rel=\"noreferrer\">Amazon‚Äôs changing policy</a> for wishlists. It‚Äôs allowing gifters to choose third-party sellers for items, which could expose recipients‚Äô delivery addresses to the gifter. The notice Amazon sent wishlist holders is a basic example of CYA messaging: Amazon can‚Äôt guarantee what a third party seller will do with your address once they have it, including giving it to a gifter for tracking purposes.</p><p>Sex workers first flagged this change on social media because many use wishlists as an easy way to accept gifts, tributes, tips, etc instead of or in addition to actual funds. This is important because payment processors are wildly hostile and actively discriminatory toward the adult industry, and having alternative ways to get paid is crucial if you‚Äôre debanked or banned from the usual payment processors. I think most use it in a supplementary fashion, though.</p>",
      "contentLength": 1101,
      "flags": null,
      "enclosureUrl": "https://www.404media.co/content/images/2026/02/nl2.27--1-.png",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Employees at Google and OpenAI support Anthropic‚Äôs Pentagon stand in open letter",
      "url": "https://techcrunch.com/2026/02/27/employees-at-google-and-openai-support-anthropics-pentagon-stand-in-open-letter/",
      "date": 1772209438,
      "author": "Amanda Silberling",
      "guid": 48885,
      "unread": true,
      "content": "<article>While Anthropic has an existing partnership with the Pentagon, the AI company has remained firm that its technology not be used for mass domestic surveillance or fully autonomous weaponry.</article>",
      "contentLength": 188,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Lawmakers Demand DHS Define ‚ÄòDomestic Terrorist‚Äô As It Uses Vast Array of Surveillance Tools",
      "url": "https://www.404media.co/lawmakers-demand-dhs-define-domestic-terrorist-as-it-uses-vast-array-of-surveillance-tools/",
      "date": 1772208627,
      "author": "Joseph Cox",
      "guid": 48875,
      "unread": true,
      "content": "<img src=\"https://www.404media.co/content/images/2026/02/54977663606_074404d0ae_k.jpg\" alt=\"Lawmakers Demand DHS Define ‚ÄòDomestic Terrorist‚Äô As It Uses Vast Array of Surveillance Tools\"><p>A group of more than a dozen Democratic lawmakers have demanded the Department of Homeland Security (DHS) provide its definition of ‚Äúdomestic terrorist,‚Äù after the agency labelled U.S. citizens Ren√©e Good and Alex Pretti, which DHS officers killed, as such. The move also comes as DHS and its various components purchase and deploy a wide range of surveillance technologies and demand sensitive information from tech companies to unmask people criticizing ICE.</p><p>‚ÄúYou and your underlings appear to be labeling untold numbers of people as ‚Äòdomestic terrorists‚Äô or individuals of concern at will without evidence, operating wildly invasive spy tools to identify targets‚Äîand then using such labels as an excuse for yet more surveillance,‚Äù the letter, addressed to DHS Secretary Kristi Noem, reads. The office of Rep. Bennie G. Thompson (D-MS), ranking member of the Committee on Homeland Security, shared a copy of the letter with 404 Media.</p><p>‚ÄúThis self-reinforcing spiral of civil liberties violations ratchets in only one direction: toward an authoritarian surveillance state that punishes dissent and inflicts state violence,‚Äù <a href=\"https://www.documentcloud.org/documents/27422493-20260227-letter-to-sec-noem-on-dhs-surveillance/?ref=404media.co\" rel=\"noreferrer\">the letter adds</a>.</p><div><div><b><strong>Do you work at DHS? I would love to hear from you. Using a non-work device, you can message me securely on Signal at joseph.404 or send me an email at joseph@404media.co.</strong></b></div></div><p>It then points to a long list of media reports, including 404 Media‚Äôs, about DHS‚Äôs increasing use of surveillance technologies and powers. Those include how <a href=\"https://www.cnn.com/2026/01/27/us/alex-pretti-protesters-minneapolis-invs?ref=404media.co\"><u>DHS shared a memo with employees</u></a> in Minneapolis telling them to capture images, license plates, and other information about protestors ‚Äúso we can capture it all in one consolidated form‚Äù; <a href=\"https://www.404media.co/elite-the-palantir-app-ice-uses-to-find-neighborhoods-to-raid/\"></a> that Palantir is working on a tool called ELITE for ICE that provides a confidence score on targets‚Äô addresses; ICE‚Äôs purchase <a href=\"https://www.404media.co/inside-ices-tool-to-monitor-phones-in-entire-neighborhoods/\"><u>of smartphone location data</u></a>; how ICE agents told legal observers they were identifying them <a href=\"https://www.nytimes.com/2026/01/30/technology/tech-ice-facial-recognition-palantir.html?ref=404media.co\"><u>with facial recognition technology</u></a>; and several more examples.</p><p>‚ÄúThe Department‚Äôs opaque, mass expansion of spy tools and framing of protesters, photographers, political opponents, and passersby as enemies of the state leans into people‚Äôs worst fears of a surveillance state. Your weaponization of DHS undercuts decades of effort to develop a Department that responsibly balances security with privacy and civil liberties protections and transparency,‚Äù the letter reads.&nbsp;&nbsp;</p><p>It then includes a list of demands for information from DHS. Many of them are about the legal regime behind those surveillance powers, and the technical infrastructure and policies related to them. One asks DHS for ‚ÄúDocumentation of the Department‚Äôs definition of the term ‚Äòdomestic terrorist,‚Äô a copy of the policies in place that permit Departmental designations of United States persons as a ‚Äòdomestic terrorist,‚Äô and a description of the consequences of such a designation.‚Äù</p><p>‚ÄúYour actions are abhorrent, blatantly unconstitutional, and corrosive to the functioning of a peaceful society. They cannot stand. Accountability is coming,‚Äù the letter adds.</p>",
      "contentLength": 3055,
      "flags": null,
      "enclosureUrl": "https://www.404media.co/content/images/2026/02/54977663606_074404d0ae_k.jpg",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "The HackerNoon Newsletter: Lessons from Building a 100+ Agent Swarm in Web3 (2/27/2026)",
      "url": "https://hackernoon.com/2-27-2026-newsletter?source=rss",
      "date": 1772208178,
      "author": "Noonification",
      "guid": 48909,
      "unread": true,
      "content": "<p>ü™ê What‚Äôs happening in tech today, February 27, 2026?</p><p>By <a href=\"https://hackernoon.com/u/mattleads\">@mattleads</a> [ 11 Min read ] Master Symfony 7.4 logging: 10 advanced Monolog patterns. Use FingersCrossed, JSON  Attributes to turn text logs into actionable observability data <a href=\"https://hackernoon.com/symfony-74-10-advanced-logging-patterns-you-should-know-about\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/johnpphd\">@johnpphd</a> [ 4 Min read ] How precompiling context for AI agents beats context stuffing. Lessons from building 100+ specialized agents for a web3 application. <a href=\"https://hackernoon.com/lessons-from-building-a-100-agent-swarm-in-web3\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/benoitmalige\">@benoitmalige</a> [ 6 Min read ] Procrastination isnt laziness‚Äîits your brain dodging uncomfortable feelings like fear of failure, judgment, or misalignment. <a href=\"https://hackernoon.com/the-perfect-first-draft-trap-is-killing-your-output\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/nickzt\">@nickzt</a> [ 5 Min read ] Scaling AI for the real world requires peeling back the layers of abstraction weve gotten too comfortable with. <a href=\"https://hackernoon.com/python-is-a-video-latency-suicide-note-how-i-hit-29-fps-with-zero-copy-c-onnx\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/ArunDHANARAJ_gfaknebg\">@ArunDHANARAJ_gfaknebg</a> [ 14 Min read ] Compare Claude Opus 4.6 and GPT‚Äë5.3 Codex across reasoning, coding, benchmarks, pricing, and safety to guide enterprise AI and agentic workload decisions.\n\n <a href=\"https://hackernoon.com/claude-opus-46-and-gpt-53-codex-evaluating-the-new-leaders-in-ai-driven-software-engineering\">Read More.</a></p><p>üßë‚Äçüíª What happened in your world this week?</p><p>We hope you enjoy this worth of free reading material. Feel free to forward this email to a nerdy friend who'll love you for it.See you on Planet Internet! With love, \n The HackerNoon Team ‚úåÔ∏è</p>",
      "contentLength": 1189,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Symfony 7.4: 10 Advanced Logging Patterns You Should Know About",
      "url": "https://hackernoon.com/symfony-74-10-advanced-logging-patterns-you-should-know-about?source=rss",
      "date": 1772208002,
      "author": "MattLeads",
      "guid": 48908,
      "unread": true,
      "content": "<p>Logging is the heartbeat of a production application. In the early days of a project, a simple&nbsp;&nbsp;tail is sufficient. But as your Symfony application scales to handle&nbsp;,&nbsp;&nbsp;and&nbsp;, ‚Äúwriting to a file‚Äù becomes a liability rather than an asset.</p><p>\\\nThe&nbsp;&nbsp;offers sophisticated tools to transform logs from simple text streams into structured, actionable observability data.</p><p>\\\nThis guide explores 10 advanced logging patterns that go beyond the defaults. We will use strict typing, PHP Attributes, and modern YAML configuration.</p><ul><li>&nbsp;(for alerting examples)</li></ul><h2>Scenation 1. The ‚ÄúBlack Box‚Äù Recorder: FingersCrossed Handler</h2><p>You want detailed debug logs when an error occurs to understand the sequence of events leading up to it, but you can‚Äôt afford the disk I/O to log debug messages for every successful request in production.</p><p>\\\nThe&nbsp;&nbsp;buffers all logs in memory during the request. If the request finishes successfully, the buffer is discarded. If an error (or a specific threshold) is reached, the entire buffer (including previous debug logs) is flushed to the persistence handler.</p><p>config/packages/prod/monolog.yaml:</p><pre><code>monolog:\n    handlers:\n        main:\n            type: fingers_crossed\n            # The strategy: \"error\" means if an ERROR occurs, dump everything.\n            action_level: error\n            # Where to dump the logs if the threshold is met\n            handler: nested\n            # Optional: Keep a small buffer size to prevent memory leaks in long processes\n            buffer_size: 50\n        nested:\n            type: stream\n            path: \"%kernel.logs_dir%/%kernel.environment%.log\"\n            level: debug\n</code></pre><p>\\\nYou‚Äôll get the forensic detail of debug-level logging exactly when you need it ‚Äî during a crash ‚Äî without filling your disk with noise during normal operations.</p><h2>Scenario 2. Segregated Channels: The ‚ÄúPayment‚Äù Log</h2><p>Your&nbsp;&nbsp;is a mix of Doctrine queries, router matching, and critical business logic. You need a dedicated file for financial transactions that can be audited separately.</p><p>\\\nCreate a custom Monolog Channel.</p><p>config/packages/monolog.yaml:</p><pre><code>monolog:\n    channels: ['payment'] # Register the channel\n\n    handlers:\n        payment:\n            type: stream\n            path: \"%kernel.logs_dir%/payment.log\"\n            level: info\n            channels: [\"payment\"] # Only listen to this channel\n\n        main:\n            type: stream\n            path: \"%kernel.logs_dir%/%kernel.environment%.log\"\n            level: debug\n            channels: [\"!payment\"] # Exclude payment logs from the main file\n</code></pre><p>Inject the logger specifically for this channel using the Target attribute (available since Symfony 5.3+).</p><pre><code>namespace App\\Command;\n\nuse Psr\\Log\\LoggerInterface;\nuse Symfony\\Component\\Console\\Attribute\\AsCommand;\nuse Symfony\\Component\\Console\\Command\\Command;\nuse Symfony\\Component\\Console\\Input\\InputInterface;\nuse Symfony\\Component\\Console\\Output\\OutputInterface;\nuse Symfony\\Component\\DependencyInjection\\Attribute\\Target;\n\n#[AsCommand(name: 'app:process-payments', description: 'Processes pending payments')]\nclass ProcessPaymentsCommand extends Command\n{\n    public function __construct(\n        #[Target('payment.logger')]\n        private readonly LoggerInterface $paymentLogger,\n        private readonly LoggerInterface $mainLogger\n    ) { parent::__construct(); }\n\n    protected function execute(InputInterface $input, OutputInterface $output): int\n    {\n        $this-&gt;mainLogger-&gt;info('Cron job app:process-payments started.');\n\n        $amounts = [10.50, 99.99, 45.00];\n        foreach ($amounts as $amount) {\n            $this-&gt;paymentLogger-&gt;info('Processing payment', ['amount' =&gt; $amount, 'status' =&gt; 'success']);\n        }\n\n        $this-&gt;mainLogger-&gt;info('Cron job finished.');\n        return Command::SUCCESS;\n    }\n}\n</code></pre><p>Run the Command. You will see&nbsp;&nbsp;created in&nbsp;&nbsp;containing only these specific entries.</p><h2>Scenario 3. Context Enrichment: The #[AsMonologProcessor] Attribute</h2><p>Logs are useless if you can‚Äôt correlate them to a specific user or request ID. You find yourself manually adding [‚Äòuser_id‚Äô =&gt; $user-&gt;getId()] to every single log statement.</p><p>\\\nA global Processor can automatically inject context into every log record.</p><pre><code>namespace App\\Log;\n\nuse Monolog\\Attribute\\AsMonologProcessor;\nuse Monolog\\LogRecord;\n\n#[AsMonologProcessor]\nclass RequestContextProcessor\n{\n    public function __invoke(LogRecord $record): LogRecord\n    {\n        // Simulated context since CLI commands don't have HTTP Requests\n        $extra = [\n            'pid' =&gt; getmypid(),\n            'user' =&gt; get_current_user(),\n        ];\n\n        return $record-&gt;with(extra: array_merge($record-&gt;extra, $extra));\n    }\n}\n</code></pre><p>In&nbsp;,&nbsp;. We use&nbsp;&nbsp;to return a modified copy.</p><p>A developer accidentally logs a user object, dumping PII (Personally Identifiable Information) or credit card numbers into the logs, violating GDPR/PCI-DSS.</p><p>\\\nA specialized processor can scans the context array and mask sensitive keys.</p><pre><code>namespace App\\Log;\n\nuse Monolog\\Attribute\\AsMonologProcessor;\nuse Monolog\\LogRecord;\n\n#[AsMonologProcessor]\nclass SensitiveDataProcessor\n{\n    private const array SENSITIVE_KEYS = ['password', 'credit_card', 'cvv', 'token'];\n\n    public function __invoke(LogRecord $record): LogRecord\n    {\n        $context = $record-&gt;context;\n\n        foreach ($context as $key =&gt; $value) {\n            if (in_array($key, self::SENSITIVE_KEYS, true)) {\n                $context[$key] = '***REDACTED***';\n            }\n        }\n\n        return $record-&gt;with(context: $context);\n    }\n}\n</code></pre><pre><code>$logger-&gt;info('User login', ['password' =&gt; 'secret123']);\n// Output in log: \"User login\" {\"password\": \"***REDACTED***\"}\n</code></pre><h2>Scenario 5. Structured Logging: JSON for ELK/Datadog</h2><p>Parsing multi-line text logs (like stack traces) in&nbsp;&nbsp;or&nbsp;&nbsp;is painful. Regex parsers break easily.</p><p>\\\nYou can output logs as JSON lines. This allows log aggregators to natively index fields like&nbsp;.</p><p>config/packages/monolog.yaml:</p><pre><code>monolog:\n    handlers:\n        json_report:\n            type: stream\n            path: \"%kernel.logs_dir%/app.json\"\n            level: info\n            formatter: monolog.formatter.json\n            channels: [\"!payment\", \"!event\"]\n</code></pre><p>\\\nOpen&nbsp;. The output should look like:</p><pre><code>{\"message\":\"Order created\",\"context\":{\"id\":123},\"level\":200,\"channel\":\"app\",\"datetime\":\"...\"}\n</code></pre><h2>Scenario 6. Spam Prevention: The Deduplication Handler</h2><p>Your database goes down. Your application receives&nbsp;&nbsp;in a minute. Your ‚ÄúEmail on Error‚Äù handler sends you&nbsp;, getting your&nbsp;<strong>SMTP server blacklisted and flooding your inbox</strong>.</p><p>\\\nThe&nbsp;&nbsp;can&nbsp;aggregate identical log records and send a single summary.</p><p>config/packages/monolog.yaml:</p><pre><code>monolog:\n    handlers:\n        deduplication:\n            type: deduplication\n            handler: nested_dedup\n            buffer_size: 60\n            time: 60\n            level: error\n            channels: [\"!console\"]\n</code></pre><p>\\\nIf the DB crashes, you receive&nbsp;<strong>one email every 60 seconds</strong>&nbsp;listing all occurrences, rather than one email per request.</p><h2>Scenario 7. Dynamic Log Levels (Runtime Debugging)</h2><p>A specific customer is reporting an issue in production. You can‚Äôt reproduce it, and you can‚Äôt switch the entire production server to DEBUG level because of the performance hit.</p><p>\\\nUse an&nbsp;&nbsp;to switch the log level dynamically based on a request header.</p><p>Create a custom strategy:</p><pre><code>namespace App\\Command;\n\nuse Psr\\Log\\LoggerInterface;\nuse Symfony\\Component\\Console\\Attribute\\AsCommand;\nuse Symfony\\Component\\Console\\Command\\Command;\nuse Symfony\\Component\\Console\\Input\\InputInterface;\nuse Symfony\\Component\\Console\\Input\\InputOption;\nuse Symfony\\Component\\Console\\Output\\OutputInterface;\n\n#[AsCommand(name: 'app:dynamic-debug', description: 'Tests dynamic log level activation')]\nclass DynamicDebugCommand extends Command\n{\n    public function __construct(private readonly LoggerInterface $logger) {\n        parent::__construct();\n    }\n\n    protected function configure(): void\n    {\n        $this-&gt;addOption('force-debug', null, InputOption::VALUE_NONE, 'Force debug logging for this run');\n    }\n\n    protected function execute(InputInterface $input, OutputInterface $output): int\n    {\n        if ($input-&gt;getOption('force-debug')) {\n            $output-&gt;writeln('Debug mode forced via option. (Simulated, as Monolog ActivationStrategy relies on Http/Request state typically. But you can add processors/handlers dynamically in real apps based on this flag).');\n        }\n\n        $this-&gt;logger-&gt;debug('This detailed trace only appears if --force-debug is passed or an error occurs.');\n        $this-&gt;logger-&gt;info('Standard processing information.');\n\n        return Command::SUCCESS;\n    }\n}\n</code></pre><h2>Scenario 8. Messenger Logging: Worker Context</h2><p>Logs from&nbsp;&nbsp;are hard to trace. You see ‚ÄúHandling message,‚Äù but you don‚Äôt know which message ID caused the error because workers run as long-running processes.</p><p>\\\nUse&nbsp;&nbsp;to inject the Message ID into the Monolog context specifically for the worker process.</p><pre><code>namespace App\\EventListener;\n\nuse Psr\\Log\\LoggerInterface;\nuse Symfony\\Component\\EventDispatcher\\Attribute\\AsEventListener;\nuse Symfony\\Component\\Messenger\\Event\\WorkerMessageReceivedEvent;\n\nreadonly class WorkerLogContextListener\n{\n    public function __construct(private LoggerInterface $logger) {}\n\n    #[AsEventListener]\n    public function onMessageHandling(WorkerMessageReceivedEvent $event): void\n    {\n        $this-&gt;logger-&gt;info('Worker started message', [\n            'message_class' =&gt; $event-&gt;getEnvelope()-&gt;getMessage()::class,\n        ]);\n    }\n}\n</code></pre><h2>Scenario 9. Excluding 404s from Error Logs</h2><p>Bots scanning your site for&nbsp;&nbsp;or&nbsp;&nbsp;generate&nbsp;<strong>thousands of 404 NotFoundHttpException logs</strong>. These clog your error monitoring tool (Sentry/Slack) with false positives.</p><p>\\\nUse the channels exclusion or a specific configuration to ignore bounced logs, or better - configure the&nbsp;&nbsp;to be ignored by the main error handler.</p><p>config/packages/monolog.yaml:</p><pre><code>monolog:\n    handlers:\n        fingers_crossed:\n            type: fingers_crossed\n            action_level: error\n            handler: nested\n            excluded_http_codes: [404, 405]\n            buffer_size: 50\n</code></pre><h2>Scenario 10. Notifier Bridge: ChatOps</h2><p>Email alerts are slow and often ignored. You want critical infrastructure failures to ping a&nbsp;&nbsp;channel immediately.</p><p>\\\nUse&nbsp;&nbsp;bridged with&nbsp;.</p><pre><code>composer require symfony/notifier symfony/slack-notifier\n</code></pre><p>config/packages/monolog.yaml:</p><pre><code>monolog:\n    handlers:\n        slack_alerts:\n            type: service\n            id: Symfony\\Bridge\\Monolog\\Handler\\NotifierHandler\n            level: critical\n</code></pre><p>\\\nThen configure the notifier chatter in&nbsp;<strong>config/packages/notifier.yaml</strong>&nbsp;and your DSN in&nbsp;.</p><pre><code>framework:\n    notifier:\n        chatter_transports:\n            slack: '%env(SLACK_DSN)%'\n        texter_transports:\n        channel_policy:\n            urgent: ['chat/slack']\n            high: ['chat/slack']\n            medium: ['chat/slack']\n            low: ['chat/slack']\n        admin_recipients:\n            - { email: admin@example.com }\n</code></pre><p>\\\n&nbsp;maps log levels to Notifier importance. A critical log becomes a&nbsp;<strong>High Priority Slack notification automatically</strong>.</p><p>Logging is not a byproduct of code - it is a feature of your infrastructure.</p><p>\\\nIn a junior developer‚Äôs mindset, logging is a safety net ‚Äî something to check only when things break. But as you scale to Senior and Lead roles, your perspective must shift. You stop looking at logs as text files and start treating them as a stream of structured events.</p><p>\\\nBy moving to Symfony 7.4 and leveraging the full power of Monolog 3, we transition from ‚Äúlogging‚Äù to ‚Äúobservability.‚Äù</p><p>\\\n&nbsp;turns your logs into a queryable database.</p><p>\\\n&nbsp;handlers solve the ‚Äúsignal-to-noise‚Äù ratio, saving you gigabytes of storage while preserving critical context.</p><p>\\\n&nbsp;ensuring every log entry carries the DNA of the request (User ID, Request ID) turn hours of debugging into minutes of verification.</p><p>\\\n&nbsp;protects your inbox and your sanity.</p><p>\\\nImplementation of these patterns distinguishes a fragile application from a robust, enterprise-grade system. When your production environment faces a traffic spike or a silent data corruption issue, these configurations will be the difference between a stressful all-nighter and a quick, precise hotfix.</p><p>If you found this helpful or have questions about the implementation, I‚Äôd love to hear from you. Let‚Äôs stay in touch and keep the conversation going across these platforms:</p>",
      "contentLength": 12321,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Netflix Ditches deal for Warner Bros. Discovery After Paramount's Offer is Deemed Superior",
      "url": "https://entertainment.slashdot.org/story/26/02/27/1027259/netflix-ditches-deal-for-warner-bros-discovery-after-paramounts-offer-is-deemed-superior?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1772208000,
      "author": "msmash",
      "guid": 48856,
      "unread": true,
      "content": "Netflix is walking away from a deal to buy Warner Bros. Discovery's studio and streaming assets after the WBD board on Thursday deemed a revised bid by Paramount Skydance to be a superior offer. From a report: Earlier this week, Paramount raised its bid to buy the entirety of WBD to $31 per share, up from $30 per share, all cash. It was the latest amendment to Paramount's multiple offers in recent months -- and since moving forward with a hostile bid to buy the company -- and it's now unseated a deal between WBD and Netflix to sell the legacy media company's studio and streaming businesses for $27.75 per share. \n\nLast week, Netflix granted WBD a seven-day waiver to reengage with Paramount, resulting in the higher bid. Paramount's offer is for the entirety of WBD, including its pay-TV networks, such as CNN, TBS and TNT. Netflix had four business days to make changes to its own proposal in light of Paramount's superior bid, the WBD board said in a statement Thursday. Instead, the decision by the streaming giant to walk away puts a pin in a drawn-out saga that saw amended offers from both bidders.",
      "contentLength": 1111,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "CISA replaces acting director after a bumbling year on the job",
      "url": "https://techcrunch.com/2026/02/27/cisa-replaces-acting-director-gottumukkala-after-a-bumbling-year-on-the-job/",
      "date": 1772207822,
      "author": "Zack Whittaker",
      "guid": 48866,
      "unread": true,
      "content": "<article>The U.S. cybersecurity agency's acting director Madhu Gottumukkala will be replaced, after a year of cuts, layoffs, and staff reassignments, and allegations of security lapses and claims he struggled to lead the agency.</article>",
      "contentLength": 219,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "SilverStone RM4A: 4U Rackmount Server/Workstation Chassis That's Great For Liquid Cooling",
      "url": "https://www.phoronix.com/review/silverstone-rm4a",
      "date": 1772206980,
      "author": "Michael Larabel",
      "guid": 48874,
      "unread": true,
      "content": "<article>For those looking to build a rackmount-ready server or workstation that can handle up to an SSI-EEB motherboard and capable of fitting a large liquid cooling setup, the RM4A is a new option from SilverStone that can fit up to a 360mm radiator while still fitting an SSI-EEB motherboard and up to eight expansion slots within 4U size constraints.</article>",
      "contentLength": 345,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Break It To Make It: How Fracturing Sculpts Tissues and Organs",
      "url": "https://www.quantamagazine.org/break-it-to-make-it-how-fracturing-sculpts-tissues-and-organs-20260227/",
      "date": 1772206838,
      "author": "Clare Watson",
      "guid": 48849,
      "unread": true,
      "content": "<p>There‚Äôs a moment, just before the tight mass of cells that is a developing mouse embryo implants itself in the womb, that it all comes apart. Hundreds of tiny fluid-filled bubbles expand between each of the orb‚Äôs few dozen cells. The bubbles grow and press outward on cell membranes ‚Äî and then, in a moment of fracture, pry them apart. Thin protein strands tether the cells together as the‚Ä¶</p>",
      "contentLength": 398,
      "flags": null,
      "enclosureUrl": "https://www.quantamagazine.org/wp-content/uploads/2026/02/Break-it-to-Make-it-cr-Jean-Leon-Maitre-Default.webp",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Microsoft: Computer Programming Is Dying, Long Live AI Literacy",
      "url": "https://news.slashdot.org/story/26/02/27/1335243/microsoft-computer-programming-is-dying-long-live-ai-literacy?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1772205660,
      "author": "msmash",
      "guid": 48855,
      "unread": true,
      "content": "theodp writes: On Tuesday, Microsoft GM of Education and Workforce Policy (and former Code.org Chief Academic Officer) Pat Yongpradit posted an obituary of sorts for coders. \"Computer programmers and software developers are codified differently in the BLS [Bureau of Labor Statistics] data,\" Yongpradit wrote. \"The modern AI-infused world needs less computer programmers (coders) and more software developers (more holistic and higher level). So when folks say that there is less hiring of computer programmers, they are right. But there will be more hiring of software developers, especially those who have adopted an AI-forward mindset and skillset. [...] The number of just pure computer programming roles has already been declining due to reasons like outsourcing, AI will just accelerate the decline.\" \n\nOn Wednesday, Yongpradit's colleague Allyson Knox, Senior Director of Education and Workforce Policy at Microsoft, put another AI nail in the coder coffin, testifying before the House Committee on Education -- the Workforce Subcommittee on Early Childhood, Elementary, and Secondary Education on Building an AI-ready America: Teaching in the Age of AI. \"Thank you to Chairman Tim Walberg, Ranking Member Bobby Scott, Chair Kevin Kiley, Ranking Member Suzanne Bonamici and members of the Subcommittee for the opportunity to share Microsoft perspective and that of the educators and parents we hear from every day across the country,\" Knox wrote in a LinkedIn post. \n\n\"Three themes continue to emerge throughout these discussions: 1. Educators want support to build AI literacy and critical thinking skills. 2. Schools need guidance and guardrails to ensure student data is protected and adults remain in control. 3. Teachers want classroom-ready tools, and a voice in shaping them. If we focus on these priorities, we can help ensure AI expands opportunity for every student across the United States.\" \n\nYongpradit and Knox report up to Microsoft President Brad Smith, who last July told Code.org CEO Hadi Partovi it was time for the tech-backed nonprofit to \"switch hats\" from coding to AI as Microsoft announced a new $4 billion initiative to advance AI education. Smith's thoughts on the extraordinary promise of AI in education were cited by Knox in her 2026 Congressional testimony. Interestingly, Knox argued for the importance of computer programming literacy in her 2013 Congressional testimony at a hearing on Our Nation of Builders: Training the Builders of the Future. \"Congress needs to come up with fresh ideas on how we can continue to train the next generation of builders, programmers, manufacturers, technicians and entrepreneurs,\" said Rep. Lee Terry said to open the discussion. So, are reports of computer programming's imminent death greatly exaggerated?",
      "contentLength": 2783,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "The Goal is for Your Startup to Become a Verb",
      "url": "https://hackernoon.com/the-goal-is-for-your-startup-to-become-a-verb?source=rss",
      "date": 1772205475,
      "author": "Startups Of The Week",
      "guid": 48907,
      "unread": true,
      "content": "<p>Whatever stage of growth you‚Äôre currently in, your north star should be the function you want to become synonymous with.</p><blockquote><p>What do you want your name to mean? </p></blockquote><p>Because after all is said and done, your product or service is a means to an end. All the technical excellence and expert architectural decisions that contribute to your unique service offering are interpreted by the end user in boring, simple thought processes‚Äî&gt;Whenever I want to do xxxx, I think of [insert startup name]. </p><p>That‚Äôs what all your playbooks should optimize for. </p><p>When people want to solve a problem, they reach for a name that feels naturally tied to the action they want to take. And if you really win, there‚Äôs another layer: Rather than just coming to mind, your name replaces the action itself. </p><p>You don‚Äôt say ‚Äúsearch for it online.‚Äù You say, ‚ÄúGoogle it.‚Äù \\n You don‚Äôt say ‚Äúorder a ride.‚Äù You say, ‚ÄúUber there.‚Äù</p><p>This phenomenon is something I‚Äôve personally experience and it has shaped my consumption decisions, at home and abroad. </p><p>To this day, whenever I refer to ride-hailing as ‚ÄúUbering.‚Äù ‚ÄúI‚Äôll Uber to you at 6 pm today‚Äù. ‚ÄúI‚Äôll be with you shortly, I‚Äôm on the phone with my Uber driver‚Äù (nevermind that it was actually a Bolt driver). But that‚Äôs just me. </p><p>In the early days of ride-hailing services in Lagos, between 2014 &amp; 16, Bolt became the default word. Uber entered in 2014. Bolt followed in 2016 and scaled aggressively. For a large segment of the market, Bolt wasn‚Äôt an Uber alternative; it was the introduction to Ride-hailing. As their first experience, it naturally became THE word. </p><p>Then inDrive arrived in 2019. And if you live in Lagos, you know what daily hold-up feels like. You know how surge pricing can turn a normal trip into a life-threatening financial decision. inDrive didn‚Äôt try to out-Uber Uber. It leaned into control, negotiation, and affordability. </p><p>When there was fear of prices stretching too far, people opened inDrive.</p><p>Over time, in certain conversations, ‚Äúcheck inDrive‚Äù became synonymous with ‚Äúfind the cheaper option.‚Äù</p><p>Three companies. Same category. Different associations forming in different pockets of the same city.</p><p>The learning here, for builders, is to actively build mental shortcuts in the minds of your users because associations like these don‚Äôt happen by accident. </p><p>And if you‚Äôre entering a market that feels somewhat crowded, fear not! </p><p><strong>You don‚Äôt have to own the entire category. You just have to own a behavior inside it.</strong></p><p>Pick the verb you want to represent, decide what you want to be synonymous with, and reinforce that idea over and over again. </p><p>:::tip\nAnd if you‚Äôre serious about testing that clarity in the real world, there‚Äôs a practical place to start.</p><p>\\\nHackerNoon‚Äôs <strong>Proof of Usefulness Hackathon</strong> is built around a simple question: Does your product actually solve a real problem for real people? It‚Äôs one thing to declare what you want to be synonymous with. It‚Äôs another to prove it publicly.</p><p>\\\nIf you‚Äôre building something meaningful and want to sharpen your positioning while competing for over $150,000 in cash prizes and software credits, this is a solid first step.</p><p>Now, let‚Äôs take a look at three startups that are clearly attempting to anchor themselves to specific mental shortcuts.</p><h2>Meet Pettr App, CreaThink Solutions, and Saturn: HackerNoon Startups of the Week</h2><p> is a digital platform designed to simplify pet ownership by centralizing pet care management in one place. From health records and appointments to service access and reminders, Pettr aims to reduce the administrative friction that comes with caring for animals.</p><p>Rather than treating pet services as isolated transactions, Pettr positions itself as an ongoing companion to pet owners ‚Äî a structured way to organize what is often an emotional and time-sensitive responsibility. Over time, that kind of utility has the potential to become second nature.</p><p> provides end-to-end digital services that combine strategic thinking with technical execution. The company works with businesses to design, develop, and deploy tailored digital solutions ‚Äî from platforms and websites to broader transformation initiatives.</p><p>Its positioning leans into the idea that building well begins with thinking well. By blending creativity with structured problem-solving, CreaThink focuses not just on delivering digital products, but on helping organizations approach technology with clarity and intention.</p><p> is a social scheduling platform built for high school students, designed to make managing school life more intuitive and connected. By organizing class schedules, clubs, sports, and social plans into one shared space, Saturn helps students navigate their daily routines with less friction.</p><p>In environments where coordination can easily become chaotic, Saturn aims to bring structure and visibility to student communities ‚Äî turning scheduling into something collaborative rather than fragmented.</p><p>Different industries. Different audiences. Different problems.</p><p>But the principle is the same.</p><p>When your function is clear, your name travels. And when that function is reinforced consistently enough, your brand becomes a verb. </p>",
      "contentLength": 5177,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Spotify is rolling out Audiobook Charts",
      "url": "https://techcrunch.com/2026/02/27/spotify-is-rolling-out-audiobook-charts/",
      "date": 1772204862,
      "author": "Aisha Malik",
      "guid": 48844,
      "unread": true,
      "content": "<article>Similar to the streaming giant's Music and Podcast Charts, the Audiobook Charts will be updated weekly and highlight the top audiobooks overall and by genre.</article>",
      "contentLength": 157,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Last 24 hours to get TechCrunch Disrupt 2026 tickets at the lowest rates of the year",
      "url": "https://techcrunch.com/2026/02/27/last-24-hours-to-get-techcrunch-disrupt-2026-tickets-at-the-lowest-rates-of-the-year/",
      "date": 1772204400,
      "author": "TechCrunch Events",
      "guid": 48843,
      "unread": true,
      "content": "<article>The lowest rates of the year for TechCrunch Disrupt 2026 end after today. Prices go up at 11:59 p.m. PT. Don't miss connecting with 10,000 founders, investors, and operators, and key takeaways from 250+ industry leaders. Register now to save up to $680, or up to 30% on group passes.</article>",
      "contentLength": 283,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "After Zomato, Deepinder Goyal returns with a $54M brain-monitoring bet",
      "url": "https://techcrunch.com/2026/02/27/after-zomato-deepinder-goyal-returns-with-a-54m-brain-monitoring-bet/",
      "date": 1772203239,
      "author": "Jagmeet Singh",
      "guid": 48842,
      "unread": true,
      "content": "<article>Zomato co-founder Deepinder Goyal's new wearable startup Temple has raised $54 million in a friends-and-family round at a post-money valuation of about $190 million.</article>",
      "contentLength": 165,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Your Smart TV May Be Crawling the Web for AI",
      "url": "https://entertainment.slashdot.org/story/26/02/27/1254229/your-smart-tv-may-be-crawling-the-web-for-ai?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1772203200,
      "author": "msmash",
      "guid": 48833,
      "unread": true,
      "content": "Bright Data, a company that operates one of the world's largest residential proxy networks, has been running an SDK inside smart TV apps that turns those devices into nodes for web crawling -- collecting data used by AI companies, among other clients -- and most consumers have had no idea it was happening. \n\nThe company has published more than 200 first-party apps to LG's app store alone and still lists Samsung's Tizen OS and LG's webOS as supported platforms, though LG says the SDK is \"not officially supported\" and its operation on webOS \"is not guaranteed.\" Google, Amazon, and Roku have all since adopted policies restricting or banning background proxy SDKs, and Bright Data no longer supports those platforms. \n\nSeveral Roku apps still running the SDK disappeared from the store after a journalist with The Verge behind this reporting contacted the company.",
      "contentLength": 868,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Intel Media Driver Update Brings Nova Lake S Support, AV1 Improvements",
      "url": "https://www.phoronix.com/news/Intel-Media-Driver-2025Q4",
      "date": 1772202725,
      "author": "Michael Larabel",
      "guid": 48848,
      "unread": true,
      "content": "<article>While at the end of February, today Intel released the Intel Media Driver 2025Q4 release as well as the latest VPL GPU Runtime for their media stack...</article>",
      "contentLength": 151,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "A Shapeshifting Supercomputer May Be More Energy Efficient",
      "url": "https://spectrum.ieee.org/reconfigurable-supercomputer",
      "date": 1772202208,
      "author": "Katherine Bourzac",
      "guid": 48826,
      "unread": true,
      "content": "<p>Sandia‚Äôs Spectra uses NextSilicon‚Äôs reconfigurable accelerators </p>",
      "contentLength": 68,
      "flags": null,
      "enclosureUrl": "https://spectrum.ieee.org/media-library/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpbWFnZSI6Imh0dHBzOi8vYXNzZXRzLnJibC5tcy82NTA2ODE2Mi9vcmlnaW4uanBnIiwiZXhwaXJlc19hdCI6MTc3NDMzMzY4NX0.2czprnIaWqbouhrUkJbHYkwpxP73nEum_7mw28sIEFM/image.jpg?width=600",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "OpenAI raises $110B in one of the largest private funding rounds in history",
      "url": "https://techcrunch.com/2026/02/27/openai-raises-110b-in-one-of-the-largest-private-funding-rounds-in-history/",
      "date": 1772201581,
      "author": "Russell Brandom",
      "guid": 48819,
      "unread": true,
      "content": "<article>The new funding consists of a $50 billion investment from Amazon as well as $30 billion each from Nvidia and SoftBank, against a $730 billion valuation. </article>",
      "contentLength": 153,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Canonical Talks Up RISC-V This Year With Ubuntu 26.04 LTS",
      "url": "https://www.phoronix.com/news/Ubuntu-RISC-V-2026",
      "date": 1772200870,
      "author": "Michael Larabel",
      "guid": 48825,
      "unread": true,
      "content": "<article>Canonical put out a new blog post today highlighting their RISC-V work over 2025 that included switching to the RVA23 profile baseline for Ubuntu 25.10 and moving forward. Now with RVA23-compatible RISC-V hardware coming to market this year, Canonical is talking up the RISC-V possibilities when paired with the upcoming Ubuntu 26.04 LTS release...</article>",
      "contentLength": 348,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "OpenAI Raises $110 Billion in the Largest Private Funding Round Ever",
      "url": "https://slashdot.org/story/26/02/27/1355236/openai-raises-110-billion-in-the-largest-private-funding-round-ever?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1772200800,
      "author": "msmash",
      "guid": 48816,
      "unread": true,
      "content": "OpenAI has closed what is now the largest private financing in history -- a $110 billion round at a $730 billion pre-money valuation that more than doubles the $40 billion raise it completed just a year ago, itself a record for a private tech company at the time. \n\nAmazon invested $50 billion, SoftBank put in $30 billion, and Nvidia committed $30 billion, and additional investors are expected to join as the round progresses. The valuation is a sharp jump from the $500 billion OpenAI commanded in a secondary financing in October, and the round dwarfs recent raises by rivals Anthropic ($30 billion) and xAI ($20 billion). \n\nThe company has been telling investors it is now targeting roughly $600 billion in total compute spend by 2030, a more measured figure than the $1.4 trillion in infrastructure commitments CEO Sam Altman had touted months earlier. OpenAI is projecting more than $280 billion in total revenue by 2030, split roughly equally between consumer and enterprise. ChatGPT now has over 900 million weekly active users and more than 50 million paying subscribers.",
      "contentLength": 1081,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "With Netflix Retreat, Trump Ally Larry Ellison Will Soon Own Warner Brothers, HBO, CNN, CBS, Paramount, Discovery, And Part Of TikTok",
      "url": "https://www.techdirt.com/2026/02/27/with-netflix-retreat-trump-ally-larry-ellison-will-soon-own-warner-brothers-hbo-cnn-cbs-paramount-discovery-and-part-of-tiktok/",
      "date": 1772198580,
      "author": "Karl Bode",
      "guid": 48814,
      "unread": true,
      "content": "<p>Netflix has retreated from its protracted bidding war with Larry Ellison for control of Warner Brothers, giving the Trump ally likely control of Warner, CNN, and HBO. <a href=\"https://about.netflix.com/en/news/netflix-declines-to-raise-offer-for-warner-bros\">In a statement</a>,  Netflix co-CEOs Ted Sarandos and Greg Peters said that Paramount‚Äôs latest offer made the acquisition financially irresponsible:</p><blockquote><p><em>‚ÄúThe transaction we negotiated would have created shareholder value with a clear path to regulatory approval. However, we‚Äôve always been disciplined, and at the price required to match Paramount Skydance‚Äôs latest offer, the deal is no longer financially attractive, so we are declining to match the Paramount Skydance bid.‚Äù</em></p></blockquote><p>The massive debt load from massively overpaying for Warner Brothers is also likely to cause major operational headaches that could result in this being a short-lived adventure much like the <a href=\"https://www.techdirt.com/2024/07/25/after-layoffs-and-endless-chaos-the-att-time-warner-discovery-mergers-come-to-a-whimpering-pathetic-finale/\">several-decades worth of pointless Warner media mergers</a> (including AT&amp;T) that preceded it. </p><p>That‚Äôs a lot of money for the Ellisons (<a href=\"https://www.reuters.com/business/finance/hollywood-hungry-gulf-states-bankroll-paramounts-warner-bros-bid-2025-12-09/\">and the Saudis</a>) to dump into a company that has, again, seen nothing but a two-decade history of disastrous overvalued mergers resulting in a <a href=\"https://www.techdirt.com/2024/07/25/after-layoffs-and-endless-chaos-the-att-time-warner-discovery-mergers-come-to-a-whimpering-pathetic-finale/\">progressively shittier and less creative company</a>, broadly despised by creatives after a parade of brutal layoffs (much more of which are certainly coming to pay off debt). </p><p>Things could could be further complicated by a sudden subscriber exodus across the brands, or the Ellisons‚Äô fortunes being further strained by a <a href=\"https://www.nytimes.com/2025/12/11/business/dealbook/ai-spending-oracle-openai.html?unlocked_article_code=1.PFA.AzCI.J6H3xgMfADjk&amp;smid=url-share\">potential AI hype bubble collapse</a>. All the lazy AI-generated Batman IP slop in the world will not be able to save this mess if the winds don‚Äôt blow favorably in the Ellisons‚Äô direction over the next two years. </p><p>Still, an overt authoritarian oligarch is now very close to controlling an unprecedented segment of U.S. traditional and new media. If it follows the established autocratic playbook, this push will continue until it runs into something other than pudding-soft public, political, and policy opposition. There‚Äôs a window here for policymakers and consumers to ensure the gambit fails, but the hour is getting late. </p>",
      "contentLength": 2057,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "How GenAI and Digital Twins Are Enabling Self Healing Supply Chain and Software Ecosystems",
      "url": "https://hackernoon.com/how-genai-and-digital-twins-are-enabling-self-healing-supply-chain-and-software-ecosystems?source=rss",
      "date": 1772198497,
      "author": "Rahul Ravindran",
      "guid": 48906,
      "unread": true,
      "content": "<p>Previously, businesses have taken disruption lightly. Something to live with, something to respond to, something that will culminate. This closure of factories, collapse of suppliers, logistical difficulties, and system failures are all unwanted guests, and they push leaders to enter the crisis mode. The fag-end work is in teams, and decisions are fast; spending is too big, and hopefully it will be the environment, the next shock to be felt somewhere in the environment. Such a way of functioning is no longer a possibility. No longer is disruption an exception. It has been set to be the operating environment.</p><p>The change that exists is not the existence of such a risk but is the reaction of the organizations to the already practically existing risk. Reaction to anticipation and anticipation to autonomy are processes of gradual transition. This change is built in the digital twin, and then there, this is not a programmed model but an organism sensitive to the dynamics of the complex systems in the real world.</p><p>Digital twins and general-purpose AI reasoning systems can always recall the system telemetry, anticipate the wear-out of performance, and automatically undertake mitigation measures (redistribution of workload, dynamic scaling, and predictive maintenance) on vast-sized digital platforms (connected-device ecosystems, streaming platforms, and supply-chain software networks).</p><h2><strong>Digital twins as living mirrors of reality</strong></h2><p>Modern digital twins are no longer static models; they are continuously evolving representations of real-world systems. It is a continuously evolving impression of actual business, which is nourished by streams of data from machines, systems, suppliers, and working processes. It expresses contemporary reality and visions of a future eventuality. Chains of suppliers, materials, inventory flows, and logistics routes are examples of the links represented in supply chains. Machines, production lines, and environmental conditions find their expressions in factories. It includes reliability, software performance trends, and loads.</p><p>The dynamism of the twin enables leaders to experiment with ideas without having to disrupt the real world. By using a plant, the behavior of a line can be studied under conditions of stress. The effect of a disruption in levels can be observed by a supply team. A software process can also monitor the propagation of failures across systems. The reaction movement impulse starts here.</p><h2><strong>From prediction to autonomy</strong></h2><p>The anticipated issue alters the dialogue. The question of what did not happen turns into the question of what will not happen as the starting point for teams. The latter is enabled by digital twins, which replicate scenarios around the clock. They address prospective supplier closures, demand fluctuations, geopolitical disasters, equipment corrosion and wear, and system overloads prior to their actual occurrence.</p><p>The next step is autonomy. The extent of digital twins with compelling reasoning models is not limited to knowledge. They suggest actions, and under precise conditions, they implement them. The parameters of production are self-regulating. Before failure, maintenance is activated. Risks and non-habitual changes in inventory are addressed. Workloads are rerouted to software systems before performance is degraded. It is no longer entombed in alarms, but human teams remain in control. They are demoted to line managers.</p><h2>Self healing systems in practice</h2><p>Self-healing does not imply that systems are not destroyed. It means that they recognize stress at a very early stage and act wisely. In the manufacturing context, this can be observed in the form of equipment that adapts itself to prevent damage or trigger maintenance even before malfunctioning. The supply networks model considers it an automatic sourcing response to the supplier risk exceeding a threshold. It occurs in software ecosystems through redistribution of traffic or capacity scaling, or automatic isolation of failed parts.</p><p>This is not possible in one tool but in a closed loop. Data flows into the twin. The signal is decoded by the twin. Scenarios are evaluated. Decisions are made. Actions are taken. The result is sent back into the model. It is a system that requires time to learn via its shortcomings and evolve.</p><h2><strong>The quiet importance of governance</strong></h2><p>A government that is not in control is dangerous to the operations. The successful organizations see digital twins as a cloth of governance and not a by-product. Risk tolerance is defined. Escalation paths are clear. The decisions are limited in nature. The decisions made by the leaders are about what to automate and what people are supposed to research.</p><p>This design will make sure that digital twins are not a rogue intelligence but rather an equal force. Silos' risk has been broken down and viewed by executives. Operations teams are not informed with noise. The real working of systems forms the basis of strategy and not spreadsheet forecasts of how systems work.</p><h2><strong>When ecosystems replace silos</strong></h2><p>To create digital twins, the starting points are not the growing assets and departments, but this is where the actual breakthrough is achieved. The supply chain cannot be called linear. Service layers, vendors, and integrations are the basis of software platforms. In a cross-cultural setting, organizational elements are not maximized, but the whole is enhanced.</p><p>Transparency suppresses information blindness. Personal fixes are substituted with integrated responses. Resilience is not a cost center but a belief center. Investors notice. Customers notice. The variation is experienced among staff members, where crisis is no longer periodic or temporary.</p><h2><strong>Leading into the autonomous era</strong></h2><p>Autonomous processes do not occur in a day, from reactive to autonomous operation. They start with the ability to see, then progress to predicting, and finally graduate to self-healing behavior with evident leadership. The possibility of such progression is based on the concept of digital twins. GenAI and intelligent reasoning algorithms are added as the means of turning wisdom into action.</p><p>The first flowing organizations are not pursuing novelty. Instead of being violent, they are opting to be non-violent. Instead of enhancing it, they are constructing shock-absorbing systems. Independence does not concern itself with replacing people in a world full of uncertainty. It is about providing them with a working system that is not contrary to them.</p>",
      "contentLength": 6457,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Ethical Challenges of Leveraging Generative AI in Financial Close and Narratives",
      "url": "https://hackernoon.com/ethical-challenges-of-leveraging-generative-ai-in-financial-close-and-narratives?source=rss",
      "date": 1772198189,
      "author": "ks2423",
      "guid": 48905,
      "unread": true,
      "content": "<p>The digital marketing is like a forest fire, with generative AI becoming viral in other industry segments as well. It is a financial revolution. The potential of the generative AI is effective and correct and can save a large amount of time not only to accelerate the end of the month closing but also detail the financial stories. But all their novelty and convenience cannot be buried under the carpet of any cobbles of ethical problems.</p><h2><strong>The Temptation of Speed and Accuracy</strong></h2><p>The monetary world is time conscious. It is monumental in itself that the stress component of making the book closing time, particularly at the culmination of a quarter or even more ideally a fiscal year, is stressful. And generative AI algorithms are the things which are, in fact, miraculous. They are able to find the information of colossal volumes of data in several seconds, see the anomalies sooner than the human eye, and even produce narrative reports that will contain literal and sensible explanations of the statistics.</p><p>And all this hastiness brings the question of trust. Who is going to take the wrong step in a situation where the report prepared by artificial intelligence can be made on the false input data? The aspect of human control can also be reduced to a minimum since teams are fairly relying too heavily on the outcome of such tools. That threat is being overtaken, as in the case of errors, they will not be pointed out by the loss or enormous alteration of the human touch. The lack of taking such AI systems seriously implies that the system will be of an unsteady nature, and any hiccup will result in dire misreporting.</p><h2><strong>Opacity in Decision Making</strong></h2><p>The last part is one of the most troubling regarding the generative AI in financial reports as it is not clear how the AI is able to arrive at some of the decisions. Admittedly, generative models need not be necessarily transparent. They are not following a trail of coded reasoning blindly, but they like picking on patterns even the inventors of those patterns themselves do not know exactly what they are. This renders it difficult to audit the rationales of the financial narrations by AI.</p><p>What does he/she do to the request that a growing authority or a board member is requesting him/her to clarify to him/her the cause behind a particular interpretation of the financial information based on the logic that is inherent in the machine learning operations? This black-box nature is of paramount concern to accountability and auditing. Traceability in finance is sacrosanct in normal finance. All the characters, all the footnotes will have a trace. These generative AI issues on this principle are yet to be reconciled.</p><h2><strong>Bias Creeping Into Narratives</strong></h2><p>Data is never neutral. It is a signifier of values and assumptions and past practices of the system where it is created. The actual danger is that information is being amplified in the product when the generative AI models are educated on financial data, particularly on the large volumes of data which are heterogeneous.</p><p>One would be in the language pattern that is habitually adopted in the financial reporting that might be biased towards optimism rather than warning subconsciously. It has the potential to shape the sight of the financial performance of a business the very instant it gets selected by an AI and starts to create the identical positive narratives on it. Besides, this bias may happen accidentally to the human operators. This systematic reporting bias might cause badly informed stakeholders and ill‚Äëinformed decision making and reputational disaster in the long term.</p><h2><strong>Data Privacy and Confidentiality Risks</strong></h2><p>One of the most confidential information which is possessed by a given organization is financial information. The fact that there is the possibility of the utilization of the generative AI implies the imposition of the megaliths of this information. Otherwise, it is a huge risk of dispensation of information unless under strict security.</p><p>In addition, by utilising the services of third‚Äëparty AI or AI‚Äëbased models on a cloud‚Äëcomputing model, the companies are, in other words, sending valuable financial information to third parties. Although the information has been anonymized, it can be reverse engineered or accidentally exposed. The potential result of such data intrusions, in the given case, is humiliation, not mentioning legal suits, regulatory fines, and unimaginable loss of trust of the stakeholders.</p><h2><strong>Human Oversight vs Machine Autonomy</strong></h2><p>Tug of war is productivity or regulation. When it comes to generating the majority of legwork, the automatic financial close and storytelling generative AI will certainly be able to do most of the work. However, when human beings begin to sacrifice excess power, then it is something to fret about.</p><p>The human perception in its capacity to process the information in the larger business world is, however, inimitable. Even the most sophisticated ones cannot even contemplate the specifics of a global crisis, instant amendment of the regulation, or strategic consequences of a takeover. The threat that it might pose is that some valuable undertones might be overlooked in case an AI replaced a human being as the financial stories writer. It is not simply a technology issue but there is solid ground on the moral aspect. The organizations must consider making sure that AI will not take the place of human work but will rather complement it particularly in the areas where judgment and situational analysis is a significant issue.</p><p>AI has no reversal. It will continue boosting its financial position. Nevertheless, the organizations would be required to exhibit a high propensity of its application with a sharp sense of the ethical minefield it involves. Neither does it presuppose existing as being technological but assumes creating fences around such technology.</p><p>It has to focus on human management. All the procedures of AI use should be audited. Factors that should be bargained include transparency and explainability, but they should not be neglected since these are among the factors that must be considered. The orientation of learning the functionality of such tools should also be accorded to the organizational teams so that they would be aware of where they would fail and critically analyze the results.</p><p>Finally, AI should be treated as a co‚Äëpilot, and not an autopilot. It can revolutionize the financial reporting through its judicious application. Even worse, the effectiveness of the very financial process can be destroyed because of the abuse of the same.</p>",
      "contentLength": 6559,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "South Korea opens the door to let Google Maps operate fully",
      "url": "https://techcrunch.com/2026/02/27/south-korea-opens-the-door-to-let-google-maps-operate-fully/",
      "date": 1772197960,
      "author": "Ram Iyer, Kate Park",
      "guid": 48811,
      "unread": true,
      "content": "<article>After years of appeals, Google has finally won approval to export high-precision geographic information out of South Korea and provide proper Google Maps services in the country, including walking and real-time driving directions.</article>",
      "contentLength": 230,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "From DevOps to Platform Engineering How Shift Left Practices Enable AI Ready Enterprise Platforms",
      "url": "https://hackernoon.com/from-devops-to-platform-engineering-how-shift-left-practices-enable-ai-ready-enterprise-platforms?source=rss",
      "date": 1772197735,
      "author": "nithish reddy",
      "guid": 48902,
      "unread": true,
      "content": "<p>DevOps was a sense of freedom. It increased the pace of teamwork, the release process ceased to be whiplashed, and the divisions between the operations and development teams were finally broken. Liberty came, bit by bit, but that burden grew. Cloud resources increased many times over, containers were growing everywhere, compliance regulations were getting more rigid, and environments began to resemble chaotic cities rather than orderly workplaces. DevOps groups were now expected to do everything within limited timeframes and at high frequency. Shift left practices put testing, security, and quality earlier in the lifecycle at the expense of overworking developers. Something had to change.</p><p>Platform engineering has not been constructed as an answer to DevOps, and it was a natural extension of it. Rather than forcing all teams to struggle with infrastructure, pipelines, and policies directly, platform engineering transforms these elements into an internal product. Developers are provided with a simple bare bones path to create, publish, and use software without necessarily understanding all the gears and cogs under the hood. The platform becomes a platform of trust, then one more is added, and then another, and another, while application teams focus on building value rather than managing complexity.</p><h2><strong>Rethinking Shift Left at Enterprise Scale</strong></h2><p>Shift left is most effective when invisible. There were security checks and compliance reviews during initial pipeline implementations that were not applied uniformly and were fragmented. This is altered by platform engineering. It has testing and governance built into the platform. Whenever developers create environments or deploy applications, the right checks automatically activate. The platform also does not give teams reminders about best practices but automatically enforces them. The system makes shift left part of the system and not an item on the to do list.</p><p>Shifting checks further up the lifecycle is no longer sufficient, especially as systems become very large and interconnected. Contemporary platforms should treat security, testing, monitoring, and reliability as continuous rather than isolated tasks. This is achieved through platform engineering, which extends shift left across every stage of delivery. The same rules, insights, and protections are applied from the moment code is written until it is executed in production. Problems are detected faster because signals are continuously flowing, rather than relying on teams to decide when to investigate. This shift everywhere approach reduces unpredictability, shortens recovery time, and creates confidence that the service will behave consistently regardless of how fast the organization is moving.</p><p>Currently, enterprise platforms need to provide much more than what was planned to deliver applications. They require very high observability, deterministic environments, and stable development and production environments. These attributes are necessitated because systems are starting to depend on a high level of automation and data driven decision making. Standardized deployment templates and built in monitoring are infrastructure definitions that assure organizations that changes are performing as expected. Learning systems can be predictable, secure, and scalable when everything runs on the same paved roads.</p><h2><strong>Why Developers Actually Like This Change</strong></h2><p>The focus on platform engineering is one of the quiet strengths in its capability to transform the experience of a developer. For UI full-stack developers, platform-embedded shift-left practices ensure that user-facing applications behave consistently across environments, making real-time features, observability-driven UX improvements, and rapid iteration safer and more predictable.</p><p>Rather than memorizing scripts or waiting on another group, developers use a bare bones interface through which they do the least amount of work, leaving the heavy work to be done on their behalf. Provisioning an environment feels normal and not dangerous. Deployments are dull and monotonous. When things go wrong, logs and metrics are already in place. The absence of friction in day to day work does not make people work harder but allows productivity to increase naturally.</p><h2><strong>The Cultural Shift Behind the Technology</strong></h2><p>Changing mentality is also part of transitioning to platform engineering. Platform teams act as product builders. They listen to internal users, improve through feedback, and measure success through adoption and reliability. Guardrails are not held against development teams. There is greater operational stability without turning teams into bottlenecks. With shift left practices ceasing to be a slogan and becoming an experience that is central to every interaction with the platform.</p><p>The trend of platform engineering can be interpreted as a more general desire to see complex systems as having a calming side. Speed is what businesses desire, not anarchy. They seek innovation, not unmanageable risk. Through the use of shift left practices on a common platform, organizations are able to create an environment that is homogeneous, observable, and ready to integrate with the next generation of intelligent capabilities. The end product is more than improved software creation but a more sustainable way to build the future.</p>",
      "contentLength": 5320,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Engineering Accountable AI Systems: Why Governance Must Become a First-Class System Layer",
      "url": "https://hackernoon.com/engineering-accountable-ai-systems-why-governance-must-become-a-first-class-system-layer?source=rss",
      "date": 1772197277,
      "author": "Aakash Ravi",
      "guid": 48903,
      "unread": true,
      "content": "<p>\\\nAI governance has a production problem.</p><p>Over the past several years, regulators, standards bodies, and industry leaders have converged on a clear consensus: AI systems must be accountable. Frameworks like the EU AI Act, the NIST AI Risk Management Framework, and emerging global standards all define expectations around fairness, auditability, risk management, and oversight.</p><p>But there is a fundamental disconnect.</p><p>Governance exists as policy. \\n AI exists as infrastructure.</p><p>And somewhere between the two, accountability breaks down.</p><p>The core issue is not regulatory clarity. It is an engineering implementation.</p><p>AI governance today is largely procedural. Documentation exists. Risk assessments are conducted. Controls are described. But the systems themselves often lack deterministic enforcement mechanisms that ensure governance requirements are actively enforced at runtime.</p><p>This is not a policy failure. It is a missing architectural layer.</p><h2><strong>The Problem: Governance Without Enforcement</strong></h2><p>Modern AI systems operate at extraordinary scale.</p><ul><li>Financial approvals affecting millions of individuals</li><li>Content ranking and moderation across global platforms</li><li>Automated operational decisions across critical infrastructure</li><li>Healthcare decision support affecting patient outcomes</li></ul><p>At this scale, even small deviations can produce systemic risk.</p><p>Yet most governance mechanisms today operate outside the system itself:</p><ul><li>Reactive investigations after incidents occur</li></ul><p>These mechanisms do not provide continuous enforcement.</p><p>They cannot guarantee that governance requirements were actually enforced at the moment decisions were made.</p><p>Without system-level enforcement, governance becomes retrospective rather than preventative.</p><h2><strong>The Root Cause: No Translation Layer Between Policy and Systems</strong></h2><p>Regulatory requirements are written in human language:</p><p>‚ÄúEnsure fairness.‚Äù \\n ‚ÄúMaintain appropriate safeguards.‚Äù \\n ‚ÄúProvide auditability.‚Äù</p><p>Production systems require deterministic specifications:</p><ul><li>Access control primitives</li></ul><p>These two domains operate independently.</p><p>Legal and compliance teams define governance requirements. Engineering teams build systems. But there is rarely a structured mechanism that translates governance mandates into enforceable technical controls.</p><p>This creates a systemic accountability gap.</p><h2><strong>Introducing the AI Accountability Control Stack (AACS)</strong></h2><p>To address this structural deficiency, I developed the <strong>AI Accountability Control Stack (AACS)</strong> ‚Äî a production-grade architectural framework that operationalizes governance requirements directly within AI system infrastructure.</p><p>The AACS transforms governance from documentation into enforceable system behavior.</p><p>Rather than relying on manual oversight, it embeds accountability into the system itself.</p><p>The architecture consists of six functional layers:</p><h3><strong>Layer 1: Policy Abstraction Layer</strong></h3><p>This layer converts governance requirements into structured, machine-readable control primitives.</p><p>Instead of policy existing only as text documents, it becomes structured metadata that systems can interpret and enforce.</p><h3><strong>Layer 2: Risk Modeling Layer</strong></h3><p>Different AI systems carry different levels of risk depending on:</p><ul></ul><p>This layer maps governance requirements to system-specific risk profiles.</p><h3><strong>Layer 3: Control Specification Layer</strong></h3><p>This layer translates governance requirements into enforceable technical specifications, including:</p><ul></ul><p>These specifications are executable, not advisory.</p><h3><strong>Layer 4: Instrumentation Layer</strong></h3><p>Instrumentation embeds monitoring and enforcement hooks directly into:</p><ul><li>Model inference pipelines</li></ul><p>This ensures governance enforcement occurs during system execution.</p><h3><strong>Layer 5: Audit Telemetry Layer</strong></h3><p>This layer generates structured, tamper-evident audit logs capturing:</p><ul><li>Applied governance controls</li></ul><p>This creates verifiable audit evidence automatically.</p><h3><strong>Layer 6: Governance Reporting Interface</strong></h3><p>This final layer converts telemetry into:</p><ul><li>Regulator-ready audit reports</li><li>Internal compliance dashboards</li></ul><p>Governance becomes continuously measurable.</p><h2><strong>Why This Architecture Matters</strong></h2><p>Existing governance frameworks define expectations. They do not define implementation architectures.</p><p>The AACS provides a deterministic translation layer between governance policy and system execution.</p><p>This produces several critical capabilities:</p><p> Controls are applied at inference time.</p><p> Evidence is generated as part of system operation.</p><p> Governance scales with infrastructure.</p><p> Governance remains intact as systems evolve.</p><h2><strong>How This Works in Real Systems</strong></h2><p>Modern AI infrastructure is:</p><ul><li>Integrated with external services</li></ul><p>The AACS integrates directly into this environment by attaching enforcement and telemetry mechanisms to service boundaries, inference pipelines, and API layers.</p><p>This allows governance controls to travel with the system regardless of deployment architecture.</p><p>Even when using externally provided models, governance wrappers can enforce access controls, logging requirements, and operational safeguards.</p><p>This ensures accountability regardless of system complexity.</p><h2><strong>The Emergence of Governance Engineering</strong></h2><p>This architectural model introduces a new engineering discipline: Governance Engineering.</p><p>Governance engineers design and implement the infrastructure required to operationalize governance requirements.</p><p>Their work ensures that governance is enforced automatically, not manually.</p><p>This function is becoming essential as regulatory expectations shift toward technical enforceability.</p><h2><strong>The Future: Governance Will Be Evaluated at the System Level</strong></h2><p>Regulatory oversight is evolving rapidly.</p><p>Future regulatory evaluation will focus not only on policy documentation, but on system-level evidence demonstrating governance enforcement.</p><p>Organizations will need to demonstrate:</p><ul><li>How governance requirements were translated into system controls</li><li>How those controls were enforced</li><li>What evidence proves enforcement occurred</li></ul><p>Architectural enforcement will become the standard.</p><h2><strong>Final Thought: Accountability Is an Architectural Decision</strong></h2><p>Accountability cannot be achieved solely through documentation, policy, or audits.</p><p>It must be engineered into the system itself.</p><p>The AI Accountability Control Stack provides a practical architectural model for achieving this by introducing a deterministic control layer that bridges governance and system execution.</p><p>As AI systems continue to scale and regulatory expectations intensify, the organizations that treat governance as infrastructure rather than policy will be best positioned to build trustworthy, resilient, and compliant AI systems.</p><p>Governance must become code.</p>",
      "contentLength": 6441,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Memory Price Hikes Will Kill Off Budget PCs and Smartphones, Analyst Warns",
      "url": "https://hardware.slashdot.org/story/26/02/27/008259/memory-price-hikes-will-kill-off-budget-pcs-and-smartphones-analyst-warns?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1772197200,
      "author": "BeauHD",
      "guid": 48803,
      "unread": true,
      "content": "An anonymous reader quotes a report from The Register: Ballooning memory prices are forecast to kill off entry-level PCs, leading to a decline in global shipments this year -- and a similar effect is going to hit smartphones. Analyst biz Gartner is projecting a drop in PC shipments of more than 10 percent during 2026, and a decline of around 8 percent for smartphones, all due to the AI-driven memory shortage. Some types of memory have doubled or quadrupled in price since last year, and Gartner believes DRAM and NAND flash used in PCs and phones is set for a further 130 percent rise by the end of 2026.\n \nThe upshot of this is that the budget PC will disappear, simply because vendors won't be able to build them at a price that will satisfy cost-conscious buyers, according to Gartner research director Ranjit Atwal. \"Because the price of memory is increasing so much, vendors lose the ability to provide entry-level PCs -- those below about $500,\" he told The Register. PC makers could just raise the price of their cheap and cheerful boxes to above that level to compensate for the memory hike, however, price-sensitive buyers simply won't bite, he added.\n \nAnother factor expected to add to declining fortunes of the PC industry this year is AI devices -- systems equipped with special hardware for accelerating AI tasks, typically via a neural processing unit (NPU) embedded in the CPU. These systems were predicted to take the market by storm, but they require more memory to support AI processing and vendors like to mark them up to a premium price. \"Historically, downgrading specifications was the way to go when prices were being squeezed, but that's difficult here,\" Atwal said. \"The thinking was that the average price [of AI PCs] would fall this year, and lead to more adoption,\" said Atwal, \"but that's not happening.\" The lack of killer applications isn't helping either.",
      "contentLength": 1892,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Building Production-Grade RAG Systems for Document AI: What It Actually Takes",
      "url": "https://hackernoon.com/building-production-grade-rag-systems-for-document-ai-what-it-actually-takes?source=rss",
      "date": 1772196800,
      "author": "Abhinav Sharma",
      "guid": 48904,
      "unread": true,
      "content": "<p>\\\nRAG is everywhere‚Äîand that‚Äôs not surprising. It‚Äôs one of the most practical ways to make large document collections queryable without building brittle, domain-specific parsers for every question type. The catch is that what works in a controlled demo often degrades quickly when you put it in front of real enterprise PDFs: scanned contracts, compliance filings, medical records, policies, and the long tail of layout and quality issues that come with them. In production, the ‚ÄúRAG problem‚Äù is less about clever prompting and more about repeatability: traceability, security, quality controls, and the ability to explain why an answer is correct (or why the system refused).</p><p>When teams get stuck, it‚Äôs rarely because vector search ‚Äúdoesn‚Äôt work.‚Äù It‚Äôs because the system can‚Äôt consistently ground answers to the right evidence, can‚Äôt enforce entitlements reliably, or can‚Äôt be evaluated and improved without breaking things. If you can‚Äôt tell a stakeholder which version of which document supported a claim‚Äîor prove the user was authorized to see it‚Äîyou don‚Äôt have a product yet. You have an experiment.</p><p>Most prototypes follow the same path: drop documents into a vector store, retrieve top-k chunks, and ask an LLM to synthesize. On clean, well-structured text, that can look excellent. The issue is what happens next. Scanned PDFs come in rotated or skewed. Multi-column reading order gets scrambled. Tables lose structure during extraction. Chunking splits mid-argument. Retrieval returns ‚Äúclose enough‚Äù context that reads plausibly but doesn‚Äôt actually support the claim. And the model, doing what it‚Äôs optimized to do, answers fluently anyway.</p><p>In production, you‚Äôre optimizing for different properties than a demo. You want the system to be reliable over messy inputs, reproducible across pipeline changes, and defensible under scrutiny. That means being able to trace an answer back to specific evidence, and having strong defaults when evidence is weak: clarifying questions, refusal behavior, or presenting ‚Äúbest available evidence‚Äù with explicit uncertainty. It also means treating access control as part of retrieval‚Äînot as an afterthought layered onto UI.</p><h2><strong>Ingestion: Where Quality Is Won or Lost</strong></h2><p>If you‚Äôve built a few of these systems, you learn quickly that ingestion determines retrieval quality more than most downstream tricks. Document AI preprocessing isn‚Äôt glamorous, but it is where you either preserve structure‚Äîor lose it permanently. For enterprise documents, OCR alone isn‚Äôt enough; you typically need OCR with layout detection, reading-order reconstruction, and structure extraction that keeps headings, sections, and tables meaningful. Managed tools like Google Document AI, Azure Document Intelligence, and Amazon Textract can cover a lot of ground. Open-source pipelines like Unstructured and GROBID are common when you need transparency or tighter control over parsing decisions.</p><p>Chunking is where teams often underestimate the complexity. A simple character or token split is fast, but it tends to cut across semantic boundaries‚Äîexactly the boundaries users care about in contracts and policies. Adaptive chunking that follows headings, section boundaries, and table boundaries usually improves both retrieval and downstream grounding. It also makes provenance feel natural to the end user: instead of surfacing an opaque internal ID like chunk_4892, you can point to something a reviewer can immediately verify‚Äî‚ÄúMSA v3.2 ‚Üí Section 9 (Termination) ‚Üí 9.2 (Termination for Cause), page 12, lines 14‚Äì22.‚Äù</p><p>Metadata is another area that tends to look optional until you need it. In practice, metadata is what makes filtering, traceability, and reproducibility possible. Useful chunk-level metadata commonly includes document IDs, section paths, page numbers, timestamps (effective date, last modified, ingested at), extraction confidence signals, and version identifiers (document hash, chunking version, embedding model version). In enterprise contexts, access-control attributes (tenant, department, confidentiality, role tags) need to be first-class, because they directly constrain retrieval and audits.</p><h2><strong>The Retrieval Stack That Actually Works</strong></h2><p>Vector similarity search is a good baseline, but it‚Äôs rarely sufficient on its own for enterprise documents. In practice, hybrid retrieval‚Äîdense embeddings plus sparse lexical retrieval like BM25‚Äîtends to be more robust, especially when users query with clause numbers, identifiers, acronyms, or exact phrasing. Dense retrieval handles semantic intent well; sparse retrieval anchors you to exact terms and rare tokens that embeddings often smooth over.</p><p>Reranking is often where systems make the biggest leap in perceived quality, not because it‚Äôs magical, but because it fixes a common failure mode: the initial retrieval set contains ‚Äúkinda relevant‚Äù chunks, and you need to promote the truly relevant ones to the top. Cross-encoder re-rankers (open models like bge-reranker or managed APIs like Cohere ranker) rescore candidate chunks using deeper query‚Äìpassage interaction. Teams usually see a noticeable lift in context precision when reranking is measured properly (for example, on a golden set with expected sources). If you keep a quantitative claim here, it‚Äôs best to tie it to a metric (‚Äúcontext precision‚Äù or ‚Äúcitation precision‚Äù) and an evaluation setup, rather than a broad ‚Äúaccuracy‚Äù number.</p><p>Query rewriting and expansion is another lever that‚Äôs easy to skip early and then rediscover later. Users don‚Äôt naturally phrase questions the way documents are written. A rewrite step can expand acronyms, normalize entities, and split multi-part questions into retrieval-friendly sub-queries. It doesn‚Äôt need to be fancy‚Äîbut it does need observability, because uncontrolled rewriting can drift away from user intent.</p><h2><strong>Security: The Layer Everyone Forgets</strong></h2><p>Most RAG demos ignore access control because it slows down the prototype. In production, it‚Äôs a primary constraint. If your system indexes HR documents, legal contracts, and engineering specs together, you need a deterministic entitlement path from user ‚Üí allowed chunks, and retrieval must be constrained by that path before any content reaches an LLM.</p><p>The pattern that tends to scale is pre-filtered retrieval: compute entitlements (RBAC/ABAC), retrieve only from chunks with compatible ACL attributes, rerank within the authorized candidate set, and log what evidence was accessed. This is also where the ‚Äúmetadata isn‚Äôt optional‚Äù point shows up in practice‚Äîwithout chunk-level tagging, you end up with leaky boundaries or expensive, brittle post-filters.</p><p>Beyond ACL, enterprise deployments typically need some combination of PII detection/masking, encryption at rest, short-lived tokens for source access, and audit logging that captures query, retrieved chunk IDs, citations, and document versions. One more modern concern worth taking seriously is prompt injection content inside documents. You don‚Äôt need to treat every document as hostile, but you do need basic guardrails so instructions embedded in source text can‚Äôt supersede your system‚Äôs rules‚Äîespecially around access control, disclosure, and how the model is allowed to behave.</p><h2><strong>Monitoring: Closing the Loop</strong></h2><p>If you operate one of these systems for more than a few weeks, you‚Äôll see drift. Documents change, the query distribution changes, the ingestion pipeline changes, and model components get updated. Without monitoring and evaluation, quality degrades quietly until users stop trusting the tool.</p><p>Practically, you want to track retrieval health (recall@k against a golden set, context precision, reranker lift), generation health (citation precision, groundedness/faithfulness checks, refusal rates), and operational health (p50/p95 latency, cost per query, ingestion lag from document update to searchable index). The most effective teams I‚Äôve seen maintain a golden evaluation dataset‚Äîcurated questions with expected source documents‚Äîand run it on a schedule and on change events (new embeddings, new chunking logic, new document batches). Tooling like Phoenix, TruLens, or commercial platforms can help, but the bigger differentiator is the discipline to keep evaluation current and to treat regressions like real production incidents.</p><p>One area that‚Äôs frequently underestimated is versioning and reproducibility. When you change OCR models, chunking logic, embedding models, rerankers, or generation prompts, you need a way to trace which versions produced which answers. That‚Äôs what makes debugging and audits feasible months later.</p><p>Stack decisions matter, but capabilities matter more. For many teams, a managed-leaning setup is attractive: ingestion via a managed Document AI tool or Unstructured-based pipeline, a hosted vector database, an orchestration layer such as LlamaIndex or LangChain, and a reranker (open or managed). Others prefer open-source deployments using Qdrant/Weaviate/OpenSearch, Haystack or similar orchestration, and self-hosted models for control and cost predictability. Either approach can work if it supports the fundamentals: document-aware ingestion, hybrid retrieval, entitlement enforcement, provenance-friendly citations, evaluation pipelines, and versioning.</p><p>On the architecture side, systems tend to become easier to operate when they‚Äôre split cleanly: ingestion workers that run asynchronously and can be retried safely; a stateless retrieval service that enforces policies and returns evidence; and a generation service that operates with bounded context and clear provenance. A typical reference deployment includes an API gateway, a job queue (Kafka/RabbitMQ), object storage for raw documents and parsed artifacts, the index layer (dense + sparse), plus centralized logging/metrics and an audit trail.</p>",
      "contentLength": 9869,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "AI-Native Automation in 5G-Advanced and 6G",
      "url": "https://hackernoon.com/ai-native-automation-in-5g-advanced-and-6g?source=rss",
      "date": 1772195975,
      "author": "viharikabhimanapati",
      "guid": 48901,
      "unread": true,
      "content": "<p>With video projected to comprise 82% of Internet traffic by 2027, hosting live events with encouraging quality is more important than ever - each second of delay can decrease engagement by 20%, and users are still abandoning service for a little bit of buffering. With the rollout of 5G-Advanced and 6G on the horizon, users require ultra-low latency with high throughput - no longer a 'nice to have', but a 'must have' and expected especially in 8K, XR, and much of game streaming via cloud. Achieving these quality expectations will not only take extreme speed but responsive networks programmed to exceed smart value added QoE for streaming and entertainment. AI-native automation can scale unique QoE, but we remain trapped in siloed systems with outdated internal business policies and procedures. The real test is not how to import machine learning AI but simply how to do AI right at the edge! Streaming now has become chaotic across fast-moving environments- city towers, edge servers, content aggregators, mobile users, and multi-CDN. So, streaming and the associated QoE can now move in countless ways simultaneously. What ISO, TSRO, and similar static tools allow for post-suffering, as they react too late when the frustration of a stopping point of view has been reached. And data on each user and droves of other users via the flowchart of the transmission path is in constant flux- it is effectively impossible to understand what catastrophe occurred and where with tranches of data scattered across the entirety of the RAN, Core, CDN, and app layer. As the expectation of seamless, flawless, and full 4K streams continues to climb, real-time AI orchestrated service workflows appear to be large and unattainable gaps in service!</p><p>The fix? An AI-native control plane that predicts and resolves problems before users even notice.</p><h2><strong>1Ô∏è. Edge-Centric Predictive QoE Modeling</strong></h2><p>Edge nodes are evolving from small data centers into decision engines in real time.&nbsp; With AI at the edge, we can anticipate and mitigate streaming interruptions by using local indicators such as buffer levels, handovers, and user movement.&nbsp; Federated learning allows these models to continue evolving regionally without having any detrimental effects on privacy.&nbsp; Imagine a streaming app on a train that predicts tower congestion while adjusting bitrate on the fly.&nbsp; The ability to move networks from reactionary to pro-active is transforming the streaming experience, making it smoother, more intelligent, and more personalized for users‚Ä¶ anywhere!</p><h2><strong>2Ô∏è. Closed-Loop Network Slicing with QoE Feedback</strong></h2><p>Network slicing allows multiple virtual networks to share infrastructure, but most still prioritize technical metrics over real user experience. AI-native automation takes this to the next level by taking real-time QoE data and adapting slices in real time. If a human ability user or AR/VR stream drops, it can route traffic away, change bandwidth, or change RAN priorities with no people involved. This creates real-time and dynamic slicing, which keeps streams stable through network changes.</p><h2><strong>3Ô∏è. Cross-Layer Root Cause Analysis with Explainable AI</strong></h2><p>It's never easy to identify the root cause of streaming issues in complex multi-domain networks‚Äîwas it the server, a CDN miss, RAN congestion, or device buffering? Explainable AI (XAI) changes this by correlating data across the transport, application, and radio layers to detect and explain anomalies. XAI doesn't only detect the fault, it explains why it happened, and this helps both operations teams, as well as autonomous systems, to identify root causes and fix problems more intelligently and quicker.</p><h2><strong>4Ô∏è. Intent-Based Streaming Policy Management</strong></h2><p>Operators need to evolve from static, threshold-based rules and toward intent-based policy engines. An example of a business intent might be, ‚ÄúDeliver live sports in ultra-low-latency to premium subscribers in metro areas.‚Äù AI would take such high-level intent and translate it into low-level configurations: managing edge caches, modulating transcoding profiles, prioritizing up-link traffic, prioritizing downlink traffic, etc. If the engine detects a deviation, such as increased rebuffering during the live sports broadcast, it can self-correct by changing policies in real-time.</p><h2><strong>Conclusion: Toward Autonomous Streaming Networks</strong></h2><p>AI-native automation is no longer an option, it‚Äôs vital to creating intelligent, resilient networks that can keep up with how we stream today (and tomorrow). As we transition from 5G-Advanced to 6G, the winners will be the ones that are able to put together edge-based intelligence, intent-based control, plus some explainability. Do it right, and you‚Äôre not just reducing churn - you‚Äôre setting the pace in streaming. Mess it up? At best you can settle for a buffering wheel.</p>",
      "contentLength": 4814,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Mesa Developers Trying To Reach A Consensus On AI Policy",
      "url": "https://www.phoronix.com/news/Mesa-AI-Policy-March",
      "date": 1772191440,
      "author": "Michael Larabel",
      "guid": 48802,
      "unread": true,
      "content": "<article>If all goes well, Mesa developers are hoping to reach a consensus or at least some common ground on an AI policy in March. Mesa is the latest open-source project making considerations around the growing activity around AI coding agents and the like and how to deal with them for this project that is crucial to the Linux desktop and open-source 3D graphics drivers at large...</article>",
      "contentLength": 376,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Numerous AMDXDNA Ryzen AI Driver Fixes For Linux 7.0-rc2",
      "url": "https://www.phoronix.com/news/Linux-7.0-rc2-DRM-Fixes",
      "date": 1772190660,
      "author": "Michael Larabel",
      "guid": 48801,
      "unread": true,
      "content": "<article>Sent out today were all of the DRM/accel driver fixes for the week, ahead of the Linux 7.0-rc2 kernel release due out on Sunday...</article>",
      "contentLength": 130,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Genode OS 26.02 Halfway Done Migrating From GitHub To Codeberg",
      "url": "https://www.phoronix.com/news/Genode-OS-26.02",
      "date": 1772190041,
      "author": "Michael Larabel",
      "guid": 48800,
      "unread": true,
      "content": "<article>Genode OS 26.02 is out as the latest feature update to this open-source operating system framework that also serves as the basis for their Sculpt general purpose OS...</article>",
      "contentLength": 167,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Ultrahuman bets on redesigned smart ring to win back US market after Oura dispute",
      "url": "https://techcrunch.com/2026/02/27/ultrahuman-unveils-new-smart-ring-as-it-awaits-u-s-clearance-after-oura-dispute/",
      "date": 1772190000,
      "author": "Jagmeet Singh",
      "guid": 48774,
      "unread": true,
      "content": "<article>Ultrahuman‚Äôs Ring Pro promises 15-day battery life and a $479 price tag as the wearables maker expands its health-tech push.</article>",
      "contentLength": 126,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Moon's Ancient Magnetic Field May Have Flickered On and Off",
      "url": "https://science.slashdot.org/story/26/02/26/2356249/moons-ancient-magnetic-field-may-have-flickered-on-and-off?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1772186400,
      "author": "BeauHD",
      "guid": 48753,
      "unread": true,
      "content": "sciencehabit quotes a report from Science Magazine: For decades, planetary scientists have pored over a mystery hidden within the Moon rocks retrieved by Apollo astronauts in the 1960s and '70s. Minerals in the rocks record the imprint of a magnetic field, nearly as powerful as Earth's, that existed more than 3.5 billion years ago and seemed to persist for millions of years. But generating a magnetic field requires a dynamo -- a churning, molten core -- and most researchers believed the Moon's tiny core would have long since cooled off, 1 billion years after it formed. Corroborating that picture are other ancient Moon rocks of about the same age that suggest the field was weak -- leaving planetary scientists baffled.\n \nNow, researchers are proposing a new way to solve the puzzle. A paper published today in Nature Geoscience theorizes that between 3.5 billion and 4 billion years ago, blobs of titanium-rich magma melted episodically just above the core, rising in plumes that drove volcanic eruptions on the surface. By intermittently stirring up the Moon's core, these bouts of melting would have caused the Moon's magnetic field to flicker on in short, powerful bursts. The paper \"links a few different concepts that people were thinking about separately, but hadn't actually brought together,\" says Sonia Tikoo, a planetary geophysicist at Stanford University who was not involved in the study.",
      "contentLength": 1409,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Lessons from Building a 100+ Agent Swarm in Web3",
      "url": "https://hackernoon.com/lessons-from-building-a-100-agent-swarm-in-web3?source=rss",
      "date": 1772177569,
      "author": "John P",
      "guid": 48794,
      "unread": true,
      "content": "<h2>Part 1: Why Agentic Engineering Isn't Vibe Coding</h2><p><em>A friend recently posted about AI skills using The Matrix analogy: Trinity doesn't learn to fly a helicopter ‚Äî Tank uploads a precise, verified program directly into her mind. She steps into the cockpit and flies.</em></p><p>That analogy is perfect. But it exposes a fundamental misunderstanding about how these systems actually get built.</p><p>Trinity doesn't vibe her way into flying. Tank uploads a <em>precise, verified program</em>.</p><p>That's the difference between vibe coding and what Addy Osmani calls <a href=\"https://addyosmani.com/blog/agentic-engineering/?utm_source=tldrnewsletter\">Agentic Engineering</a>. \"Vibe coding\" has poisoned the well ‚Äî it suggests you can prompt your way to production software. You can't.</p><p>I have 70+ agents in my web3 development workflow. They're not prompt dumps. They're structured: clear responsibilities, explicit knowledge files, defined handoff points between agents. Building them took the same architectural thinking that's always separated working systems from chaos.</p><p>The old principles translate directly:</p><ul><li> (Don't Repeat Your Prompt)</li><li><strong>Separation of concerns ‚Üí Agent boundaries</strong></li><li><strong>Interface design ‚Üí Handoff contracts</strong></li><li><strong>Documentation ‚Üí Precompiled context</strong></li></ul><p>Building good skills is architecture work. The Trinity scene works because someone  that pilot program. Tank didn't vibe code it.</p><h2>The Problem That Started Everything</h2><p>The biggest thing I learned building AI coding workflows: <strong>more context is not better</strong>.</p><p>I work in web3. I have ABIs that are thousands of lines. A Ponder database schema that would eat half the context window if I fed it in raw. My first instinct was to give the AI everything and let it figure out what matters.</p><p>The AI gets lost. Important instructions get ignored. It latches onto random details. Results get worse as context gets bigger. There's a term for this: . As the context window fills up, earlier instructions get \"crowded out\" and the model starts ignoring them.</p><p>So I built a skills-specialist agent.</p><p>Its only job is precompiling context for other agents. It reads my raw ABIs, schemas, and docs, then generates slim reference files tailored to specific tasks. It builds skills.</p><p>When I need UI work done, I don't hand my ui-designer the entire codebase. The skills-specialist has already built a component reference with just the props and patterns that agent needs. When I need contract integration, the web3-implementer gets only the relevant functions and events. The raw ABI stays on disk.</p><p><strong>Agents building context for agents.</strong></p><h2>The Memory Hierarchy Mental Model</h2><p>The mental model that made everything click: treat context like RAM, not a junk drawer.</p><p>| Layer | What It Holds |\n|----|----|\n| Disk | Full codebase, raw ABIs, complete schemas |\n| RAM | Precompiled skills ‚Äî task-specific reference files |\n| Registers | The current prompt and immediate context |</p><p>You don't load everything into memory. You load what you need for the current task.</p><p>My skills-specialist is the compiler that transforms disk into RAM. Without it, I'm back to stuffing context and hoping for the best.</p><p>Here's the pattern my skills-specialist generates:</p><pre><code># MorphoVault Reference\n\n&gt; Use when implementing vault deposit/withdraw flows.\n\n## Terminology\n- **shares**: Vault shares representing proportional ownership\n- **assets**: The underlying token being deposited\n\n## Key Functions\n\n### deposit(uint256 assets, address receiver) ‚Üí uint256 shares\nDeposits assets and mints shares to receiver.\nSee: protocols/morpho/abis/MetaMorpho.json\n\n### withdraw(uint256 assets, address receiver, address owner) ‚Üí uint256 shares\nBurns shares and sends assets to receiver.\nSee: protocols/morpho/abis/MetaMorpho.json\n\n## Events\n\n### Deposit(address indexed sender, uint256 assets, uint256 shares)\n### Withdraw(address indexed sender, uint256 assets, uint256 shares)\n\n## Related Hooks\n- useVaultDeposit: src/hooks/blockchain/useVaultDeposit.ts\n- useVaultBalance: src/hooks/ponder/useVaultBalance.ts\n</code></pre><p>Short. Scannable. Pointers to source files. Domain terms defined. Clear sections.</p><p>The raw Morpho ABI is 2,000+ lines. This reference is 30 lines and contains everything an agent needs to implement a deposit flow.</p><h2>The Craft Behind the Curtain</h2><p>Skills don't build themselves. My skills-creator is itself a skill ‚Äî one I built through iteration, testing, and architectural thinking.</p><p>Every skill in my system has:</p><ul><li> ‚Äî What does this agent own?</li><li> ‚Äî What precompiled context does it need?</li><li> ‚Äî When does it call other agents?</li><li> ‚Äî How do we know it's done?</li></ul><p>That's not vibing. That's engineering.</p><p>The distribution insight is right ‚Äî skills compress the distance between user and value. But someone still has to build them well. That's the craft.</p><p>Next, I'll cover the organizational breakthrough that made 70+ agents manageable: the distinction between  (personas you converse with) and  (workers you dispatch).</p><p>Turns out only ~10 needed to be conversational. The rest just needed to be discoverable.</p><p>\\\n<em>This is Part 1 of \"Lessons from Building a 100+ Agent Swarm in Web3.\" Follow for Part 2 on agent organization, or connect if you're building similar systems.</em></p>",
      "contentLength": 5000,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "GitScrum MCP Server: How AI Assistants Are Revolutionizing Project Management",
      "url": "https://hackernoon.com/gitscrum-mcp-server-how-ai-assistants-are-revolutionizing-project-management?source=rss",
      "date": 1772177494,
      "author": "Renato Marinho",
      "guid": 48793,
      "unread": true,
      "content": "<p>The way we interact with project management tools is changing. Instead of clicking through endless menus and dashboards, what if you could simply ask your AI assistant to create sprints, track time, or generate team reports? That's exactly what the GitScrum MCP Server enables.</p><p>Built on the Model Context Protocol, this open-source server connects AI assistants like Claude, GitHub Copilot, and Cursor directly to your GitScrum workspace. It's not just another integration‚Äîit's a complete operational layer that gives AI full access to your project management stack.</p><h2>What is the Model Context Protocol?</h2><p>The Model Context Protocol (MCP) is an open standard that allows AI assistants to interact with external systems in a structured, secure way. Think of it as an API specifically designed for AI agents‚Äîinstead of humans clicking buttons, your AI assistant can read, create, and update data through natural conversation.</p><p>GitScrum's implementation brings this to project management, offering 29 tools with over 160 operations across tasks, sprints, time tracking, client CRM, analytics, and more.</p><h2>Zero Context Switching: Managing Projects Through Conversation</h2><p>The most powerful aspect of the GitScrum MCP Server is how it eliminates context switching. Here's what you can do without leaving your AI chat:</p><pre><code>textYou: \"What's on my plate today?\"\nAI: Fetches your tasks due today across all projects.\n\nYou: \"Show me what the team shipped this week\"\nAI: Generates a standup digest with completed work and blockers.\n</code></pre><p><strong>Sprint Planning Made Simple</strong></p><pre><code>textYou: \"Create a sprint for next week with the top 5 backlog items\"\nAI: Creates the sprint, assigns tasks, and sets the timeline.\n</code></pre><p><strong>Real-Time Project Insights</strong></p><pre><code>textYou: \"Which projects are over budget?\"\nAI: Returns burn-down data and flags at-risk projects.\n</code></pre><pre><code>textYou: \"Send the Q1 proposal to Acme Corp\"\nAI: Creates the proposal, attaches the client, and sends it.\n</code></pre><p>The server provides access to every major GitScrum feature:</p><ul><li>: Create, update, complete, filter, duplicate, and manage subtasks</li><li>: Full lifecycle management with KPIs, stats, and progress tracking</li><li>: Access workflows, task types, labels, and team members</li><li>: Start/stop timers, view logs, analyze productivity</li></ul><ul><li>: Complete CRUD operations</li><li>: Create and manage epics across projects</li><li>: Custom workflow management</li><li>: Dynamic tagging and filtering</li></ul><ul><li>: Channels, messages, search, and notifications</li><li>: Knowledge base management</li><li>: Personal note vault with sharing capabilities</li><li>: Thread management on any entity</li></ul><ul><li>: Manage contacts and interactions</li><li>: Create, issue, send, and track payments</li><li>: Full proposal lifecycle with approval workflows</li><li>: 8+ financial and CRM reports</li></ul><ul><li>: Automated team digests</li><li>: Real-time consumption and alerts</li><li>: Team and task-level activity streams</li><li>: 10+ operational reports</li></ul><p>The fastest way to get started is using the hosted SSE server:</p><pre><code>texthttps://mcp.gitscrum.com/sse\n</code></pre><p>Zero installation required. Just add the URL and your GitScrum token to Claude Desktop, Cursor, or any SSE-compatible client. Perfect for teams that want instant setup without managing infrastructure.</p><p>For organizations requiring local deployment:</p><pre><code>bashnpx -y @gitscrum-studio/mcp-server\n</code></pre><p>Runs locally via stdio transport. Requires Node.js 18+. Ideal for VS Code, GitHub Copilot, or offline environments.</p><p>The GitScrum MCP Server was built with the principle of least privilege:</p><ul><li>: Only CREATE, READ, UPDATE operations are allowed. Destructive actions must be performed in the GitScrum web app.</li><li>: Credentials never touch the MCP server. Authentication happens directly with GitScrum's OAuth service.</li><li>: Access tokens are stored locally with restricted filesystem permissions.</li><li>: Automatic lockout after failed authentication attempts.</li></ul><h2>1. Automated Sprint Planning</h2><p>Instead of manually dragging tasks into sprints, describe what you need: \"Create a two-week sprint starting Monday with all high-priority backend tasks from the Q1 milestone.\" Your AI assistant handles the rest.</p><h2>2. Cross-Project Reporting</h2><p>Ask for insights across your entire workspace: \"Show me all overdue tasks across all projects assigned to frontend developers.\" No more jumping between project dashboards.</p><p>Streamline client workflows: \"Generate an invoice for Acme Corp for 40 hours at $150/hour, send it, and add a note that payment is due in 30 days.\"</p><p>Daily standups become conversations: \"What did Sarah complete yesterday? Are there any blockers for the design team?\"</p><p>The server is built in TypeScript and designed for efficiency:</p><ul><li>: Each tool uses a single  parameter, reducing LLM context tokens by ~80% compared to individual tool definitions.</li><li>: Full TypeScript coverage with Zod schemas for validation.</li><li>: 378 tests across 22 suites ensure reliability.</li><li>: Open source and free to use, modify, and extend.</li></ul><ol><li> (if self-hosting):</li></ol><pre><code>   bashnpx -y @gitscrum-studio/mcp-server\n</code></pre><ol start=\"2\"><li><p>: \\n  Add the server configuration to Claude Desktop, VS Code, or Cursor settings.</p></li><li><p>: \\n  Tell your AI assistant: \"Login to GitScrum\"</p><p>The OAuth flow opens in your browser‚Äîno credentials shared with the MCP server.</p></li></ol><pre><code>   text\"What tasks are due this week?\"\n   \"Create a new task in Project Alpha\"\n   \"Show me the team's velocity for Q1\"\n</code></pre><h2>The Future of Project Management</h2><p>The GitScrum MCP Server represents a shift in how we think about project management interfaces. Instead of learning complex UIs, teams can simply describe what they need. AI assistants become project managers, analysts, and productivity coaches‚Äîall through natural conversation.</p><p>This isn't about replacing project managers. It's about giving them superpowers. Let AI handle the routine queries, data aggregation, and administrative tasks, so humans can focus on strategy, creativity, and relationships.</p><p>The GitScrum MCP Server is open source and actively maintained. The team welcomes contributions:</p><p>Whether you're fixing bugs, adding new tools, or improving documentation, there's room for everyone to make this project better.</p><p>The Model Context Protocol is unlocking new possibilities for how we interact with software. GitScrum's implementation shows what's possible when AI assistants have full operational access to project management tools.</p><p>With 29 tools, 160+ operations, and zero context switching, the GitScrum MCP Server is more than an integration‚Äîit's a new way to work. Try it today and experience project management through conversation.</p>",
      "contentLength": 6271,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "How AI-Native Engineering Boosts Your App‚Äôs Scalability",
      "url": "https://hackernoon.com/how-ai-native-engineering-boosts-your-apps-scalability?source=rss",
      "date": 1772177365,
      "author": "Varsha Ojha",
      "guid": 48792,
      "unread": true,
      "content": "<p>Modern applications often struggle to scale, not because of weak infrastructure, but because decision-making intelligence is added only after systems are already under load. Auto-scaling, DevOps pipelines, and cloud elasticity help, but they are&nbsp;largely reactive&nbsp;by design.</p><p>As user demand grows, engineering teams are forced to chase latency spikes, error rates, and infrastructure bottlenecks after they appear, turning scalability into a constant firefight.</p><p>This is where AI-native solutions fundamentally change how scalability is engineered. By embedding intelligence directly into system architecture and the software development lifecycle, AI-native systems&nbsp;anticipate&nbsp;growth instead of reacting to it. Decisions around capacity, performance, and resource usage become predictive rather than manual.</p><p>Enterprises adopting <a href=\"https://quokkalabs.com/ai-native-development-services\">AI native software engineering</a> approaches, often in partnership with specialized AI native engineering service companies, are redefining how scalable systems are built. This blog explains how AI-native engineering turns scalability from an operational burden into a built-in system capability, across infrastructure, performance, and development velocity.</p><h2><strong>How AI-Native Engineering Improves App Scalability</strong></h2><p>AI-native engineering improves app scalability by changing how systems detect,&nbsp;anticipate, and respond to growth. Instead of reacting after performance degrades, intelligence is embedded across infrastructure, performance management, and&nbsp;development&nbsp;workflows.</p><p>This allows applications to scale smoothly, predictably, and cost-efficiently as demand increases, without constant manual intervention.</p><h3><strong>1. Automated Infrastructure Management Removes Scaling Bottlenecks</strong></h3><p>As apps grow, manual infrastructure tuning becomes unsustainable. Human-defined rules and static configurations fail when traffic patterns shift rapidly or unpredictably.</p><p>AI-native engineering changes infrastructure behavior by enabling systems to manage themselves. Intelligent models continuously analyze resource usage across containers, microservices, and environments, adjusting CPU, memory, and storage allocation in real time. This prevents both over-provisioning, which wastes cost, and under-provisioning, which causes performance degradation.</p><p>The scalability impact is immediate and long-term. Applications&nbsp;maintain&nbsp;stable performance during sudden traffic spikes, while operational overhead decreases as infrastructure decisions no longer depend on constant human intervention.</p><p>&nbsp;Scalability improves when infrastructure decisions are automated and data-driven, not manually enforced.</p><h3><strong>2. Predictive Scaling and Intelligent Load Balancing</strong></h3><p>Reactive auto-scaling works only after systems start to struggle. By the time thresholds are crossed, users are already experiencing slowdowns, errors, or timeouts. This gap becomes more visible as apps scale and traffic patterns grow more complex.</p><p>AI-native engineering introduces predictive scaling by learning from historical traffic, seasonal usage, feature launches, and real-time behavior. Instead of waiting for load to spike, the system&nbsp;anticipates&nbsp;demand and&nbsp;allocates&nbsp;resources in advance. This proactive approach keeps performance stable even during sudden surges.</p><p>Intelligent load balancing further strengthens scalability by routing traffic based on service health, latency, and capacity rather than static rules. Unhealthy instances are avoided automatically, reducing the risk of cascading failures during peak usage.</p><p>&nbsp;Predictive scaling keeps apps fast before growth becomes visible, not after problems appear.</p><p>As applications grow, performance tuning becomes harder to manage manually. More services, APIs, databases, and integrations mean more places where latency can&nbsp;creep in&nbsp;quietly. Traditional approaches rely on engineers reacting to alerts after users start complaining.</p><p>AI-native engineering changes this by making performance optimization continuous rather than episodic. AI systems&nbsp;monitor&nbsp;API response times, database queries, cache efficiency, and network latency in real time. Patterns that&nbsp;indicate&nbsp;emerging bottlenecks are detected early, often before they&nbsp;impact&nbsp;users.</p><p>Instead of one-time fixes, AI-driven optimization adapts continuously. Slow queries are flagged, inefficient execution paths are&nbsp;identified, and resource allocation is adjusted automatically as usage evolves. Over time, the system learns which optimizations deliver the most impact under different conditions.</p><p>&nbsp;AI-native systems&nbsp;don‚Äôt&nbsp;just scale under load, but learn how to perform better as scale increases.</p><h3><strong>4. Faster Development Cycles Enable Scalability Through Speed</strong></h3><p>Scalability is not only about infrastructure capacity. It is also about how quickly teams can adapt systems as demand grows. Slow development cycles turn scalability into a bottleneck because architecture, performance fixes, and optimizations&nbsp;lag behind&nbsp;user growth.</p><p>AI-native engineering accelerates development by embedding intelligence into the software delivery process itself. AI-assisted testing, debugging, and code generation reduce the time&nbsp;required&nbsp;to&nbsp;validate&nbsp;changes under real-world load. Issues that would traditionally surface late in production are&nbsp;identified&nbsp;earlier in development.</p><p>This speed allows teams to evolve backend services, APIs, and infrastructure incrementally without destabilizing the system. New features can be released confidently while performance safeguards&nbsp;remain&nbsp;intact. As demand changes, the architecture can adapt in parallel rather than playing catch-up.</p><p>&nbsp;Applications scale more reliably when engineering velocity scales alongside user demand, not after it.</p><h3><strong>5. Intelligent Resource Allocation Controls Cost at Scale</strong></h3><p>Scalability often breaks down not because systems cannot handle growth, but because costs spiral faster than usage or revenue. Traditional scaling approaches add capacity reactively, leading to over-provisioned infrastructure during low demand and performance risks during spikes.</p><p>AI-native engineering introduces intelligence into resource allocation. Instead of treating&nbsp;compute, memory, and storage as static pools, AI systems continuously analyze workload patterns and adjust resource usage at a granular level. This ensures that each service receives exactly what it&nbsp;needs,&nbsp;when it&nbsp;needs it.</p><p>By&nbsp;eliminating&nbsp;waste across environments, AI-native systems keep infrastructure lean even as traffic grows. This creates predictable cost behavior while&nbsp;maintaining&nbsp;performance under load. Scaling becomes a controlled, measurable process rather than an expensive guess.</p><p>&nbsp;Sustainable scalability depends on intelligent resource allocation, not simply adding more capacity.</p><h2><strong>Core Pillars of AI-Native Scalability</strong></h2><p>AI-native scalability is not driven by isolated tools or one-off optimizations. It is the result of a few foundational principles that shape how systems grow, adapt, and remain stable over time. When these pillars are designed into the architecture, scalability becomes predictable instead of reactive.</p><h3><strong>1. Intent-Driven Engineering</strong></h3><p>In AI-native systems, scaling decisions are tied directly to business intent. Instead of scaling based on raw infrastructure thresholds, systems understand why growth is happening and respond accordingly.</p><p>This alignment ensures that technical expansion always supports real user demand and business outcomes, not just traffic volume.</p><h3><strong>2. Continuous Learning Systems</strong></h3><p>Every interaction becomes feedback. AI-native platforms learn from usage patterns, performance signals, and failures, refining how they scale over time.</p><p>This allows systems to adapt naturally as products, users, and behaviors evolve.</p><h3><strong>3. Proactive Monitoring and Anomaly Detection</strong></h3><p>Rather than waiting for alerts after failures&nbsp;occur, AI-native monitoring&nbsp;identifies&nbsp;risks early. Anomalies are detected before they cascade, protecting performance as scale increases.</p><p>&nbsp;Scalability improves when systems understand intent, learn continuously, and&nbsp;anticipate&nbsp;risk, not when teams react after problems appear.</p><p>App scalability breaks down when growth is handled reactively rather than engineered proactively. AI-native engineering changes this by embedding intelligence into how systems are built, deployed, and evolved.</p><p>Instead of relying on static rules and manual interventions, AI-native solutions automate infrastructure decisions, predict demand,&nbsp;optimize&nbsp;performance continuously, and control cost as scale increases.</p><p>The result is not just the ability to handle more users, but the ability to grow intelligently without destabilizing performance or operations. Scalability becomes a built-in system behavior rather than an operational burden that teams constantly manage.</p><p>Scalable apps are not tuned after&nbsp;growth, but&nbsp;are engineered to scale from the start through intelligence, automation, and learning. Partner with <a href=\"https://quokkalabs.com/\">Quokka Labs</a> to design and deliver AI native software engineering services that help applications scale predictably, control cost, and&nbsp;maintain&nbsp;performance as demand grows. Start with an AI-native scalability assessment tailored to your product.</p>",
      "contentLength": 9066,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "I Built a Local AI Firewall and made it Open Source Because Nobody Else Was Going To !",
      "url": "https://hackernoon.com/i-built-a-local-ai-firewall-and-made-it-open-source-because-nobody-else-was-going-to?source=rss",
      "date": 1772177095,
      "author": "Raviteja Nekkalapu",
      "guid": 48791,
      "unread": true,
      "content": "<article>Most AI apps send raw user input straight to OpenAI with zero filtering. I got tired of seeing it and built Sentinel Protocol, an open source local proxy with 81 security engines that scans every LLM request and response. It blocks PII, catches prompt injections, detects hallucinated URLs in model output, and handles MCP poisoning for AI agents. One command to start. Change one line in your SDK. 52,069 lines of code, 9 dependencies, MIT license. No cloud, no telemetry, everything runs on your machine.</article>",
      "contentLength": 506,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Plaid valued at $8B in employee share sale",
      "url": "https://techcrunch.com/2026/02/26/plaid-valued-at-8b-in-employee-share-sale/",
      "date": 1772176745,
      "author": "Marina Temkin",
      "guid": 48737,
      "unread": true,
      "content": "<article>The new valuation is a 31% increase from $6.1 billion Plaid reached in April.</article>",
      "contentLength": 77,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "The Complete Guide to AI Agent Memory Files (CLAUDE.md, AGENTS.md, and Beyond)",
      "url": "https://hackernoon.com/the-complete-guide-to-ai-agent-memory-files-claudemd-agentsmd-and-beyond?source=rss",
      "date": 1772176589,
      "author": "Paolo Perrone",
      "guid": 48790,
      "unread": true,
      "content": "<article>Learn how CLAUDE.md, AGENTS.md, and AI memory files work. Covers file hierarchy, auto-memory, @imports, and which files you actually need for your setup.</article>",
      "contentLength": 153,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Why Some Companies Keep Changing ‚Äî But Never Find Stability",
      "url": "https://hackernoon.com/why-some-companies-keep-changing-but-never-find-stability?source=rss",
      "date": 1772176404,
      "author": "Nicolas Picks",
      "guid": 48789,
      "unread": true,
      "content": "<article>Strategies shift frequently. Teams reorganize. Priorities are updated again before the previous ones have fully settled.</article>",
      "contentLength": 120,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "The PS5 Controller Hack That Exposed Seven Thousand Living Rooms",
      "url": "https://hackernoon.com/the-ps5-controller-hack-that-exposed-seven-thousand-living-rooms?source=rss",
      "date": 1772176296,
      "author": "Omotayo",
      "guid": 48788,
      "unread": true,
      "content": "<article>A simple project to use a PS5 controller on a robot vacuum accidentally exposed 7,000 homes. </article>",
      "contentLength": 93,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "The TechBeat: AI Builder Stack: Linear, Cursor, Vercel & QA.tech (2/27/2026)",
      "url": "https://hackernoon.com/2-27-2026-techbeat?source=rss",
      "date": 1772176269,
      "author": "Techbeat",
      "guid": 48787,
      "unread": true,
      "content": "<p>By <a href=\"https://hackernoon.com/u/lomitpatel\">@lomitpatel</a> [ 5 Min read ] \n How CMOs win CFO buy-in using incrementality, trust, AI, and capital allocation to drive margin expansion and revenue durability. <a href=\"https://hackernoon.com/how-cmos-win-cfo-buy-in-at-scale\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/melissaindia\">@melissaindia</a> [ 4 Min read ] \n Learn 6 proven strategies to secure executive buy-in for Master Data Management by aligning MDM with ROI, risk reduction, and business goals. <a href=\"https://hackernoon.com/selling-master-data-management-to-leadership-6-proven-strategies\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/opensourcetheworld\">@opensourcetheworld</a> [ 7 Min read ] \n I replaced $1,200/year in cloud subscriptions with one home server. Here's the setup, costs, apps, Bitcoin node, local AI, and what I'd do differently.  <a href=\"https://hackernoon.com/i-replaced-$1200year-in-cloud-subscriptions-with-a-single-home-server-heres-what-i-learned\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/confluent\">@confluent</a> [ 5 Min read ] \n Learn how Python developers build real-time AI agents using MCP, Kafka, and Flink‚Äîmodern agentic workflows explained on HackerNoon. <a href=\"https://hackernoon.com/how-python-devs-can-build-ai-agents-using-mcp-kafka-and-flink\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/saumyatyagi\">@saumyatyagi</a> [ 15 Min read ] \n Most teams plateau at \"AI writes code, a human reviews it.\" This article presents the Dark Factory Pattern ‚Äî a four-phase architecture using holdout scenarios a <a href=\"https://hackernoon.com/the-dark-factory-pattern-moving-from-ai-assisted-to-fully-autonomous-coding\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/scylladb\">@scylladb</a> [ 4 Min read ] \n Discover how Yieldmo migrated from DynamoDB to ScyllaDB to cut database costs, achieve multicloud flexibility, and deliver ads in single-digit millisecond laten <a href=\"https://hackernoon.com/how-yieldmo-cut-database-costs-and-cloud-dependencies\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/khamisihamisi\">@khamisihamisi</a> [ 4 Min read ] \n Western tech is built in environments of abundance. In emerging markets, these assumptions often fail quickly. <a href=\"https://hackernoon.com/building-for-emerging-markets-what-western-startups-miss\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/crafinsstudio\">@crafinsstudio</a> [ 20 Min read ] \n I tested eight piano apps on two pianos for three weeks. Here's what I'd actually recommend. <a href=\"https://hackernoon.com/best-piano-learning-apps-in-2026-an-in-depth-comparison-of-music-education-technology\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/scylladb\">@scylladb</a> [ 5 Min read ] \n Blitz migrated from Postgres and Elixir to Rust and ScyllaDB, cutting latency, costs, and 100+ cores down to four cloud nodes. <a href=\"https://hackernoon.com/rust-rewrite-postgres-exit-blitz-revamps-its-league-of-legends-backend\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/chris127\">@chris127</a> [ 8 Min read ] \n Stablecoins aren't just \"crypto dollars\"‚Äîthey're experiments in digital money stability. Each type offers different trade-offs, learn more about them here <a href=\"https://hackernoon.com/a-comprehensive-guide-to-stablecoins-types-risks-and-the-future-of-digital-money\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/thomascherickal\">@thomascherickal</a> [ 51 Min read ] \n Google Antigravity is not just for coding. It is for your entire computer. Stop scrolling - everything you do on a computer has just been automated. <a href=\"https://hackernoon.com/google-antigravity-the-disruptor-that-just-changed-the-computing-world-forever\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/mexcmedia\">@mexcmedia</a> [ 2 Min read ] \n MEXC ranks No. 1 globally in XAUT perpetual volume, hitting $3.43B as tokenized gold demand rises amid record spot gold prices in 2026. <a href=\"https://hackernoon.com/mexc-ranks-no-1-in-xaut-perpetual-volume-globally-demonstrating-strong-liquidity-and-user-activity\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/qatech\">@qatech</a> [ 8 Min read ] \n Manual testing can't keep up with modern development. See how QA.tech's AI testing automation catches bugs on every PR -- no Playwright or Cypress scripts to ma <a href=\"https://hackernoon.com/the-ai-builder-stack-linear-cursor-vercel-and-qatech\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/davidiyanu\">@davidiyanu</a> [ 8 Min read ] \n Cloud cost and system reliability are the same problem viewed through different instruments.  <a href=\"https://hackernoon.com/when-cloud-bills-crash-the-system-cost-as-a-reliability-issue\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/vinitabansal\">@vinitabansal</a> [ 13 Min read ] \n  The more you adopt self-sabotage behaviors to deal with your feelings of self-doubt, the stronger those connections get. <a href=\"https://hackernoon.com/a-guide-on-how-to-rewire-self-doubt\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/playerzero\">@playerzero</a> [ 11 Min read ] \n How 2025 transformed AI from a developer tool into engineering infrastructure‚Äîand why operating it safely is now the real challenge. <a href=\"https://hackernoon.com/2025-ai-news-wrapped-how-ai-went-mainstream-in-engineering\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/mexcmedia\">@mexcmedia</a> [ 2 Min read ] \n MEXC‚Äôs February report shows 267% BTC coverage, rising ETH reserves, and monthly audited Proof of Reserves verified with Merkle Tree tech. <a href=\"https://hackernoon.com/mexc-releases-february-proof-of-reserve-report-btc-coverage-rises-to-267percent\">Read More.</a></p><p>By <a href=\"https://hackernoon.com/u/scylladb\">@scylladb</a> [ 6 Min read ] \n ZEE5 cut database costs 5X and achieved single-digit millisecond latency by migrating to ScyllaDB, redesigning APIs, and optimizing data models. <a href=\"https://hackernoon.com/tracking-millions-of-heartbeats-on-zees-streaming-platform\">Read More.</a></p>",
      "contentLength": 3224,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Anthropic, the Pentagon, and the Illusion of Conflict",
      "url": "https://hackernoon.com/anthropic-the-pentagon-and-the-illusion-of-conflict?source=rss",
      "date": 1772176253,
      "author": "Alexander Borschel",
      "guid": 48786,
      "unread": true,
      "content": "<article>Public tension between Anthropic and the Pentagon may be strategic signaling, not separation. Ethical positioning protects reputation, while defense integration continues through controlled deployments and negotiation. Public perception, procurement leverage, and backchannel talks all shape how AI becomes embedded in national security infrastructure. Anthropic‚Äôs public ethical stance and Pentagon pressure likely reflect negotiation leverage, not disengagement. AI integration continues behind controlled federal deployments.</article>",
      "contentLength": 530,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "NASA Reveals Identity of Astronaut Who Suffered Medical Incident Aboard ISS",
      "url": "https://science.slashdot.org/story/26/02/27/002252/nasa-reveals-identity-of-astronaut-who-suffered-medical-incident-aboard-iss?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1772175600,
      "author": "BeauHD",
      "guid": 48736,
      "unread": true,
      "content": "Longtime Slashdot reader ArchieBunker shares a report from NBC News: NASA revealed that astronaut Mike Fincke was the crew member who suffered a medical incident at the International Space Station in January, which prompted the agency to carry out the first evacuation due to a medical issue in the space station's 25-year history. The rare decision to cut a mission short and bring Fincke and three other crew members home early made for a dramatic week in space early this year.\n \nIn a statement released by NASA \"at the request of Fincke,\" the veteran astronaut said he experienced a medical event on Jan. 7 \"that required immediate attention\" from his space station crew members. \"Thanks to their quick response and the guidance of our NASA flight surgeons, my status quickly stabilized,\" Fincke, 58, said in the statement. [...] In his statement, Fincke thanked his Crew-11 colleagues, along with NASA astronaut Chris Williams and Russian cosmonauts Sergey Kud-Sverchkov and Sergei Mikaev, who were also aboard the space station at the time and are still in space. Fincke also thanked the teams at NASA, SpaceX and the medical professionals at Scripps Memorial Hospital La Jolla. \"Their professionalism and dedication ensured a positive outcome,\" he said.\n \nFincke ended his statement by saying he is \"doing very well\" and still actively involved with standard post-flight reconditioning at NASA's Johnson Space Center in Houston. \"Spaceflight is an incredible privilege, and sometimes it reminds us just how human we are,\" he said. \"Thank you for all your support.\"",
      "contentLength": 1571,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "The ‚ÄúPerfect First Draft‚Äù Trap Is Killing Your Output",
      "url": "https://hackernoon.com/the-perfect-first-draft-trap-is-killing-your-output?source=rss",
      "date": 1772172651,
      "author": "BenoitMalige",
      "guid": 48785,
      "unread": true,
      "content": "<blockquote><p>The more a thing tends to be permanent, the more it tends to be lifeless.</p></blockquote><p>\\\nHey, listen. You‚Äôre not lazy. Let‚Äôs get that out of the way right now.</p><p>\\\nLazy people don‚Äôt lie awake at night, hearts pounding, staring at the ceiling while mentally screaming at themselves for not sending that email, not starting that proposal, not having that hard conversation.</p><p>\\\nThis is the special, advanced-class procrastination reserved for people who are highly competent. It‚Äôs the one that feels like a personal betrayal. You built a career on being reliable, on delivering, on being the person who gets shit done. And now you‚Äôre frozen by a single, seemingly simple task.</p><p>\\\nA few weeks ago, I wanted to record a video. Simple task. Right?</p><p>\\\nNo. I procrastinated for two weeks.</p><p>\\\nThis was a feeling i‚Äôve felt a thousand times. This time, I wanted to get to the bottom of it.</p><p>Because it makes no sense. If you‚Äôre anything like me, you do what you‚Äôve always done: you try to out-logic it.</p><p>\\\nYou break it down into smaller steps. You buy a new planner. You try the Pomodoro technique. And when that fails, you deploy the big gun: self-flagellation, aka&nbsp;.</p><p>\\\n<em>‚ÄúWhat is wrong with you? You‚Äôre better than this. Just fucking DO IT.‚Äù</em></p><p>\\\nAnd it doesn‚Äôt work. It just makes you feel worse, which makes the task feel even more monumental. It‚Äôs a shitty, vicious cycle, and the only thing it efficiently produces is shame.</p><p>\\\nI used to think this was a moral failing. Some sort of crack in my discipline.</p><p>Well‚Ä¶ bad news for me, good news for you: I was looking at it all wrong.</p><p>Procrastination isn‚Äôt the problem. It‚Äôs the alarm system.</p><h2><strong>The Real Reason You‚Äôre Paralyzed (It‚Äôs Not What You Think)</strong></h2><p>For years, I thought procrastination was about the&nbsp;. It‚Äôs not. It‚Äôs about the&nbsp;&nbsp;you associate with the task.</p><p>Let that sink in for a sec. You‚Äôre not avoiding the spreadsheet. You‚Äôre avoiding recording the video, or the anxiety of interpreting the numbers wrong. You‚Äôre not avoiding the difficult conversation with your employee or your partner.</p><p>\\\nYou‚Äôre avoiding the gut-wrenching discomfort of potential conflict, or the guilt of having to be the \"bad guy\", the feeling of being seen as someone who made a shitty piece of content. You‚Äôre afraid of being rejected, not loved, not worthy.</p><p>Your brain, in its primitive wisdom, is doing a simple cost-benefit analysis: \"Engage in this thing that will make me feel like crap, or‚Ä¶ literally do anything else.\" It‚Äôs a rational choice üôÇ</p><p>\\\nThe problem is, the \"anything else\" comes with a side order of self-criticism.</p><p>\\\nSo the first question to ask isn‚Äôt \"How do I force myself to do this?\" \\n It‚Äôs:<strong>\"What specific feeling am I trying to avoid, and why does it scare me so much?\"</strong></p><p>Is it the fear of being judged? Of looking stupid? Of the exhausting mental effort required? Of the confrontation? Name the ghost. It loses power when you shine a light on it. Then, sit with it. Don‚Äôt try to fix anything. Just be with the feeling. Welcome it like it‚Äôs your own, because it is.</p><p>\\\nIf you want help seeing exactly what‚Äôs behind your resistance, take this&nbsp;; it shows you how far you‚Äôve drifted from alignment.</p><h2><strong>The \"Perfect First Draft\" Trap That's Killing Your Momentum</strong></h2><p>When I started this newsletter, I used to sit down to write something, and I‚Äôd expect the final, polished, brilliant version to just flow out of my fingertips on the first try. I had a reputation to uphold, after all.</p><p>\\\nThe result? I‚Äôd stare at a blank screen for an hour. I‚Äôd check my email, i‚Äôd open instagram to check on my 342 followers. I‚Äôd get a glass of water. I‚Äôd do anything&nbsp;&nbsp;write. The gap between my vision of \"perfect\" and the reality of my first, shitty sentence was too vast to cross.</p><p>\\\nThe breakthrough only came when I gave myself permission to write a \"vomit draft.\" No one would ever see it. It could be clumsy, poorly worded, and make no sense at all. The only goal was to get the ideas&nbsp;<em>out of my head and onto the screen</em>.</p><p>Suddenly, writing wasn't a performance. It was an excavation. I could take that messy, ugly lump of clay and start shaping it. The first pass was for me. The second, third, and tenth passes were for everyone else.</p><p>\\\nThis is the iterative mindset. It‚Äôs not about getting it right. It‚Äôs about getting it&nbsp;. You can‚Äôt steer a parked car. You can‚Äôt edit a blank page. Your job isn't to be a genius on the first try. Your job is to be a stubborn, relentless editor of your own work.</p><p>Iterate, Iterate, Iterate.</p><p>Stop trying to build the perfect finished product. Just lay the first brick. It‚Äôs designed to be bad. Your job is fix it later.</p><h2><strong>When Procrastination is Actually Your Wisest Self Screaming to Be Heard</strong></h2><p>Sometimes, the voice in your head saying \"you&nbsp;&nbsp;do this\" isn't your intuition. It's the ghost of your old boss, your dad, some article you read, or society's boring-ass checklist for a successful life.</p><p>\\\nYour procrastination, in these cases, is your soul's last-ditch effort to stage a protest.</p><p>In plain, simple terms.. sometimes, it‚Äôs just not aligned with who you are or what you actually want.</p><p>Have you ever had projects that you&nbsp;&nbsp;were smart, lucrative opportunities? And you just‚Ä¶ couldn't‚Ä¶ start. You beat yourself up for weeks. Is this happening right now? Ask yourself this question:</p><p>\"If I wasn't&nbsp;&nbsp;to be hard on myself, would I still be trying to do this?\"</p><p>\\\nThe answer will probably be a resounding&nbsp;. The project is a \"should\" born out of obligation, not passion.</p><p>\\\nThe next time you're stuck, try this. And ask: \"Is this&nbsp;&nbsp;priority? Or is this someone else's agenda I've internalized? Is there a different, better, more&nbsp;&nbsp;way to achieve the underlying goal?\"</p><p>\\\nThe resistance might not be something to break through. It might be something to listen to.</p><h2><strong>The Bottom Line You Probably Won't Like</strong></h2><p>Beating procrastination isn't about finding a new, more sophisticated way to bully yourself. It‚Äôs the exact opposite. It‚Äôs about getting curious. It‚Äôs about treating the resistance not as an enemy, but as a data point.</p><p>\\\nYour brain (as usual) is trying to protect you from something. Your job is to figure out what, and then to gently, cleverly, redesign the process so it doesn't feel so threatening.</p><p>\\\nStop trying to win a war with yourself. You‚Äôll always lose. Start a conversation instead.</p><h2><strong>Your Actions for the Week (The Procrastination Prescription)</strong></h2><p>You read the words. Now, here are the actions. Pick one and do it&nbsp;.</p><p>\\\n1. The \"Vomit Draft\" Ship. </p><p>Stop waiting for perfect. Pick one thing you're overthinking (an email, a project outline, a social post, a video script). Your mission is to create the&nbsp;<strong>most embarrassing, shitty first version possible</strong>&nbsp;and send it to one person or post it somewhere&nbsp;. The goal is to intentionally lower the bar so you can jump over it.&nbsp;<strong>Perfection is the enemy of done.</strong></p><p>2. The \"Priority\" Interrogation. </p><p>Take 5 minutes. Write down the #1 thing you're procrastinating on. Now, ask yourself this one question:&nbsp;<strong>\"If I was forbidden from being hard on myself, would I still be trying to do this?\"</strong>&nbsp;Listen to the gut answer. If it's \"Fuck no,\" you have your answer. It's not a priority; it's a prison. Cross it off or radically change the approach. If it's \"Hell yes,\" then you know it's just fear, and you've already taken its power away by naming it.</p><p>3. The \"Visibility\" Audit. </p><p>You're hiding. We all are. Where are you playing small by choice? Make a list of 3 areas in your work or life where you're being&nbsp;&nbsp;to avoid judgment or rejection. Is it not posting your ideas? Not speaking up in meetings? Not pitching that client? Pick ONE and break the pattern this week.&nbsp;<strong>Send one email you're scared to send. Say the thing in the meeting.&nbsp;&nbsp;with worse ideas are already winning. Your value is useless if you hide it.</strong></p><p>&nbsp;Action ‚Üí Feedback ‚Üí Iteration ‚Üí Identity. That's the entire game.</p>",
      "contentLength": 7814,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Victory! Tenth Circuit Finds Fourth Amendment Doesn‚Äôt Support Broad Search of Protesters‚Äô Devices and Digital Data",
      "url": "https://www.eff.org/deeplinks/2026/02/victory-tenth-circuit-finds-fourth-amendment-doesnt-support-broad-search-0",
      "date": 1772172182,
      "author": "Saira Hussain",
      "guid": 48735,
      "unread": true,
      "content": "<p>In a big win for protesters‚Äô rights, the U.S. Court of Appeals for the Tenth Circuit <a href=\"https://www.ca10.uscourts.gov/sites/ca10/files/opinions/010111390292.pdf\">overturned</a> a lower court‚Äôs dismissal of a challenge to sweeping warrants to search a protester‚Äôs devices and digital data and a nonprofit‚Äôs social media data.</p><p>The case, <a href=\"https://www.aclu-co.org/cases/armendariz-and-chinook-center-v-city-colorado-springs-et-al/\"><em>Armendariz v. City of Colorado Springs</em></a>, arose after a housing protest in 2021, during which Colorado Springs police arrested protesters for obstructing a roadway. After the demonstration, police also obtained warrants to seize and search through the devices and data of Jacqueline Armendariz Unzueta, who they claimed threw a bike at them during the protest. The warrants included a search through all of her photos, videos, emails, text messages, and location data over a two-month period, as well as a time-unlimited search for 26 keywords, including words as broad as ‚Äúbike,‚Äù ‚Äúassault,‚Äù ‚Äúcelebration,‚Äù and ‚Äúright,‚Äù that allowed police to comb through years of Armendariz‚Äôs private and sensitive data‚Äîall supposedly to look for evidence related to the alleged simple assault. Police further obtained a warrant to search the Facebook page of the Chinook Center, the organization that spearheaded the protest, despite the Chinook Center never having been accused of a crime.</p><p>The district court dismissed the <a href=\"https://www.aclu-co.org/cases/armendariz-and-chinook-center-v-city-colorado-springs-et-al/?document=First-Amended-Complaint\">civil rights lawsuit</a> brought by Armendariz and the Chinook Center, holding that the searches were justified and that, in any case, the officers were entitled to <a href=\"https://www.eff.org/deeplinks/2021/04/why-eff-supports-repeal-qualified-immunity\">qualified immunity</a>. The plaintiffs, represented by the ACLU of Colorado, appealed. EFF‚Äîjoined by the Center for Democracy and Technology, the Electronic Privacy Information Center, and the Knight First Amendment Institute at Columbia University‚Äîwrote an <a href=\"https://www.eff.org/deeplinks/2024/09/eff-tenth-circuit-protest-related-arrests-do-not-justify-dragnet-device-and?language=en\">amicus brief</a> in support of that appeal.</p><p>In a 2-1 opinion, the Tenth Circuit reversed the district court‚Äôs dismissal of the lawsuit‚Äôs Fourth Amendment search and seizure claims. The court painstakingly picked apart each of the three warrants and found them to be overbroad and lacking in particularity as to the scope and duration of the searches. The court further held that in furnishing such facially deficient warrants, the officers violated ‚Äúclearly established‚Äù law and thus were not entitled to qualified immunity. Although the court did not explicitly address the First Amendment concerns raised by the lawsuit, it did note the backdrop against how these searches were carried out, including animus by Colorado Springs police leading up to the housing protest.</p><p>It is rare for appellate courts to call into question any search warrants. It‚Äôs even rarer for them to deny qualified immunity defenses. The Tenth Circuit‚Äôs decision should be celebrated as a big win for protesters and anyone concerned about police immunity for violating people‚Äôs constitutional rights. The case is now remanded back to the district court to proceed‚Äîand hopefully further vindicate the privacy rights we all have in our devices and digital data.</p>",
      "contentLength": 2951,
      "flags": null,
      "enclosureUrl": "https://www.eff.org/files/banner_library/protest-2024-2.jpg",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "2 Months Into 2026 We Are Over Half 2025‚Äôs Total Count Of Measles Cases",
      "url": "https://www.techdirt.com/2026/02/26/2-months-into-2026-we-are-over-half-2025s-total-count-of-measles-cases/",
      "date": 1772164944,
      "author": "Timothy Geigner",
      "guid": 48728,
      "unread": true,
      "content": "<p><a href=\"https://www.techdirt.com/tag/measles/\">Measles</a>. Yes, yes, I know you‚Äôre sick of hearing about it. For that, though, you must lay the blame at the feet of Donald Trump, RFK Jr., and this entire administration of clown-tools that isn‚Äôt bothering to do anything about what has become the worst continuous outbreak of the disease in America in several decades. Their fault, not mine. </p><p>And, yes, this is getting worse, not better. The <a href=\"https://www.cdc.gov/measles/data-research/index.html\">CDC‚Äôs measles tracking site</a> is a combination of woefully inaccurate and behind when it comes to current case counts (more to come on that shortly), but it‚Äôs at least useful in benchmarking what 2025 looked like. While certainly underreported, the CDC tallied 2,281 cases of measles in America last year. That site is updated only once a week on Fridays. Either due to that, or incompetence, or a more nefarious attempt to downplay the problem, the current case count is wrong.</p><p>The CDC site shows a 2026 case count of 982. That would be bad enough, but it‚Äôs actually worse. The <a href=\"https://www.medpagetoday.com/pediatrics/generalpediatrics/120027\">actual count is well over 1,000 cases</a>, which means we‚Äôre somewhere right around half of 2026‚Äôs case total as of right now. So you don‚Äôt feel the need to check a calendar, it‚Äôs still February.</p><blockquote><p><em>‚ÄúIt is very concerning to see more than 1,000 cases in the U.S. this early in the year,‚Äù Martha Edwards, MD, president of the South Carolina Chapter of the American Academy of Pediatrics, told&nbsp;MedPage Today. ‚ÄúAlready, we have more than half the number of cases seen in all of 2025, and the number of cases in 2025 was one of the highest annual case counts seen in decades.‚Äù</em></p><p><em>‚ÄúAs people continue to believe inaccurate information about vaccines, and as non-medical exemption rates continue to rise throughout the country, we can expect case counts to continue to rise, threatening children and immunocompromised individuals with a disease that was nearly eliminated in our country through vaccination,‚Äù she added.</em></p></blockquote><p>The true number is going to be even higher than that. There are outbreaks of one size or another in many, many states. South Carolina alone has nearly 1,000 reported cases. The truly frustrating thing about all of this is that this problem is a simple one to fix. More people need to get vaccinated for measles via the widely available MMR vaccine. </p><p>To achieve that, the government needs to do two simple things. First, cut the shit when it comes to the misinformation about vaccines that is scaring the hell out of a percentage of the population. In fact, advocate for those same vaccines. Get Kennedy hopped up on those psychedelics he likes if you need to, but he needs to be front and center telling people to get vaccinated. And stop the nonsense that is going on with supposed religious exemptions for vaccinations.</p><blockquote><p><em>Edwards highlighted the need for ‚Äúaccurate information about the dangers of measles virus and the complications that can ensue, in addition to communicating the safety and efficacy of the measles vaccine.‚Äù</em></p><p><em>‚ÄúRaising the bar to obtain non-medical exemptions for vaccines and requiring families to gain accurate information about the dangers of vaccine-preventable illnesses and the importance of vaccines would be a huge benefit in helping to raise vaccination rates in South Carolina and the rest of the country,‚Äù she added. ‚ÄúWe would love to see a requirement for parents to come in person to the health department, watch a video on vaccine-preventable illnesses, and have a conversation with a healthcare professional before they choose non-medical exemptions.‚Äù</em></p></blockquote><p>Second, take the data collection and sharing about measles seriously. Along those same lines, demonstrate leadership by helping state governments and local medical facilities collect and share data, strategize protective measures to stop the spread of the disease, and pump the ecosystem full of real-time accurate information about where the disease is, how it spreads, and how to handle an infection. </p><p>That isn‚Äôt happening. Instead, you get stories like how South Carolina‚Äôs state government doesn‚Äôt require any <a href=\"https://www.propublica.org/article/south-carolina-measles-hospital-admissions?utm_source=bluesky&amp;utm_medium=social&amp;utm_campaign=propublica-bsky&amp;utm_content=2-20\">mandatory reporting of measles cases</a> in the state when patients are admitted. One doctor in the state had to find out that patients in her own area had been hospitalized with measles from Facebook.</p><blockquote><p><em>Dr. Leigh Bragg, a pediatrician working a county away, wasn‚Äôt even aware that anyone in South Carolina had been hospitalized with measles-related illnesses until a short time later when she logged on to Facebook and saw someone relay the distraught husband‚Äôs comments.&nbsp;</em></p><p><em>Part of the reason Bragg didn‚Äôt know is that South Carolina doesn‚Äôt require hospitals to report admissions for measles, potentially obscuring the disease‚Äôs severity. In the absence of mandatory reporting rules, she and other doctors are often left to rely on rumors, their grapevines of colleagues, and the fragments of information the state public health agency is able to gather and willing to share.&nbsp;</em></p></blockquote><p>So, what you get is South Carolina reporting that roughly 2% of its measles cases have resulted in hospitalization. Nobody with any knowledge of measles thinks that is even remotely accurate. </p><blockquote><p><em>‚ÄúA hospitalization rate at 2% is ludicrous,‚Äù said Dr. Paul Offit, director of the Vaccine Education Center and an infectious disease physician at Children‚Äôs Hospital of Philadelphia who served on the Centers for Disease Control and Prevention‚Äôs immunization advisory committee.&nbsp;</em></p><p><em>‚ÄúIt‚Äôs vast underreporting,‚Äù Offit said. ‚ÄúMeasles makes you sick.‚Äù</em></p></blockquote><p>Without that sort of accurate data, neither the state nor federal government knows where to help, nor how how much help is needed. If Kennedy and Trump wanted to actually confront this growing problem, that‚Äôs the kind of organization the federal government and its health-related agencies could help with. But this administration seems content to put its hands over its eyes and shout, ‚ÄúNuh uh, I can‚Äôt see you!‚Äù</p><p>This is going to continue to get worse until real action is taken. Until then, I guess we all just try to keep an eye out for rashes. </p>",
      "contentLength": 5999,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Anthropic CEO Says AI Company 'Cannot In Good Conscience Accede' To Pentagon",
      "url": "https://tech.slashdot.org/story/26/02/26/2352217/anthropic-ceo-says-ai-company-cannot-in-good-conscience-accede-to-pentagon?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1772163000,
      "author": "BeauHD",
      "guid": 48724,
      "unread": true,
      "content": "An anonymous reader quotes a report from the Associated Press: Anthropic CEO Dario Amodei said Thursday the artificial intelligence company \"cannot in good conscience accede\" to the Pentagon's demands to allow wider use of its technology. The maker of the AI chatbot Claude said in a statement that it's not walking away from negotiations, but that new contract language received from the Defense Department \"made virtually no progress on preventing Claude's use for mass surveillance of Americans or in fully autonomous weapons.\"\n \nThe Pentagon's top spokesman has reiterated that the military wants to use Anthropic's artificial intelligence technology in legal ways and will not let the company dictate any limits ahead of a Friday deadline to agree to its demands. Sean Parnell said Thursday on social media that the Pentagon \"has no interest in using AI to conduct mass surveillance of Americans (which is illegal) nor do we want to use AI to develop autonomous weapons that operate without human involvement.\"\n \nAnthropic's policies prevent its models, such as its chatbot Claude, from being used for those purposes. It's the last of its peers -- the Pentagon also has contracts with Google, OpenAI and Elon Musk's xAI -- to not supply its technology to a new U.S. military internal network. Parnell said the Pentagon wants to \"use Anthropic's model for all lawful purposes\" but didn't offer details on what that entailed. He said opening up use of the technology would prevent the company from \"jeopardizing critical military operations.\" \"We will not let ANY company dictate the terms regarding how we make operational decisions,\" he said. In a post on X, Parnell said Anthropic will \"have until 5:01 PM ET on Friday to decide. Otherwise, we will terminate our partnership with Anthropic and deem them a supply chain risk for DOW.\"",
      "contentLength": 1839,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "dReLU Activation Function: Matching SwiGLU Performance with 90% Sparsity",
      "url": "https://hackernoon.com/drelu-activation-function-matching-swiglu-performance-with-90percent-sparsity?source=rss",
      "date": 1772161671,
      "author": "Language Models (dot tech)",
      "guid": 48784,
      "unread": true,
      "content": "<p>We introduce a new activation function, named dReLU (Equation 2), where ReLU is applied after both the up- and gate-projection[1].</p><p>\\\nTo demonstrate the effectiveness and performance of dReLU, we conducted an experiment comparing 300M-parameter decoder-only architecture models using dReLU and SwiGLU, both pretrained under the fineweb dataset [47] for 5B tokens. Refer to Appendix A.1 for the detailed model architecture hyperparameters. The evaluation result is shown in Table 2.</p><p>\\\nOur findings reveal models employing the dReLU structure exhibit similar convergence compared to those using the SwiGLU structure. Notably, we evaluate the perplexity of both models on Wikitext2 [39]. DReLU-based models show slightly better performance on WikiText-2 [39].</p><p>\\\nFigure 4 illustrates the loss curves during training, demonstrating that models with the dReLU activation function achieve similar convergence ability compared to their SwiGLU counterparts. To further validate this observation, we evaluate the perplexity of these models on the Wikitext2 dataset. As shown in Table 2. Notably, although SwiGLU-based model has lower training loss, dReLU based model has lower validation perplexity. These results provide strong evidence that adopting the dReLU structure does not compromise model performance. We evaluate on more downstream tasks in Appendix A.1.</p><p>\\\nAnother question we need to address is the dReLU-based model‚Äôs sparsity. To investigate the sparsity of the dReLU-based model, we propose a methodology for measuring and evaluating a model‚Äôs performance under different sparsity levels. Our approach involves selecting the top-k% of values activated by dReLU or other activation functions based on their absolute magnitude, as described in Equations 3 and 4.</p><p>(1) Yixin Song, Institute of Parallel and Distributed Systems (IPADS), Shanghai Jiao Tong University;</p><p>(2) Haotong Xie, Institute of Parallel and Distributed Systems (IPADS), Shanghai Jiao Tong University;</p><p>(3) Zhengyan Zhang, Department of Computer Science and Technology, Tsinghua University;</p><p>(4) Bo Wen, Institute of Parallel and Distributed Systems (IPADS), Shanghai Jiao Tong University;</p><p>(5) Li Ma, Shanghai Artificial Intelligence Laboratory;</p><p>(6) Zeyu Mi, Institute of Parallel and Distributed Systems (IPADS), Shanghai Jiao Tong University Mi yzmizeyu@sjtu.edu.cn);</p><p>(7) Haibo Chen, Institute of Parallel and Distributed Systems (IPADS), Shanghai Jiao Tong University.</p><p>[1] We omit the bias in both the up- and gate-projection to match the form of Equation 1.</p>",
      "contentLength": 2518,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Analyzing ReLUfication Limitations: Enhancing LLM Sparsity via Up Projection",
      "url": "https://hackernoon.com/analyzing-relufication-limitations-enhancing-llm-sparsity-via-up-projection?source=rss",
      "date": 1772161351,
      "author": "Language Models (dot tech)",
      "guid": 48783,
      "unread": true,
      "content": "<h3>3.1 Limitations about Existing ReLUfication</h3><p>\\\nWe first evaluate the sparsity of ReLULlama-7B [59] and the original Llama-2-7B [60], as shown in Table 1. The results reveal that existing ReLUfication methods can only improve the sparsity from 40% to 67%, indicating their limited effectiveness in significantly enhancing model sparsity.</p><p>\\\nTo investigate the underlying reasons for this limitation, we profile the activation distribution of the gate and up projection components separately in ReLULlama-7B and Llama-2-7B, as illustrated in Figure 3. The figure shows that after ReLUfication, the combined activation becomes more concentrated around 0, with the sparsity increasing to 67%. This can be attributed to the ReLU activation function applied after the gate weight, which masks all negative activations to zero.</p><p>\\\nTo further push the sparsity, shifted-ReLU [42] has been proposed, which adjusts the threshold of ReLU function to mask out more activations in the gate projection. However, the improvements brought by this method are limited. Another line of work is to adopt progressive sparsity regularization to the intermediate output to introduce more zero activation output [55]. However, this method carries the risk of performance degradation.</p><p>\\\nExisting ReLUfication methods primarily focus on modifying the gate component. Different from previous work, we find that existing ReLUfication doesn‚Äôt alter the activation distribution of the up projection component, as shown in Figure 3(c) and (f). According to the definition of Gated-MLP (Equation 1), the gate and up projection components jointly influence the sparsity of neuron activations in parallel. However, a significant number of activation values in the up projection component remain less than 0. This suggests that masking the outputs of the up and gate matrices that are less than 0 as inactive could introduce stronger sparsity without sacrificing non-linear capabilities. This observation motivates us to explore the possibility of further enhancing model sparsity by modifying the up projection.</p><p>(1) Yixin Song, Institute of Parallel and Distributed Systems (IPADS), Shanghai Jiao Tong University;</p><p>(2) Haotong Xie, Institute of Parallel and Distributed Systems (IPADS), Shanghai Jiao Tong University;</p><p>(3) Zhengyan Zhang, Department of Computer Science and Technology, Tsinghua University;</p><p>(4) Bo Wen, Institute of Parallel and Distributed Systems (IPADS), Shanghai Jiao Tong University;</p><p>(5) Li Ma, Shanghai Artificial Intelligence Laboratory;</p><p>(6) Zeyu Mi, Institute of Parallel and Distributed Systems (IPADS), Shanghai Jiao Tong University Mi yzmizeyu@sjtu.edu.cn);</p><p>(7) Haibo Chen, Institute of Parallel and Distributed Systems (IPADS), Shanghai Jiao Tong University.</p>",
      "contentLength": 2738,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Optimizing LLM Inference: Sparse Activation, MoE, and Gated-MLP Efficiency",
      "url": "https://hackernoon.com/optimizing-llm-inference-sparse-activation-moe-and-gated-mlp-efficiency?source=rss",
      "date": 1772161013,
      "author": "Language Models (dot tech)",
      "guid": 48782,
      "unread": true,
      "content": "<p><strong>Efficient Inference of LLMs</strong>. Efficient LLM inference poses challenges that necessitate a synergistic combination of algorithmic and systemic approaches. From an algorithmic standpoint, researchers have explored various methods to reduce computation and memory overheads, including compressing models [40, 63, 18, 34, 61], modifying model structures [3, 21], and speculative decoding methods [32, 12, 10]. On the systemic front, there are efforts that effectively integrate the features of downstream hardware and upper-level models to maximize the efficiency of computation and memory utilization [4, 49, 16, 64], leading to the development of more efficient frameworks like vLLM [29].</p><p>\\\nSparse activation, in particular, has emerged as a research area that demands an even tighter integration of algorithmic and systemic approaches. The selection of activation functions and the construction of activation predictors are algorithmic problems, while fully exploiting the sparse activation of LLMs on specific hardware is a systemic challenge. By leveraging sparse activation, researchers have achieved promising results in building efficient LLM inference systems [36, 56].</p><p>\\\n. MoE techniques induce effective sparsity in LLMs by determining which subset of subnetworks (referred to as \"experts\") to activate during the inference pass, often through a trained \"router\" subnetwork. This approach allows the model to enhance its capacity without escalating the computational expenses [31, 53].</p><p>\\\n<strong>Intrinsic Activation Sparsity</strong>. Intrinsic activation sparsity is known to be present in LLMs that utilize ReLU family nonlinearities in their MLP blocks [68, 33]. This phenomenon has been explored to accelerate inference speed and reduce memory usage [56, 36, 37]. With this phenomenon, each neuron can be viewed as an expert to reduce the computation overhead.</p><p>\\\n We now delve into the components of LLMs that our study aims to analyze: the Gated-MLP blocks, which are commonly used. A Gated-MLP block consists of three fully</p><p>\\\nconnected layers and performs the following computation:</p><p>(1) Yixin Song, Institute of Parallel and Distributed Systems (IPADS), Shanghai Jiao Tong University;</p><p>(2) Haotong Xie, Institute of Parallel and Distributed Systems (IPADS), Shanghai Jiao Tong University;</p><p>(3) Zhengyan Zhang, Department of Computer Science and Technology, Tsinghua University;</p><p>(4) Bo Wen, Institute of Parallel and Distributed Systems (IPADS), Shanghai Jiao Tong University;</p><p>(5) Li Ma, Shanghai Artificial Intelligence Laboratory;</p><p>(6) Zeyu Mi, Institute of Parallel and Distributed Systems (IPADS), Shanghai Jiao Tong University Mi yzmizeyu@sjtu.edu.cn);</p><p>(7) Haibo Chen, Institute of Parallel and Distributed Systems (IPADS), Shanghai Jiao Tong University.</p>",
      "contentLength": 2739,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "TurboSparse-LLM: Accelerating Mixtral and Mistral Inference via dReLU Sparsity",
      "url": "https://hackernoon.com/turbosparse-llm-accelerating-mixtral-and-mistral-inference-via-drelu-sparsity?source=rss",
      "date": 1772160681,
      "author": "Language Models (dot tech)",
      "guid": 48781,
      "unread": true,
      "content": "<p>Exploiting activation sparsity is a promising approach to significantly accelerating the inference process of large language models (LLMs) without compromising performance. However, activation sparsity is determined by activation functions, and commonly used ones like SwiGLU and GeGLU exhibit limited sparsity. Simply replacing these functions with ReLU fails to achieve sufficient sparsity. Moreover, inadequate training data can further increase the risk of performance degradation. To address these challenges, we propose a novel dReLU function, which is designed to improve LLM activation sparsity, along with a high-quality training data mixture ratio to facilitate effective sparsification. Additionally, we leverage sparse activation patterns within the Feed-Forward Network (FFN) experts of Mixtureof-Experts (MoE) models to further boost efficiency. By applying our neuron sparsification method to the Mistral and Mixtral models, only 2.5 billion and 4.3 billion parameters are activated per inference iteration, respectively, while achieving even more powerful model performance. Evaluation results demonstrate that this sparsity achieves a 2-5√ó decoding speedup. Remarkably, on mobile phones, our TurboSparse-Mixtral-47B achieves an inference speed of 11 tokens per second. Our models are available at https://huggingface.co/PowerInfer.</p><p>Large Language Models (LLMs) have achieved remarkable results, demonstrating emergent natural language abilities as the number of model parameters scales [9, 67]. These models have pushed the state-of-the-art performance across a wide range of downstream applications, such as QA and coding. However, most LLMs, such as Llama [60], Mistral [24], and Gemma [58], utilize all of their parameters during inference. These are known as dense models. The escalating demand for computational resources by dense models has become a significant barrier to the development of powerful and accessible AI, given the substantial costs involved.</p><p>\\\nTo address the efficiency issues inherent in dense models, conditional computation [7, 6] has emerged as a crucial approach, which refers to activating part of the neurons in a network. There are two primary methods to achieve conditional computation. Mixture-of-Experts (MoE) [17, 31] is the first promising method, which introduces conditional computation by manually setting constraints on the model architecture prior to training, such as determining the number of experts to activate. This technique selectively activates specific parts of the model in response to particular inputs through a process known as expert routing, resulting in significant efficiency improvements. For instance, Switch Transformer [17] has scaled the model to the trillion-parameter level without increasing computational FLOPs significantly. Another promising method is utilizing the natural emergence of sparse activation due to the ReLU activation function [33], which naturally outputs zero elements that have no contribution in computation results. This activation sparsity presents a significant opportunity for efficient inference. Deja Vu [36] utilizes that sparsity exists in dense models due to ReLU to achieve 2√ó speedups. PowerInfer [56] achieving up to 11√ó speedups for deploying larger LLMs in a single consumer-grade GPU setting.</p><p>\\\nRecent LLMs typically prefer activation functions such as GELU [23] and Swish [50]. However, these functions do not significantly promote activation sparsity and are challenging to accelerate with conditional computation. To address this, ReLUfication [42], an existing state-of-the-art method, replaces the original activation function with ReLU and continues with pretraining. Despite its potential, this approach often struggles to achieve the desired levels of activation sparsity and may risk performance degradation [30, 59].</p><p>\\\nWe argue that the failure of existing ReLUfication methods can be attributed to two main reasons. First, simply substituting SwiGLU with ReGLU is inefficient, as it only increases sparsity from 40% to around 70%. It suggests that a deeper investigation into the model architecture is necessary to achieve higher levels of sparsity. Second, the limited diversity of pretraining data and the insufficient number of training tokens in current approaches lead to incomplete capability recovery [42, 30]. As a result, expanding the diversity of pretraining datasets and increasing the number of training tokens are critical steps towards enhancing model performance.</p><p>\\\nTo address these challenges, we first conduct a comprehensive analysis of the existing ReLUfication approach and identify that its shortcomings stem from the negative activations in the GLU component. Therefore, we propose an efficient activation function named dReLU. We apply dReLU in the pretraining of small-scale LLMs, alongside SwiGLU, and our findings indicate that LLMs using dReLU match the performance of those using SwiGLU, while also achieving close to 90% sparsity. Additionally, we collect a diverse range of pretraining corpora from the open-source community, including web, code, and mathematical datasets, to enhance the effectiveness of ReLUfication.</p><p>\\\nMeanwhile, we also conduct a sparsity analysis on MoE-based LLMs. Interestingly, we observe that the feed-forward networks (FFNs) within the experts remain sparsely activated, similar to the behavior exhibited by dense LLMs. This phenomenon suggests an opportunity to further accelerate inference speed by combining MoE techniques with ReLU-based sparse activation.</p><p>\\\nTo validate the effectiveness of our proposed method, we implemented it on the Mistral-7B and Mixtral-47B models, converting them to TurboSparse-Mistral-47B and TurboSparse-Mixtral-47B, respectively. Extensive experiments across a wide range of downstream tasks demonstrate (Figure 1) that our enhanced models not only meet but often surpass the performance of their original counterparts.</p><p>\\\nRemarkably, in the TurboSparse-Mistral-7B model, we increase the average sparsity of the FFN to 90% while enhancing model capabilities. In MoE models, we further improve the sparsity in the TurboSparse-Mixtral-47B, originally introduced due to expert routing, from 75% to 97% by</p><p>\\\nincorporating sparse neuron activations. This substantial increase in sparsity significantly reduces FLOPs during the inference process.</p><p>\\\nFinally, we integrate our two new models with PowerInfer to evaluate the inference speed. Performance evaluation reveals that our models deliver an average 2.83√ó generation speedup.</p><p>\\\nThe key contributions of this paper include:</p><p>\\\n<strong>‚Ä¢ Efficient dReLU activation function</strong>: Our method utilizes fewer than 150B tokens, representing less than 1% of the typical pretraining tokens (commonly 15T tokens [11]).</p><p>\\\n<strong>‚Ä¢ Sparse activated models</strong>: We will release our sparsely-activated TurboSparse-Mistral7B and TurboSparse-Mixtral-47B models. Both models demonstrate better performance compared to the original versions.</p><p>\\\n<strong>‚Ä¢ Practical inference speedup:</strong> Evaluation shows that with our models, we can achieve a 2-5√ó speedup. Notably, we can achieve up to 10 tokens/s even without a GPU on TurboSparse-Mixtral-47B.</p><p>(1) Yixin Song, Institute of Parallel and Distributed Systems (IPADS), Shanghai Jiao Tong University;</p><p>(2) Haotong Xie, Institute of Parallel and Distributed Systems (IPADS), Shanghai Jiao Tong University;</p><p>(3) Zhengyan Zhang, Department of Computer Science and Technology, Tsinghua University;</p><p>(4) Bo Wen, Institute of Parallel and Distributed Systems (IPADS), Shanghai Jiao Tong University;</p><p>(5) Li Ma, Shanghai Artificial Intelligence Laboratory;</p><p>(6) Zeyu Mi, Institute of Parallel and Distributed Systems (IPADS), Shanghai Jiao Tong University Mi yzmizeyu@sjtu.edu.cn);</p><p>(7) Haibo Chen, Institute of Parallel and Distributed Systems (IPADS), Shanghai Jiao Tong University.</p>",
      "contentLength": 7822,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Data Centres: Will They Create a New Indian IT Boom?",
      "url": "https://hackernoon.com/data-centres-will-they-create-a-new-indian-it-boom?source=rss",
      "date": 1772159811,
      "author": "Vipin Labroo",
      "guid": 48780,
      "unread": true,
      "content": "<p>\\\n‚ÄãIndia ostensibly has everything that is required to help it make one of the leading data centre hubs in the world. From low infrastructure and manpower costs to active government support, it apparently has things neatly lined up to help it do just that. But given the existing power situation in the country and the excessive reliance on coal-generated electricity, there are many challenges to be overcome to get there. </p><p>\\\nThese include straining the water resources available in the country, which are already under intense pressure to cater to the needs of nearly a billion and a half people. Land acquisition and the creation of a suitably skilled workforce are other major challenges that need to be addressed.</p><h2><strong>Data Centres- The Only Path Ahead for the Indian IT Sector?</strong></h2><p>‚ÄãThe IT sector is one of the few success stories that the country has seen with regard to providing a well-paying career path to millions of Indian youth this century. Apart from the technically qualified who take up jobs in this sector, there is an even larger number of people who find indirect employment working as security staff, drivers, real estate managers, and canteen personnel.</p><p>\\\n‚ÄãThe impending wind-down of the IT sector puts millions of livelihoods at stake, which makes it imperative that the opportunity afforded by the likely emergence of data centres as a major growth area acts as a godsend. Worldwide, the massive growth of cutting-edge technologies like AI, 5G, cloud computing, and the IoT has led to an enormous surge in the demand for data storage, thereby making data centres a vitally critical component of the upcoming and emerging technology eco-systems. </p><p>\\\nBesides, data centres are also required to help manage the data as well as processing needs of the high-growth sectors like finance, e-commerce, healthcare, gaming, and a host of other industries that rely on dependable digital support in the shape of world-class data centres.</p><p>\\\nAs a matter of fact, it is raining investments in India, when it comes to major Indian and international business groups' interest in helping grow thedata centre sector. </p><h2>Can focusing on data centres move India down the IT value chain?</h2><p>For all those tom-tomming the impending rise of India as a major global data centre hub, there is a contrary school of thought that fears that this could possibly move the Indian industry down the IT value chain. It suggests that rather than being known for low-end server farms, India should stride ahead with a focus on creating world-class SaaS products, designing chips, and building cutting-edge new-age AI models.</p><p>Despite the misgivings of a few, the overriding consensus is that data centre growth augurs well for the Indian IT industry as it helps lay the foundation for the accelerated growth and adoption of AI and Cloud technologies across the world. </p><p>\\\n‚ÄãThey hold that it makes eminent sense for a nation that boasts the largest and&nbsp;most data-intensive mobile user numbers in the world to work on expanding data centre capacity expansion on an unprecedented scale. Besides, the rapid and massive growth and adoption of AI have necessitated that data centre growth in the country be encouraged in every possible manner. Doing so also helps protect data sovereignty, something to which the government is fully committed.</p><p>\\\nClearly, the data centre story has just begun in India.</p>",
      "contentLength": 3366,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "LXD 6.7 Released With AMD GPU Passthrough Support",
      "url": "https://www.phoronix.com/news/LXD-6.7-Released",
      "date": 1772154558,
      "author": "Michael Larabel",
      "guid": 48711,
      "unread": true,
      "content": "<article>Canonical today released LXD 6.7 as the latest feature update to this system container and virtual machine manager commonly used in Ubuntu Linux environments...</article>",
      "contentLength": 160,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Three Alternatives to Measure the Elapsed Time of Code Execution",
      "url": "https://hackernoon.com/three-alternatives-to-measure-the-elapsed-time-of-code-execution?source=rss",
      "date": 1772153406,
      "author": "Nicolas Fr√§nkel",
      "guid": 48779,
      "unread": true,
      "content": "<p>For as long as I have been coding in Java, we have had requirements to measure the execution time of blocks of code. While  the current good practice is to use OpenTelemetry's traces, not every company has reached this stage yet. Plus, some of the alternatives are OpenTelemetry-compatible. Let's see them in order.</p><p>The basic option is what we have been doing for ages, and what the other options rely on anyway. It's based on the following API: <a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/System.html#currentTimeMillis\">System.currentTimeMillis()</a>.</p><p>\\\nUsage is pretty straightforward: \\n </p><pre><code>long start = System.currentTimeMillis();\n// Execute code\nlong end =  System.currentTimeMillis();\nSystem.out.println(\"Code executed in \" + (end - start) + \" milliseconds\");\n</code></pre><h2>The Object-Oriented Alternative</h2><p>If you are an OOP developer, then you'd rather encapsulate state. Here's a draft of such encapsulation: \\n </p><pre><code>class Timer {\n    private long startTime;\n\n    public void start() {\n        startTime = System.currentTimeMillis();\n    }\n\n    public long stop() {\n        return System.currentTimeMillis() - startTime();\n    }\n}\n</code></pre><p>\\\nYou can add a  method to reuse the object, a  method to pause the timing, or decide to have a separate  method on top of . Nothing changes the overall design. Both <a href=\"https://guava.dev/releases/19.0/api/docs/com/google/common/base/Stopwatch.html\">Guava</a> and <a href=\"https://commons.apache.org/proper/commons-lang/apidocs/org/apache/commons/lang3/time/StopWatch.html\">Apache Commons Lang</a> provide a  class, with minor variations. If either of them is on the classpath, don't reinvent the wheel and use it.</p><h2>The Functional Alternative</h2><p>A functional approach is also possible if that's what you prefer. Let's start by timing a method that accepts a parameter and returns a value, in other words, a <code>java.util.function.Function</code>. We can wrap it in a timing method that accepts the said function, and a . \\n </p><pre><code>public class TimeUtils {\n    public static &lt;I,O&gt; O time(I input, Function&lt;I,O&gt; function, Consumer&lt;Long&gt; time) {\n        long start = System.currentTimeMillis();                     //1\n        O result = function.apply(input);                            //2\n        time.accept(System.currentTimeMillis() - start);             //3\n        return result;\n    }\n}\n</code></pre><ol><li>Compute the time and wrap it in a consumer</li></ol><p>\\\nWe can use it like this: \\n </p><pre><code>var result = TimeUtils.time(\n    0,                                                               //1\n    value -&gt; value + 1,                                              //2\n    time -&gt; System.out.println(\"Time: \" + time  + \" ms\"));           //3\nSystem.out.println(\"value: \" + result);\n</code></pre><ol></ol><p>\\\nWe must add more code to cater to other method signatures. \\n </p><pre><code>public class TimeUtils {\n\n    public static &lt;T&gt; T time(Supplier&lt;T&gt; supplier, Consumer&lt;Long&gt; time) {      //1\n        long start = System.currentTimeMillis();\n        T result = supplier.get();\n        time.accept(System.currentTimeMillis() - start);\n        return result;\n    }\n\n    public static &lt;T&gt; T time(T t, Consumer&lt;T&gt; consumer, Consumer&lt;Long&gt; time) { //2\n        long start = System.currentTimeMillis();\n        consumer.accept(t);\n        time.accept(System.currentTimeMillis() - start);\n    }\n}\n</code></pre><ol></ol><p>\\\nYou can do the same with  and . If your methods require more than two parameters, you'll need to model more functional interfaces, , , , etc.</p><h2>The Annotations Alternative</h2><ul><li>An annotation, , </li><li>An annotation processor, which scans methods and filters those annotated with  at either compile-time or runtime</li></ul><p>\\\nIn the first case, we rely on bytecode manipulation to weave the OOP or functional alternatives above around the original method. In the second one, we would need to intercept the instantiation of classes having such annotated methods, and wrap them in a <a href=\"https://blog.frankel.ch/the-power-of-proxies-in-java/\">java.lang.reflect.Proxy</a>. In both cases, you generate additional code to:</p><ol><li>Call the annotated method</li><li>Do something with the time, , log execution time</li></ol><p>\\\nThe code is more complex than the two previous alternatives, so I won't develop it further.</p><p>\\\n<a href=\"https://eclipse.dev/aspectj/\">AspectJ</a>, an Aspect-Oriented Programming framework, provides the overall engine. You'll only need to develop the annotation and the wrapping code.</p><p>In this post, I described three alternatives to measure the elapsed time of code execution: object-oriented, functional, and annotations. Depending on your context, you may want to use one or the other. In any case, I suggest you don't roll out your own, but use one of the available libraries/frameworks.</p><p><em>Originally published at <a href=\"https://blog.frankel.ch/jvm-timing-options/\">A Java Geek</a> on February 22nd, 2026</em></p>",
      "contentLength": 4234,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Four Convicted Over Spyware Affair That Shook Greece",
      "url": "https://yro.slashdot.org/story/26/02/26/2242230/four-convicted-over-spyware-affair-that-shook-greece?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1772153100,
      "author": "BeauHD",
      "guid": 48710,
      "unread": true,
      "content": "A Greek court has convicted four individuals linked to the marketing of Predator spyware in the wiretapping scandal that shook the country in 2022. The BBC reports: In what became known as \"Greece's Watergate,\" surveillance software called Predator was used to target 87 people -- among them government ministers, senior military officials and journalists. The four who had marketed the software were found guilty by an Athens court of misdemeanours of violating the confidentiality of telephone communications and illegally accessing personal data and conversations.\n \nThe court sentenced the four defendants to lengthy jail sentences, suspended pending appeal. Although they each face 126 years, only eight would be typically served which is the upper limit for misdemeanors. One in three of the dozens of figures targeted had also been under legal surveillance by Greece's intelligence services (EYP). Prime Minister Kyriakos Mitsotakis, who had placed EYP directly under his supervision, called it a scandal, but no government officials have been charged in court and critics accuse the government of trying to cover up the truth.\n \nThe case dates back to the summer of 2022, when the current head of Greek Socialist party Pasok, Nikos Androulakis - then an MEP - was informed by the European Parliament's IT experts that he had received a malicious text message containing a link. Predator spyware, marketed by the Athens-based Israeli company Intellexa, can get access to a device's messages, camera, and microphone. Its use was illegal in Greece at that time but a new law passed in 2022 has since legalised state security use of surveillance software under strict conditions. Androulakis also discovered that he had been tracked for \"national security reasons\" by Greece's intelligence services. The scandal has since escalated into a debate over democratic accountability in Greece.",
      "contentLength": 1891,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Fast KV Compaction Makes Long Context LLMs Practical",
      "url": "https://hackernoon.com/fast-kv-compaction-makes-long-context-llms-practical?source=rss",
      "date": 1772153099,
      "author": "aimodels44",
      "guid": 48778,
      "unread": true,
      "content": "<article>Fast KV Compaction via Attention Matching shows how to compress LLM KV cache in seconds, not hours, while preserving long-context performance.</article>",
      "contentLength": 142,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Ubuntu 26.04 Resolute Snapshot 4 Released",
      "url": "https://www.phoronix.com/news/Ubuntu-26.04-Snapshot-4",
      "date": 1772152016,
      "author": "Michael Larabel",
      "guid": 48702,
      "unread": true,
      "content": "<article>The fourth and final monthly snapshot of Ubuntu 26.04 \"Resolute Raccoon\" is now available for testing. This alternative to the Ubuntu 26.04 daily ISOs is a monthly test release that also helps exercise the Ubuntu Linux release automation processes...</article>",
      "contentLength": 250,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "How to Reverse Video with fal-ai‚Äôs FFMPEG Utility",
      "url": "https://hackernoon.com/how-to-reverse-video-with-fal-ais-ffmpeg-utility?source=rss",
      "date": 1772151299,
      "author": "aimodels44",
      "guid": 48777,
      "unread": true,
      "content": "<article>Learn how fal-ai‚Äôs workflow-utilities/reverse-video reverses playback for creative effects, motion analysis, and advanced video editing workflows.</article>",
      "contentLength": 148,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Colorado Lawmakers Push for Age Verification at the Operating System Level",
      "url": "https://tech.slashdot.org/story/26/02/26/233213/colorado-lawmakers-push-for-age-verification-at-the-operating-system-level?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1772150520,
      "author": "BeauHD",
      "guid": 48678,
      "unread": true,
      "content": "Colorado lawmakers are proposing SB26-051, a bill that would require operating systems to register a user's age bracket and share it with apps via an API. PCMag reports: The bill comes from state Sen. Matt Ball and Rep. Amy Paschal, both Democrats. \"The intent is to create thoughtful safeguards for kids online through a privacy-forward framework for age assurance,\" Ball told PCMag. \"Unlike some laws in other states, SB 51 doesn't require users to share personally identifiable information or use facial recognition technology.\"\n \nThe legislation also promises to centralize the age check through the OS, rather than mandating that each app enforce their own age-verification mechanism, which can involve scanning the user's official ID, thus raising privacy and security concerns. The bill also forbids the sharing of the age-bracket data for any other purpose. But it looks like it's easy to bypass the age check proposed by SB26-051. The legislation itself doesn't mention any state ID check to verify the owner's age. In addition, the bill doesn't seem to cover websites, only apps and app stores. The report notes that the legislation was based on California's bill AB 1043, which was passed last year and expected to take effect January 1, 2027.",
      "contentLength": 1254,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Netflix backs out of bid for Warner Bros. Discovery, giving studios, HBO, and CNN to Ellison-owned Paramount",
      "url": "https://techcrunch.com/2026/02/26/netflix-warner-bros-discovery-paramount-wbd-bid-studios-hbo-cnn-ellison/",
      "date": 1772150139,
      "author": "Graham Starr",
      "guid": 48695,
      "unread": true,
      "content": "<article>In a one-two punch of centibillion-dollar offers, the bidding war for Warner Bros. Discovery is over. David Ellison-owned Paramount will acquire Warner Bros. Discovery. Netflix has lost.</article>",
      "contentLength": 186,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "GUI-Owl-1.5 Brings Cross-Device AI Agents Closer to Reality",
      "url": "https://hackernoon.com/gui-owl-15-brings-cross-device-ai-agents-closer-to-reality?source=rss",
      "date": 1772149499,
      "author": "aimodels44",
      "guid": 48776,
      "unread": true,
      "content": "<article>GUI-Owl-1.5 shows how AI agents can automate tasks across phones, PCs, and browsers using multi-platform training, reasoning, and RL.</article>",
      "contentLength": 133,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Jack Dorsey just halved the size of Block‚Äôs employee base ‚Äî and he says your company is next",
      "url": "https://techcrunch.com/2026/02/26/jack-dorsey-block-layoffs-4000-halved-employees-your-company-is-next/",
      "date": 1772149412,
      "author": "Connie Loizos",
      "guid": 48694,
      "unread": true,
      "content": "<article>Jack Dorsey has long been an open admirer of Elon Musk. Now, it seems, he may have been taking notes.</article>",
      "contentLength": 101,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Jack Dorsey's Block Cuts Nearly Half of Its Staff In AI Gamble",
      "url": "https://slashdot.org/story/26/02/26/2250206/jack-dorseys-block-cuts-nearly-half-of-its-staff-in-ai-gamble?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1772148000,
      "author": "BeauHD",
      "guid": 48677,
      "unread": true,
      "content": "Jack Dorsey's Block is cutting more than 4,000 jobs, or nearly half its workforce, as part of a deliberate shift toward becoming a smaller, \"intelligence-native\" company built around AI. The Verge reports: \"We're not making this decision because we're in trouble,\" Dorsey says. \"Our business is strong. Gross profit continues to grow, we continue to serve more and more customers, and profitability is improving. But something has changed. We're already seeing that the intelligence tools we're creating and using, paired with smaller and flatter teams, are enabling a new way of working which fundamentally changes what it means to build and run a company. And that's accelerating rapidly.\"\n \nDorsey opted to do a big layoff instead of gradual cuts because \"I'd rather take a hard, clear action now and build from a position we believe in than manage a slow reduction of people toward the same outcome.\" The layoffs were announced on Thursday as part of the company's Q4 2025 earnings. In a shareholder letter (PDF), Dorsey says that \"We believe Block will be significantly more valuable as a smaller, faster, intelligence-native company. Everything we do from here is in service of that.\"",
      "contentLength": 1190,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Anthropic CEO stands firm as Pentagon deadline looms",
      "url": "https://techcrunch.com/2026/02/26/anthropic-ceo-stands-firm-as-pentagon-deadline-looms/",
      "date": 1772147946,
      "author": "Rebecca Bellan",
      "guid": 48693,
      "unread": true,
      "content": "<article>Anthropic CEO Dario Amodei said Thursday that he \"cannot in good conscience accede\" to the Pentagon's demands to give the military unrestricted access to its AI systems. </article>",
      "contentLength": 170,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Outtelligence: The Advantage AI Cannot Compound",
      "url": "https://hackernoon.com/outtelligence-the-advantage-ai-cannot-compound?source=rss",
      "date": 1772147144,
      "author": "Nomcebo Mkhize",
      "guid": 48775,
      "unread": true,
      "content": "<p>I‚Äôm going to introduce a new word. Not because the idea is new. But because the moment demands a name for it. The word is .</p><p>\\\nAnd if artificial intelligence continues accelerating the way it is, this may become the most important cognitive skill of the next decade.</p><p>\\\nIf you study capital markets long enough, you learn something simple:</p><p>\\\nWhen something becomes abundant, its value drops.  used to be scarce. Now it‚Äôs infinite.  used to be expensive. Now it‚Äôs automated.  is becoming a commodity.</p><p>\\\nThat should concern you.</p><p>\\\nBecause when intelligence becomes cheap, the real advantage shifts somewhere else.</p><p>\\\nI call that shift .</p><p>Outtelligence is not intelligence. It is the ability to step outside the system intelligence operates in. Intelligence answers questions. Outtelligence questions the frame that produced the question. Intelligence optimizes. Outtelligence reallocates.</p><p>\\\nIf intelligence plays the game better, outtelligence decides whether the game is worth playing.</p><p>Large language models, including those developed by OpenAI, operate by predicting high-probability patterns from historical data. That makes them powerful.</p><p>\\\nIt also makes them traditional.</p><p>\\\nAI is trained on what has already stabilized.</p><p>AI compounds consensus. It does not initiate structural rebellion.</p><p>\\\nAnd that is where most people misunderstand the threat.</p><p>\\\nThe danger is not that AI replaces your job.</p><p>\\\nThe danger is that AI shapes your frame.</p><p> doesn't compete where everyone is competing. He buys mispriced assets. Outtelligence works the same way. If everyone has AI-assisted intelligence, then intelligence is no longer a long-term advantage. Frame independence is.</p><p>Power does not sit in effort. Power sits in perception control. If AI systems generate the dominant language, they begin influencing:</p><ul><li>What feels authoritative?</li></ul><p>Most professionals will unknowingly conform to machine-shaped consensus. Outtelligence is resistance to invisible alignment.</p><p>\\\nIt is the ability to ask:</p><ul><li>What perspective is missing?</li></ul><p>Markets reward differentiation. Not participation. If AI makes everyone clearer, faster, and more articulate, then clarity alone stops being impressive.</p><p>\\\nOuttelligence becomes the differentiator because it produces.</p><ul><li><p><strong>Strategic lack of balance asymmetry</strong></p></li></ul><p>In marketing terms: .</p><p>\\\nOuttelligence creates new categories.</p><h2><strong>The Cognitive Shift (System Model)</strong></h2><p>Problem ‚Üí Struggle ‚Üí Reflection ‚Üí Insight ‚Üí Mental Model Upgrade</p><ul><li><p><strong>Problem ‚Üí Prompt ‚Üí Output ‚Üí Publish</strong></p><p>Efficiency increased. Cognitive friction decreased. The quiet cost is: Friction is where independent models are built. Without friction, you get fluency. Not depth.</p></li></ul><h2><strong>Intelligence vs Outtelligence</strong></h2><p><strong>Data ‚Üí Analysis ‚Üí Optimization ‚Üí Performance</strong></p><p><strong>Assumptions ‚Üí Incentives ‚Üí Frame Shift ‚Üí Structural Advantage</strong></p><p>Intelligence improves the machine. Outtelligence questions the machine.</p><h2><strong>The Real Divide of the Next Decade</strong></h2><p>It won‚Äôt be: AI users vs non-users.</p><p>\\\nIt will be: <strong>AI-dependent thinkers vs AI-sovereign thinkers.</strong></p><ul><li><p><strong>Accept generated framing.</strong></p></li><li><p><strong>Optimize within algorithmic boundaries.</strong></p></li></ul><p>Use the AI's probabilistic nature against itself, thus deliberately exploring the long tail of possibilities it was trained to deprioritize.</p><p>\\\nThe tool does not determine the frame. The user does. But this requires something difficult: <strong>the discipline to use AI without being subtly shaped by its gravitational pull toward consensus.</strong></p><p>\\\n<em>Could AI itself help us step outside the frame? A skilled user can prompt for the improbable, not just the probable, exploring perspectives the model was trained to deprioritize. The difference is intent. AI-dependent thinkers accept the first high-probability output. AI-sovereign thinkers use AI's probabilities against themselves.</em></p><h2><strong>The Organizational Problem</strong></h2><p>Even if you maintain frame independence, organizations have immune systems. They reward execution, not questioning whether the project should exist. Outtelligence at the individual level creates insight. At the organizational level, it requires structure:</p><p><strong>Who is tasked with challenging assumptions? What incentives exist for killing a project that would have succeeded inside the current frame? Most companies claim to value \"thinking differently.\" Few tolerate the discomfort. The ones that do will survive the compression AI brings.</strong></p><p>AI has made me faster. Cleaner and more precise.</p><p>\\\n<strong>But I‚Äôve noticed something subtle:</strong></p><p>My tolerance of being open to one interpretation has decreased. I resolve confusion too quickly. Clarity feels good. But premature clarity is cognitive laziness disguised as productivity. Outtelligence requires staying in confusion longer than is comfortable. That is now a competitive act.</p><p>When intelligence becomes abundant, independent framing becomes scarce. Scarcity drives value.</p><p>\\\n<strong>Outtelligence is scarce because:</strong></p><ul></ul><p>\\\nMost people will not choose that path. Which makes it valuable.</p><p>AI will not destroy intelligence. It will compress it. The question is whether you allow it to compress your perception as well. Outtelligence is the discipline of stepping outside the machine‚Äôs frame before the machine defines yours. That is not anti-technology. It is a strategic positioning. And positioning, not effort, is what compounds.</p>",
      "contentLength": 5158,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Ctrl-Alt-Speech: Let Fly The Claudes Of War, With Casey Newton",
      "url": "https://www.techdirt.com/2026/02/26/ctrl-alt-speech-let-fly-the-claudes-of-war-with-casey-newton/",
      "date": 1772146800,
      "author": "Mike Masnick",
      "guid": 48675,
      "unread": true,
      "content": "<p>In this week‚Äôs roundup of the latest news in online speech, content moderation and internet regulation, Ben is joined by Casey Newton, founder and editor of <a href=\"https://www.platformer.news/\">Platformer</a> and co-host of <a href=\"https://open.spotify.com/show/44fllCS2FTFr2x2kjP9xeT\">Hard Fork</a>, a podcast that makes sense of the rapidly changing world of tech. Together, they discuss:</p><p>Play along with Ctrl-Alt-Speech‚Äôs <a href=\"https://www.ctrlaltspeech.com/bingo/\">2026 Bingo Card</a> and get in touch if you win!</p>",
      "contentLength": 365,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "What's the Point of School When AI Can Do Your Homework?",
      "url": "https://news.slashdot.org/story/26/02/26/2154237/whats-the-point-of-school-when-ai-can-do-your-homework?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1772145600,
      "author": "BeauHD",
      "guid": 48671,
      "unread": true,
      "content": "An anonymous reader quotes a report from 404 Media: There's a new agentic AI called Einstein that will, according to its developers, live the life of a student for them. Einstein's website claims that the AI will attend lectures for you, write your papers, and even log into EdTech platforms like Canvas to take tests and participate in discussions. Educators told me that Einstein is just one of many AI tools that can do homework for students, but should be seen as a warning to schools that are increasingly seen by students as a place to gain a diploma and status as opposed to the value of education itself.\n \nIf an AI can go to school for you what's the point of going to school? For Advait Paliwal, Brown dropout and co-creator of Einstein, there isn't one. \"I think about horses,\" he said. \"They used to pull carriages, but when cars came around, I'd argue horses became a lot more free,\" he said. \"They can do whatever they want now. It would be weird if horses revolted and said 'no, I want to pull carriages, this is my purpose in life.'\" But humans aren't horses. \"This is much bigger than Einstein,\" Matthew Kirschenbaum told 404 Media. \"Einstein is symptomatic. I doubt we'll be talking about Einstein, as such, in a year. But it's symptomatic of what's about to descend on higher ed and secondary ed as well.\"\n \n[...] The attractiveness of agentic AIs is a symptom of a decades-long trend in higher education. \"Universitiesby and large adopted a transactive model of education,\" Kirschenbaum said. \"Students see their diploma as a credential. They pay tuition and at the end of four years, sometimes five years, they receive the credential and, in theory at least, that is then the springboard to economic stability and prosperity.\" Paliwal seems to agree. He told 404 Media that he attempted to change the university from the inside while working as a TA, but felt stymied by politics. \"The only way to force these institutions to evolve is to bring reality to their face. And usually the loudest critics are the ones who can't do their own job well and live in fear of automation,\" he said. \"I think we really need to question what learning even is and whether traditional educational institutions are actually helping or harming us,\" said Paliwal. \"We're seeing a rise in unemployment across degree holders because of AI, and that makes me question whether this is really what humans are born to do. We've been brainwashed as a society into valuing ourselves by the output of our productive work, and I think humanity is a lot more beautiful than that. Is it really education if we're just memorizing things to perform a task well?\"\n \nKirschenbaum added: \"What we're finding is that if forms of education can be transacted then we've just about arrived at the point where autonomous software AI agents are capable of performing the transaction on your behalf,\" he said. \"And so the whole educational paradigm has come back to essentially bite itself in the ass.\"",
      "contentLength": 2980,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Python is a Video Latency Suicide Note: How I Hit 29 FPS with Zero-Copy C++ ONNX",
      "url": "https://hackernoon.com/python-is-a-video-latency-suicide-note-how-i-hit-29-fps-with-zero-copy-c-onnx?source=rss",
      "date": 1772145299,
      "author": "Nick Maletsky",
      "guid": 48699,
      "unread": true,
      "content": "<h3>I accepted a challenge: build a real-time YOLOv8 video pipeline using vanilla ONNX Runtime. No bloated frameworks. No Python bottlenecks. Just raw C++ grit.</h3><p>Let's be honest: Python is the undisputed king of the research lab. But if you're trying to stream live H.264 video through a neural network at scale on edge hardware? Python's Global Interpreter Lock (GIL) and its pathological obsession with memory copying are glaring liabilities.</p><p>\\\nI was recently tasked with a simple objective: create fast inference for a video stream using a vanilla ONNX runtime and a YOLOv8 segmentation model. It sounded easy on paper. Grab FFmpeg, process the frames, and encode them back out.</p><p><strong>In reality, it was a journey through engineering hell.</strong>&nbsp;Here is how I dragged a sluggish 10 FPS prototype into a rock-solid 29 FPS beast, and the \"final boss\" bugs I had to slay along the way.</p><h2>The FogAI Sandbox: Validation Before Integration</h2><p>This repository isn't a standalone toy---it is a&nbsp;. I use this environment to rigorously stress-test specific computer vision models, engine builds, and optimization patterns before they are promoted to the&nbsp;.</p><p>\\\nIf a strategy (like Zero-Copy hardware mapping) can't survive here at 29 FPS, it has no business being inside an industrial autonomous nervous system.</p><p>\\\n<strong>Previous Chapters in the FogAI Saga:</strong></p><h2>The \"Memory Copy Tax\" Trap</h2><p>Most computer vision prototypes are slow because they treat memory like a game of Hot Potato.</p><p>\\\nMy initial architecture was the \"standard\" mess: FFmpeg decoded H.264 into YUV hardware formats, converted it to an OpenCV&nbsp;&nbsp;(BGR) to feed the model, applied masks on the RGB image, converted it&nbsp;&nbsp;to YUV, and finally hit the encoder.</p><p>\\\n<strong>That's three unnecessary memory copies and two heavy pixel-format conversions.</strong>&nbsp;On an ARM CPU processing 4K frames, that overhead burns up to&nbsp;&nbsp;just moving bits around.</p><p>\\\nI fixed this by implementing&nbsp;<strong>Zero-Copy Hardware Mapping</strong>. Instead of converting the frame, I mapped the&nbsp;&nbsp;hardware Y-plane (Luminance) directly into an OpenCV&nbsp;&nbsp;wrapper.</p><pre><code>// Mapping the hardware Y-plane natively - zero memcpy, zero overhead.\ncv::Mat y_plane(yuvFrame-&gt;height, yuvFrame-&gt;width, CV_8UC1,\n                yuvFrame-&gt;data, yuvFrame-&gt;linesize);\n\n// YOLO segmentation masks now inject binary modifications directly\n// onto the hardware Y sequence.\ny_plane(bbox).setTo(0, valid_mask);\n</code></pre><p>\\\nBy bypassing the conversion overhead, I skipped the CPU bottleneck entirely. But I was still capped at 23 FPS.&nbsp;</p><h2>Mutability and Asynchronous Reordering</h2><p>Profiling showed that my threads were locked in a sequential death grip. The&nbsp;&nbsp;abstraction relies on mutating shared internal buffers. If I just spawned more threads on a single model, they contaminated each other, and the system segfaulted.</p><p>\\\n&nbsp;I instantiated a concurrent pool of&nbsp;<code>std::unique_ptr&lt;YOLO_Segment&gt;</code>&nbsp;models---one unique ONNX model instance per worker thread.</p><p>\\\nBut there was a catch:&nbsp;<strong>DASH video requires strict frame order.</strong>&nbsp;Since workers finish at different times, Frame 2 might finish before Frame 1, causing the video to stutter like a 90s jump-cut. I had to inject a reorder buffer using an&nbsp;&nbsp;to ensure flawless H.264 synchronization.</p><pre><code>// Reorder buffer logic to keep the stream sequential\nstd::map&lt;int64_t, FramePayload&gt; reorderBuffer;\nint64_t expected_pts = 0;\n\nwhile (true) {\n    auto payload = inferenceQueue.pop(); // Workers drop processed frames here\n    reorderBuffer[payload.pts] = payload;\n\n    // Emit frames only when the sequential timestamp flags align\n    while (!reorderBuffer.empty() &amp;&amp; reorderBuffer.begin()-&gt;first == expected_pts) {\n        auto it = reorderBuffer.begin();\n        encoder.writeFrame(it-&gt;second.yuvFrame, it-&gt;second.pts);\n        reorderBuffer.erase(it);\n        expected_pts++;\n    }\n}\n</code></pre><h2>The Final Boss: Thread Cache Thrashing</h2><p>On paper, the logic was perfect. In practice, my FPS plummeted to&nbsp;. My Time-To-Inference (TTI) latencies shot up from 43ms to a horrific 890ms.</p><p>\\\n<strong>I was a victim of CPU Cache Thrashing.</strong></p><p>\\\nEven though I had decoupled my locks, the underlying ML libraries (OpenCV and ONNX) were \"helping\" me by spawning their own internal threads.</p><ol><li>: Defaults to&nbsp;<code>hardware_concurrency() / 2</code>&nbsp;threads&nbsp;. With 10 workers, it spawned 100+ internal threads on my 20-core CPU.</li><li>: Automatically deploys workers for operations like&nbsp;.</li></ol><p>\\\nMy designated workers were fighting ONNX's threads, which were fighting OpenCV's threads.&nbsp;<strong>Thousands of context switches were destroying my L1/L2 caches every second.</strong></p><p>\\\nThe fix was a brutal \"No\" to implicit concurrency. I stripped the libraries of their right to spawn threads:</p><pre><code>int main() {\n  // Globally disable implicit OpenCV threading\n  cv::setNumThreads(1);\n\n  // Cap ONNX Runtime to a single thread per op\n  Ort::SessionOptions session_options;\n  session_options.SetIntraOpNumThreads(1);\n  session_options.SetInterOpNumThreads(1);\n}\n</code></pre><p>\\\nThe context-switching noise vanished. My CPU instruction cache is synchronized. The pipeline immediately hit a flawless&nbsp;&nbsp;with a TTI ceiling of ~329ms.</p><h2>Maintenance Over Ego: The Vanilla Strategy</h2><p>A common question I get is: \"If you're so focused on performance, why not fork the engine and optimize the kernels yourself?\"</p><p>\\\nThe answer is&nbsp;<strong>Technical Debt avoidance.</strong></p><p>If you hack the engine's internals, you're signing up for a never-ending maintenance loop. Every time a new version drops with support for fresh hardware---like&nbsp;&nbsp;(57% prefill boost) or&nbsp;&nbsp;--- you'd have to re-port your custom optimizations manually. By sticking with a&nbsp;, I can \"catch\" these hardware updates for free just by bumping a version number.</p><p>\\\nSimilarly, I chose not to optimize the coding/decoding pipeline. Why? Because hardware vendors already did. Whether it's&nbsp;&nbsp;or the&nbsp;, these chips have silicon-level acceleration for H.264. Focus the code on the&nbsp;; leave the codecs to the metal they were built for.</p><h2>Conclusion: Stop Guessing, Start Profiling</h2><p>Scaling AI for the real world requires peeling back the layers of abstraction we've gotten too comfortable with. Python hides these latency taxes until you put the system into production.</p><p>\\\nIf you are tasked with heavy tensor payloads on video:</p><ol><li>---work on the hardware planes directly.</li><li>---one instance per worker.</li><li><strong>Reorder sequential outputs</strong>---don't let async finish times break your stream.</li><li><strong>Never let your libraries spawn their own threads.</strong></li><li>---optimize your architecture, not the engine, to keep tech debt low.</li></ol><p>\\\nNext for the FogAI node? We're prepping&nbsp;&nbsp;for a zero-copy run‚Ä¶</p>",
      "contentLength": 6402,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "PayPal might not be looking to sell itself: Report",
      "url": "https://techcrunch.com/2026/02/26/paypal-might-not-be-looking-to-sell-itself-report/",
      "date": 1772144622,
      "author": "Dominic-Madori Davis",
      "guid": 48663,
      "unread": true,
      "content": "<article>PayPal may not be in talks to be acquired, sources have told Semafor, after a previous news report that Stripe was sniffing around.</article>",
      "contentLength": 131,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Google Launches Nano Banana 2 Model With Faster Image Generation",
      "url": "https://tech.slashdot.org/story/26/02/26/2145253/google-launches-nano-banana-2-model-with-faster-image-generation?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1772143200,
      "author": "BeauHD",
      "guid": 48653,
      "unread": true,
      "content": "Google has launched Nano Banana 2 (Gemini 3.1 Flash Image), a faster, more realistic image generation model that becomes the default across Gemini, Search, Lens, and Flow. TechCrunch reports: The new Nano Banana 2 retains some of the high-fidelity characteristics of the Pro model but produces images faster. The company says you can create images with a resolution ranging from 512px to 4K, in different aspect ratios. Nano Banana 2 can maintain character consistency for up to five characters and fidelity of up to 14 objects in one workflow for better storytelling. Users can also issue complex requests with detailed nuances for image generation, Google says. In addition, users can create media with more vibrant lighting, richer textures, and sharper detail.\n \n[...] On Google's higher-end plans, Google AI Pro and Ultra, subscribers can continue to use Nano Banana Pro for specialized tasks by regenerating images via the three-dot menu. [...] The company said that all images created through the new model will have a SynthID watermark, which is Google's mark to denote AI-generated images. The images are also interoperable with C2PA Content Credentials, created by an industry body consisting of companies like Adobe, Microsoft, Google, OpenAI, and Meta. Google said that since launching the SynthID verification in the Gemini app in November, people have used it over 20 million times.",
      "contentLength": 1396,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Pipe Network Launches SolanaCDN: A Free, Open-Source Validator Client With Built-In Acceleration",
      "url": "https://hackernoon.com/pipe-network-launches-solanacdn-a-free-open-source-validator-client-with-built-in-acceleration?source=rss",
      "date": 1772141681,
      "author": "Chainwire",
      "guid": 48698,
      "unread": true,
      "content": "<p>San Francisco, CA, February 26th, 2026/Chainwire/SolanaCDN delivers 3.8x faster shred propagation through a global mesh of 35,000+ nodes, provided as a public good for the Solana network</p><p><a href=\"https://www.pipe.network/\">Pipe Network</a> today announced the launch of <a href=\"https://solanacdn.com\">SolanaCDN</a>, a free, open-source Solana validator client with an integrated CDN acceleration layer. Built as a fork of Anza's Agave, SolanaCDN gives every Solana validator access to faster shred propagation through Pipe's global network of 35,000+ PoP (Point-of-Presence) nodes.</p><p>The client and CDN layer are both completely free. Pipe Network is providing SolanaCDN as public good infrastructure for the Solana ecosystem.</p><h3>The problem SolanaCDN solves</h3><p>Validator performance on Solana is heavily influenced by network geography. Validators closer to block producers see shreds earlier, vote sooner, and earn more rewards. Validators in less connected regions face slower propagation, missed votes, and reduced leader slot revenue regardless of their hardware.</p><p>SolanaCDN addresses this by giving validators a second, faster path for shred delivery alongside native gossip. Shreds and vote packets route through Pipe's global mesh, which continuously measures every network path and routes traffic along the fastest available route in real time.</p><p>Native gossip still runs underneath. SolanaCDN adds a parallel fast lane.</p><p>SolanaCDN delivers 3.8x faster propagation than standard Turbine, with a P50 cross-region latency of approximately 78ms compared to the roughly 300ms baseline on standard gossip.</p><p>The client also ships with Pipe-built optimizations available out of the box before the CDN layer is enabled: optimized shred coalescing for leaders (Fast Shreds), snapshot downloads from Pipe's global network, and restore progress with real-time ETAs during validator catchup.</p><h3>Public good infrastructure</h3><p>Faster propagation is a network effect. Every validator running SolanaCDN improves shred delivery globally, which means faster block finalization, fewer forks, and fewer missed slots across the entire Solana network.</p><blockquote><p>\"Validator performance shouldn't be determined by geography,\" said David Rhodus, CEO of Pipe Network. \"SolanaCDN gives every validator access to the same fast infrastructure. The more validators that run it, the faster Solana gets for everyone.\"</p></blockquote><p>SolanaCDN is a fully compatible Agave fork. Validators can install it as a drop-in replacement for their existing client. The CDN layer is optional, activated with a single configuration flag, and is non-consensus by design. It does not modify block production, consensus logic, leader scheduling, or voting rules. All CDN operations are non-blocking and fail-safe. If the CDN layer is unavailable, the validator continues operating normally.</p><p>Built-in Prometheus metrics and CDN-versus-gossip race data give operators full visibility into performance changes in their environment.</p><p>SolanaCDN is available now. The source code is published on GitHub and the client is ready to run on Solana mainnet-beta.</p><p><a href=\"https://www.pipe.network/\">Pipe Network</a> is a global edge infrastructure company built on Solana. The network operates 35,000+ hyperlocal PoP nodes globally, providing distributed storage with fast reads and real-time data delivery. Pipe's overlay network tracks latency, loss, and jitter across every path in real time and routes traffic along the fastest one.</p><p>:::tip\nThis story was published as a press release by Chainwire under HackerNoon‚Äôs Business Blogging&nbsp;</p><p>This article is for informational purposes only and does not constitute investment advice. Cryptocurrencies are speculative, complex, and involve high risks. This can mean high prices volatility and potential loss of your initial investment. You should consider your financial situation, investment purposes, and consult with a financial advisor before making any investment decisions. The HackerNoon editorial team has only verified the story for grammatical accuracy and does not endorse or guarantee the accuracy, reliability, or completeness of the information stated in this article. #DYOR</p>",
      "contentLength": 4010,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "sudo-rs Breaks Historical Norms With Now Enabling Password Feedback By Default",
      "url": "https://www.phoronix.com/news/sudo-rs-password-feedback",
      "date": 1772141471,
      "author": "Michael Larabel",
      "guid": 48662,
      "unread": true,
      "content": "<article>On recent builds of Ubuntu 26.04 when being prompted by sudo for the password, password feedback is now enabled by default to show asterisk (*) characters when inputting your password. Traditionally sudo has not provided password feedback in the name of security to not divulge the length of your password in case anyone is looking/capturing your screen. But upstream sudo-rs has now changed the default behavior in the name of an improved UX...</article>",
      "contentLength": 445,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "What Does It Mean to Be Human When Tortured?",
      "url": "https://hackernoon.com/what-does-it-mean-to-be-human-when-tortured?source=rss",
      "date": 1772141010,
      "author": "Sam",
      "guid": 48697,
      "unread": true,
      "content": "<p>What does it mean to be human when you are living under a techno-controlled state system?</p><p>When your thoughts are being read, the last of your freedoms is taken away from you.</p><p>When you are constantly being monitored, potentially by people you used to know as people.</p><p>\\\nWhen you are kept awake by voices, not random, but deliberate, from people who used to love you but are now under the gun, literally, by rich and unfeeling ‚Äúhumans‚Äù who can‚Äôt stand an independent soul, who feel threatened by so much authenticity, so much raw energy.</p><p>\\\nAnyone can eat, anyone can shit, anyone can code, anyone can cycle, anyone can say A B C, anyone can be a ruler.</p><p>\\\nI am not writing to gain anything nor to lose anything. I only write to lose the sense of awareness that is unbearable, to avoid the madness of having to listen to a mind that has no other occupation than to contemplate itself.</p><p>\\\nI can‚Äôt even write without being edited. I have no freedom even on my page.</p><p>\\\nAm I even writing, or am I remotely controlled? All who have failed to stand up against this tyranny are co-responsible for their imprisonment. There are 5 guys in the Pentagon who rule this world, they have a CCTV in every living room on earth, and a super duper advanced search engine by which they can look up anything about anyone in a sec. It was developed by people like you and me, who wanted to earn a salary. We are not free. We are all losers except those 5 people.</p><p>\\\nNobody wants to hear this, nobody wants to listen to this, yet every day we have to live it.</p><p>\\\nWhy?&nbsp; + when did I go wrong?</p><p>\\\nIt's like what if we just tried to give one another all the feeling of being worthy? Just basic human dignity?</p><p>\\\nJust like the USA is letting any European country win, they could just bomb them lol</p><p>\\\nWhat does that even mean</p><p>I don‚Äôt understand that phrase</p><p>You are too good at losing?</p><p>Y‚Äôall, do you feel like somebody is giving what you know about how it all works?</p><p>\\\nI need to sit here and guess what they are whispering in my ear</p><p>Why do you even care to talk to me???</p><p>Are you not bored looking at me?</p><p>Don't you feel as if you got better things to do???</p><p>Is that what your life has become? Looking at a ‚Äúloser‚Äù living a non-life???</p><p>I don't understand your obsession with me.</p><p>Invite me for a cuppa if you want to have a chat???</p><p>I don't give it to anyone</p><p>No genius writing from me</p><p>\\\nThe club opener was contradicting himself by uttering these words. As if the comfortable silence was coercively enforced on the audience. Reminiscent of Stalin‚Äôs opinion on humor‚Äôs redundancy, for its people were happy already. When the end goal is clear, the KPIs‚Äô magic number is known, all that is left to do is pretend we have reached it, we have obtained it. What we do in between becomes a mirage of ghostly meanderings of empty souls seeking a reason to be affirmed in their existence. We laugh, but we don‚Äôt know why; we invent, we fill the gap in our explanation, oh, it must be the paradox of things unrelated.</p><p>\\\nThere is no audience for these words, so I am happy for this to be unconsidered. Stalinistically happy. And the train of where we don‚Äôt need to be can be missed at convenience, for its platform is being built as we speak, or listen. Or, really, how can these things differ from one another? Isn‚Äôt speaking a form of listening to others through ourselves? Are we ever separated from others?</p><p>\\\nWhy do we hurt when we are one, when we are connected uneradically by waves unseen that the universe carries forth and back and forth again?</p><p>\\\nIs it pain or an affirmation of being? And is seeking its opposite a perversion of the divine presence that can only be felt when earthly matters are waning?</p><p>\\\nHell on earth is an overspecification, so would heaven be. Heaven without qualification. We live into the next moment by rearranging entropy, but mind does not follow accordingly.</p><p>\\\nWhose ppl who don't believe in me, have you ever tried? How do you know? What evidence do you have? Do they tell you?</p><p>\\\nWill things be different in the USA?</p><p>Are things different for you?</p><p>Why are you still looking at me?</p>",
      "contentLength": 4059,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "QIELend: Bringing Efficient DeFi Lending to The QIE Blockchain",
      "url": "https://hackernoon.com/qielend-bringing-efficient-defi-lending-to-the-qie-blockchain?source=rss",
      "date": 1772140888,
      "author": "BTCWire",
      "guid": 48696,
      "unread": true,
      "content": "<p>Decentralized lending has become one of the foundational pillars of modern DeFi. Protocols like Aave demonstrated that users want permissionless borrowing and yield generation without relying on traditional intermediaries. However, high network fees and fragmented liquidity across chains continue to limit adoption.</p><p>QIELend aims to solve this by delivering a familiar, capital-efficient lending experience ‚Äî but on the high-performance QIE Blockchain. Keep your yield ‚Äî not pay it to gas.</p><p>Built for interoperability and low-cost execution, QIELend allows users to supply assets, earn yield, and borrow against their holdings with significantly lower transaction friction than many legacy DeFi environments.</p><h3>Aave-Style Lending, Optimized for QIE</h3><p>At its core, QIELend operates similarly to leading money markets: users deposit assets into liquidity pools, earn interest from borrowers, and can unlock liquidity by borrowing against their collateral.</p><p>The key difference is infrastructure efficiency.</p><p>By operating on QIE‚Äôs high-throughput, low-fee Layer-1, QIELend enables micro-efficient lending that would be uneconomical on higher-cost networks.</p><p>Wrapped assets are tokens locked on their original blockchain and mirrored on QIE, allowing users to use ETH, BNB, and USDC within the QIE ecosystem and redeem them back at any time.</p><p>Together, these represent exposure to ETH, BNB, USD liquidity, and the native QIE ecosystem ‚Äî all standardized under the QIE-20 format for seamless composability.</p><p>More markets, including XRP and Solana, are planned for upcoming releases.</p><h2>Liquidity Is Already Live</h2><p>The protocol has launched with $100,000+ in initial liquidity, providing the foundation for early lending and borrowing activity.</p><p>As utilization grows, additional liquidity providers are expected to deepen the markets and improve capital efficiency across the ecosystem.</p><h2>Why Lending Protocols Matter in DeFi</h2><p>Decentralized lending unlocks several powerful financial use cases:</p><p>Users can supply supported assets and earn interest from borrowers ‚Äî similar to depositing funds in an interest-bearing account, but without centralized custody risk.</p><h2>2. Unlock Liquidity Without Selling</h2><p>Long-term holders often do not want to sell core assets like ETH or QIE. Lending protocols allow users to:</p><ul><li>Borrow stablecoins against holdings</li></ul><p>This is one of the primary drivers of DeFi lending adoption globally.</p><h2>3. Capital Efficiency for Traders</h2><p>Active traders can use borrowed liquidity to:</p><ul><li>Fund additional positions</li><li>Participate in new opportunities</li></ul><p>All while keeping their base collateral intact.</p><p>QIELend is currently offering highly competitive borrowing conditions:</p><ul><li><p>QUSDC borrowing from as low as 0.01% APR</p></li><li><p>Volatile assets like WQIE around 5% APR</p></li></ul><p>Collateral requirements are dynamically risk-based:</p><ul><li>up to ~80% drawdown protection for QUSDC</li></ul><p>This risk-weighted model helps maintain protocol stability while maximizing capital efficiency for users.</p><h2>Built for Interoperability</h2><p>A major strength of QIELend is its cross-chain asset pipeline.</p><p>Users can seamlessly onboard major crypto assets into the QIE ecosystem:</p><p><img src=\"https://cdn.hackernoon.com/images/FS1PiuQb1sWxoW2ESuJpZswu0xk2-6o83hy8.jpeg\" alt=\"\">Bridge ETH and BNB to QIE:</p><p>üëâ https://www.bridge.qie.digital/</p><p>Swap native QIE to WQIE (QIE-20 standard):</p><p>üëâ https://www.swap.dex.qie.digital/swap</p><p>Standardizing assets into the QIE-20 format ensures that all markets ‚Äúspeak the same language,‚Äù improving composability across DeFi applications.</p><p>Getting started with QIELend is intentionally straightforward:</p><ol><li>Connect via MetaMask or QIE Wallet</li><li>Earn yield or borrow against collateral</li></ol><p>If assets imported via MetaMask are not immediately visible, users may simply refresh the interface after supplying funds.</p><p>Token contract addresses for supported assets can always be verified via the QIE explorer:</p><p>Notably, QIE Wallet already includes these assets by default for a smoother onboarding experience.</p><p>Maximizing Returns with Smart Looping</p><p>For users looking to go beyond basic lending, QIElend introduces an efficient looping mechanism designed to enhance capital productivity. Instead of earning yield on a single supply, users can manually re-supply borrowed assets in a streamlined flow, effectively increasing their exposure to lending rewards and incentive programs. Because QIElend runs on the ultra-low-fee QIE network, this strategy remains practical even for smaller portfolios where high gas costs on other chains would normally erode profits. The result is a more capital-efficient approach to DeFi yield, supported by clear health-factor visibility and built-in risk awareness tools.</p><h2>Why QIELend Matters for the QIE Ecosystem</h2><p>Every successful Layer-1 ecosystem eventually requires a robust money market. Lending protocols create:</p><ul><li>stronger DeFi composability</li></ul><p>By launching early and focusing on efficiency, QIELend is positioning itself as the core liquidity engine of the QIE financial stack.</p><p>As additional assets like XRP and Solana come online, the protocol‚Äôs addressable liquidity universe is expected to expand meaningfully.</p><h2>QIElend vs Aave: The Next Evolution in DeFi Lending Efficiency</h2><p>QIElend offers a structurally more efficient lending experience than legacy DeFi protocols such as Aave by removing much of the operational friction that arises from high gas costs and slower block-based execution. While established platforms rely on traditional on-chain transaction models where every supply, borrow, or repayment incurs meaningful network fees and timing delays, QIElend is built natively on the high-performance QIE blockchain, enabling near-zero-cost transactions and near-instant position updates.</p><p>This allows users to manage collateral more actively, reduces the incentive burden on liquidators, and supports faster market rebalancing, which in turn can translate into more competitive effective borrowing rates. By optimizing liquidity specifically for its ecosystem rather than competing across congested global markets, QIElend delivers a lending environment designed for speed, capital efficiency, and practical usability at scale.</p><p>QIELend brings a proven DeFi primitive ‚Äî decentralized lending ‚Äî into a faster and more cost-efficient environment on the QIE Blockchain.</p><p>With live liquidity, competitive borrowing rates, and a growing multi-asset pipeline, the protocol provides both yield opportunities for suppliers and flexible capital access for borrowers.</p><p>For users seeking Aave-style functionality without high network friction, QIELend represents an important step forward in the evolution of the QIE ecosystem.</p><p>:::tip\nThis story was published as a press release by Btcwire under HackerNoon‚Äôs Business Blogging&nbsp;</p><p>This article is for informational purposes only and does not constitute investment advice. Cryptocurrencies are speculative, complex, and involve high risks. This can mean high prices volatility and potential loss of your initial investment. You should consider your financial situation, investment purposes, and consult with a financial advisor before making any investment decisions. The HackerNoon editorial team has only verified the story for grammatical accuracy and does not endorse or guarantee the accuracy, reliability, or completeness of the information stated in this article. #DYOR</p>",
      "contentLength": 7137,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Chinese Official's Use of ChatGPT Revealed a Global Intimidation Opperation",
      "url": "https://tech.slashdot.org/story/26/02/26/2045225/chinese-officials-use-of-chatgpt-revealed-a-global-intimidation-opperation?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1772140800,
      "author": "BeauHD",
      "guid": 48652,
      "unread": true,
      "content": "New submitter sabbede shares a report from CNN Politics: A sprawling Chinese influence operation -- accidentally revealed by a Chinese law enforcement official's use of ChatGPT -- focused on intimidating Chinese dissidents abroad, including by impersonating US immigration officials, according to a new report from ChatGPT-maker OpenAI. The Chinese law enforcement official used ChatGPT like a diary to document the alleged covert campaign of suppression, OpenAI said. In one instance, Chinese operators allegedly disguised themselves as US immigration officials to warn a US-based Chinese dissident that their public statements had supposedly broken the law, according to the ChatGPT user. In another case, they describe an effort to use forged documents from a US county court to try to get a Chinese dissident's social media account taken down. \"This is what Chinese modern transnational repression looks like,\" Ben Nimmo, principal investigator at OpenAI, told reporters ahead of the report's release. \"It's not just digital. It's not just about trolling. It's industrialized. It's about trying to hit critics of the CCP [Chinese Communist Party] with everything, everywhere, all at once.\"\n \nMichael Horowitz, a former Pentagon official focused on emerging technologies, said the report from OpenAI \"clearly demonstrates the way that China is actively employing AI tools to enhance information operations. US-China AI competition is continuing to intensify. This competition is not just taking place at the frontier, but in how China's government is planning and implementing the day-to-day of their surveillance and information apparatus.\"",
      "contentLength": 1644,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Google paid startup Form Energy $1B for its massive 100-hour battery",
      "url": "https://techcrunch.com/2026/02/26/google-paid-startup-form-energy-1b-for-its-massive-100-hour-battery/",
      "date": 1772139863,
      "author": "Tim De Chant",
      "guid": 48641,
      "unread": true,
      "content": "<article>The deal paves the way for Form Energy to raise a new funding round before potentially going public next year.</article>",
      "contentLength": 110,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "DOJ‚Äôs Losing Streak Continues Because Federal Officers Just Can‚Äôt Stop Lying",
      "url": "https://www.techdirt.com/2026/02/26/dojs-losing-streak-continues-because-federal-officers-just-cant-stop-lying/",
      "date": 1772139240,
      "author": "Tim Cushing",
      "guid": 48647,
      "unread": true,
      "content": "<p>I‚Äôll take my joy where I can. And this iteration of the Trump DOJ continues to provide bright bursts of schadenfreude-tinted sunshine. </p><p>Any competent DOJ can close cases. Any  competent prosecutor can push a case past a grand jury. Any sufficiently slippery solicitor (mixing in some British for the sheer alliteration of it all) can convince a judge that the lies told by officers were merely good faith blunders not worthy of anything more than a judicial ‚Äúno one‚Äôs perfect‚Äù shrug.</p><p> DOJ <a href=\"https://www.techdirt.com/2025/12/31/rule-of-law-administration-keeps-losing-cases-because-it-has-no-respect-for-the-rule-of-law/\" data-type=\"link\" data-id=\"https://www.techdirt.com/2025/12/31/rule-of-law-administration-keeps-losing-cases-because-it-has-no-respect-for-the-rule-of-law/\">fails at </a>. It can‚Äôt <a href=\"https://www.techdirt.com/2025/07/29/trump-may-be-winning-on-main-but-his-local-prosecutors-cant-even-get-grand-jury-indictments/\" data-type=\"link\" data-id=\"https://www.techdirt.com/2025/07/29/trump-may-be-winning-on-main-but-his-local-prosecutors-cant-even-get-grand-jury-indictments/\">secure indictments</a>. It can‚Äôt convince grand juries that vindictive prosecutions are  prosecutions. And its prosecutors are constantly undermined by (1) prejudicial, fact-free social media posts and public statements by administration officials, (2) the <a href=\"https://www.techdirt.com/2025/11/24/federal-judge-spends-most-of-233-pages-calling-out-dhs-ice-cbp-border-patrol-for-their-lies/\" data-type=\"link\" data-id=\"https://www.techdirt.com/2025/11/24/federal-judge-spends-most-of-233-pages-calling-out-dhs-ice-cbp-border-patrol-for-their-lies/\">illegal actions</a> of federal officers, (3) their own ineptitude, (4) the lies <a href=\"https://www.techdirt.com/2025/08/11/trump-doj-cant-score-ice-protest-convictions-because-federal-officers-keep-lying/\" data-type=\"link\" data-id=\"https://www.techdirt.com/2025/08/11/trump-doj-cant-score-ice-protest-convictions-because-federal-officers-keep-lying/\">told by federal officers</a>, and (5) any or all of the above.</p><p>High-level prosecutors keep getting sidelined because they‚Äôve been <a href=\"https://www.techdirt.com/2026/01/13/trumps-loyalist-prosecutors-continue-to-get-kicked-off-cases-because-theyre-not-legally-appointed/\" data-type=\"link\" data-id=\"https://www.techdirt.com/2026/01/13/trumps-loyalist-prosecutors-continue-to-get-kicked-off-cases-because-theyre-not-legally-appointed/\">illegally appointed</a>. Other prosecutors have refused to engage with the administration‚Äôs vindictive plans, resulting in most of them retiring or being fired. Consequently, there‚Äôs a shortage of qualified, experienced prosecutors. The void is being constantly refilled by some of the emptiest people ever to leverage MAGA loyalty into federal employment. </p><p>It took less than a year for the Trump DOJ to almost completely destroy the ‚Äú<a href=\"https://www.justsecurity.org/120547/presumption-regularity-trump-administration-litigation/\" data-type=\"link\" data-id=\"https://www.justsecurity.org/120547/presumption-regularity-trump-administration-litigation/\">presumption of regularity</a>‚Äù ‚Äî the legal concept that the government is acting in good faith, even if its legal arguments aren‚Äôt the best. It took less than a year for the Trump DOJ to <a href=\"https://www.techdirt.com/2026/01/16/welcome-to-the-resistance-grand-juries/\" data-type=\"link\" data-id=\"https://www.techdirt.com/2026/01/16/welcome-to-the-resistance-grand-juries/\">turn grand juries</a> into coin flips.</p><blockquote><p><em>In 2016, the most recent year for which&nbsp;<a href=\"https://bjs.ojp.gov/content/pub/pdf/fjs16st.pdf\">the Justice Department has published data</a>, federal prosecutors concluded more than 155,000 prosecutions and declined over 25,000 cases presented by investigators.&nbsp;<strong>In only six instances was a grand jury‚Äôs refusal to indict listed as the reason for dropping the matter</strong>.</em></p></blockquote><p>Six times in a one year over 25,000 declined cases. Trump‚Äôs loyalist US Attorney pick, Lindsey Halligan, put her insurance law background to work and‚Ä¶ managed to do this twice during a  (attempted) prosecution. </p><p>When prosecutors aren‚Äôt shooting themselves in the foot (or being shot in the foot by their employer), they‚Äôre losing cases because the people they expect to back up their cases ‚Äî the federal officers claiming to have been assaulted, etc. ‚Äî can‚Äôt even back up their own narratives when testifying in court.</p><blockquote><p><em>The most recent significant fumble came from Minneapolis prosecutors, who last week&nbsp;<a href=\"https://www.theguardian.com/us-news/2026/feb/13/justice-department-moves-to-drop-charges-alfredo-alejandro-aljorna-julio-cesar-sosa-celis-ice-minnesota\">dismissed felony assault charges</a>&nbsp;they had filed against two Venezuelan men&nbsp;<a href=\"https://www.dhs.gov/news/2026/01/15/dhs-releases-more-details-about-three-violent-criminal-illegal-aliens-who-violently\">accused</a>&nbsp;of ‚Äúviolently beating‚Äù an Immigration and Customs Enforcement (ICE) officer ‚Äúwith weapons‚Äù on 14 January.</em></p></blockquote><p>According to the early government narrative, federal officers were assaulted by ‚Äúviolent criminal illegal aliens‚Äù during a stop of an undocumented Venezuelan. The officers claimed two other men came out of a nearby apartment and attacked an officer with a ‚Äúsnow shovel and broom handle.‚Äù That case is now dead because‚Ä¶ well, the testifying officers lied. </p><blockquote><p><em>[O]n 12 February, prosecutors filed a motion to dismiss both men‚Äôs cases, saying: ‚ÄúNewly discovered evidence in this matter is materially inconsistent with the allegations in the complaint affidavit.‚Äù</em></p><p><em>ICE director Todd Lyons said ICE and the DoJ had&nbsp;<a href=\"https://www.theguardian.com/us-news/2026/feb/13/ice-officers-minneapolis\">opened an investigation</a>&nbsp;into the case after videos revealed ‚Äúsworn testimony provided by two separate officers appears to have made untruthful statements‚Äù, marking a rare acknowledgement of possible wrongdoing by DHS officials.</em></p></blockquote><p>It‚Äôs extremely rare for the government to dismiss its  prosecution with prejudice, meaning it can‚Äôt  seek to refile these criminal charges against the alleged perpetrators. And I don‚Äôt know if Todd Lyons just misspoke or if he actually tried to use the exonerative tense while simultaneously stating these officers lied. ‚ÄúSworn testimony‚Ä¶ appears to have made untruthful statements‚Äù sounds like the courtroom version of a government official discussing a shooting by an officer with the phrase ‚Äúthe officer‚Äôs weapon discharged,‚Äù suggesting no one actually pulled the trigger.</p><p>Whatever the case, there‚Äôs definitely a trend here. </p><blockquote><p><em>In Chicago, of 92 people arrested for assaulting or impeding officers last fall, 74 cases have resulted in no charges; in 13 cases, charges were filed and dismissed; and five charged cases were still pending, a&nbsp;<a href=\"https://www.fox9.com/news/dhs-arrests-assaulting-ice-agents-rarely-charged-regularly-dismissed-jan-28\">recent investigation</a>&nbsp;by Fox 9, a Minneapolis-based station, showed. As of the end of January, there have been no convictions.</em></p><p><em>In LA, the federal public defenders have won all six cases filed against ICE protesters that have gone to trial since June, the&nbsp;<a href=\"https://www.latimes.com/california/story/2026-02-06/federal-public-defenders-winning\">LA Times recently reported</a>. Fewer than 1% of federal criminal defendants were acquitted across the US in fiscal year 2024, with US prosecutors traditionally having a roughly 90% conviction rate, the paper noted.</em></p></blockquote><p>I assume the DOJ bloodshed will continue. Trump hates losing and he hates people who lose in his name even more. But replacing talent with loyalists isn‚Äôt going to end this losing streak. If nothing else, this iteration of the DOJ has the chance to go down in history as one of the worst ever assembled, even if we consider nothing else but its win-loss record. </p><p>It doesn‚Äôt mean the DOJ is harmless, however. It‚Äôs still more than willing to engage in vindictive prosecutions, ignore court orders, and take bite after bite of the apple (so to speak) until it finally manages to at least pierce the skin. And that means a lot of people are going to have their lives upended, even if only temporarily, just to please a tyrant who thinks anything or anyone presenting even the most minimal of opposition should be subjected to punishment. </p>",
      "contentLength": 5778,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "iPhone and iPad Are First Consumer Devices Cleared for NATO Classified Data",
      "url": "https://mobile.slashdot.org/story/26/02/26/2036231/iphone-and-ipad-are-first-consumer-devices-cleared-for-nato-classified-data?utm_source=rss1.0mainlinkanon&utm_medium=feed",
      "date": 1772138400,
      "author": "BeauHD",
      "guid": 48640,
      "unread": true,
      "content": "Apple's iPhone and iPad running iOS 26 and iPadOS 26 have become the first consumer mobile devices cleared for NATO-restricted classified data. No special software or settings are required. MacRumors reports: Apple's devices are the first and only consumer mobile products that have reached this government certification level after security testing and evaluation by the German government. iPhones and iPads running iOS 26 and iPadOS 26 are now certified for use with classified data in all NATO nations.\n \nIn an announcement of the security clearance, Apple touted its security features: \"Apple designs security into all of its products from the start, ensuring the most sophisticated protections are built in across hardware, software, and Apple silicon. This unique approach allows Apple users to benefit from industry-leading security protections such as best-in-class encryption, biometric authentication with Face ID, and groundbreaking features like Memory Integrity Enforcement. These same protections are now recognized as meeting stringent government and international security requirements, even for restricted data.\"",
      "contentLength": 1129,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "Microsoft Updates DirectX Shader Compiler With Improved Vulkan Driver Interoperability",
      "url": "https://www.phoronix.com/news/DX-Shader-Compiler-Better-VLK",
      "date": 1772137087,
      "author": "Michael Larabel",
      "guid": 48648,
      "unread": true,
      "content": "<article>Microsoft has published a new version of its open-source DirectX Shader Compiler. Besides adding Shader Model 6.9 production support, making this DX Compiler update interesting to us are the SPIR-V back-end improvements and enhancing interoperability with Vulkan drivers...</article>",
      "contentLength": 273,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    },
    {
      "title": "So, we‚Äôre getting Prada Meta AI glasses, right?",
      "url": "https://techcrunch.com/2026/02/26/so-were-getting-prada-meta-ai-glasses-right/",
      "date": 1772136715,
      "author": "Sarah Perez",
      "guid": 48632,
      "unread": true,
      "content": "<article>Mark Zuckerberg was at Prada's fashion week event in Milan, leaving everyone to wonder if we're getting Meta AI glasses under the Prada brand.</article>",
      "contentLength": 142,
      "flags": null,
      "enclosureUrl": "",
      "enclosureMime": "",
      "commentsUrl": null
    }
  ],
  "tags": [
    "tech"
  ]
}