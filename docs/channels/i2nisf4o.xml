<?xml version="1.0" encoding="utf-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Reddit</title><link>https://konrad.website/feeds/</link><description></description><item><title>[D] 100 Hallucinated Citations Found in 51 Accepted Papers at NeurIPS 2025</title><link>https://www.reddit.com/r/MachineLearning/comments/1qjz88r/d_100_hallucinated_citations_found_in_51_accepted/</link><author>/u/mgcdot</author><category>ai</category><category>reddit</category><pubDate>Thu, 22 Jan 2026 16:32:26 +0000</pubDate><source url="https://www.reddit.com/r/MachineLearning/top/?sort=top&amp;t=day&amp;limit=3">Reddit - ML</source><content:encoded><![CDATA[   submitted by    /u/mgcdot ]]></content:encoded></item><item><title>Rust 1.93.0 is out</title><link>https://blog.rust-lang.org/2026/01/22/Rust-1.93.0/</link><author>/u/manpacket</author><category>rust</category><category>reddit</category><pubDate>Thu, 22 Jan 2026 14:04:09 +0000</pubDate><source url="https://www.reddit.com/r/rust/top/?sort=top&amp;t=day&amp;limit=3">Reddit - Rust</source><content:encoded><![CDATA[The Rust team is happy to announce a new version of Rust, 1.93.0. Rust is a programming language empowering everyone to build reliable and efficient software.If you have a previous version of Rust installed via , you can get 1.93.0 with:If you'd like to help us out by testing future releases, you might consider updating locally to use the beta channel () or the nightly channel (). Please report any bugs you might come across!
Update bundled musl to 1.2.5The various  targets now all ship with musl 1.2.5. This primarily affects static musl builds for , , and  which bundled musl 1.2.3. This update comes with several fixes and improvements, and a breaking change that affects the Rust ecosystem.For the Rust ecosystem, the primary motivation for this update is to receive major improvements to
musl's DNS resolver which shipped in 1.2.4 and received bug fixes in 1.2.5. When using 
targets for static linking, this should make portable Linux binaries that do networking more
reliable, particularly in the face of large DNS records and recursive nameservers.
Allow the global allocator to use thread-local storageRust 1.93 adjusts the internals of the standard library to permit global allocators written in Rust
to use std's  and
 without
re-entrancy concerns by using the system allocator instead. attributes on  linesPreviously, if individual parts of a section of inline assembly needed to be 'd, the full 
block would need to be repeated with and without that section. In 1.93,  can now be applied to
individual statements within the  block.Many people came together to create Rust 1.93.0. We couldn't have done it without all of you. Thanks!]]></content:encoded></item><item><title>ZXC: another (too) fast decompressor</title><link>https://github.com/hellobertrand/zxc</link><author>/u/pollop-12345</author><category>reddit</category><pubDate>Thu, 22 Jan 2026 13:35:09 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>I made a documentary about Open Source in Ukraine and around the world</title><link>https://www.reddit.com/r/linux/comments/1qjujym/i_made_a_documentary_about_open_source_in_ukraine/</link><author>/u/whit537</author><category>reddit</category><pubDate>Thu, 22 Jan 2026 13:29:51 +0000</pubDate><source url="https://www.reddit.com/r/linux/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Linux</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>30 years of ReactOS</title><link>https://reactos.org/blogs/30yrs-of-ros/</link><author>/u/anh0516</author><category>reddit</category><pubDate>Thu, 22 Jan 2026 13:29:05 +0000</pubDate><source url="https://www.reddit.com/r/linux/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Linux</source><content:encoded><![CDATA[Happy Birthday ReactOS! Today marks 30 years since the first commit to the ReactOS source tree.
It‚Äôs been such a long journey that many of our contributors today, including myself, were not alive during this event.
Yet our mission to deliver ‚Äúyour favorite Windows apps and drivers in an open-source environment you can trust‚Äù continues to bring people together.
Let‚Äôs take a brief look at some of the high and low points throughout our history.1996-2003: The Painful Road to ReactOS 0.1.0ReactOS started from the ashes of the FreeWin95 project, which aimed to provide a free and open-source clone of Windows 95.
FreeWin95 suffered from analysis paralysis, attempting to plan the whole system before writing any code.
Tired of the lack of progress on the project, Jason Filby took the reins as project coordinator and led a new effort targeting Windows NT.
The project was renamed to ‚ÄúReactOS‚Äù as it was a reaction to Microsoft‚Äôs monopolistic position in home computer operating systems.Progress on ReactOS was very slow at first.
Contributors had to first build a very basic NT-like kernel before they could develop drivers for it, then continue developing the kernel; not too dissimilar to the process of bootstrapping a new programming language.
Once a few basic drivers were written, other contributors were able to learn from these examples and develop other drivers.While writing this article, I reached out to Eric Kohl. He developed the original storage driver stack for ReactOS (atapi, scsiport, class2, disk, cdrom, cdfs) and has been with the project since 1998. I asked him about his experiences with ReactOS during this time, how he found the project, and what contributing to ReactOS was like during those early days. He wrote:I think I found ReactOS while searching for example code for my contributions to the WINE project.
I subscribed to the mailing list and followed the discussions for a few days.
The developers were discussing the future of shell.exe, a little command line interpreter that could only change drives and directories and execute programs.
A few days [later] I had started to convert the FreeDOS command.com into a Win32 console application, because I wanted to extend it to make it 4DOS compatible.
4DOS was a very powerful command line interpreter.
On December 4th, 1998 I introduced myself and suggested to use my converted FreeDOS command.com as the future ReactOS cmd.exe.
I had a little conversation with Jason Filby and Rex Joliff, the CVS repository maintainer.
I sent my cmd.exe code to Rex and he applied it to the repository.
After applying a few more cmd-related patches over the next weeks, Rex asked me whether I would like to have write-access to the repository.
I accepted the offer‚Ä¶The first version I downloaded and used was 0.0.8.
It was not much more than a DOS-based bootloader, some drivers, and a basic kernel that ran a few test routines after initialization.Version 0.0.8 didn‚Äôt use PE files, but flat (position independent) binaries.
There was no PE loader,  no smss, no csrss, no winlogon, no process heaps, no process environments, no threads, etc.
Each and every little feature was a milestone.Initially there was not a review process at all.
You write some code, test it and fix it until it works.
Then you commit it.
If something failed on another machine, you got a reply on the mailing list and discussed a solution.
You fixed the issue and committed a fix.
That‚Äôs how it worked.There was always an open and friendly atmosphere.
It was and still is always nice to talk to other developers.
No fights, no wars, like in some other projects.Editors note: minor errors were corrected.ReactOS 0.1.0 was released on February 1st, 2003 and received minor updates up until November 2003.
ReactOS 0.1.0 was the first version of ReactOS that could boot from a CD.
It had a command line interface and no desktop.
Watch a demo of it below, provided courtesy of archeYR.During this period ReactOS saw rapid development.
New drivers were being built all the time, a basic desktop was built, and ReactOS became increasingly stable and usable.
Public interest grew as ReactOS matured.
In October 2005, Jason Filby stepped down as project coordinator, and Steven Edwards was voted to be the next project coordinator.ReactOS 0.2.x boot screenReactOS 0.2.x desktop and file explorerReactOS 0.2.0 with VMware video driver for NT 4It wasn‚Äôt all sunshine and rainbows though.
In January 2006, concerns grew about contributors having access to leaked Windows source code and possibly using this leaked source code in their contributions.
In response, Steven Edwards strengthened the project‚Äôs intellectual property policy and the project made the difficult decision to audit the existing source code and temporarily freeze contributions.The ongoing audit and contribution freeze from the end of the ReactOS 0.2.x era slowed development and momentum considerably for ReactOS 0.3.x.
Following challenges with the audit, Steven Edwards stepped down as project coordinator and Aleksey Bragin assumed the role by August 2006.Despite the challenges during this time, ReactOS 0.3.x continued to build upon ReactOS‚Äôs legacy.
ReactOS 0.3.0 was released on August 28th, 2006.
It introduced networking support and a package manager called ‚ÄúDownload!‚Äù.
This package manager would become the basis for RAPPS, the package manager built into modern versions of ReactOS.
In July 2008, the x86_64 port of ReactOS was started.
One year later, ReactOS 0.3.10 imported the UniATA driver, written by Alexandr Telyatnikov (Alter).
While we run into limitations with the UniATA driver today, UniATA enabled ReactOS to support SATA storage devices and to support partitions greater than 8GB in size.
On February 8th, 2012, ReactOS 0.3.14 supported being built using the MSVC compiler and added visual style support.Download!, the package manager for ReactOS 0.3.x2016-Today: ReactOS 0.4.xReactOS 0.4.0 was released on February 16th, 2016.
It introduced a new graphical shell that utilized more Windows features and was more similar architecturally to Windows Explorer.
ReactOS 0.4.0 also introduced support for kernel debugging using WinDbg when compiled with MSVC.
Being able to use standard Windows tools for kernel debugging has helped us progress considerably.
ReactOS 0.4.0 continued to receive incremental updates every few months up until versions 0.4.14 and 0.4.15 which had years of development updates each.
Today, the x86_64 port of ReactOS is similarly functional to its x86 counterpart, but with no WoW64 subsystem to run x86 apps its usability is limited.A humorous diagram made in 2015 to explain the complexity of Windows ExplorerReactOS 0.4.15 desktop, shown with Luna visual style and large taskbar icons appliedWe‚Äôre continuing to move ReactOS forward. Behind the scenes there are several out-of-tree projects in development. Some of these exciting projects include a new build environment for developers (RosBE), a new NTFS driver, a new ATA driver, multi-processor (SMP) support, support for class 3 UEFI systems, kernel and usermode address space layout randomization (ASLR), and support for modern GPU drivers built on WDDM.The future of ReactOS will be written by the people who believe in the mission and are willing to help carry it forward.Note: Statistics were calculated at commit f60b1c9Total unique contributors: 301Total lines of code: 14,929,578]]></content:encoded></item><item><title>[D] AISTATS 2026 Paper Acceptance Result</title><link>https://www.reddit.com/r/MachineLearning/comments/1qjuitb/d_aistats_2026_paper_acceptance_result/</link><author>/u/mathew208</author><category>ai</category><category>reddit</category><pubDate>Thu, 22 Jan 2026 13:28:29 +0000</pubDate><source url="https://www.reddit.com/r/MachineLearning/top/?sort=top&amp;t=day&amp;limit=3">Reddit - ML</source><content:encoded><![CDATA[AISTATS 2026 acceptance decisions are being released today. This thread is for discussing this year‚Äôs outcomes.   submitted by    /u/mathew208 ]]></content:encoded></item><item><title>Prominent Intel Compiler Engineer Heads Off To AMD</title><link>https://www.phoronix.com/news/Intel-Compiler-Expert-Now-AMD</link><author>/u/anh0516</author><category>reddit</category><pubDate>Thu, 22 Jan 2026 13:24:57 +0000</pubDate><source url="https://www.reddit.com/r/linux/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Linux</source><content:encoded><![CDATA[Michael Larabel is the principal author of Phoronix.com and founded the site in 2004 with a focus on enriching the Linux hardware experience. Michael has written more than 20,000 articles covering the state of Linux hardware support, Linux performance, graphics drivers, and other topics. Michael is also the lead developer of the Phoronix Test Suite, Phoromatic, and OpenBenchmarking.org automated benchmarking software. He can be followed via Twitter, LinkedIn, or contacted via MichaelLarabel.com.]]></content:encoded></item><item><title>Helm + container images across clusters... need better options</title><link>https://www.reddit.com/r/kubernetes/comments/1qjscp3/helm_container_images_across_clusters_need_better/</link><author>/u/Timely-Dinner5772</author><category>reddit</category><pubDate>Thu, 22 Jan 2026 11:42:25 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[Running container images via Helm across clusters is a mess. Every small change in image or values can break stuff. Charts get messy fast. Env overrides, tags, versions all pile up. i tried Chainguard for auditing and building images but it feels heavy and rigid for our setup. Any sug for something lighter or more flexible that works at scale? Workflows, tools, whatever. Need ideas.]]></content:encoded></item><item><title>Do not fall for complex technology</title><link>https://rushter.com/blog/complex-tech/</link><author>/u/f311a</author><category>reddit</category><pubDate>Thu, 22 Jan 2026 11:31:28 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[Fifteen years ago, I wanted to set up a note-taking system.
At the time, Evernote was the tool everyone was talking about, so choosing it seemed like the right and easy decision.After storing around 500 notes for eight years, Evernote became a mess to use.
It was bloated, heavily monetized, and slow to work with. So I wanted to switch.About that time came Notion. Everyone was talking about it. I jumped on the bandwagon and migrated a few hundred of
my notes to it that were still relevant. It did not even occur to me that switching from a bloated and slow app to
a web app would result in a similar outcome later. I followed a popular choice again.After struggling for a year, I switched to Markdown notes and a plugin for an editor that renders inline images.
I'm still using this to this day. It is simple, and I will be able to open my notes 10-20 years later.
I can edit them in any editor. It works offline and does not depend on commercial products.
I encrypt my notes locally so they can be stored safely on any cloud service.I don't even use images anymore, so this could be simple plain-text files.
Why did no one tell me that I can start simple and switch to a complex system if I really need it?It took me almost ten years to understand that, don't be like me!This process never stops. There are now Roam Research and Obsidian, where people spend more time organizing
notes than writing them. Some people become obsessed with documenting everything and never reading it anymore, just
because everyone talks how cool it is.Remember the peak of popularity of microservices and the use of GraphQL?
Small teams of 3-5 developers used them to build simple web apps
just because it was cool and big tech was writing about it a lot.Simple systems became more complex for no benefit. A complex working system should only grow from a simple one.
You need to gather initial knowledge and requirements about your project first. Iterating a simple system is much
faster and easier. When a project starts, things change a lot. It's common to rewrite the whole project from scratch 2-3
times in startups just because the initial prototype resulted in so much technical debt and bad decisions. I had experienced this
multiple times at my jobs. Not every system should be complex in the first place.If you can only start with a complex system, there is a high chance it's broken by design.The list of complex technologies is very big and I can go on and on.
Oftentimes, you don't need to use ten cloud services, hundreds of serverless functions and so on.
Not only can it be simpler, but it can also be faster and cheaper too!
You just need to ask yourself why you need a particular technology in this
project first. Sometimes the hardest part is to convince the management, though.In blogging circles, one of the popular topics is "I migrated my blog from X to Y". Some people change
their blog engines 3-4 times and I'm not an exception.I started with WordPress, then I migrated to Django, and right now my blog is completely static.When I was using Django, I needed a good server with proper caching so that when traffic spikes, it can handle it.Right now, I don't need a database. Hosting static HTML files is simple, and you can do it for free.
The only dynamic part is  comments. I'm using CloudFlare workers with a simple 50-line script that just
stores comments in Cloudflare Workers KV.They are not loaded dynamically. I just import them to markdown
files and regenerate the blog. There is no database to serve them. They are preserved in markdown forever.The whole blog engine is 800 lines of Python code that supports comments, RSS, categories, and so on.
I know exactly how it works, and adding new features is super easy. There is also nothing to hack.
Internally, static website generators are pretty complex to handle various use cases.
But, if I were using a popular static generator, adding custom features would be still hard.A lot of companies are trying to force AI everywhere. Look at Microsoft, they added it everywhere.
In most cases, it does not make the life of a user easier. In the case of Microsoft, it actually results in more bugs
and the worst UI. This time, ignoring complexity is much harder for a user, so the best shot is to switch to Linux where you have full control.I think about this a lot. It's easy to spot problems in other products, but the product that you are working on
can suffer from the same problems. It's harder to notice, especially when you don't use it.Another problem with LLMs is that it is much easier to add new features to your project now.
If you use LLMs, keep things simple and the scope of changes limited.
When you aim for big changes, the code quality drops significantly.
You stop paying attention to the changes to the point that you stop understanding how things work.There is an old tale regarding code reviews. A team lead reviewed 100 lines of code and found three bugs.
After that, he reviewed 1500 lines PR and found zero bugs. This happened because the scope of the changes was so big,
that his brain just refused to concentrate on every change.The quality of LLM output depends on code size, too.
Their context is limited, and the bigger and more complex the codebase, the worse they perform.]]></content:encoded></item><item><title>A clear visual explanation of what HTTPS protects</title><link>https://howhttps.works/why-do-we-need-https/</link><author>/u/Digitalunicon</author><category>reddit</category><pubDate>Thu, 22 Jan 2026 11:13:10 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[We need HTTPS for 3 reasons.Privacy, integrity, and identification.Let's talk about privacy first.When you browse to a website without HTTPS, I could be eavesdropping on your password.Reason number 2: integrity.I am sending another message to Browserbird unencrypted.But before it reaches Browserbird, I intercept the message.I update the message to say bad things about Browserbird and forward it to him.Why would Compugter say such things about me?And crab-in-the-middle attacks are the worst.I make sure that your communication is not being tampered with.Reason number 3: identification.Identification means that I can check that this message is coming from Compugter.HTTPS, via SSL certificates, ensures you are connected exactly with the receiver you would expect.This SSL certificate is valid and has been issued by a legitimate Certificate Authority. You are good to go.We'll be talking more about SSL certificates and Certificate Authorities soon, so stay tuned.Next on HowHTTPS.works...Now that we know the why, the next step is to understand symmetric and asymmetric encryption. Big words, but easy concepts.]]></content:encoded></item><item><title>[Media] musicfree: a cross-platform music downloader implemented in Rust</title><link>https://www.reddit.com/r/rust/comments/1qjqq51/media_musicfree_a_crossplatform_music_downloader/</link><author>/u/Every_Juggernaut7580</author><category>rust</category><category>reddit</category><pubDate>Thu, 22 Jan 2026 10:07:17 +0000</pubDate><source url="https://www.reddit.com/r/rust/top/?sort=top&amp;t=day&amp;limit=3">Reddit - Rust</source><content:encoded><![CDATA[musicfree is a music download tool written in pure Rust. It supports multiple platforms, including Windows, macOS, Unix, and Android. There are two versions available: a CLI version at musicfree and a Tauri version at musicfree-tauri.Currently, it supports downloading single videos from YouTube and Bilibili, downloading playlists, and cover images.]]></content:encoded></item><item><title>Making and Scaling a Game Server in Kubernetes using Agones</title><link>https://noe-t.dev/posts/making-and-scaling-a-game-server-in-k8s-using-agones/</link><author>/u/noe__0</author><category>reddit</category><pubDate>Thu, 22 Jan 2026 09:42:46 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[If you‚Äôre interested in Kubernetes like I am, you‚Äôve probably found yourself exploring related projects on GitHub and you might have stumbled upon a repository called Agones. If you‚Äôve never heard about it, Agones is a project created by Google to manage and deploy video game servers on Kubernetes.Recently, I dipped my toes in the water and tried it out. I had a lot of fun doing so and I want to share everything I learned. In this article, we will go over the following:The creation of a basic .Integrating it with .Its deployment on .The making of a matchmaking service in Go.Setting up and benchmarking  for our infrastructure based on the matchmaking‚Äôs player queue.I‚Äôll share a lot of relevant code snippets and diagrams, but if you want to get the full picture, you can find the source code and the Kubernetes manifests in this GitHub repository:Before going any further, we need to address a question regarding Agones:  That was my first reaction upon discovering Agones because, in theory, anyone can just deploy their game server as a regular deployment on a cluster, right? Well, things are actually a bit more complicated than that.If you look into the Agones documentation, you will find this section which basically answers the question. To put it simply, game server workloads are both stateful and stateless. An empty game server is stateless and can be safely deleted or moved, while a game server with players probably has in-memory state and must not leave the node.In other words, Agones allows you to manage and scale game server workloads based not only on CPU, memory, or traffic but also on . Thanks to that, you can update game servers without shutting down servers with active players, reuse a game server on which a game has ended or even set autoscaling based on the number of full game servers. And much more.Developing a game server in GoTo start, we obviously need a game to work with. For this purpose, I will be making a quick and simple game of  in Go.Since this is just a simple demo, I won‚Äôt be trying to make something grandiose. It will just be a basic HTTP server with a WebSocket on which two players will connect to battle. For a real game, you would probably want to use UDP connections.Both players will be connected to the WebSocket and will have to select their move. The connection stays open for both players until they both selected a move. Once both players chose their moves, the server sends the winner to them.To do this, I used standard Go packages such as  and github.com/gorilla/websocket.The root path () serves the index.html file (which is embedded in the binary) and the  path serves the WebSocket connection.The index.html is just a very basic web page with buttons for each move (rock, paper, scissors). It uses JavaScript to send a message to the WebSocket when a button is clicked. Results are displayed in the  div.I won‚Äôt go too much into details about the game logic since, well, it‚Äôs just a simple game of rock paper scissors.The game loop is fully coded in the WebSocket handler, and it uses methods from the  package located in . Here‚Äôs a basic overview of what this handler does:If you try to make something similar, keep in mind that you have to handle what happens when a player disconnects or leaves the game. In this case, I just made it so the player gets deleted from the game allowing them or someone else to rejoin. You may want to just end the game or kick everyone else if one of the players disappears.In order to manage concurrency, I use a simple  to ensure that the player list and moves are not modified at the same time. Before every operation, I lock the mutex and unlock it after the operation is complete. For example:Upon game end, the WebSocket connections are closed and the game server shuts down.The end result looks like this:Very impressive, isn‚Äôt it? Jokes aside, this simple multiplayer game will be more than enough for us to get started with Agones.Adding Agones to a game serverNow that we have a game server ready, we need to make some tweaks in order to deploy it with Agones. If you try to deploy it as of right now, it will just crash as Agones expects your container to send regular ping.To explain briefly how things work in Agones, when deploying a game server, we use the well named  resource. You can think of GameServers as the equivalent of Pods in the Agones world. They are what will be running your game server container.The main difference with regular Pods is that GameServers run your image alongside an  which is responsible for managing the lifecycle of the game server. This sidecar is responsible for ensuring that the game server is healthy and available for players. It communicates with the Kubernetes API to update the GameServer resource status.---
title: GameServer Architecture
config:
  look: handDrawn
---
graph TD
    KubeAPI["kube-apiserver"]

    subgraph GameServer["GameServer"]
        subgraph Pod["Pod"]
            GameContainer["**Your Game Server** *Container*"]
            AgonesSidecar["**agones-sdk** *Container*"]

            GameContainer <-->|SDK gRPC| AgonesSidecar
        end
    end

    AgonesSidecar -->|HTTP PATCH GameServer resource| KubeAPI
The bare minimum to get your game server up and running with Agones is to implement a . To do this, we first need to import the Agones Game Server Client SDK. In my case, I will be importing the Go package but there are also SDKs for other languages such as Java or C++ and also for game engines such as Unity or Unreal Engine.Even if your language or game engine doesn‚Äôt have an SDK, you can still use Agones by making and deploying a sidecar container alongside your game server. This sidecar container would be responsible for communicating with Agones and you would just need to communicate with your game binary. Or else, you can just communicate directly with Agones using the gRPC API or the HTTP API which should be supported by most languages.Once we have our SDK installed, we need to actually implement the health check. This is usually done by creating a loop that sends a ping to Agones every few seconds. Here‚Äôs how you can do it in Go:Now, we can technically already deploy our game server on a Kubernetes cluster with Agones by creating a  with our game container image. However, we are far from production-ready. We still need to at least implement the following Agones functions: - To indicate that the game server is ready to accept connections from players. - To tell Agones to shut down the game server.Implementing the  function is pretty straightforward. We just need to call it from the SDK when starting the game server:For the  function, things are a bit more complicated. What we want to do is to implement a graceful shutdown process. Basically, it means that we need our server to handle signals like  by waiting for everything to complete before shutting down. It is especially important in order to avoid loss of player data or of an unsaved game for instance.Fortunately, this pattern is pretty easy to implement in Go. We will be using the context package to handle cancellation and timeouts coupled with the signal package to handle, as its name implies, signals.We are first going to need to create a context that will be used all throughout our server. In order to have it be cancellable with Unix signals, we will be creating it using  from the  package. We can then, at the end of our  function, have all of our code for shutting down our server after .Currently, we handle shutdown from signals correctly, but not necessarily gracefully. In general, when implementing this pattern, we want to ensure that all ongoing operations are completed before shutting down. In our case, this isn‚Äôt really important as the process of shutting down the client SDK and the HTTP server should be pretty straightforward.However, let‚Äôs say you‚Äôre making an actual game: you may want to save the result of your game to a database, for example. In Kubernetes, Pods getting deleted are first sent a , and have a grace period of 30 seconds. After that, Kubernetes sends a , which you want to avoid if possible. If for some reason the database you‚Äôre sending your data to is experiencing issues, you will want to rollback your transaction before being forcefully terminated.We can achieve this by having a timeout, and to do that, we‚Äôre going to make, once again, a new context, but with  this time around. This way, we will be able to pass down the context with timeout to our different shutdown functions and ensure that our game server is properly shut down in a given amount of time.In my case, I set it up with a timeout of 10 seconds. This is more than enough for the Agones client SDK and the HTTP server to shut down gracefully.With all of this, we now have the lifecycle of our game server fully implemented and ready to be deployed alongside Agones‚Äô SDK sidecars in actual  resources.Now that we have our game server ready, we can deploy it on a Kubernetes cluster. I‚Äôm using a basic kind cluster for this example, but you can use any Kubernetes cluster you want. The only important requirement is to install Agones on your cluster. To do so, you can simply use Helm chart like so:We will be deploying our game server in the  namespace. If you want to deploy yours in a different one, you may need to change some values in your Helm deployment of Agones.Once we have our cluster ready with Agones up and running, we can start by deploying our game server image in a simple GameServer resource:You should then be able to see it by running . You should see something like this:Notice how Agones picked a random port between 7000 and 8000 for the game server. This port is exposed on the host node‚Äôs network using the hostPort field of Pods. This means that you can access the game server directly from your host machine using the IP address and port number.You can even check its events to see the different steps it went through:Which should give you something like this:You should be able to access the game directly from your web browser by visiting .Next, we can deploy the game server in a Fleet. If GameServers are the equivalent of Pods, you can think of Fleets as the equivalent of Deployments or StatefulSets. They allow us to have replicas of our GameServer and scale them up and down without killing active game servers. We can create one just like so:We can then check the GameServers it created:This fleet can easily be scaled up by running :But, right now, if you try to scale it down, it could kill active GameServers. What we want to do in order to avoid that is to use a GameServerAllocation. This type of resource allows us to set its state from  to , which will prevent Agones from deleting that GameServer. Let‚Äôs allocate a random GameServer from our fleet with :Now, let‚Äôs do something a bit extreme and scale the fleet down to 0 replicas:If you look at the list of GameServers, you‚Äôll notice that the one we allocated is still there:This is great, as we managed to scale down without stopping a GameServer that has been marked as being allocated for a game. If you go ahead and finish playing a game on this server, you‚Äôll notice that the GameServer gets automatically deleted.Of course, in real life, you would probably use the Kubernetes API to allocate our GameServers instead of using kubectl. This way, we can automate the allocation process without manual intervention.Making a matchmaking serviceSo far, we managed to make a game server, hook it up to Agones and deploy it on a Kubernetes cluster. All of this is great but it‚Äôs nothing we couldn‚Äôt have achieved by simply using regular Kubernetes resources such as Deployments or StatefulSets. But now that we have everything set up, we can actually go a bit further and exploit Agones‚Äô features to have a  which will scale our game servers automatically based on demand üöÄ.Or, at least, that‚Äôs what we‚Äôre going to do in the next part of this post. For now, we‚Äôll focus on making a matchmaking service that will match 2 players together and will allocate a GameServer to them.If you look online, you might find an open-source solution for matchmaking called Open Match. It has been made by Google, and it can work with Agones, which is great. However, as of writing this, there hasn‚Äôt been any update in over 2 years. A second version of Open Match called Open Match 2 seems to be planned but there are no releases yet and only a single person seems to be working on it.Here‚Äôs what we‚Äôll be working with:---
config:
  look: handDrawn
---
sequenceDiagram
    participant Player as üë§ Player
    participant WebSocketServer as üåê HTTP Server
    participant Topic_matchmaking as üìá Topic: matchmaking
    participant Matcher as ‚öôÔ∏è Matcher
    participant Topic_match_results as üìá Topic: match_results_{playerID}
    participant KubernetesAPI as ‚ò∏Ô∏è Kubernetes API

    Player->>WebSocketServer: Connect via WebSocket
    WebSocketServer->>WebSocketServer: Generate playerID
    WebSocketServer->>Topic_match_results: Subscribe
    WebSocketServer->>Topic_matchmaking: Publish playerID

    Topic_matchmaking->>Matcher: Deliver playerID

    alt No one waiting
        Matcher->>Matcher: Store playerID as waiting
        Note right of Matcher: Wait for next player
    else Another player waiting
        Matcher->>KubernetesAPI: Allocate GameServer
        KubernetesAPI-->>Matcher: GameServer address
        Matcher->>Topic_match_results: Publish match for both players
        Topic_match_results->>WebSocketServer: Deliver match result
        WebSocketServer->>Player: Redirect to match-ip:port
    end
For simplicity‚Äôs sake, I copied the base structure of the game server and reused it in the matchmaking service. This is why we are once again working with an HTTP server serving a WebSocket on . This time, we redirect the player by opening the web page the matchmaking service will return.The core component of this matchmaking system is the . As you can see on the diagram, we are working with two topics:: Player requests for a match.: Topics for the response to the player.The brain of the operation is named the , and is basically a process that will take a player from the queue and match them with another one. Once a match is made, it will reserve a GameServer by creating a  through the Kubernetes API. It then sends them both the server address they need to join via the match results topic of both player.To work with Pub/Sub in Go, we‚Äôll be using a great library called Watermill, which will simplify the task a lot. What‚Äôs great about this library is that it works with a lot of different options, including Kafka, RabbitMQ or even PostgreSQL. To keep things simple, I chose to go with a simple Go Channel which you can also use as a Pub/Sub with Watermill.Here‚Äôs how the WebSocket handler initiates the matchmaking process and waits for a match result with Watermill:As you can see, it‚Äôs pretty straightforward with functions such as  and .That‚Äôs basically it for the ‚Äúfrontend‚Äù part of the matchmaking service, but there‚Äôs a second part which is called the matcher. It runs as a goroutine but it could be run as a separate service if we were to use another Pub/Sub. It‚Äôs responsible for matching two players from the  queue.To do that, I used a Router from Watermill, which gives a lot of features that are pretty nice to build event-driven systems. In our case, I‚Äôm just using it to add a handler for the  topic, which can be done just like this:Handler functions in Watermill work like you would expect, by taking a message as input to process it.What‚Äôs really important are the parts that are highlighted. You should be able to see the basic matchmaking logic which is to set a player as  if no other player is waiting. And when a second player joins, match them together and publish the result to both players.Last but not least, we have to take a look at the  function which allocates a random GameServer and returns its IP and port. To do that, I simply use the Kubernetes API to create a resource like we made earlier.However, if you try deploying the matchmaking service just like that with a Deployment, it will actually not do anything. This is because by default, we are using the  ServiceAccount to access the Kubernetes API from our Pod. To fix this, we just need to create a new  and a  that grants the necessary permission to create  resources.And then, we can use this newly created ServiceAccount in our Deployment:Now, we can just create a Service for this Deployment and access it using port-forwarding like that:If we access the matchmaking service at  and try to play a game, we get this:As you can see from the screen briefly flashing to black, the matchmaking service indeed redirects to a game server once a match is found.Something to keep in mind is that in its current state, the matchmaking is not scalable. You can‚Äôt really run multiple instances of the matchmaking as you could end up with players stuck in different matcher‚Äôs instances.However, it shouldn‚Äôt really matter as you can shard the matchmaking service by region (eu, us, etc.) or skill-level (Elo, rank). Then, you can have an instance of the matchmaking service for each shard. For example, you could have an instance running only on eu.elo100-200.matchmaking and one on us.elo100-200.matchmaking.Also, I used a WebSocket again because I shamelessly copy-pasted the code from the game server as the base for the matchmaking service. However, you would be better off using an HTTP API where you issue a ticket and poll the match result. Or, maybe even SSE?Setting up autoscaling of game serversEverything works pretty well so far, right? Well, there‚Äôs still a problem that remains to be solved. If you‚Äôve followed along until now, so far we have a game running on Agones. There are multiple instances and a matchmaking service that routes each player to one of them. However, if we have 6 players all playing at the same time, we‚Äôll end up with our 3 games instances being allocated, making it impossible for the matchmaking service to find a game for any new players.To solve this issue, we have to set up  for our fleet of game servers. To do that, we need to create a FleetAutoscaler:I set it up with a  which ensures that there‚Äôs always a buffer of ready game servers available. In this case, I set it to 10 instances which are checked every 5 seconds.There are other policies which are also interesting to look at such as:The counter policy which scales based on a GameServer counter. It can be useful if you set up multiple rooms in a single game instance like I mentioned earlier.The webhook policy which allows us to scale based on a custom logic we can implement as a webhook handler. We can, for instance, scale it based on the number of players waiting in the matchmaking system.The WASM policy which as its name implies, allows us to scale based on a custom logic using WebAssembly modules. I have yet to find a use case for it, but it‚Äôs definitely interesting to explore.The Schedule policy which is pretty neat as it allows us to set a policy for a specific time period. It can be useful to scale up during an event or for the release of a game, for example.For simplicity‚Äôs sake, we‚Äôll continue with the buffer policy as it works decently well if we set the sync interval to a low value.Now, for the fun part, let‚Äôs put this autoscaling to the test!There‚Äôs a tool called k6 which is a load testing tool made by Grafana that can be used to simulate a large number of users connecting to our game server. We can use it to test our autoscaling policy and see how it performs under load. It simulates users with a custom script that can be written in JavaScript.Here‚Äôs the one I made for this project:As you can see, this script  opens the WebSocket connection with the matchmaking service and just sends a GET request to the game server.We‚Äôll be running this script in k6 with 100 virtual users for a duration of 30 seconds.As you can see, the autoscaler has a hard time keeping up with the load. To avoid that, we can increase the buffer size and decrease the sync interval. Or even better, switch to the webhook policy and implement a webhook endpoint which exposes the number of players currently waiting for a game server allocation.This little experiment with Agones took longer than I first expected it to be, but I learned a lot and had quite some fun. Overall, I would say that Agones is very interesting in the way it transforms how we work with Kubernetes.I think making a game and a matchmaking system from scratch to work with Agones really helped me understand better how concepts would work together. I understood so much more about Agones doing it this way than I did at first when going through the documentation.Still, there are many things I haven‚Äôt tried, such as the other autoscaling policies, using counters and lists, or just working with an actual game server with real-time communication in UDP. There are also related projects such as Quilkin which is a UDP proxy that can be used to route traffic to game servers and seems to work well with Agones.I hope this article has been helpful for you and that you have learned something new about Agones and Kubernetes. I would appreciate any feedback you might have on this article. Thank you for reading!]]></content:encoded></item><item><title>Using Go Workspaces? Stop scripting loops and use the work pattern</title><link>https://www.reddit.com/r/golang/comments/1qjngob/using_go_workspaces_stop_scripting_loops_and_use/</link><author>/u/jayp0521</author><category>golang</category><category>reddit</category><pubDate>Thu, 22 Jan 2026 06:46:53 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[‚ÄãI haven't seen this discussed much in articles or tutorials, so I wanted to share a massive quality-of-life feature I stumbled across while digging through PRs.If you use Go Workspaces, you have probably tried running `go generate ./...` from the root, only to find it fails or ignores your modules. Usually, the "fix" is searching online and finding hacky scripts involving sed, xargs, or manually iterating through every module one by one. It is annoying and brittle.It turns out there is a native, elegant way to run commands against every module in your go.work file simultaneously. You simply use work as the package target.Even AI assistants seem to hallucinate or get confused when I ask about this, likely because it‚Äôs a newer pattern that hasn't made it into the training data yet. Hopefully, this saves you some scripting time! Believe you need 1.25+]]></content:encoded></item><item><title>[D] Which data design patterns have held up for you in production?</title><link>https://www.reddit.com/r/MachineLearning/comments/1qjmqy8/d_which_data_design_patterns_have_held_up_for_you/</link><author>/u/Aggravating_Map_2493</author><category>ai</category><category>reddit</category><pubDate>Thu, 22 Jan 2026 06:07:01 +0000</pubDate><source url="https://www.reddit.com/r/MachineLearning/top/?sort=top&amp;t=day&amp;limit=3">Reddit - ML</source><content:encoded><![CDATA[I came across this article on data design patterns and found it grounded in real system behavior rather than tools. It walks through patterns that show up when supporting ML and AI workloads at scale. After reading this , I was curious to hear from others here: which patterns you rely on most, which ones failed under scale and patterns you think are overused. I am keen on hearing more about failures and lessons learned than success stories from people who have been there and done that.]]></content:encoded></item><item><title>High cardinality explained with interactive examples</title><link>https://signoz.io/blog/high-cardinality-data/</link><author>/u/ankit01-oss</author><category>reddit</category><pubDate>Thu, 22 Jan 2026 05:23:11 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Essay: Performance Reviews in Big Tech: Why ‚ÄúFair‚Äù Systems Still Fail</title><link>https://medium.com/@dmitrytrifonov/big-tech-performance-review-01fff2c5924d</link><author>/u/NoVibeCoding</author><category>reddit</category><pubDate>Thu, 22 Jan 2026 04:57:43 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Satya Nadella at Davos: a masterclass in saying everything while promising nothing</title><link>https://jpcaparas.medium.com/satya-nadella-at-davos-a-masterclass-in-saying-everything-while-promising-nothing-8495c75c5ba3?sk=a6efaf2b6a15adefcf82403ff62ef8da</link><author>/u/jpcaparas</author><category>reddit</category><pubDate>Thu, 22 Jan 2026 04:39:02 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Job Applicants Sue A.I. Recruitment Tool Company. A recently filed lawsuit claims the ratings assigned by A.I. screening software are similar to those of a credit agency and should be subject to the same laws.</title><link>https://www.nytimes.com/2026/01/21/business/ai-hiring-tools-lawsuit-eightfold-fcra.html?unlocked_article_code=1.GFA.9XQK.n_nH_2Z3omQR</link><author>/u/esporx</author><category>ai</category><category>reddit</category><pubDate>Thu, 22 Jan 2026 03:52:58 +0000</pubDate><source url="https://www.reddit.com/r/artificial/top/?sort=top&amp;t=day&amp;limit=3">Reddit - AI</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>MLFS 12.4(musl LFS)</title><link>https://www.reddit.com/r/linux/comments/1qjiei6/mlfs_124musl_lfs/</link><author>/u/Intelligent_Comb_338</author><category>reddit</category><pubDate>Thu, 22 Jan 2026 02:37:53 +0000</pubDate><source url="https://www.reddit.com/r/linux/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Linux</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Redhat Openshift vs. Suse Rancher Enterprise Support</title><link>https://www.reddit.com/r/kubernetes/comments/1qjhowq/redhat_openshift_vs_suse_rancher_enterprise/</link><author>/u/Open-Ask-1918</author><category>reddit</category><pubDate>Thu, 22 Jan 2026 02:06:39 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[Looking for real world feedback from people who have had to utilize the enterprise support offerings from Redhat and Suse for OpenShift and Ranchers on premise solutions.Who do you think provides better support?I‚Äôm looking to create multiple downstream clusters integrated VMWare and want centralized management, monitoring, and deployments. I‚Äôm thinking Rancher is better suited for this purpose but value the feedback of others more experienced and haven‚Äôt had a chance to poke around at ACM from Redhat.Also curious about which product you think is better for this job?]]></content:encoded></item><item><title>Human Intelligence, AI, and the Problem I Think We&apos;re Missing</title><link>https://www.reddit.com/r/artificial/comments/1qjfapw/human_intelligence_ai_and_the_problem_i_think/</link><author>/u/tony_24601</author><category>ai</category><category>reddit</category><pubDate>Thu, 22 Jan 2026 00:21:48 +0000</pubDate><source url="https://www.reddit.com/r/artificial/top/?sort=top&amp;t=day&amp;limit=3">Reddit - AI</source><content:encoded><![CDATA[I can vividly remember teaching my AP English class in 1999 when I first heard of ‚ÄúTurnitin.com‚Äù; my first thought was ‚Äúhow am I going to scan all of these pages into that thing?‚Äù Back then I graded papers on a first pass with my trusty No. 2 Dixon Ticonderoga pencil. Now what was I going to do?For years I used my pencil as a key aid in the writing process with my students. It was collaborative because we worked together ‚Äì I would suggest ideas an reframe sentences and thoughts to model writing in line with whatever rubric my assignment called for. Often times students adopted my suggestions whole-cloth, other times we would workshop different stylistic choices. My students and I shared in the rhetorical process. If they chose to use my margin note ‚Äútry something like this,‚Äù are they not able to claim ownership because the original words were mine and not theirs?I was the human intelligence that helped guide my students. They took my advice and incorporated it often. Other times they vehemently opposed my suggestions. I was their personal ChatGPT and I enjoyed that work immensely. But it was often brief and temporal, because I only had so much time to visit individually with 75 students. Can we really now castigate a tool that students can have beside them during every moment of their learning journey?The ethical dilemma is this: students could accept, reject, argue with, or ignore me. Today, institutions now assume AI outputs are automatically suspect while often students see them as automatically authoritative. Agency is the key issue. When I suggested phrasing, students exercised their agency to decide whether to adopt or reject my suggestions. My authority was negotiable and if they accepted my suggestions, even verbatim, authorship was never in question.Students are struggling today with teachers making them think AI is a ‚Äúforbidden oracle,‚Äù whereas teachers are also short-sighted in thinking Turnitin is an infallible detector. The problem is in both cases human judgment is being ‚Äúoutsourced.‚Äù In 1999, I trusted my students negotiate my (human) guidance; now we pretend that same negotiation between students and AI itself is the problem. What mattered was not that I was always right; but that my authority was provisional.Fast forward almost 30 years and now we not only have a tool for students to generate a decent five-paragraph essay, but a second tool that claims it can detect the use of the first. And that tool is the same one I struggled to understand in 1999: Turnitin. Although this time Turnitin is losing the battle against this newer tool, and students all over academia are suffering from that loss.Academia now is forced to embrace a structure that rewards certainty over caution. Boom: you get the AI-cheating accusation era. We‚Äôre living in a time where a student can be treated like they robbed a bank because a dashboard lit up yellow. Is this how math teachers felt about calculators when they first entered the scene? Can you today imagine any high-level mathematics course that didn‚Äôt somehow incorporate this tool? Is ChatGPT the ‚Äúwriting calculator‚Äù that in decades will sit beside every student in an English class along with that No. 2 Dixon Ticonderoga? Or will pencils continue to suffer a slow extinction?I‚Äôm not writing this because I think academic dishonesty is cute. Students absolutely can use AI to outsource thinking, and pretending otherwise is na√Øve. I‚Äôm writing this because the process of accusing students is an ethical problem now. It‚Äôs not just ‚ÄúAre people cheating?‚Äù It‚Äôs ‚ÄúWhat evidence counts, who bears the burden, and how much harm are we willing to cause to catch some portion of cases?‚Äù When a school leans on AI detectors as objective arbiters, the ethics get ugly fast: false positives, biased outcomes, coerced confessions, and a general atmosphere of suspicion that corrodes learning.I believe it is ethically wrong to treat AI-detection scores as dispositive evidence of misconduct; accusations should require due process and corroborating evidence. current detectors are error-prone and easy to game, and the harms of false accusations are severe. If institutions want integrity, they should design integrity‚Äîthrough assessment design, and clear AI-use policies, not outsource judgment to probabilistic software and call it ‚Äúaccountability.‚Äù MIT‚Äôs teaching-and-learning guidance says this bluntly: AI detection has high error rates and can lead to false accusations; educators should focus on policy clarity and assessment design instead of policing with detectors. (MIT Sloan Teaching & Learning Technologies).MA in Composition--AI Integrated Writing ]]></content:encoded></item><item><title>I have released dodo pdf reader v0.6.0</title><link>https://github.com/dheerajshenoy/dodo</link><author>/u/dheerajshenoy22</author><category>reddit</category><pubDate>Wed, 21 Jan 2026 23:46:05 +0000</pubDate><source url="https://www.reddit.com/r/linux/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Linux</source><content:encoded><![CDATA[Hello everyone, wanted to share my pdf reader dodo that I have been working for a while. it's based on MuPDF and Qt6. I started developing it because I wanted some niche features that I could not find in others, and also wanted it to be minimal and not reduce screen real-estate.Its still in alpha, I'm open to suggestions, feature requests etc.]]></content:encoded></item><item><title>&quot;proposal: spec: type inferred composite literals&quot; has been added to the active column of the proposals project</title><link>https://www.reddit.com/r/golang/comments/1qjbwth/proposal_spec_type_inferred_composite_literals/</link><author>/u/theclapp</author><category>golang</category><category>reddit</category><pubDate>Wed, 21 Jan 2026 22:07:16 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[Excerpt from the proposal:Composite literals construct values for structs, arrays, slices, and maps. They consist of a type followed by a brace-bound list of elements. e.g.,x := []string{"a", "b", "c"} I propose adding untyped composite literals, which omit the type. Untyped composite literals are assignable to any composite type. They do not have a default type, and it is an error to use one as the right-hand-side of an assignment where the left-hand-side does not have an explicit type specified.var x []string = {"a", "b", "c"} var m map[string]int = {"a": 1} type T struct { V int } var s []*T = {{0}, {1}, {2}} a := {1, 2, 3} // error: left-hand-type has no type specified Go already allows the elision of the type of a composite literal under certain circumstances. This proposal extends that permission to all occasions when the literal type can be derived.]]></content:encoded></item><item><title>Sysinfo next release needs some help</title><link>https://www.reddit.com/r/rust/comments/1qjbpbx/sysinfo_next_release_needs_some_help/</link><author>/u/imperioland</author><category>rust</category><category>reddit</category><pubDate>Wed, 21 Jan 2026 21:59:42 +0000</pubDate><source url="https://www.reddit.com/r/rust/top/?sort=top&amp;t=day&amp;limit=3">Reddit - Rust</source><content:encoded><![CDATA[As a reminder, the sysinfo crate gathers System's information such as processes, memory usage, etc.Next sysinfo release is kinda stuck at the moment as I'm trying to get the missing parts for the NetBSD support. Currently I'm missing:If anyone knows how to get the missing information, it'd be awesome!Otherwise, well, I'll just release an incomplete support.]]></content:encoded></item><item><title>Why json/v2 remains experimental in 1.26?</title><link>https://www.reddit.com/r/golang/comments/1qjb1n7/why_jsonv2_remains_experimental_in_126/</link><author>/u/alpako70</author><category>golang</category><category>reddit</category><pubDate>Wed, 21 Jan 2026 21:35:08 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[This is unpleasant surprise. I assume it is still not ready for production. But would appreciate to learn what concerns lead authors to postpone it to later.   submitted by    /u/alpako70 ]]></content:encoded></item><item><title>Results from the 2025 Go Developer Survey</title><link>https://go.dev/blog/survey2025</link><author>/u/Bomgar85</author><category>golang</category><category>reddit</category><pubDate>Wed, 21 Jan 2026 21:29:03 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[Hello! In this article we‚Äôll discuss the results of the 2025 Go Developer
Survey, conducted during September 2025.Thank you to the 5,379 Go developers who responded to our survey invitation
this year. Your feedback helps both the Go team at Google and the wider Go
community understand the current state of the Go ecosystem and prioritize
projects for the year ahead.Our three biggest findings are:Broadly speaking, Go developers asked for help with identifying and applying
best practices, making the most of the standard library, and expanding the
language and built-in tooling with more modern capabilities.Most Go developers are now using AI-powered development tools when seeking
information (e.g., learning how to use a module) or toiling (e.g., writing
repetitive blocks of similar code), but their satisfaction with these tools
is middling due, in part, to quality concerns.A surprisingly high proportion of respondents said they frequently need to
review documentation for core  subcommands, including , , and , suggesting meaningful room for improvement with the 
command‚Äôs help system.Read on for the details about these findings, and much more.Most survey respondents self-identified as professional developers (87%) who
use Go for their primary job (82%). A large majority also uses Go for personal
or open-source projects (72%). Most respondents were between 25 ‚Äì 45
years old (68%) with at least six years of professional development experience
(75%). Going deeper, 81% of respondents told us they had more professional
development experience than Go-specific experience, strong evidence that Go is
usually not the first language developers work with. In fact, one of the
themes that repeatedly surfaced during this year‚Äôs survey analysis seems to
stem from this fact: when the way to do a task in Go is substantially
different from a more familiar language, it creates friction for developers to
first learn the new (to them) idiomatic Go pattern, and then to consistently
recall these differences as they continue to work with multiple languages.
We‚Äôll return to this theme later.The single most common industry respondents work in was ‚ÄúTechnology‚Äù (46%),
but a majority of respondents work outside of the tech industry (54%). We saw
representation of all sizes of organizations, with a bare majority working
somewhere with 2 ‚Äì 500 employees (51%), 9% working alone, and 30%
working at enterprises of over 1,000 employees. As in prior years, a majority
of responses come from North America and Europe.This year we observed a decrease in the proportion of respondents who said
they were fairly new to Go, having worked with it for less than one year
(13%, vs. 21% in 2024). We suspect this is related to industry-wide
declines in entry-level software engineering roles; we commonly hear from
people that they learned Go for a specific job, so a downturn in hiring would
be expected to reduce the number of developers learning Go in that year. This
hypothesis is further supported by our finding that over 80% of respondents
learned Go  beginning their professional career.Other than the above, we found no significant changes in other demographics
since our 2024 survey.How do people feel about Go?The vast majority of respondents (91%) said they felt satisfied while working
with Go. Almost ‚Öî were ‚Äúvery satisfied‚Äù, the highest rating. Both of these
metrics are incredibly positive, and have been stable since we began asking
this question in 2019. The stability over time is really what we monitor from
this metric ‚Äî we view it as a lagging indicator, meaning by the time
this satisfaction metric shows a meaningful change, we would expect to already
have seen earlier signals from issue reports, mailing lists, or other
community feedback.Why were respondents so positive about Go? Looking at open-text responses to
several different survey questions suggests that it‚Äôs the gestalt, rather than
any one thing. These folks are telling us that they find tremendous value in
Go as a holistic platform. That doesn‚Äôt mean it supports all programming
domains equally well (it surely does not), but that developers‚Äô value the
domains it  nicely support via stdlib and built-in tooling.Below are some representative quotations from respondents. To provide context
for each quote, we also identify the satisfaction level, years of experience
with Go, and industry of the respondent.‚ÄúGo is by far my favorite language; other languages feel far too complex and
unhelpful. The fact that Go is comparatively small, simple, with fewer bells
and whistles plays a massive role in making it such a good long-lasting
foundation for building programs with it. I love that it scales well to
being used by a single programmer and in large teams.‚Äù ‚ÄúThe entire reason I use Go is the great tooling and standard library.  I‚Äôm
very thankful to the team for focusing on great HTTP, crypto, math, sync,
and other tools that make developing service-oriented applications easy and
reliable.‚Äù ‚Äú[The] Go ecosystem is the reason why I really like the programming
language. There are a lot of npm issues lately but not with Go.‚Äù This year we also asked about the other languages that people use. Survey
respondents said that besides Go, they enjoy working with Python, Rust, and
TypeScript, among a long tail of other languages. Some shared characteristics
of these languages align with common points of friction reported by Go
developers, including  areas like error handling, enums, and object-oriented
design patterns. For example, when we sum the proportion of respondents who
said their next-favorite language included one of the following factors, we
found that majorities of respondents enjoy using languages with inheritance,
type-safe enums, and exceptions, with only a bare majority of these languages
including a static type system by default.Proportion of respondentsWe think this is important because it reveals the larger environment in which
developers operate ‚Äî it suggests that people need to use different
design patterns for fairly mundane tasks, depending on the language of the
codebase they‚Äôre currently working on. This leads to additional cognitive load
and confusion, not only among developers new to Go (who must learn idiomatic
Go design patterns), but also among the many developers who work in multiple
codebases or projects. One way to alleviate this additional load is
context-specific guidance, such as a tutorial on ‚ÄúError handling in Go for
Java developers‚Äù. There may even be opportunities to build some of this
guidance into code analyzers, making it easier to surface directly in an IDE.This year we asked the Go community to share their sentiment towards the Go
project itself. These results were quite different from the 91% satisfaction
rate we discussed above, and point to areas the Go Team plans to invest our
energy during 2026. In particular, we want to encourage more contributors to
get involved, and ensure the Go Team accurately understands the challenges Go
developers currently face. We hope this focus, in turn, will help to increase
developer trust in both the Go project and the Go Team leadership. As one
respondent explained the problem:‚ÄúNow that the founding first generation of Go Team members [are] not
involved much anymore in the decision making, I am a bit worried about the
future of Go in terms of quality of maintenance, and its balanced decisions
so far wrt to changes in the language and std lib. More presence in form of
talks [by] the new core team members about the current state and future
plans might be helpful to strengthen trust.‚Äù What are people building with Go?We revised this list of ‚Äúwhat types of things do you build with Go?‚Äù from 2024
with the intent of more usefully teasing apart what people are building with
Go, and avoid confusion around evolving terms like ‚Äúagents‚Äù. Respondent‚Äôs top
use cases remain CLIs and API services, with no meaningful change in either
since 2024. In fact, a majority of respondents (55%) said they build 
CLIs and API services with Go. Over ‚Öì of respondents specifically build cloud
infrastructure tooling (a new category), and 11% work with ML models, tools,
or agents (an expanded category). Unfortunately embedded use cases were left
off of the revised list, but we‚Äôll fix this for next year‚Äôs survey.Most respondents said they are not currently building AI-powered features into
the Go software they work on (78%), with ‚Öî reporting that their software does
not use AI functionality at all (66%). This appears to be a decrease in
production-related AI usage year-over-year; in 2024, 59% of respondents were
not involved in AI feature work, while 39% indicated some level of
involvement. That marks a shift of 14 points away from building AI-powered
systems among survey respondents, and may reflect some natural pullback from
the early hype around AI-powered applications: it‚Äôs plausible that lots of
folks tried to see what they could do with this technology during its initial
rollout, with some proportion deciding against further exploration (at least
at this time).Among respondents who are building AI- or LLM-powered functionality, the most
common use case was to create summaries of existing content (45%). Overall,
however, there was little difference between most uses, with between 28%
‚Äì 33% of respondents adding AI functionality to support classification,
generation, solution identification, chatbots, and software development.What are the biggest challenges facing Go developers?One of the most helpful types of feedback we receive from developers are
details about the challenges people run into while working with Go. The Go
Team considers this information holistically and over long time horizons,
because there is often tension between improving Go‚Äôs rougher edges and
keeping the language and tooling consistent for developers. Beyond technical
factors, every change also incurs some cost in terms of developer attention
and cognitive disruption. Minimizing disruption may sound a bit dull or
boring, but we view this as an important strength of Go. As Russ Cox wrote in
2023, ‚ÄúBoring is good‚Ä¶ Boring means being able to focus on your work, not
on what‚Äôs different about Go.‚Äù.In that spirit, this year‚Äôs top challenges are not radically different from
last year‚Äôs. The top three frustrations respondents reported were ‚ÄúEnsuring
our Go code follows best practices / Go idioms‚Äù (33% of respondents), ‚ÄúA
feature I value from another language isn‚Äôt part of Go‚Äù (28%), and ‚ÄúFinding
trustworthy Go modules and packages‚Äù (26%). We examined open-text responses to
better understand what people meant. Let‚Äôs take a minute to dig into each.Respondents who were most frustrated by writing idiomatic Go were often
looking for more official guidance, as well as tooling support to help enforce
this guidance in their codebase. As in prior surveys, questions about how to
structure Go projects were also a common theme. For example:‚ÄúThe simplicity of go helps to read and understand code from other
developers, but there are still some aspects that can differ quite a lot
between programmers. Especially if developers come from other languages,
e.g. Java.‚Äù ‚ÄúMore opinionated way to write go code. Like how to structure a Go project
for services/cli tool.‚Äù ‚ÄúIt‚Äôs hard to figure out what are good idioms. Especially since the core
team doesn‚Äôt keep Effective Go up-to-date.‚Äù The second major category of frustrations were language features that
developers enjoyed working with in other ecosystems. These open-text comments
largely focused on error handling and reporting patterns, enums and sum types,
nil pointer safety, and general expressivity / verbosity:‚ÄúStill not sure what is the best way to do error handling.‚Äù ‚ÄúRust‚Äôs enums are great, and lead to writing great type safe code.‚Äù ‚ÄúThere is nothing (in the compiler) that stops me from using a maybe nil
pointer, or using a value without checking the err first. That should be
[baked into] the type system.‚Äù ‚ÄúI like [Go] but I didn‚Äôt expect it to have nil pointer exceptions :)‚Äù ‚ÄúI often find it hard to build abstractions and to provide clear intention
to the future readers of my code.‚Äù The third major frustration was finding trustworthy Go modules. Respondents
often described two aspects to this problem. One is that they considered many
3rd-party modules to be of marginal quality, making it hard for really good
modules to stand out. The second is identifying which modules are commonly
used and under which types of conditions (including recent trends over time).
These are both problems that could be addressed by showing what we‚Äôll vaguely
call ‚Äúquality signals‚Äù on pkg.go.dev. Respondents provided helpful
explanations of the signals they use to identify trustworthy modules,
including project activity, code quality, recent adoption trends, or the
specific organizations that support or rely upon the module.‚ÄúBeing able to filter by criteria like stable version, number of users and
last update age at pkg.go.dev could make things a bit easier.‚Äù ‚ÄúMany pacakges are just clones/forks or one-off pojects with no
history/maintenance. [sic]‚Äù ‚ÄúMaybe flagging trustworthy packages based on experience, maturity and
community feedback?‚Äù We agree that these are all areas where the developer experience with Go could
be improved. The challenge, as discussed earlier, is doing so in such a way
that doesn‚Äôt lead to breaking changes, increased confusion among Go
developers, or otherwise gets in the way of people trying to get their work
done with Go. Feedback from this survey is a major source of information we
use when discussing proposals, but if you‚Äôd like to get involved more directly
or follow along with other contributors, visit the Go proposals on
GitHub;
please be sure to follow this process if
you‚Äôd like to add a new proposal.In addition to these (potentially) ecosystem-wide challenges, this year we
also asked specifically about working with the  command. We‚Äôve informally
heard from developers that this tool‚Äôs help system can be confusing to
navigate, but we haven‚Äôt had a great sense of how frequently people find
themselves reviewing this documentation.Respondents told us that except for , between 15% ‚Äì 25% of them
felt they ‚Äúoften needed to review documentation‚Äù with working with these
tools. This was surprising, especially for commonly-used subcommands like
 and . Common reasons included remembering specific flags,
understanding what different options do, and navigating the help system
itself. Participants also confirmed that infrequent use was one reason for
frustration, but navigating and parsing command help appears to be the
underlying cause. In other words, we all expect to need to review
documentation sometimes, but we don‚Äôt expect to need help navigating the
documentation system itself. As on respondent described their journey:‚ÄúAccessing the help is painful. go test ‚Äìhelp # didn‚Äôt work, but tell[s] me
to type  instead‚Ä¶ go help test # oh, actually, the info I‚Äôm
looking for is in  go help testflag # visually parsing through
text that looks all the same without much formatting‚Ä¶ I just lack time to
dig into this rabbit hole.‚Äù What does their development environment look like?Operating systems and architecturesGenerally, respondents told us their development platforms are UNIX-like. Most
respondents develop on macOS (60%) or Linux (58%) and deploy to Linux-based
systems, including containers (96%). The largest year-over-year change was
among ‚Äúembedded devices / IoT‚Äù deployments, which increased from 2% -> 8% of
respondents; this was the only meaningful change in deployment platforms since
2024.The vast majority of respondents develop on x86-64 or ARM64 architectures,
with a sizable group (25%) still potentially working on 32-bit x86 systems.
However, we believe the wording of this question was confusing to respondents;
next year we‚Äôll clarify the 32-bit vs. 64-bit distinction for each
architecture.Several new code editors have become available in the past two years, and we
expanded our survey question to include the most popular ones. While we saw
some evidence of early adoption, most respondents continued to favor VS
Code (37%) or
GoLand (28%). Of the newer editors, Zed and
Cursor were the highest ranked, each becoming the preferred editor of 4% of
respondents. To put those numbers in context, we looked back at when VS Code
and GoLand were first introduced. VS Code (released in 2015) was favored by
16% of respondents one year after its release. IntelliJ has had a
community-led Go plugin longer than we‚Äôve been surveying Go developers (üíô),
but if we look at when JetBrains began officially supporting Go in IntelliJ
(2016), within one year IntelliJ was preferred by 20% of respondents.Note: This analysis of code editors does not include respondents who were
referred to the survey directly from VS Code or GoLand.The most common deployment environments for Go continue to be Amazon Web
Services (AWS) at 46% of respondents, company-owned servers (44%), and Google
Cloud Platform (GCP) at 26%. These numbers show minor shifts since 2024, but
nothing statistically significant. We found that the ‚ÄúOther‚Äù category
increased to 11% this year, and this was primarily driven by Hetzner (20% of
Other responses); we plan to include Hetzner as a response choice in next
year‚Äôs survey.We also asked respondents about their development experience of working with
different cloud providers. The most common responses, however, showed that
respondents weren‚Äôt really sure (46%) or don‚Äôt directly interact with public
cloud providers (21%). The biggest driver behind these responses was a theme
we‚Äôve heard often before: with containers, it‚Äôs possible to abstract many
details of the cloud environment away from the developer, so that they don‚Äôt
meaningfully interact with most provider-specific technologies. This result
suggests that even developers whose work is  to clouds may have
limited experience with the larger suite of tools and technology associated
with each cloud provider. For example:‚ÄúKinda abstract to the platform, Go is very easy to put in a container and
so pretty easy to deploy anywhere: one of its big strength[s].‚Äù ‚ÄúThe cloud provider really doesn‚Äôt make much difference to me. I write code
and deploy it to containers, so whether that‚Äôs AWS or GCP I don‚Äôt really
care.‚Äù We suspect this level of abstraction is dependant on the use case and
requirements of the service that‚Äôs being deployed ‚Äî it may not always
make sense or be possible to keep it highly abstracted. In the future, we plan
to further investigate how Go developers tend to interact with the platforms
where their software is ultimately deployed.Finally, we can‚Äôt discuss development environments in 2025 without also
mentioning AI-powered software development tools. Our survey suggests
bifurcated adoption ‚Äî while a majority of respondents (53%) said they
use such tools daily, there is also a large group (29%) who do not use these
at all, or only used them a few times during the past month. We expected this
to negatively correlate with age or development experience, but were unable to
find strong evidence supporting this theory except for  new developers:
respondents with less than one year of professional development experience
(not specific to Go) did report more AI use than every other cohort, but this
group only represented 2% of survey respondents.At this time, agentic use of AI-powered tools appears nascent among Go
developers, with only 17% of respondents saying this is their primary way of
using such tools, though a larger group (40%) are occasionally trying agentic
modes of operation.The most commonly used AI assistants remain ChatGPT, GitHub Copilot, and
Claude. Most of these agents show lower usage numbers compared with our 2024
survey (Claude and Cursor are
notable exceptions), but due to a methodology change, this is not an
apples-to-apples comparison. It is, however, plausible that developers are
‚Äúshopping around‚Äù less than they were when these tools were first released,
resulting in more people using a single assistant for most of their work.We also asked about overall satisfaction with AI-powered development tools. A
majority (55%) reported being satisfied, but this was heavily weighted towards
the ‚ÄúSomewhat satisfied‚Äù category (42%) vs. the ‚ÄúVery satisfied‚Äù group (13%).
Recall that Go itself consistently shows a 90%+ satisfaction rate each year;
this year, 62% of respondents said they are ‚ÄúVery satisfied‚Äù with Go. We add
this context to show that while AI-powered tooling is starting to see adoption
and finding some successful use cases, developer sentiment  towards them
remains much softer than towards more established tooling (among Go
developers, at least).What is driving this lower rate of satisfaction? In a word: quality. We asked
respondents to tell us something good they‚Äôve accomplished with these tools,
as well as something that didn‚Äôt work out well. A majority said that creating
non-functional code was their primary problem with AI developer tools (53%),
with 30% lamenting that even working code was of poor quality. The most
frequently cited benefits, conversely, were generating unit tests, writing
boilerplate code, enhanced autocompletion, refactoring, and documentation
generation. These appear to be cases where code quality is perceived as less
critical, tipping the balance in favor of letting AI take the first pass at a
task. That said, respondents also told us the AI-generated code in these
successful cases still required careful review (and often, corrections), as it
can be buggy, insecure, or lack context.‚ÄúI‚Äôm never satisfied with code quality or consistency, it never follows the
practices I want to.‚Äù ‚ÄúAll AI tools tend to hallucinate quickly when working with medium-to-large
codebases (10k+ lines of code). They can explain code effectively but
struggle to generate new, complex features‚Äù ‚ÄúDespite numerous efforts to make it write code in an established codebase,
it would take too much effort to steer it to follow the practices in the
project, and it would add subtle behaviour paths - i.e. if it would miss
some method it would try to find its way around it or rely on some side
effect. Sometimes those things are hard to recognize during code review. I
also found it mentally taxing to review ai generated code and that overhead
kills the productivity potential in writing code.‚Äù When we asked developers what they used these tools for, a pattern emerged
that is consistent with these quality concerns. The tasks with most adoption
(green in the chart below) and least resistance (red) deal with bridging
knowledge gaps, improving local code, and avoiding toil. The frustrations that
developers talk about with code-generating tools were much less evident when
they‚Äôre seeking information, like how to use a specific API or configure test
coverage, and perhaps as a result, we see higher usage of AI in these areas.
Another spot that stood out was  code review and related suggestions
‚Äî people were less interested in using AI to review other people‚Äôs code
than in reviewing their own. Surprisingly, ‚Äútesting code‚Äù showed lower AI
adoption than other toilsome tasks, though we don‚Äôt yet have strong
understanding of why.Of all the tasks we asked about, ‚ÄúWriting code‚Äù was the most bifurcated, with
66% of respondents already or hoping to soon use AI for this, while ¬º of
respondents didn‚Äôt want AI involved at all. Open-ended responses suggest
developers primarily use this for toilsome, repetitive code, and continue to
have concerns about the quality of AI-generated code.Once again, a tremendous thank-you to everyone who responded to this year‚Äôs Go
Developer Survey!We plan to share the raw survey dataset in Q1 2026, so the larger community
can also explore the data underlying these findings. This will only include
responses from people who opted in to share this data (82% of all
respondents), so there may be some differences from the numbers we reference
in this post.This survey was conducted between Sept 9 - Sept 30, 2025. Participants were
publicly invited to respond via the Go Blog, invitations on social media
channels (including Bluesky, Mastodon, Reddit, and X), as well as randomized
in-product invitations to people using VS Code and GoLand to write Go
software. We received a total of 7,070 responses. After data cleaning to
remove bots and other very low quality responses, 5,379 were used for the
remainder of our analysis. The median survey response time was between 12
‚Äì 13 minutes.Throughout this report we use charts of survey responses to provide supporting
evidence for our findings. All of these charts use a similar format. The title
is the exact question that survey respondents saw. Unless otherwise noted,
questions were multiple choice and participants could only select a single
response choice; each chart‚Äôs subtitle will tell the reader if the question
allowed multiple response choices or was an open-ended text box instead of a
multiple choice question. For charts of open-ended text responses, a Go team
member read and manually categorized all of the responses. Many open-ended
questions elicited a wide variety of responses; to keep the chart sizes
reasonable, we condensed them to a maximum of the top 10-12 themes, with
additional themes all grouped under ‚ÄúOther‚Äù. The percentage labels shown in
charts are rounded to the nearest integer (e.g., 1.4% and 0.8% will both be
displayed as 1%), but the length of each bar and row ordering are based on the
unrounded values.To help readers understand the weight of evidence underlying each finding, we
included error bars showing the 95% confidence
interval for responses;
narrower bars indicate increased confidence. Sometimes two or more responses
have overlapping error bars, which means the relative order of those responses
is not statistically meaningful (i.e., the responses are effectively tied).
The lower right of each chart shows the number of people whose responses are
included in the chart, in the form ‚Äún = [number of respondents]‚Äù.]]></content:encoded></item><item><title>Is agentless container security effective for Kubernetes workloads at scale?</title><link>https://www.reddit.com/r/kubernetes/comments/1qja0wg/is_agentless_container_security_effective_for/</link><author>/u/amylanky</author><category>reddit</category><pubDate>Wed, 21 Jan 2026 20:57:34 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[We're running hundreds of Kubernetes workloads across multiple clusters, and the idea of deploying agents into every container feels unsustainable. Performance overhead, image bloat, and operational complexity are all concerns.Is agentless container security actually viable, or is it just marketing? anyone actually secured container workloads at scale without embedding agents everywhere?]]></content:encoded></item><item><title>What are the top 5 safe, high-paying jobs that AI is unlikely to replace over the next few decades?</title><link>https://www.reddit.com/r/artificial/comments/1qj91oh/what_are_the_top_5_safe_highpaying_jobs_that_ai/</link><author>/u/Curious_Suchit</author><category>ai</category><category>reddit</category><pubDate>Wed, 21 Jan 2026 20:21:15 +0000</pubDate><source url="https://www.reddit.com/r/artificial/top/?sort=top&amp;t=day&amp;limit=3">Reddit - AI</source><content:encoded><![CDATA[As AI continues to automate routine and analytical tasks, many roles will evolve or disappear. This raises an important question about which careers can offer long-term security, meaningful work, and strong earning potential in an AI-driven world]]></content:encoded></item><item><title>The NexPhone is an upcoming phone that can boot desktop Linux along with Android (and Microslop Windows 11) - made for USB-C docking to monitors</title><link>https://nexphone.com/</link><author>/u/HiGuysImNewToReddit</author><category>reddit</category><pubDate>Wed, 21 Jan 2026 19:55:34 +0000</pubDate><source url="https://www.reddit.com/r/linux/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Linux</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Backpressure Patterns in Go: From Channels to Queues to Load Shedding</title><link>https://medium.com/@Realblank/backpressure-patterns-in-go-from-channels-to-queues-to-load-shedding-0841c9fe5607</link><author>/u/Real_Blank</author><category>golang</category><category>reddit</category><pubDate>Wed, 21 Jan 2026 19:38:45 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Belgrade Go meetup - Thursday, Jan 29</title><link>https://www.meetup.com/golang-serbia/events/312819083/</link><author>/u/GaussCarl</author><category>golang</category><category>reddit</category><pubDate>Wed, 21 Jan 2026 19:28:44 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[Join us for the next Golang meetup on January 29th! We have two great talks:
We will explore how testing multiple variables can identify meaningful improvements in any project. As an example, we will see how it can inform game design decisions and identify most optimal game variation. At the end we will see how a testing framework can be implemented in Go.
üá¨üáß The presentation will be in English.Desktop Applications with Go and Fyne
How to build a desktop application using Fyne. Pros and cons of UI development in Go, beginner-friendly, with practical demos. If you're interested in building Desktop applications in Go, this meetup is for you!
üá∑üá∏ The presentation will be in Serbian.
Location: Finbet Belgrade Office, Ju≈æni bulevar 10, Belgrade
Please RSVP to help us with planning.
Pozivamo vas na naredni Golang meetup koji ƒáe se odr≈æati 29.01. Imamo dva sjajna predavanja:Multivarijantno testiranje
Istra≈æiƒáemo kako testiranje vi≈°e promenljivih mo≈æe da pomogne u otkrivanju znaƒçajnih pobolj≈°anja u bilo kom projektu. Kao primer, videƒáemo kako se ovaj pristup mo≈æe koristiti za dono≈°enje odluka u dizajnu igara i za identifikovanje najoptimalnije varijante igre. Na kraju ƒáemo videti kako se testing framework mo≈æe implementirati u Go-u.
üá¨üáß Prezentacija ƒáe biti na engleskom jeziku.Desktop aplikacije sa Go i Fyne
Kako razviti desktop aplikaciju koristeƒái Fyne. Prednosti i mane UI developmenta u Go-u, beginner-friendly, sa praktiƒçnim demo primerima. Ako vas zanima pravljenje Desktop aplikacija u Go-u, ovo je meetup koji ne smete propustiti!
üá∑üá∏ Prezentacija ƒáe biti na srpskom jeziku.
Lokacija: Prostorije Finbet-a, Ju≈æni bulevar 10, Beograd
Molimo vas za RSVP kako bismo lak≈°e isplanirali dogaƒëaj.]]></content:encoded></item><item><title>RISC-V Kubernetes cluster with Jenkins on 3x StarFive VisionFive 2 (Lite)</title><link>https://youtube.com/watch?v=641TnJyHt4g&amp;amp;si=AqXuJ3-A5M7PkQjS</link><author>/u/Opvolger</author><category>reddit</category><pubDate>Wed, 21 Jan 2026 17:53:51 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>ArgoCD / Kargo + GitOps Help/Suggestions</title><link>https://www.reddit.com/r/kubernetes/comments/1qj4dyt/argocd_kargo_gitops_helpsuggestions/</link><author>/u/pixel-pusher-coder</author><category>reddit</category><pubDate>Wed, 21 Jan 2026 17:33:52 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[I've been running an argocd setup that seems to work pretty well. The main issue I had with it was that testing a deployment on say staging involves pushing to git main in order to get argo to apply my changes. I'm trying to avoid using labels. I know there's patterns that use that, but if the data is not in git to me that defeats the point. So I looked and a few GitOps solutions and Kargo seemed to be the most interesting one. The basic flow seems to be pretty slick. Watch for changes (Warehouse), creates a change-set (Freight) and Promote the change to the given Stage. The main thing that seems to be missing is applying a diff for a given environment that has both a version change AND a config change. So say I have a new helm chart with some breaking changes. I'd like to configure some values.yaml changes for say staging and update to version 2.x and promote those together to staging. If that works, It would be nice to apply the diff to prod, then staging, etc. It feels like Kargo only supports artifacts without say git/config changes. How do people manage this? If I have to do a PR for each env that won't be reflected till they get merged, then you might as well just update the version in your PR. The value add of kargo seems pretty minor at that point.Am I missing something? How to you take a change and promote it through various stages? Right now I'm just committing to main since everything is staging still but that doesn't seem like a proper pattern. ]]></content:encoded></item><item><title>[D] Do you feel like companies are scooping / abusing researchers for ideas during hiring for researcher roles?</title><link>https://www.reddit.com/r/MachineLearning/comments/1qj3t98/d_do_you_feel_like_companies_are_scooping_abusing/</link><author>/u/quasiproductive</author><category>ai</category><category>reddit</category><pubDate>Wed, 21 Jan 2026 17:13:24 +0000</pubDate><source url="https://www.reddit.com/r/MachineLearning/top/?sort=top&amp;t=day&amp;limit=3">Reddit - ML</source><content:encoded><![CDATA[After having gone through at least 3 rounds where I had to present research solutions for problems, I get the feeling that I'm doing free labour for these guys. They usually give you a week and given the current glut of candidates, it feels like this could easily be happening in the background. This includes Mid tech companies (not FAANG) and startups. Is there some truth to this suspicion?For the most recent one, I purposefully chose not to dive into the advanced literature heavy stuff even though I did do the work. The scope of the task was pretty vague ("design an ML system blah blah") and as soon as I started my presentation, one of my interviewers immediately questioned me about whether I had read the literature and wasn't interested in older approaches to the same problem. The rest of the interview was spent getting grilled, as is usual. My motivation was to work bottom up and demonstrate strong fundamentals. Perhaps, I'm missing something here]]></content:encoded></item></channel></rss>