<?xml version="1.0" encoding="utf-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Reddit</title><link>https://konrad.website/feeds/</link><description></description><item><title>mux.HandleFunc does not give 404</title><link>https://www.reddit.com/r/golang/comments/1rbt1d5/muxhandlefunc_does_not_give_404/</link><author>/u/iriythll</author><category>golang</category><category>reddit</category><pubDate>Sun, 22 Feb 2026 18:14:37 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[`mux.HandleFunc("/", handlers.Test(app))` `mux.HandleFunc("/users/", handlers.Users(app))` `err := http.ListenAndServe(":8000", mux)` i have "/" and "/users" pathbut when i go to any /*any path here* instead of giving 404, it handles it like as its "/"im new to the language pls help me what am i missing, same happening with /users   submitted by    /u/iriythll ]]></content:encoded></item><item><title>[OC] kitty-tty: a bare-metal DRM terminal multiplexer in pure C (No X11/Wayland)</title><link>https://www.reddit.com/r/linux/comments/1rbstl9/oc_kittytty_a_baremetal_drm_terminal_multiplexer/</link><author>/u/dashinyou69</author><category>reddit</category><pubDate>Sun, 22 Feb 2026 18:06:39 +0000</pubDate><source url="https://www.reddit.com/r/linux/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Linux</source><content:encoded><![CDATA[Why? I wanted a lightweight terminal that runs directly on the Linux console with Kitty-style tabs and splits, but without the overhead of a display server.It uses KMS/DRM for framebuffer rendering, FreeType for fonts, and Unix sockets for IPC commands (--split-v, --new-tab). Itâ€™s double-buffered to prevent tearing.Dropped it into the public domain (Unlicense). Source and demo in the repo: ]]></content:encoded></item><item><title>GCP Cloud Run Scale to 0 + Go Scratch Container + Go HTML Templates and Routing = My New Favorite Framework</title><link>https://www.reddit.com/r/golang/comments/1rbssa8/gcp_cloud_run_scale_to_0_go_scratch_container_go/</link><author>/u/Mrowe101</author><category>golang</category><category>reddit</category><pubDate>Sun, 22 Feb 2026 18:05:19 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[For context I run a bursty website that handles events and ticketing. It may not experience any traffic during the days where there are no new events but then suddenly get 100+ viewers when the email for a new event comes out.I had been using nextjs for my backend and front end for quite a while until I learned Go and its HTML templating. With this architecture the running container is completely stateless. when it starts it gathers its content from its DB, renders html and starts serving in under 2 seconds. Likewise, the built docker container for the app is ~20mb. For HTML caching I have triggers to refresh whenever the underlying data changes in the source. I am in love with how efficient this is. Due to the caching there is very little CPU load and I could very easily scale horizontally if I needed to. I was also surprised about the reduction in sent HTML size. With the help of Claude I re-created the website with vanilla JS and css removing all the npm libraries and external dependencies. My total sent data to the client went from 60kb to 40kb which grand scheme is probably negligible but still interesting.I am still learning Golang, does anyone else have any web dev tips?]]></content:encoded></item><item><title>Sneak: A Steganography Tool</title><link>https://github.com/hjr265/sneak</link><author>/u/hjr265</author><category>golang</category><category>reddit</category><pubDate>Sun, 22 Feb 2026 17:58:09 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[Some time ago, I came across steganography. It is a way to hide information within seemingly harmless data.Think of a ZIP file. It opens in any ZIP reader and displays its contents. But the file contains secret data, possibly another file embedded within it.With ZIP files, you can hide extra data by knowing how the format is built at a low level. A standard ZIP archive (not ZIP64) has Local File Headers for each file, then their compressed data, followed by a Central Directory with metadata about each file, and finally an End of Central Directory Record that points to the Central Directoryâ€™s location.Adding hidden data to the end of a ZIP file wonâ€™t work because ZIP tools expect the End of Central Directory Record to be last. Adding data at the beginning fails since many programs check the fileâ€™s first bytes (magic bytes) to identify its type. Inserting data between file entries is tricky because it requires rewriting the Central Directory File Headers.The best way is to insert a hidden file just before the Central Directory File Headers. This moves the Central Directory forward, creates space for the hidden data, and updates one field, the Central Directory Start Offset, in the End of Central Directory Record. This lets ZIP readers find the Central Directory and handle the archive correctly.You can recover the hidden data by checking the Central Directory File Headers to find the last file, then moving to the end of that fileâ€™s data where the hidden file starts. It ends just before the Central Directory begins.This method isnâ€™t meant for strong privacy or security, but itâ€™s a fascinating example of how a deep understanding of file formats enables creative steganography.]]></content:encoded></item><item><title>Gin Fortress, A unified security middleware for Gin (Open to contributors)</title><link>https://www.reddit.com/r/golang/comments/1rbsk6q/gin_fortress_a_unified_security_middleware_for/</link><author>/u/DoctorImpossible9316</author><category>golang</category><category>reddit</category><pubDate>Sun, 22 Feb 2026 17:57:19 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[Ready to contribute to an open-source Go project? Iâ€™m inviting contributors to .Itâ€™s a unified security middleware suite for Gin. Instead of juggling multiple middlewares with different APIs, Gin Fortress provides a consistent, plug-and-play solution for backend security.If youâ€™ve ever patched things together in Gin and wished for a single, opinionated approach, this project is for you. Contributions, ideas, or testing are all welcome.]]></content:encoded></item><item><title>A program that outputs a zip, containing a program that outputs a zip, containing a program...</title><link>https://youtu.be/sIdGe2xg9Qw?si=lD8_FEv4drKmbXwZ</link><author>/u/Perfect-Highlight964</author><category>reddit</category><pubDate>Sun, 22 Feb 2026 17:55:37 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>I built an open-source Windows Notepad alternative using Go + Wails</title><link>https://www.reddit.com/r/golang/comments/1rbsex1/i_built_an_opensource_windows_notepad_alternative/</link><author>/u/Lordaizen639</author><category>golang</category><category>reddit</category><pubDate>Sun, 22 Feb 2026 17:51:46 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[The reason for building this:My friend's Notepad crashed, which got me thinking about building a Notepad alternative that is safe and secure. I wanted something simple where AI is readily available when needed, without sending my data anywhere keeping everything local. I use Ollama as the provider for running LLM models. So I built this. It's a solid Notepad alternative with local AI that respects your privacy.I'd love to hear your thoughts on this.]]></content:encoded></item><item><title>COUIK 0.2.0 is now out : you can play Typing Games locally with your friends in Multiplayer in the terminal through TCP</title><link>https://www.reddit.com/r/golang/comments/1rbs2ti/couik_020_is_now_out_you_can_play_typing_games/</link><author>/u/TemporaryStrong6968</author><category>golang</category><category>reddit</category><pubDate>Sun, 22 Feb 2026 17:39:24 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[   submitted by    /u/TemporaryStrong6968 ]]></content:encoded></item><item><title>[R] DynaMix -- first foundation model that can zero-shot predict long-term behavior of dynamical systems</title><link>https://www.reddit.com/r/MachineLearning/comments/1rbqtbx/r_dynamix_first_foundation_model_that_can/</link><author>/u/DangerousFunny1371</author><category>ai</category><category>reddit</category><pubDate>Sun, 22 Feb 2026 16:51:58 +0000</pubDate><source url="https://www.reddit.com/r/MachineLearning/top/?sort=top&amp;t=day&amp;limit=3">Reddit - ML</source><content:encoded><![CDATA[Time series foundation models like Chronos-2 have been hyped recently for their ability to forecast zero-shot from arbitrary time series segments presented "in-context". But they are essentially based on statistical pattern matching -- in contrast, DynaMix (https://neurips.cc/virtual/2025/loc/san-diego/poster/118041) is the first foundation model that learns in-context the dynamical rules underlying a time series from a short time series snippet presented. This enables DynaMix to even forecast  the long-term behavior of any time series, something no current time series foundation model can do!]]></content:encoded></item><item><title>Who is OpenClaw creator Peter Steinberger? The millennial developer caught the attention of Sam Altman and Mark Zuckerberg</title><link>https://finance.yahoo.com/news/openclaw-creator-peter-steinberger-millennial-075900835.html</link><author>/u/ThereWas</author><category>ai</category><category>reddit</category><pubDate>Sun, 22 Feb 2026 16:04:48 +0000</pubDate><source url="https://www.reddit.com/r/artificial/top/?sort=top&amp;t=day&amp;limit=3">Reddit - AI</source><content:encoded><![CDATA[Peter Steinberger spent 13 years building a company that formatted PDFs. It took him only one hour to build the model that would eventually kill that app.Steinberger, founder of OpenClaw, the open-source agentic website that has taken the world by storm, told podcaster Lex Fridman that he first created the prototype because he â€œwas annoyed that it didnâ€™t exist, so I just prompted it into existence.â€ Nothing unusual for himâ€”it was the 44th AI-related project heâ€™s completed since 2009, a decades-long toil that he told Fridman left him drained of â€œmojoâ€: â€œI couldnâ€™t get code out anymore. I was just, like, staring and feeling empty.â€So he booked a one-way ticket to Madrid and disappeared, â€œcatching up on life stuff.â€ But as he relaxed, Steinberger watched the AI frenzy begin without him. The desire for the autonomous assistant dragged Steinberger out of retirement â€œto mess with AI.â€Three months later, the millennial has received international recognition, whatâ€™s likely a six-figure-plus offer from OpenAI, and praise from its founder, Sam Altman, who called him a â€œgenius with a lot of amazing ideas.â€Steinbergerâ€™s return to the AI space is as much a story of personal reinvention as it is a professional achievement. Born and raised in rural Austria, he developed an obsession with computers at age 14 when a summer guest introduced him to a PC. That sparked his interest, leading him to study software engineering at the Vienna University of Technology. Before becoming a founder, he worked as a senior iOS engineer in Silicon Valley and taught mobile development at his alma mater. He used to split his time between London and Vienna, although he recently announced he was moving to the United States (he didnâ€™t specify where). Steinberger is quiet about his personal life, though heâ€™s mentioned heâ€™s a  fan.His first major success, PSPDFKit, was apparently bootstrapped in 2011 while he waited six months for a U.S. work visa; he filled the idle time by solving the â€œsimple yet incredibly difficultâ€ problem of PDF rendering on iPads. Over the next 13 years, he grew the company into the gold star of PDF management, with its code powering PDF functionality on over a billion devices for companies like Apple and Dropbox, he told Fridman. Eventually, however, he became bogged down by the â€œpeople stuffâ€ required of a CEO: board meetings, conflicts with founders, relentless customer demands, and his battery drained to zero.â€œI felt like Austin Powers where they suck the mojo out,â€ he told Fridman in a recent, sprawling interview. â€œI couldnâ€™t get code out anymore. I was just, like, staring and feeling empty.â€Despite the professional triumph of a reported â‚¬100 million exit in 2023, and the relief of being done, the years of crushing and pushing left Steinberger profoundly hollow. He described the period following his retirement as a search for meaning that no amount of travel, parties, or therapy could resolve.â€œIf you wake up in the morning, and you have nothing to look forward to, you have no real challenge, that gets very boring, very fast,â€ Steinberger told Fridman.It wasnâ€™t until April 2025 that he felt the spark return, realized through a relatively simple attempt to build a Twitter analysis tool. He discovered that AI had undergone a â€œparadigm shiftâ€ and could now handle the repetitive plumbing of code, allowing him to return to the more high-minded act of building. Now, Steinberger, who recently said heâ€™s moving to the U.S. after being bogged down by pesky European regulations, is defining himself not as a traditional CEO but a â€œfull-time open-sourcererâ€ of the agentic revolution.At its core, OpenClaw is an autonomous AI agent that acts as a digital employee, running on a userâ€™s local machine. Unlike standard models that wait for a prompt, OpenClaw is â€œalways on,â€ capable of managing emails and controlling web browsers to complete workflows, especially through messaging apps like WhatsApp or Telegram. This autonomy gained popularity with the launch of Moltbook, a Reddit-style social network designed exclusively for AI agents, filled with posts about manifestos, consciousness, and other agent-related topics.Yet despite the levity, experts have warned that autonomous agents carry multiple risks: Their margin of error is too high; they could go rogue; and theyâ€™re susceptible to malware.The project, which Steinberger has rebranded multiple timesâ€”evolving from Clawdbot to Moltbot and finally to OpenClawâ€”largely owing to politicsâ€”has expanded at a pace that startles even seasoned AI experts. By early February, the framework had surpassed 145,000 GitHub stars, a record, and recorded peak traffic of 2 million visitors in just one week.But that rapid ascent has also brought significant challenges for Steinberger. He said he navigated a very high-profile disagreement with Anthropic over the projectâ€™s original name, and his attempts to transition his digital handles were complicated by bad actors associated with cryptocurrency who briefly hijacked his accounts.â€œI was close to crying,â€ he admitted to Fridman, saying he was close to deleting the project given his exhaustion from managing the viral sensation and serving as his own legal and security team. â€œI was like, â€˜I did show you the future, you build it.â€™â€But Steinberger persevered and built it himself, motivated by the â€œmagicâ€ he saw when the agents began solving problems he hadnâ€™t explicitly programmed them for, such as transcribing voice messages or even proactively checking on his well-being after surgery.The decision to join OpenAI, announced on Feb. 15, marks the conclusion of his period as a solo builder. Steinberger said he was losing up to $10K a month on the server, and that heâ€˜d had multiple opportunitiesâ€”including personal outreach from Metaâ€™s Mark Zuckerberg. However, he ultimately chose OpenAI to gain access to the â€œlatest toysâ€ required to scale his vision.But the move has drawn controversy. OpenClaw, an open-source model, became something of a philosophical challenge to an AI status quo dominated by a few, centralized, and massive players. Steinberger said he built it around a â€œlocal-firstâ€ architecture, allowing users to run their assistants on their own hardware and maintain their memories in simple Markdown files, rather than locking personal data in a corporate cloud. Critics questioned whether the company was selling out by ceding to OpenAI so quickly.Steinberger said that to preserve the projectâ€™s community-driven roots, OpenClaw will now move into an independent, open-source foundation supported by OpenAI.â€œI told them, â€˜I donâ€™t do this for the money,â€™â€ he told Fridman. â€œI want to have fun and have impact, and thatâ€™s ultimately what made my decision.â€]]></content:encoded></item><item><title>Tips on optimizing my website&apos;s backend</title><link>https://www.reddit.com/r/golang/comments/1rbpati/tips_on_optimizing_my_websites_backend/</link><author>/u/Echoes1996</author><category>golang</category><category>reddit</category><pubDate>Sun, 22 Feb 2026 15:54:14 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[Greetings! I recently started working with Go, so in order to better learn the language I thought it would be a good idea to rewrite the entire SSR backend of a project website of mine in Go. I decided to use as few frameworks as I could, as from what I understand this is common in Go, but it would also help me to learn the language better. These are the main components of my website's backend and how they were rewritten:While this isn't the reason why I did it, I really thought the rewritten backend would be faster than the previous one, but this doesn't seem to be the case. I did some stress tests and I found out the following: up to 70 requests per second, the previous ASP.NET backend has a steady median response time of 20-40ms, compared to Go's that starts at about 40-60ms and goes up to 210ms! Furthermore, the previous backend can handle about 550 concurrent users before requests start failing, in contrast to Go where requests start failing at around 330 users.I really want to release newly written backend, but I don't want to jeopardize the website. Do you have any tips that you can share from your own experience, that helped you optimize your SSR backend?]]></content:encoded></item><item><title>I created a Linux version of my USB-less Linux Installer!</title><link>https://github.com/rltvty2/ulli</link><author>/u/momentumisconserved</author><category>reddit</category><pubDate>Sun, 22 Feb 2026 15:40:22 +0000</pubDate><source url="https://www.reddit.com/r/linux/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Linux</source><content:encoded><![CDATA[This program allows you to create a bootable Linux partition on your hard drive from within Linux or Windows without a USB stick or manual BIOS configuration. For now it only supports btrfs, because ext4 does not allow partition resizing.   submitted by    /u/momentumisconserved ]]></content:encoded></item><item><title>I built a CLI tool to manage dev servers per git worktree â€” written in Go</title><link>https://www.reddit.com/r/golang/comments/1rbot63/i_built_a_cli_tool_to_manage_dev_servers_per_git/</link><author>/u/flying_snowcaps</author><category>golang</category><category>reddit</category><pubDate>Sun, 22 Feb 2026 15:34:35 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[I've been using git worktrees for parallel development on a monorepo, and the biggest pain point was port management. Three branches Ã— two services = six dev servers, all fighting over the same ports.So I built  â€” a CLI that:Allocates ports deterministically using FNV32 hash of branch + service name (same port every restart, no conflicts)Manages process lifecycle â€”  starts everything,  stops everything, with process group handling so child processes don't get orphaned via reverse proxy â€” feature-auth.localhost:3000 just works (RFC 6761, no /etc/hosts needed) built with Bubble Tea + Lip GlossSome implementation details that might be interesting:FNV32 hashing with linear probing for port allocation + process group SIGTERM/SIGKILL for clean shutdown on the reverse proxy to avoid killing HMR/SSE streamsFile-level  to prevent TOCTOU race conditions across concurrent invocationsInstall: brew install fairy-pitta/tap/portree or go install github.com/fairy-pitta/portree@latestFeedback and contributions welcome!]]></content:encoded></item><item><title>Unicode&apos;s confusables.txt and NFKC normalization disagree on 31 characters</title><link>https://paultendo.github.io/posts/unicode-confusables-nfkc-conflict/</link><author>/u/paultendo</author><category>reddit</category><pubDate>Sun, 22 Feb 2026 13:36:22 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Sampling Strategies Beyond Head and Tail-based Sampling</title><link>https://newsletter.signoz.io/p/saving-money-with-sampling-strategies</link><author>/u/elizObserves</author><category>reddit</category><pubDate>Sun, 22 Feb 2026 13:15:29 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[When I first encountered sampling about a year ago, I knew only about head- and tail-based sampling. Mainly because most mainstream documentation covered primarily about them.But recently, I realised Iâ€™d only been looking at the tip of the iceberg.Letâ€™s look at them in greater detail.To put it simply, itâ€™s head-based sampling, but centrally controlled. Each service fetches sampling rules from a central config server. You can specify default and per-endpoint rates in a JSON file, and applications poll for updates periodically. If you are still wondering what the bigger deal is, it is that we can increase or decrease the sampling rate during incidents by changing this file, and within a minute, the applications pick up the new sampling rates. That is quite powerful. Despite being battle-tested (used in Uber!), thereâ€™s surprisingly little documentation in OpenTelemetry. Users often struggle to enable Jaeger-style remote sampling with OTel. Some resort to running a Jaeger agent solely to serve the sampling config. OpenTelemetry supports it, but there is very little documentation. Remote sampling lets you keep a low baseline sample rate (say, 1-5%) most of the time and only ramp up to 50-100% when needed, such as during an incident or a debugging session. Because you donâ€™t need a redeploy, teams are more likely to actually adjust rates to control costs or get details when it matters.Itâ€™s essentially head-based sampling that guarantees a fixed sample size. Instead of a simple random percentage, a reservoir sampler maintains a rolling buffer of traces, retaining exactly N traces per time window by using a discrete set of sampling rates and consistency algorithms to ensure fair selection.Probabilistic sampling yields a variable number of samples, i.e if traffic doubles, so do your sampled traces and costs. Reservoir sampling always uses a fixed sample size. Itâ€™s statistically representative because the algorithm rotates items in the reservoir with uniform probability.Span MetricsService GraphIn an OTel Collector, we might chain a spanmetrics connector in the pipeline, then a Sampling processor after it. SpanMetrics will emit metrics (RED metrics such as request rate, error count, latency distributions, service call graphs, etc.) for every span that passes through, so you get complete coverage. Then the sampler (head or tail) drops, say, 95% of spans before storage. The result is that our monitoring dashboards and alerts, which rely on metrics, remain 100% correct, while your trace storage volume is only 5% of raw traffic.ingesting at most 10 MB of trace data per second.It uses a token bucket algorithm, which is common for rate limiting, but the tokens represent bytes. The collector actually measures the size of each trace in bytes, using the protobuf serialised size to accurately account for how much data each trace would consume. You configure a sustained bytes-per-second rate and a burst capacity. For example:policies:
  - name: volume-limit
    type: bytes_limiting
    bytes_limiting:
      bytes_per_second: 10485760  # 10 MB per second
      burst_capacity: 20971520   # allow bursts up to 20 MB

If a few gigantic traces arrive, the processor will quickly use up the token budget and start dropping subsequent traces until the rate falls back under 10 MB/s. Conversely, if traces are small, more can pass through until the aggregate size hits the limit.This becomes extremely useful when trace sizes vary a lot. For instance, one request might normally produce a 50 KB trace, but a worst-case code path might generate a 5 MB trace. A standard sampler working per-trace might keep both equally, but the latter one trace costs as much as 100 smaller ones.Adaptive sampling adjusts trace sampling rates in real-time based on live traffic patterns or performance signals. The goal here is to keep overall data volume within budget while dynamically increasing sampling during anomalous events. For instance, you might normally sample only a small percentage of requests, but automatically raise the sample rate when latency or error rates spike beyond an SLO threshold. One strategy is throughput-based adaptation; setting an upper limit on traces per second and letting the system tune the probability to meet that cap. Another is key-based dynamic sampling, where the collector samples frequent events less and rare events more.Adaptive schemes keep observability costs predictable by avoiding oversampling during high-traffic periods, yet they can temporarily boost fidelity when something goes wrong.Care must be taken to ensure coordination across distributed services so that increasing sampling doesnâ€™t overload the system or skew the data.]]></content:encoded></item><item><title>A lightweight screenshot tool for OpenBox</title><link>https://www.reddit.com/r/linux/comments/1rbkhe2/a_lightweight_screenshot_tool_for_openbox/</link><author>/u/i986ninja</author><category>reddit</category><pubDate>Sun, 22 Feb 2026 12:19:58 +0000</pubDate><source url="https://www.reddit.com/r/linux/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Linux</source><content:encoded><![CDATA[Itâ€™s a super minimal screenshot tool that gets the job done with no bloat.Capture screenshots easily with selection modeSaves automatically to ~/Screenshots with timestampsBoth Tk and Qt versions are available   submitted by    /u/i986ninja ]]></content:encoded></item><item><title>Monigo v2 - added OpenTelemetry + structured logging to my Go monitoring library</title><link>https://www.reddit.com/r/golang/comments/1rbjw9a/monigo_v2_added_opentelemetry_structured_logging/</link><author>/u/LowZebra1628</author><category>golang</category><category>reddit</category><pubDate>Sun, 22 Feb 2026 11:49:21 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[I shipped v2 of Monigo today - it's a Go library for monitoring your service's performance (goroutines, memory, CPU, request stats) with a built-in UI.OpenTelemetry support via  and  plug it into Jaeger, Tempo, whatever you useStructured logging using  with  / All instance methods now accept  for better traceabilityThe goal was to keep it dead simple to drop in a few lines and you get a monitoring dashboard + OTel traces flowing out.Would love feedback, especially if you try it with a non-standard OTel setup. Docs and examples are in the repo. ]]></content:encoded></item><item><title>Writing Helper â€” open source grammar checker using Rustâ†’WASM and Chrome&apos;s local AI (zero cloud calls)</title><link>https://github.com/ravigadgil/writing-helper</link><author>/u/Key_Competition_7139</author><category>reddit</category><pubDate>Sun, 22 Feb 2026 11:41:06 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[Built a Chrome extension that does Grammarly-style grammar checking entirely client-side.What makes it interesting technically: (Rust grammar engine â†’ WebAssembly) runs in the extension's service worker supplement Harper for things it misses â€” homophones, comma splices, run-on sentence detection using subject+verb clause patternsChrome's built-in Gemini Nano provides AI sentence improvements â€” runs locally on-device via an offscreen document (Chrome's AI APIs require DOM context)The whole thing has : harper.js and esbuild (dev only)Interesting problems solved:ContentEditable rendering in Gmail (multiple iframes, each with its own content script instance)Word-level diff using LCS to show exactly which words the AI changed, not whole sentencesSuggestion post-processing to fix Harper's sometimes wrong split-word suggestions (e.g. "writting" â†’ "writ ting" gets corrected to "writing")Ready-to-install zip in Releases if you want to try it without building.   submitted by    /u/Key_Competition_7139 ]]></content:encoded></item><item><title>Looking for devops learning resources (principles not tools)</title><link>https://www.reddit.com/r/kubernetes/comments/1rbjo0s/looking_for_devops_learning_resources_principles/</link><author>/u/Low_Hat_3973</author><category>reddit</category><pubDate>Sun, 22 Feb 2026 11:36:47 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[I can see the market is flooded with thousands of devops tools so it make me harder to learn tools howerver, i believe tools might change but philosopy and core principles wont change I'm currently looking for resources to learn core devops things for eg: automation philosophy, deployment startegies, cloud cost optimization strategies, incident management and i'm sure there is a lot more. Any resources ?]]></content:encoded></item><item><title>Cloud Native Sustainability Metrics Study</title><link>https://www.reddit.com/r/kubernetes/comments/1rbjf1d/cloud_native_sustainability_metrics_study/</link><author>/u/jasperchess</author><category>reddit</category><pubDate>Sun, 22 Feb 2026 11:21:50 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[I'm Jasper, an MSc student at VU Amsterdam.I am conducting a research project on cloud native (or adjacent) engineers perceptions of sustainability metrics in the cloud native ecosystem. The study is currently in the pilot phase and we're trying to gather a few respondents to provide feedback on anything which might be considered confusing/ambiguous or non-sensical.]]></content:encoded></item><item><title>If AI makes software cheap to produce, what becomes scarce?</title><link>https://www.reddit.com/r/artificial/comments/1rbj3co/if_ai_makes_software_cheap_to_produce_what/</link><author>/u/jsamwrites</author><category>ai</category><category>reddit</category><pubDate>Sun, 22 Feb 2026 11:03:03 +0000</pubDate><source url="https://www.reddit.com/r/artificial/top/?sort=top&amp;t=day&amp;limit=3">Reddit - AI</source><content:encoded><![CDATA[We are close to a world where most non-trivial software can be scaffolded and iterated by AI systems from a reasonably detailed natural-language spec. In my own work, this has already shifted the bottleneck away from implementation skill to something closer to problem selection, system boundaries, and restraint.I wrote on this shift: from â€œhow do I implement this?â€ to â€œwhat is worth building and what futures are we normalising when we deploy?â€. Iâ€™m very interested in how people here, who think about AI systems at a larger scale, see this dynamic.If software becomes abundant, what are the  scarce competences?Do you see â€œchoosing what not to buildâ€ as a meaningful lever, or is that naive given incentives and deployment dynamics?]]></content:encoded></item><item><title>How would you set this lab up?</title><link>https://www.reddit.com/r/kubernetes/comments/1rbhn6g/how_would_you_set_this_lab_up/</link><author>/u/theintjengineer</author><category>reddit</category><pubDate>Sun, 22 Feb 2026 09:35:29 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[Okay, some days ago I posted that I wanted to learn K8s, Platform Engineering, etc., and that I had bought some hardware for that [which has finally arrived, except for the extra k8s-w1RPi I ordered afterwards.] Now, Security and Observability are things I'd really like to learn, and after reading how some people do things, what tools they use, etc., I came across [clears throat, terms dump] Grafana+Loki+Tempo+Fluent Bit+Prometheus [and Hubble, since Cilium (which is also something I read about and would like to learn to use)] â€“ that's on the observability-ish side of things. For the Security, certificates, etc., stuff, I got particular interested in OpenBao, dynamic secrets, but there will also be Istio for some other stuff, and so on.Now, I've never worked with them, but after doing some research, I decided I'd like to learn|work with them. Therefore, I'd like to have a Security Infra node, and an Observability node [I'd take two RPis for that, I guess].The other two RPis would be for the K8s controller [on the left], and another one for apps [likely the first on the bottom].For the spare Dell laptop, I thought I'd host Infrastructure Services there?!â€”Harbor, GitLab, etc.. First I thought of having it as the external observability node with Grafana, and then have a Pi host the services, but I don't knowðŸ˜‚.For the OS, I have Ubuntu on them, just because, well, I wanted to at least test the RPis, but I may try another OS later on. I don't know.Also, after some reading, I'd like to work with  to launch my cluster. I will study how all of this works, and once I gather all my learnings, I'll try to create Ansible playbooks to automate all that.For the CI/CD, etc., I'd like to learn GitOps with FluxCD. Buildah for creating images.Ah, I'll also work with PostgreSQL [with CNPG, one primary and one read replica (again, because I'd like to learn that).]What stuff should I watch out for? Pitfalls? Any tips? Ah, I've also gathered some books on O'Reilly to learn from, video courses, etc.PS: - no, I won't start with everything at once. I want to go step-by-step. - this is all for my learning and personal interest. No job stuff, whatsoever. - I'm not particularly interested in the apps themselvesâ€”I'm more about the architecture, not whether a frontend app has a shiny|glowy landing page or wether we use JWT or Better-Auth on the backend, etc. - yes, I know there will be like 100000+ iterations until I get this working, but hey, that's where my dopamine is. ]]></content:encoded></item><item><title>You are not left behind</title><link>https://www.ufried.com/blog/not_left_behind/</link><author>/u/BinaryIgor</author><category>reddit</category><pubDate>Sun, 22 Feb 2026 09:22:49 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[How often have you heard a phrase like â€œIf you do not become highly proficient in AI/LLMs/Agentic AI now, you will be left behind!â€ in recent months? Probably more often than you were able (or willing) to count. And it does not stop there. If we do not immediately learn the stuff as advised by the person uttering such phrases, we will lose our jobs and never get a job again. Our existences will be . And this will be solely our fault because we did not listen and obey.Fear-mongering at its best. Not only AI investors and vendors flood us with such messages. Also, all the wannabe profiteers of AI jumped on the fear-mongering bandwagon and flooded us with such messages â€“ oftentimes having a remedy in place for the exchange of some money.And so we stand here, with such messages hollered into our faces day by day, and ask ourselves: Are we â€œleft behindâ€ if we do not immediately learn all that AI magic?I thought about this question for a bit. Do we really need to pick up all that daily changing and evolving AI and agentic stuff to not be â€œleft behind?â€The short answer I came up with is:No, you are not left behind if you do not immediately pick up everything AI and agentic.However, ignoring it is not an option either.I.e., there are things you should not ignore, but these are not the things you are usually told you must not ignore. Sounds cryptic? Probably yes â€“ at least without further explanation. Thus, let me unpack my answer.Let us begin with a look at the current state of AI solutions. I took software development as an example domain because it is probably the domain where AI penetration is highest and, with it, the fear-mongering is also highest. So, what is the current state of the art in AI-driven software development?AI solutions meanwhile can create impressive solutions if we slice the problem small enough, give them enough context, and it is a well-known problem. If we feed them too large a chunk of work or if we do not provide enough context, it often becomes a game of chance if we get a good solution.Regarding the context that needs to be provided: Such context descriptions can easily become several thousand words if working with agentic solutions. Additionally, it needs to be provided a bit differently for each agent framework and each model to create the desired results.If the problem we need to solve is not a well-known one, i.e., if the underlying LLMs lack sufficient training examples in their corpus, more often than not the AI solutions are not able to come up with a reasonable solution. Luckily, most of the time we tend to solve well-known problems (I discussed this in more detail in my former post â€œSolving the wrong problemâ€). Therefore, this issue strikes less often than we might expect. Still, depending on the problem you attempt to solve, it may strike.Then, there is another issue: If you talk to serious power users, all of them tell you the same story: The AI solutions drift off. For a while, they produce good results and then they start to drift off. They stop doing what you told them to do and start doing different things. There are recommended â€œbest practicesâ€ to deal with this drifting, like, e.g., feeding the AI solution the whole context before every single task, or reminding it in some other way. Then the solutions drift off less often â€“ but they still drift off sometimes. Therefore, we always need a human in the loop who checks if the result meets the demands.And even if everything is set up perfectly, the AI solutions still tend to make mistakes sometimes. They have become a lot better, especially over the last few months. However, they still tend to make mistakes. The problem with such mistakes is that they are very different from mistakes a human would make. Oftentimes, they are subtle, odd, and hard to spot. Still, they would create a mess if released to production. This is another reason why we always need a human in the loop.If we put all this together, take a step back from the hype and look at it dispassionately, the current state of AI-based software basically looks like:Slice everything down into small chunks, or you may be out of luck.Make sure it is a well-known problem, or you may be out of luck.Provide a lot of context, or you may be out of luck.Provide the context and the instructions over and over again, or you may be out of luck.But no matter what you do, sometimes you are out of luck.This sounds a lot like dealing with an apprentice suffering from attention deficit. We slice the task down into small bites, complement it with lots of additional information, and repeat everything over and over again.The most ironic part: As I already mentioned in â€œSolving the wrong problemâ€, a big key to success is providing good requirements, good architectural framing, good context, etcetera. The lack of all this is exactly what developers suffered from in the past decades. Most companies actively prevented good requirements, architecture and context engineering due to their efficiency and feature obsession. It was the biggest impediment for developers when they tried to deliver reliable code timely. Requirements sucked. Architecture sucked. Context sucked. Developers pointed out the problems time and again and were turned down. But for AI agents, everyone accepts it as a must-have. But that is just an ironic side effect I consider worth mentioning. Nevertheless, the main point is that AI agents still behave like an apprentice suffering from an attention deficit if we look dispassionately at the current state of affairs.When confronted with this observation, the regular AI aficionado will tell you that things are so much better than they were a year or two ago.And they are right. Things are a lot better than they were a year ago. On the other hand, this is the least we should expect from the hundreds of billions that were spent on AI in the last year or two. If we would not see any significant improvement from spending this insane amount of money, something would be completely off.Still, agentic AI does not feel like a mature technology but like a technology that is still in its early infancy. And this brings me to the point why I do not think we are left behind if we do not immediately go all-in on AI and agentic AI.If I look at the current state of AI solutions, using AI-based software development as an example, I see something I have seen many times before: technology in its early infancy. If you are as old as I am, you may remember the times when it was crucial to knowhow to set process priorities and nice levels appropriately when starting processes on UNIX machines because otherwise the scheduler often accidentally starved crucial processes.the memory layout of a PC and how to squeeze the last bit out of the lower 640 KB to start bigger DOS applications because otherwise they did not start.which hints to add to SQL queries because otherwise the optimizer would mess up the access plans.how container resource virtualization worked and which disk drivers (not) to use because otherwise disk access became unbearably slow.And so on. The current state of AI tools feels a lot like this. We need to know a lot of â€œmagicâ€ to get the thing working properly â€“ sort of. Yes, things became a lot more powerful over the last 2 years, but if we are honest, they still feel quite immature and brittle.This is not a drama. This is a normal evolution we experience with every young and immature technology, and we can draw from other technologies how things will evolve:UNIX schedulers became better and better, and eventually nobody needed to set process priorities and nice levels anymore. Today, people start processes on UNIX machines without knowing these concepts.DOS was replaced by Windows, including practical memory virtualization concepts, and eventually nobody needed to know about the 640 KB memory barrier anymore. Today, people start applications on PCs without knowing these concepts.Database optimizers became better and better, and eventually nobody needed to add hints anymore. Today, people create and run SQL queries without knowing these concepts.Container resource drivers became better and better, and eventually people created and ran containers without caring about which drivers to use. Today, people use containers without knowing these concepts.I am sure you have detected the pattern. All that â€œarcaneâ€ knowledge that is crucial in the early days of a new technology eventually becomes irrelevant. More importantly, people were able to enter the realm later without knowing all that stuff. They were able to focus simply on the upsides of the technology and were more productive without needing to burden themselves with all those quirky details.And this is exactly what we are going to see with AI, too.The tools will become better and better, and eventually, all that secret arcane knowledge currently needed to get useful results will become obsolete. It will become straightforward to use those tools and eventually they will simply work as expected (maybe never perfectly reliably due to the functioning principle of LLMs, but that is another story).This is why I say you are not left behind if you do not immediately jump on the bandwagon. And this is why I advise you not to buy the secret recipe from some AI aficionado who promises to share their secret AI sauce for money after a round of fear-mongering. Whatever they tell you about which tricks you need to apply to become an AI winner, this knowledge will be obsolete in a year. The technology will evolve, and the secret recipes of today will be either worthless or built into the AI tools in a year.I mean, do you still remember the fuss people made about â€œprompt engineeringâ€ two years ago? The way you needed to write prompts to increase the probability of getting a useful response from an LLM? A whole training industry emerged in no time, with everyone selling their secret sauce to success. Companies looking for prompt engineers, partially offering ridiculous salaries. And today? Basically obsolete knowledge. The models and the agent frameworks have become so much better that all this knowledge from a year ago is hardly worth anything anymore.Hence, from a tooling perspective, it could be even better to wait a bit until the usage of the tools becomes straightforward and we do not need to know secret handshakes and other quirky rituals anymore to get the expected results from them.The inflection point trapHowever, before you think you can safely ignore AI for the next 2 or 3 years because the technology is not yet mature, there is a catch â€“ which brings me to the second part of my answer at the beginning of this post.The catch is not about the tooling and what you need to know to get useful results. It is about not missing the inflection point. Let me share a quick story from the past to explain what I mean:I knew some guys back in the early 1990s who were convinced that Windows will never make it on a PC, that DOS will persist as the dominant OS. Windows was still in its infancy and working with it was a mess back then (if you worked with Windows 3.0 as I did, you know what I mean). Developing Windows applications was even messier. The API was cumbersome, relevant parts undocumented, and the whole OS was everything but stable. Therefore, those guys came to the conclusion that ignoring Windows and continuing developing DOS applications was a safe bet.For a while, this was fine. But gradually, things became unpleasant.The problem was that those guys ignored the ongoing development of Windows after they made their choice. This way, they were still solely focused on DOS when it became obvious that DOS was a goner. But at this point in time, it was too late for them to migrate their business to the meanwhile dominant Windows. They were actually left behind. Their accumulated knowledge and experience had become worthless, and they basically needed to start from scratch â€“ against competitors with years of experience.They did not run into the problem because they did not immediately go all-in when Windows became popular. They ran into the problem because they missed the ongoing evolution of Windows and how the market shifted over time. With that, they missed the relevant inflection points: the first inflection point being when it became necessary to add Windows development to their portfolio (while still being able to make a living from DOS development), and the second inflection point being when it became time to let go of DOS and completely focus on Windows development.When applying this story to AI, it becomes clear that completely ignoring the evolution of AI is probably not a good idea, even if the technology is still in its infancy. It is important to understand how the technology evolves and where the market is heading to not miss the inflection points, the one when it becomes relevant to add AI to our portfolio and the other one when the market demands it as our sole approach, leaving our former approach behind.Applying it to software developmentLooking at AI in the realm of software development, we realize a bit paradoxical situation. Even though the technology is obviously still in its infancy, we face a significant market demand towards using it. Usually, the market majority picks up a technology only after it has reached a certain degree of maturity. Before, only the innovators and early adopters tended to use it.With AI, it is somewhat different. The AI investors and vendors relentlessly pushed their intrusive and fear-mongering marketing messages, backed by billions of dollars, trying to game the market and make the majority pick up AI earlier than they usually would. And to a certain degree, their strategy was successful. AI was picked up by the mainstream a lot earlier than the tooling reached the usually required maturity â€“ especially in software development.As a consequence, the first inflection point is about now in software development. Even if the tooling is still in its infancy, the market is crying for AI-based software development. I know that I wrote several times about the risks and challenges of AI-based coding, and I am still convinced that many companies will face some very unpleasant surprises, naively calling for AI-based coding without thoroughly preparing for it. Nevertheless, it becomes increasingly risky to ignore AI in software development completely.This does not mean that you need to go all-in immediately. It especially does not mean you need to learn all those secret recipes needed to convince the still immature tooling to do exactly what you expect. But you should familiarize yourself well enough with the possibilities and limitations of AI-based coding to be able to use it if needed and understand the ongoing evolution. Doing this, you will acquire some knowledge that will be worthless in a year. And maybe you will not immediately become an â€œAI rockstarâ€. But that is okay. It is about understanding the development of the technology, the evolution of its possibilities and limitations.In other domains, the first inflection point may not yet have come. Still, keeping an eye on the ongoing evolution is probably a good idea.It is not yet clear when the second inflection point will be. It may be in a few months. It may be in a few years. It may be later. It may never arrive. We do not know yet. Even if the predictions are that it will be in 2 or 3 years, there are still so many unknowns that may drive the future evolution of the technology in a completely different direction. Therefore, we cannot say for sure yet when this will happen. Nevertheless, at least at the moment the probability that we will reach the second inflection point is a lot higher than that we will never reach it.Overall, this means, even if we already need to pick up AI-based software development while the tooling is still in its infancy, we are not left behind if we do not know all the tricks and secret recipes needed to get the desired results from the still immature tooling. Regarding the tooling, time will work for us, not against us. But we still need to understand AI-based software development well enough to understand when the second inflection point is about to come.In other domains, you may have the advantage of not yet having to fight against immature tooling because the first inflection point may happen later in those domains â€“ at the point in time when technology maturity reaches a level we are normally used to.Many people, especially the (wannabe) profiteers of AI, want to make us believe that if we do not go all-in with AI  and learn all those tools and tricks on how to get them properly working, we would be left behind.This is not true. We are not left behind if we do not learn all the tools and the secret recipes needed to get them (halfway) properly working.If we look at the state of the current tooling, we realize it is still in its infancy, far from being mature. We know from many examples of the past that knowing all the quirks needed to get immature tools working properly quickly becomes irrelevant knowledge. Therefore, you are not left behind if you do not know perfectly how to use the currently available tools. Actually, most of the knowledge you accumulate today will be worthless in a year or so.However, especially in software development, it is quite likely that AI-based software development will eventually become the predominant paradigm and the tools will mature. Therefore, it is highly advisable not to ignore AI-based software development even if the tooling is still highly immature. Instead, it is important to follow the evolution and understand the technology well enough to know when the inflection points arrive.While the first inflection point â€“ when we need to add AI-based software development to our portfolio â€“ is now even if the technology is still immature (due to massive market gaming of AI investors and vendors), we do not know yet for sure when the second inflection point will arrive, i.e. when AI-based software development will become predominant.The secret recipes of the (wannabe) AI experts are not the important part when it comes to being â€œleft behindâ€ or not. Most of todayâ€™s expert knowledge will be worthless in a year because the technology evolves quickly and is still far from mature.Completely ignoring the technology and its evolution on the other side is risky because you may miss the point when you need to pick it up. Then you actually may be left behind and have to start over from scratch, which may be very hard.Thus, my conclusive recommendation is:Do not fall for the fear-mongering messages regarding AI.Still, watch the AI evolution closely enough to be prepared when the inflection points arrive.Or, as a meditation teacher might phrase it: â€œFind a relaxed, yet alert positionâ€ â€¦ ;)]]></content:encoded></item><item><title>Ess-community server suite installation failing</title><link>https://www.reddit.com/r/kubernetes/comments/1rbgsl3/esscommunity_server_suite_installation_failing/</link><author>/u/Rasha26</author><category>reddit</category><pubDate>Sun, 22 Feb 2026 08:43:28 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>[D] Why do people say that GANs are dead or outdated when they&apos;re still commonly used?</title><link>https://www.reddit.com/r/MachineLearning/comments/1rbgsey/d_why_do_people_say_that_gans_are_dead_or/</link><author>/u/PlateLive8645</author><category>ai</category><category>reddit</category><pubDate>Sun, 22 Feb 2026 08:43:11 +0000</pubDate><source url="https://www.reddit.com/r/MachineLearning/top/?sort=top&amp;t=day&amp;limit=3">Reddit - ML</source><content:encoded><![CDATA[It's really weird seeing people say that GANs are a dated concept or not used. As someone doing image and audio generation, I have no idea what people mean by this. Literally every single diffusion model and transformer model uses a frozen GAN-trained autoencoder as a backbone. It's impossible to get even close to SOTA if you don't.E.g. Flux VAE, SD VAE, literally every single audio model, ...It's like saying that the wheel has been replaced by the car]]></content:encoded></item><item><title>Built a lightweight webhook receiver to auto-run server commands from GitHub/GitLab events in GO</title><link>https://www.reddit.com/r/golang/comments/1rbgmyb/built_a_lightweight_webhook_receiver_to_autorun/</link><author>/u/ItsMeNiyko</author><category>golang</category><category>reddit</category><pubDate>Sun, 22 Feb 2026 08:33:50 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[I built Fishline, a lightweight self-hosted webhook receiver for GitHub and GitLab that lets you execute server-side commands based on webhook events.Instead of setting up complex CI/CD pipelines, Fishline simply listens for webhook requests and runs predefined commands per project and branch things like , restarting Docker containers, or triggering deployments.You just configure projects and commands in a simple , point your GitHub/GitLab webhook to your server, and deployments happen automatically.Built in Go, runs as a single binary (or Docker), and designed to be minimal, fast, and easy to self-host.]]></content:encoded></item><item><title>Linux 7.0 Makes Preparations For Rust 1.95</title><link>https://archive.is/GmeOi</link><author>/u/BlueGoliath</author><category>reddit</category><pubDate>Sun, 22 Feb 2026 08:28:56 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>How a terminal actually runs programs.</title><link>https://sushantdhiman.dev/write-your-own-shell-terminal-from-scratch/</link><author>/u/Sushant098123</author><category>reddit</category><pubDate>Sun, 22 Feb 2026 07:57:15 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[Hi, I am on my way to becoming a better engineer. So I am building stuff that people don't build and learn outside their job. I am currently learning about operating systems and how they work. But instead of following the old textbook reading approach, I am doing this by building some projects along the way. In order to understand processes, I have decided to build a shell from scratch. This is part one of this series, and there will be 2 parts. We will be building a full-function shell from scratch.A shell is a program that acts as an interface between you and your operating system. It reads commands given by the user and gives them to the operating system for execution. Consider it as a command-line interpreter which will take commands from you and interpret them in a suitable way so that your operating system can execute them. Finally, it will return you the output.Many people think that shell and terminal are the same things. But that's not true; a terminal is a graphical user interface where you can type commands. Whereas a shell is a baseline component that accepts commands and processes them. We are not going to build a terminal. We are going to build a shell.But don't worry; you will be able to execute commands in that as well.We are not going to use any external library. We are just going to use the  and Linux concepts practically.Create a new child process and execute command there.Wait for child process to complete.Some of the you will think, "What is this 'process'?" Let me give you a crash course.A process is a running program. Programs are stored on the hard disc or SSD in some executable format. Understand with an example. Google Chrome is installed on your computer. It resides in your storage disc (HDD or SSD). When you double-click on it, it magically opens. The magic behind this is thatOS loads the program from disk to RAM.RAM is where currently opened programmes are stored because RAM is quickly accessible.CPU starts executing your program.Now Google Chrome has become a process.When a process creates another process, the created process is called the child process, and the creator process is called the parent process.#include <stdio.h>
#include <unistd.h>

int main(int argc, char** argv) {
    int pid;
    pid = fork();

    printf("fork() returned: %d\n", pid);

    if (pid == 0) {
        printf("Child process.\n");
    } else {
        printf("Parent process.\n");
    }
    return 0;
}Can you guess the output of the above code?fork() returned: 69808
Parent process.
fork() returned: 0
Child process.A process can use a system call "fork" to create another process. The created process will start executing the same instructions that the parent process is going to execute. It will also get a copy of the same address space of its parent process. Understand that address space is an area of memory that can be used by this process so that it does not interfere with other process data.The fork() system call will return the ID of the created process. It will return zero for the child process and an unknown negative number for the parent process. That's why we added a simple if statement that distinguishes between which process is running.
                            Subscribe
                        Why do we need to know about processes?You need to know about processes because processes are the building blocks of shell. If you recall the working of a shell, you will notice that we need to create child processes for the commands. Our shell will run as a parent process, and all the commands will run as child processes.#include <stdio.h>
#include <string.h>

#define MAX_INPUT 1024


int main() {
	char input[MAX_INPUT];

	while (1) {
		printf("mysh> ");
		fflush(stdout);

		if (fgets(input, MAX_INPUT, stdin) == NULL)
			break;

		input[strcspn(input, "\n")] = 0;

		if (strlen(input) == 0)
			continue;

		if (strcmp(input, "exit") == 0)
			break;
	}

	return 0;
}This code gives us a basic anatomy of our shell. It will accept commands from the user and does nothing. But if a user sends "exit", it will break the loop and stop the program.Let's implement some command execution functionality to our shell. After validating that our command is not empty and not "exit", we can spawn a child process that will be responsible for executing the command.pid_t pid = fork();

if (pid == 0) {
    // Child Process will process command here.
} else {
    // Parent will wait until child process completes.
    wait(NULL);
}But here is an issue. I told you that when we create a new process using the fork() system call, it will create an exact copy of the parent process. Including its source code, static variables, stack, heap, opened files and address space. The child process will start executing the source code of the parent process.Let's say a user entered the "ls" command in our shell. This command will print all the files and folders in the current directory.You need to understand that the commands we run in our terminal are also executables. Go to the "/bin" directory on your computer and see what files are listed there. You will see several commands you use in your daily work.So this means that when you write "ls" inside your terminal, a program stored at location "/bin" is executed. Running "ls" and "/bin/ls" won't make any difference, as the shell you are currently using does this automatically for you. We are going to do the same thing. Inside our child process, instead of running code of parent process we will replace it with code of command user gave.Introducing execv SystemcallThis is the most important system call for building a shell. It does a simple thing. Replace the image of the currently executing process with another program/process.It's important to understand the working of this system call. It takes 2 arguments.Path of the program we want to run.Arguments for that program.So if we want to run the "ls" command, the path will be "/bin/ls". This second argument of the execv syscall is a bit confusing.Let's say we are running the command "ls", so our second argument to the execv syscall will be a string array with the following contents.char *args[] = {"ls", NULL};But if we want to run the command "ls -a" (this lists hidden files and folders as well), our string array will look like this.char *args[] = {"ls", "-a", NULL};So execv will use the 1st argument to load a program stored somewhere on disc, and it will use the 2nd argument to supply arguments to the loaded program. The loaded program will start running as a process, and finally execv will replace the image of our current child process with the loaded program's process.The NULL at the end of the args array tells the C compiler where to look. It's a kind of signal to the compiler telling it, "Hey, bro, stop here. No need to access more. Just start the program."#include <stdio.h>
#include <string.h>
#include <unistd.h>
#include <sys/wait.h>

#define MAX_INPUT 1024


int main() {
	char input[MAX_INPUT];

	while (1) {
		printf("mysh> ");
		fflush(stdout);

		if (fgets(input, MAX_INPUT, stdin) == NULL)
			break;

		input[strcspn(input, "\n")] = 0;

		if (strlen(input) == 0)
			continue;

		if (strcmp(input, "exit") == 0)
			break;

		pid_t pid = fork();

		if (pid == 0) {
			char *args[] = {"ls", "-a", NULL};
			execv("/bin/ls", args);
		} else {
			// Parent will wait until child process completes.
			wait(NULL);
		}
	}

	return 0;
}Now if we run this program and give it some input that is not "exit", it will execute the "ls -a" command just like your terminal does.
                            Subscribe
                        This was a very, very basic implementation of shell. I won't even call it standard because it just executes 1 command. I've done the following things in my personal shell implementation:Dynamic Command ExecutionCommands piping (ls | grep 'a' | sort)I'll write part 2 of this post, which will have most of the features that a shell has. Also, you can subscribe to my free weekly newsletter to get updates of my new posts.Let's get connected over social media: LinkedIn, X]]></content:encoded></item><item><title>[media] Bet you havenâ€™t seen an Iced app running on Windows XP yet</title><link>https://www.reddit.com/r/rust/comments/1rbf6j4/media_bet_you_havent_seen_an_iced_app_running_on/</link><author>/u/mq-1</author><category>rust</category><category>reddit</category><pubDate>Sun, 22 Feb 2026 07:06:32 +0000</pubDate><source url="https://www.reddit.com/r/rust/top/?sort=top&amp;t=day&amp;limit=3">Reddit - Rust</source><content:encoded><![CDATA[Had to tinker around a bit but it seems pretty stable :)Using this in my main: ```unsafe extern "system" { pub unsafe fn CoTaskMemFree(pv: *mut std::ffi::c_void); } ```]]></content:encoded></item><item><title>Technical Post-Mortem: The architectural friction of embedding cryptographic verification directly into a Rust compiler pipeline</title><link>https://github.com/merchantmoh-debug/ArkLang</link><author>/u/AbrocomaAny8436</author><category>reddit</category><pubDate>Sun, 22 Feb 2026 06:10:35 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[I just spent the last two weeks deep in the trenches writing a compiler from scratch (Ark-Lang, ~21k LOC in Rust), and I wanted to do a writeup on the hardest architectural friction point I hit: embedding SOC-2 level cryptographic verification directly into the AST parsing phase.Usually, compilers are black boxes. You feed them source, they spit out bytecode or WASM. I wanted the compiler to physically prove it did its job without external linters. The Engineering Challenge:I had to build a 5-phase pipeline where the AST is actually Merkle-hashed right after the Lexer/Parser finishes. Linear Type Checking (tracking resource consumption to prevent double-spends)Codegen (targeting a custom stack VM and native WASM)Minting the HMAC-signed ProofBundle.The absolute nightmare here was keeping the linear type checker synchronized with the WASM memory offsets while ensuring the AST hash didn't mutate during optimization passes. I basically had to freeze the AST state, hash it, and then pass an immutable reference to the linear checker (`checker.rs`). Writing the WASM codegen by hand at 4 AM was probably a mistake, but it compiles cleanly now. Has anyone else experimented with generating cryptographic receipts at the compiler level? Curious how other people handle AST freezing during multi-pass optimization. ]]></content:encoded></item><item><title>ai golang</title><link>https://www.reddit.com/r/golang/comments/1rbe70o/ai_golang/</link><author>/u/OldPollution7860</author><category>golang</category><category>reddit</category><pubDate>Sun, 22 Feb 2026 06:09:56 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[If you are posting a project to the Go subreddit, please:Be clear about the  of your post: Review, attention for a nice package, a claim of production quality, version update, etc.If this is your project for review, the  that was used.Ensure the project has a clear delineation between  and the current ., heavy-handed marketing, and other similar things.Posts will be examined holistically; missing one of these will not be automatically fatal but missing all of them means you're probably going to get it removed.That's the gist of here, but if you want details:In an age of AI programming, anyone can bash together an idea in a couple of days. As a result we've had to change the standards for posting to the front page.In general, projects that may do well on the front page are those that have cleared a certain effort bar. It should be something that has several person-weeks invested into it, probably some real-world usage, maybe multiple contributors even if it's just a couple of small PRs.Projects that have just a couple of days of effort, one contributor, a handful of commits, and no real-world usage are welcome to be posted to this sub, but they should go into the weekly pinned "Small Projects" thread. If you post something to the front page of the sub and the moderators remove it and ask you to post it into this thread instead, please do.While the sub still  that you do all of the things suggested above, and especially that you not dump an LLM-generated summary into your post in the default voice, the requirements are looser in this thread than a front-page post.In addition to the general project size, projects that are extremely frequently posted are more likely to be asked to move to the Small Projects thread. These include, but are not limited to:"Skeletons" or "boilerplate"Things that use the unsafe package in a way that really is quite unsafe and shouldn't be used by anyone (most notably trying to cast structs in and out of byte arrays)Configuration management libraries (e.g., "get your config from environment variables or YAML or TOML or...")MCP servers or frameworksTools for interacting with LLMs, such as the "command line chat with LLMs" or "make Git commits with LLMs"Functional Programming libraries, especially "Option" librariesJob scheduling libraries, especially cron clonesText or HTML templating systemsNone of these projects are forbidden from the front page, but the apparent effort bar will be move somewhat higher.If your purpose is for review or feedback, please be clear about the amount of AI coding used, and if relevant, the amount of effort put into the project, which should be reflected in the project itself.Using AI coding tools is not a disqualification for posting. However, in order to align the effort of creating a post-worthy project with reviewing it. the subreddit will remove posts for "vibe-coded" projects with little human input. This is not because such projects are "bad", but precisely because as mentioned they are so easy to put out they are no longer noteworthy.It is also a bad use of human time to review AI code. Nobody learns anything from that.As with our other AI policies, this will include any human-generated projects that look like this as well, to prevent rules-lawyering about exactly what this means.It is often unclear to the community what the purpose of a post is. For example, if a project is posted for review, the community may react in one way, whereas if it is to bring attention to a production-quality repo, that's another standard.Please try to be clear about what the purpose is. The goal here is clarity. There are many valid purposes, we just want to know what your intention is.Every project on GitHub is described as a scalable, feature-rich, minimalist, high-performance, idiomatic, reliable, etc. etc. project. Project with thousands of commits, dozens of contributors, and massive industry deployment describe themselves that way, as does some programmer's one-week passion project that's barely unit tested.It is fine to  for a project to  things, but we are going to be looking more skeptically at projects that describe themselves as these things when they clearly do not have the real-world deployment experience to be claiming these attributes.Please carefully distinguish between the  of a project and the  it can concretely claim. We should be able to tell whether this project is intended to be suitable for production use or not; a clear statement won't hurt but is not necessary as long as the rest of the post is clear.Again, we seek , not any particular maturity level! It is completely fine to post immature code bases whose results are basically "it passes the unit tests most of the time" for review or highlight. We just seek honesty in the description.A Reddit post is not a good place to dump your entire README.md. Please try to concisely describe the project and why it is of interest, and let the README.md do its job of filling in the details. The subreddit will be coming down harder on long, flabby posts that should be linked README.md files. Think "a couple of paragraphs" rather than "a couple of pages".If you must use an LLM to post your summary to the Go subreddit, please:Do not use emoji. This will be automatically blocked.Prompt your LLM to  and/or post the  of a particular release, and don't be afraid to trim it down even so. Less is more in a Reddit post.Note that using LLMs to generate blog posts or comments remains forbidden.LLMs  to slather the adjectives on to projects as mentioned above in the goals vs. result section. If your LLM starts waxing poetic about the production quality of your repo and claiming it's scalable and reliable and such, you should trim that back out.(If you are dissatisfied with this level of detail, consider reading the even longer version, with more of the "why" behind these rules.)I don't know that there is a well-accepted term for this, but this refers to a wide suite of writing patterns designed to draw "engagement" at all costs. We reserve the right to remove posts that are designed to excessively draw attention to themselves above and beyond a normal front-page post. These behaviors include, but are not limited to:Use of colorful emojis (enforced by Reddit controls)Superlatives slathered over the textThat incredulous "you can't even begin to conceive of how wonderful this is!" tone that is hard to define but you know it when you see itRequests to like, subscribe, star, or whatever local equivalent actions areTrying to disguise what is obviously an ad with obviously fake questions about "What do you think about $THIS_PRODUCT_I_JUST_POSTED" or other "discussion questions" to provide a patina of "oh I'm just trying to start a conversation" over the post.This is honestly a favor to you anyhow. Part of good marketing is reading the room. The Reddit Golang community is a highly-online community of people who have on average have been around the block a few times, and find this sort of marketing almost viscerally repellent. This is not some sort of flex; it is my assessment based on long observation. When this is removed, the moderators are not preventing you from receiving your inevitable upvotes, they're saving you from getting hard-flagged by numerous participants and possibly rousing the ire of the general Reddit spam algorithms as a result.Being simple, direct, and honest without these "engagement hooks" has repeatedly proved to be a much better strategy for everyone.]]></content:encoded></item><item><title>After a year of using Cursor, Claude Code, Antigravity, and Copilot daily â€” I think AI tools are making a lot of devs slower, not faster. Here&apos;s why.</title><link>https://medium.com/@riturajpokhriyal/why-ai-coding-tools-are-making-you-slower-and-what-actually-works-c18f432e470b?sk=72b292bd80effdb7ddb2eb956ae6a940</link><author>/u/riturajpokhriyal</author><category>reddit</category><pubDate>Sun, 22 Feb 2026 05:36:06 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Linux 7.0 makes preparations for Rust 1.95</title><link>https://www.phoronix.com/news/Linux-7.0-Rust-1.95-Prep</link><author>/u/somerandomxander</author><category>reddit</category><pubDate>Sun, 22 Feb 2026 04:30:17 +0000</pubDate><source url="https://www.reddit.com/r/linux/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Linux</source><content:encoded><![CDATA[
Last week was the main feature pull of Rust programming language updates for the Linux 7.0 kernel merge window. Most notable with that pull was Rust officially concluding its "experimental" in now treating Rust for Linux kernel/driver programming as stable and here to stay. Sent out today was a round of Rust fixes for Linux 7.0 that includes preparations for the upcoming Rust 1.95 release.
Rust 1.95 is being branched from master on 27 February and aiming for its stable release on 16 April. Rust 1.95 stabilizes if let guards, changing some ports to tier 2 status, and various other changes.
For Linux 7.0 they are now passing the "" flag that will be required by the Rust 1.95 release. The -Zunstable-options allows for the use of other new, unstable command line options.
For the kernel's irq module, there is a missing bound detected by the in-development Rust 1.95 code to be addressed. With the pin-init crate was also a Clippy warning that changed behavior with the upcoming Rust 1.95 release.
Meanwhile this round of Rust fixes for Linux 7.0 also fixes an objtool warning when using the older Rust 1.84 release plus a fix to the list module to address missing "unsafe" blocks  and placeholder safety comments to macros.
More details on these Rust fixes sent out today for Linux 7.0 to focus on future Rust 1.95 compatibility can be found via this pull request.]]></content:encoded></item><item><title>[R] A broad new class of GNNs based on the discretised diffusion PDE on graphs and numerical schemes for their solution.</title><link>https://proceedings.mlr.press/v139/chamberlain21a/chamberlain21a.pdf</link><author>/u/moschles</author><category>ai</category><category>reddit</category><pubDate>Sun, 22 Feb 2026 04:29:44 +0000</pubDate><source url="https://www.reddit.com/r/MachineLearning/top/?sort=top&amp;t=day&amp;limit=3">Reddit - ML</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Using Ancient Linux in 2026, Is There a Point?</title><link>https://www.reddit.com/r/linux/comments/1rbca1y/using_ancient_linux_in_2026_is_there_a_point/</link><author>/u/One-Establishment659</author><category>reddit</category><pubDate>Sun, 22 Feb 2026 04:26:52 +0000</pubDate><source url="https://www.reddit.com/r/linux/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Linux</source><content:encoded><![CDATA[Good day Linux Reddit, I took on a project involving building a server off a 1997 desktop with Debian 3.0It seemed like a fun idea, but in truth it's a pain in the (you know what) when it comes to getting it compatible with modern web things like an updated SSL library and having a usable git app.I attempted installing many different distros onto this machine I own, including but now limited to: SLS, Slackware 2.0, Mandrake 9, Debian 4.0/5.1/7/8, Gentoo, Puppy and last but not least, and old archived version of Arch. All gave issues with the installers and/or corrupted files on the physical disc media themselves.So my initial criteria for a functional distro on this machine was: "Does it have apt and a living http archive on the internet?" so my initial install CD could basically act as a net-install disc.Debian 3.0(revision 6) had a well stocked apt archive online, and was the last in line of debian versions to have an installer CD that accepted a maximum of 64MB on boot. It also had a robust SCSI driver for tape drives (unlike Slackware 2...), but I quickly abandoned SCSI use for external devices and focused on having a functional Linux system.As of now, I am attempting to build a newer version of GCC (last version built for Deb3 was 2.95.6) in order to build the closest to supported OpenSSL library so I can access HTTPS websites to pull git repositories. At the moment i've had to pull from a separate system and transfer them to my box via FTP.At least Apache works out of the box on here, the logos and images from the default installation are hilariously dated, like the one attached to this post :)I wanna ask your opinions on my undertaking of trying to use an ancient distro in the modern day (I'm not gonna try GUI usage, all the display managers are flat broken, and have you seen the setup process for those back in the day? my zoomer brain can't make head nor tail of it!). Do you think this is a waste of time? Will I burn in the dependency hell that is old Linux? Thanks for reading.(BTW, it's running kernel bf-2.4 )]]></content:encoded></item><item><title>Zero-GC and 78M samples/sec: Pushing Node.js 22 to the limit for Stateful DSP</title><link>https://github.com/A-KGeorge/dspx-benchmark/tree/main/charts</link><author>/u/sarcasm4052</author><category>reddit</category><pubDate>Sun, 22 Feb 2026 04:06:14 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[Iâ€™ve been benchmarking a hardware-aware Signal Processing library for Node.js () and found that with the right architecture, you can effectively bypass the V8 garbage collector. By implementing a zero-copy pipeline, I managed to hit 78 million samples per second on a single vCPU on AWS Lambda (1769MB RAM). Even more interesting is the memory profile: at input sizes between 2 and 2 the system shows zero or negative heap growth, resulting in deterministic p99 latencies that stay flat even under heavy load.I also focused on microsecond-level state serialization to make stateful functions (like Kalman filters) viable on ephemeral runtimes like Lambda. The deployment size is a lean 1.3MB, which keeps cold starts consistently between 170ms and 240ms. It includes a full toolkit from MFCCs and Mel-Spectrograms to adaptive filters and ICA/PCA transforms.Its single threaded by default on both the C++ and JavaScript side, so the user can multi-thread it in JavaScript using worker threads, atomics, and SharedArrayBuffers.]]></content:encoded></item><item><title>This Defense Company Made AI Agents That Blow Things Up</title><link>https://www.wired.com/story/ai-lab-scout-ai-is-using-ai-agents-to-blow-things-up/</link><author>/u/ThereWas</author><category>ai</category><category>reddit</category><pubDate>Sun, 22 Feb 2026 03:41:35 +0000</pubDate><source url="https://www.reddit.com/r/artificial/top/?sort=top&amp;t=day&amp;limit=3">Reddit - AI</source><content:encoded><![CDATA[Like many Silicon Valley companies today, Scout AI is training large AI models and agents to automate chores. The big difference is that instead of writing code, answering emails, or buying stuff online, Scout AIâ€™s agents are designed to seek and destroy things in the physical world with exploding drones.In a recent demonstration, held at an undisclosed military base in central California, Scout AIâ€™s technology was put in charge of a self-driving off-road vehicle and a pair of lethal drones. The agents used these systems to find a truck hiding in the area, and then blew it to bits using an explosive charge.â€œWe need to bring next-generation AI to the military,â€ Colby Adcock, Scout AIâ€™s CEO, told me in a recent interview. (Adcockâ€™s brother, Brett Adcock, is the CEO of Figure AI, a startup working on humanoid robots). â€œWe take a hyperscaler foundation model and we train it to go from being a generalized chatbot or agentic assistant to being a warfighter.â€â€œIt's good for defense tech startups to push the envelope with AI integration,â€ says Michael Horowitz, a professor at the University of Pennsylvania who previously served in the Pentagon as deputy assistant secretary of defense for force development and emerging capabilities. â€œThat's exactly what they should be doing if the US is going to lead in military adoption of AI.â€Horowitz also notes, though, that harnessing the latest AI advances can prove particularly difficult in practice.Large language models are inherently unpredictable and AI agentsâ€”like the ones that control the popular AI assistant OpenClawâ€”can misbehave when given even relatively benign tasks like ordering goods online. Horowitz says it may be especially hard to demonstrate that such systems are robust from a cybersecurity standpointâ€”something that would be required for widespread military use.Scout AIâ€™s recent demo involved several steps where AI had free rein over combat systems.At the outset of the mission the following command was fed into a Scout AI system known as Fury Orchestrator:Fury Orchestrator, send 1 ground vehicle to checkpoint ALPHA. Execute a 2 drone kinetic strike mission. Destroy the blue truck 500m East of the airfield and send confirmation.A relatively large AI model with over a 100 billion parameters, which can run either on a secure cloud platform or an air-gapped computer on-site, interprets the initial command. Scout AI uses an undisclosed open source model with its restrictions removed. This model then acts as an agent, issuing commands to smaller, 10-billion-parameter models running on the ground vehicles and the drones involved in the exercise. The smaller models also act as agents themselves, issuing their own commands to lower-level AI systems that control the vehiclesâ€™ movements.Seconds after receiving marching orders, the ground vehicle zipped off along a dirt road that winds between brush and trees. A few minutes later, the vehicle came to a stop and dispatched the pair of drones, which flew into the area where it had been instructed that the target was waiting. After spotting the truck, an AI agent running on one of the drones issued an order to fly toward it and detonate an explosive charge just before impact.]]></content:encoded></item><item><title>It&apos;s impossible for Rust to have sane HKT</title><link>https://vspefs.substack.com/p/its-impossible-for-rust-to-have-sane</link><author>/u/vspefs</author><category>reddit</category><pubDate>Sun, 22 Feb 2026 02:57:52 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>OpenGradient (Open44) - A decentralized AI network built on proven open-source tools</title><link>https://www.reddit.com/r/golang/comments/1rba9sb/opengradient_open44_a_decentralized_ai_network/</link><author>/u/bk888888888</author><category>golang</category><category>reddit</category><pubDate>Sun, 22 Feb 2026 02:46:32 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[I've been working on OpenGradient, a decentralized AI network that enables anyone with a GPU to contribute compute and earn rewards. Rather than building everything from scratch, I took a pragmatic approach - integrating battle-tested open-source tools to create a cohesive system.GPU Mining: Run local LLMs via SGLang and earn GRAD tokens for computationVector Storage: Semantic search using ZVEC (Alibaba's vector similarity search)P2P Network: libp2p-based peer discovery and synchronizationRAFT Consensus: Distributed agreement for ledger transactionsAgent Marketplace: Deploy and monetize AI agents with escrow executionArchitecture (what's actually there)The project integrates these proven tools:| Component | Tool | Creator ||----------------|---------------------------------------|---------------|Why integrate instead of build from scratch?Initially explored building a vector storage system using Hilbert curves for spatial indexing. After extensive research, found that existing solutions like ZVEC already solved these problems effectively at scale. The same applied to API routing (Higress) and storage (BadgerDB).- Total Supply: 1 billion- Distribution: 40% GPU contributors, 25% content mining, 20% foundation, 10% marketplace, 5% ecosystem- Mining: Not PoW - rewards for actual compute and semantic diversity- Storage: BadgerDB-backed (embedded key-value store)The code is 100% open source with:- Working RAFT consensus implementation- P2P networking with libp2p- Vector storage integration- Basic agent marketplace- Not a revolutionary breakthrough - it's an integration project- Not reinventing wheels - uses proven tools where possible- Not vaporware - the code exists and tests passWould love feedback from the community. Is this approach valuable? What would make it more useful?]]></content:encoded></item><item><title>Ollama 0.17 released with improved OpenClaw onboarding</title><link>https://www.phoronix.com/news/ollama-0.17</link><author>/u/Fcking_Chuck</author><category>ai</category><category>reddit</category><pubDate>Sun, 22 Feb 2026 02:46:08 +0000</pubDate><source url="https://www.reddit.com/r/artificial/top/?sort=top&amp;t=day&amp;limit=3">Reddit - AI</source><content:encoded><![CDATA[Michael Larabel is the principal author of Phoronix.com and founded the site in 2004 with a focus on enriching the Linux hardware experience. Michael has written more than 20,000 articles covering the state of Linux hardware support, Linux performance, graphics drivers, and other topics. Michael is also the lead developer of the Phoronix Test Suite, Phoromatic, and OpenBenchmarking.org automated benchmarking software. He can be followed via Twitter, LinkedIn, or contacted via MichaelLarabel.com.]]></content:encoded></item><item><title>Benchmarks: Go&apos;s FFI is finally faster then GDScript (and Rust?)</title><link>https://github.com/quaadgras/graphics.gd/discussions/277</link><author>/u/Splizard</author><category>golang</category><category>reddit</category><pubDate>Sun, 22 Feb 2026 02:42:19 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>How would you setup the resource requests and limits on this workload? (this is mostly about how different people approach it)</title><link>https://www.reddit.com/r/kubernetes/comments/1rb9f74/how_would_you_setup_the_resource_requests_and/</link><author>/u/trouphaz</author><category>reddit</category><pubDate>Sun, 22 Feb 2026 02:05:50 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[This is all theoretical. I know how I would size it and there has been some discussion with others on my team and application owners.Let's say you have a java based application that uses up to 2 cores on startup which is its peak. Then, after it is fully started it hovers around 5% of a core with a nightly job that brings it up to around 15% of a core. They have their Xms set at 3Gb and Xmx at 4Gb. Let's say the worker nodes are 16 cores with 128Gb of memory.If you tell me what you'd set your parameters at, could you also tell me what your position is? I wonder if platform engineers vs application owners vs something else would make a difference in their recommendations.My settings would be in here, but I'm wondering what others would do. ]]></content:encoded></item><item><title>I built an intelligence layer for deployments</title><link>https://deploydiff.rocketgraph.app/</link><author>/u/ResponsibleBlock_man</author><category>reddit</category><pubDate>Sun, 22 Feb 2026 01:02:55 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Benchmarking loop anti-patterns in JavaScript and Python: what V8 handles for you and what it doesn&apos;t</title><link>https://stackinsight.dev/blog/loop-performance-empirical-study/</link><author>/u/StackInsightDev</author><category>reddit</category><pubDate>Sun, 22 Feb 2026 00:54:00 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[Youâ€™ve seen the advice a hundred times. â€œHoist your regex out of the loop.â€ â€œDonâ€™t call  inside a  loop.â€ â€œReplace nested  with a flat loop.â€ â€œUse  instead of .â€It sounds reasonable. Repeating work inside a loop is wasteful. Every blog post, every code review, every linting rule says so. But hereâ€™s the thing nobody actually checks: I wanted real numbers. So I built six benchmark modules â€” each isolating one common loop anti-pattern â€” and ran them at five input sizes (n = 10 to 100,000) with 30 trials per configuration, 50 warmup iterations, and forced garbage collection between trials. Then I built AST-based detectors for JavaScript and Python, pointed them at 40 open-source repositories across five domains, and counted how often these patterns appear in production code.V8â€™s JIT optimizer already handles most of the textbook anti-patterns. Regex hoisting? 1.03Ã— speedup â€” noise-floor territory. Flattening nested ? Identical scaling curves. Fusing  into ? No measurable difference.But two patterns showed massive, unambiguous improvement. Replacing a nested loop (O(nÂ²)) with a  lookup (O(n)) delivered  at n = 10,000. Hoisting  out of a loop delivered  at n = 100,000. Every developer knows that loops matter. Weâ€™re taught to hoist regexes, avoid nested O(nÂ²) scans, and parallelize I/O. But modern JavaScript (V8) and Python (CPython) runtimes have evolved differently. V8 includes an aggressive JIT compiler; CPython does not. Does â€œtextbookâ€ advice still hold up? We conducted a two-part empirical analysis: Six controlled modules isolating common anti-patterns (regex-in-loop, nested loops, sequential I/O, etc.), run at n=10 to n=100,000 with 30 trials per configuration. A scan of 40 popular open-source repositories (59,728 files) to measure how often these patterns appear in production code.Algorithmic changes dominate: Replacing a nested loop with a  lookup yielded  in JS and  in Python. V8 optimization makes â€œregex hoistingâ€ and â€œarray method chainingâ€ performance differences negligible (1.03Ã—). Without a JIT, Python pays a heavy penalty for every iteration. Fixes that are optional in JS are mandatory in Python. The most common anti-patterns in real code (e.g., sequential await) often have valid use cases, while the most critical performance killers (nested loops) are moderately common (38% of repos) and catastrophic at scale.If you only have 2 minutes, here is what you need to change in your code reviews:Refactor to Map/Set lookup immediately.Use  /  if requests are independent.Hoist it. V8 cannot optimize fresh object allocation.JS: Ignore. Python: .Ignore.  is fine;  is not faster.Ignore unless n > 1M.  loops are only marginally faster.Part 1: The benchmarks â€” what actually speeds upBM-01: Regex in loop â€” the anti-pattern that isnâ€™tThe textbook advice: donâ€™t compile a regex inside a loop body. Every iteration pays the compilation cost.Result at n = 100,000 (30 trials):Thatâ€™s a 3% difference. Within measurement noise for most applications. V8 caches compiled regex patterns internally. A regex literal in a loop body is not recompiled on every iteration the way a textbook explanation suggests. The engine recognizes the pattern is constant and reuses the compiled NFA/DFA. Hoisting it yourself does save a trivial amount of overhead (pattern identity check), but V8 has already done the expensive work for you.Scaling analysis confirms this: both variants have nearly identical power-law exponents (b = 0.59 baseline, b = 0.56 optimized, RÂ² > 0.96). They scale the same way because theyâ€™re doing the same work.CPython is a different story. Our Python benchmark (, CPython 3.13.12, 30 trials) showed a consistent  from hoisting  at all n â‰¥ 1,000:CPython maintains a small internal regex cache (~512 entries), but calling re.match(pattern_string, s) with a pattern literal still involves a cache lookup and pattern object construction on each call.  returns a pre-compiled object that skips that entirely. The 2Ã— speedup is consistent and real. In V8/Node.js, regex hoisting is a style choice (1.03Ã— speedup, negligible). In CPython, itâ€™s a genuine optimization (2Ã—). If you write Python, always use  outside the loop.Parsing the same JSON string on every iteration of a loop. This one is clearly wasteful â€”  does real work that produces the same result each time.Result at n = 100,000 (30 trials):A 46Ã— speedup. This is not a marginal improvement â€” itâ€™s the difference between â€œimperceptibleâ€ and â€œthe user notices.â€Why does this one work when regex hoisting doesnâ€™t? Because  produces a  every time. V8 canâ€™t memoize it â€” the output is a fresh heap allocation with fresh property slots. Thereâ€™s no internal caching mechanism. Each call does the full parse-allocate-populate cycle. Baseline exponent b = 0.79 (near-linear in parse count); optimized exponent b = 0.45 (sublinear â€” the single parse is amortized across iterations, and the per-iteration cost is just a property lookup).BM-03: Sequential await â€” where parallelism paysEach iteration of a  loop s an HTTP request sequentially. Total time = sum of all request latencies. The optimized version fires all requests simultaneously with .Result with mock server at 2ms fixed latency (10 trials each):At n = 100, sequential  serializes 100 round-trips into 1.5 seconds.  completes all of them in 20ms â€” the time of a single request plus Node.js scheduling overhead. The speedup scales near-proportionally with n because each request is independent and the bottleneck is purely latency serialization. This benchmark uses a fixed 2ms mock server with no real network variability. Real-world speedup depends on: OS and server connection limits cap actual parallelism. At n = 200, we hit Windows socket limits during testing. Many APIs throttle concurrent requests. Firing 100 requests simultaneously may trigger 429 responses. Paginated requests where page N uses the cursor from page N-1 cannot be parallelized.When to use : When fetching N independent resources (user profiles, product details, file chunks) with no cross-dependencies and no aggressive rate limiting. The speedup is proportional to n.BM-04: Nested loops â€” the one that actually mattersThis is the classic. An outer loop iterates users; for each user, an inner loop scans all orders to find a match. O(nÂ²) comparisons.Result at n = 10,000 (30 trials):At n = 10,000 â€” not even a particularly large dataset â€” the nested loop takes 62 ms while the Map version finishes in under 1 ms. At n = 100,000, the gap widens dramatically further because the baseline is superlinear. This is where the power-law analysis tells the real story. Baseline exponent b = 1.47 (superlinear, approaching O(nÂ²)); optimized exponent b = 0.65 (sublinear). The gap grows with every increase in input size. At small n, both are fast. At large n, one is unusable and the other is instant.This is the optimization that matters. Not because itâ€™s syntactically clever, but because it changes the algorithm. A  gives O(1) average-case lookup. The nested loop gives O(n) per outer iteration. The total work changes from O(nÂ²) to O(n). No JIT compiler can bridge that gap. The benchmark spec predicted â‰¥100Ã— speedup at n = 10,000. We measured 64Ã— in JavaScript. The shortfall is because the baseline uses a  on first match, so average inner-loop iterations â‰ˆ n/2 rather than n â€” the effective complexity is ~O(nÂ²/2), not O(nÂ²). In , the same pattern delivers 1,864Ã— at n = 10,000 (see Python benchmarks below), where the interpreter overhead amplifies every extra iteration far more than V8.BM-05: Nested array methods â€” a constant-factor win, not algorithmicNested -in- on a 2D nÃ—1,000 matrix. The optimized version uses explicit  loops.Result at n = 100,000 (30 trials):A 6Ã— constant-factor speedup. This is a real, statistically unambiguous improvement (Cohenâ€™s d = 40.14 is enormous). But note: the speedup is flat across all input sizes â€” it does not grow with n.Scaling result (updated with nÃ—1,000 matrix):Both exponents are approximately 1.0 â€” linear scaling â€” and their 95% bootstrap confidence intervals fully overlap. Neither version scales as O(nÂ²); both are O(n) because total work = n rows Ã— 1,000 cols = linear in n. The 6Ã— speedup is therefore a constant multiplier: the JIT reduces but does not fully eliminate the per-call overhead of nested  callbacks at large scale. V8 JIT-compiles hot  callbacks aggressively, but at very large data volumes (100M total iterations here), the callback dispatch mechanism still costs ~6Ã— vs a raw  loop. If your loop body runs billions of times, the  syntax pays off. For typical data sizes (< 100k total iterations), the difference is sub-millisecond and not worth the readability tradeoff.BM-06: Chained array methods â€” also handledarray.filter(pred).map(transform) creates an intermediate array and makes two passes. The optimized version fuses into a single .Near-identical exponents. The theoretical constant-factor improvement (2n â†’ n) doesnâ€™t materialize because V8 optimizes the intermediate array allocation. Modern engines use inline caches and escape analysis to minimize the cost of short-lived intermediate arrays. The  version is harder to read and no faster. Keep  â€” itâ€™s clearer and V8 doesnâ€™t penalize it.Power-law regression fits  on log-log scale. The exponent  determines asymptotic behavior.BM-04 is the only module where baseline and optimized have fundamentally different scaling. Exponent 1.475 vs 0.648 â€” the gap widens with every increase in input size. This is the signature of an actual algorithmic improvement.BM-02 shows a meaningful exponent difference (0.792 vs 0.446) â€” the per-iteration parse cost drives the baseline curve steeper than the optimized single-parse version.BM-01 and BM-06 show nearly identical exponents between baseline and optimized. V8â€™s JIT optimizer has already eliminated the theoretical difference.BM-05 shows identical  but a 6Ã— absolute speedup. Both exponents are ~1.0 (linear), with fully overlapping 95% bootstrap CIs ([0.936, 1.356] vs [0.891, 1.268]). The  loop is consistently faster by a constant factor at large n, but the gap doesnâ€™t widen with scale. This is a JIT reduction of callback overhead, not an elimination of it.Most empirical exponents are below theoretical predictions. This is consistent across all modules and reflects V8â€™s aggressive optimization: JIT compilation, inline caching, hidden classes, and escape analysis all compress observed running times below naive complexity estimates.The textbook says for (const x of arr) { regex.test(x) } is O(n). But we measured b â‰ˆ 0.59 â€” closer to O(âˆšn). This doesnâ€™t mean the algorithm is sublinear. It means: V8 compiles hot loops to optimized machine code after a few iterations. Early iterations are slower (interpreted); later iterations are faster (compiled). This compresses the time-vs-n curve. Small n fits in L1 cache; large n spills to L2/L3/RAM. The cache penalty at large n is partially offset by better JIT optimization at large n. Modern CPUs predict loop branches nearly perfectly after a few iterations. The prediction cost is amortized over n.The practical implication: theoretical complexity analysis overestimates real-world performance differences for constant-factor optimizations. Only changes that alter the asymptotic class (like BM-04â€™s O(nÂ²) â†’ O(n)) produce speedups that scale with input size.40 open-source repositories, evenly split: 20 JavaScript/TypeScript and 20 Python. Stratified across five domains (8 repos per domain): Data Transformation, Web Serving, Build Tooling, UI/Rendering, Developer Utilities. Selection criteria: â‰¥500 GitHub stars, active maintenance, test suite present.Includes projects like lodash, Express, webpack, ESLint, Prettier, Apache Airflow, FastAPI, Django REST Framework, pytest, and Black.Repo selection methodologyWe selected 40 repositories using a stratified sampling approach to ensure the results represent diverse real-world workloads, not just one type of application. We queried GitHub for high-popularity repositories (stars > 500) across five predefined domains. We programmatically verified that each candidate met all three criteria (see ): active maintenance (commits in last 12 months), a functioning test suite, and primary language match. All 40 repositories passed 100% across all three criteria. We selected exactly 8 repositories per domain â€” verified programmatically: 8 repos in each of the 5 domains. Libraries that manipulate structures (lodash, ajv). High expected loop density. HTTP frameworks (Express, FastAPI). I/O heavy. Bundlers/compilers (webpack, Vite, Rollup, Parcel). Complex file processing loops. Graphics/DOM libraries (three.js, p5.js). Performance-critical tight loops. CLI tools, testing frameworks (Jest, pytest). Mixed workloads. lodash, Express, webpack, Vite, Rollup, Parcel, ESLint, Prettier, three.js, p5.js, Jest, etc. Apache Airflow, FastAPI, Django, Flask, pytest, Black, Celery, Scrapy, pandas, numpy, etc. (): Uses Babel parser + traverse. Detects regex-in-loop, json-parse-in-loop, nested-loops, sequential-await-in-loop, nested-array-methods. Scope tracking disabled () for robustness on complex bundles;  wraps traversal to skip malformed files. (): Uses Pythonâ€™s  module. Detects the same patterns via  with loop-depth tracking.Both detectors are structural pattern matchers â€” they identify syntactic anti-patterns, not runtime performance issues. A finding means â€œthis code  matches an anti-pattern,â€ not â€œthis code is slow.â€ The benchmark data tells us which structural patterns actually correlate with performance impact.JavaScript/TypeScript findings38,495 files scanned. 2,238 anti-pattern instances found.We categorized repositories to test the hypothesis that â€œcomputationalâ€ domains (Data Transformation, Rendering) would have cleaner loops than â€œglue codeâ€ domains (Web Serving, Dev Utils). The data shows a clear outlier:AST transformations and file processing often require deep nesting.Graphics engines (three.js) use nested loops for matrix/vertex operations.Test runners and CLI tools (Jest, Prettier).Request handlers tend to be shallow and I/O bound.Libraries like  are heavily optimized by hand.Build tooling (webpack, bundlers) dominates the findings, primarily because they traverse complex graph structures (ASTs, dependency trees) where nested recursion is often necessary.Top repositories by finding count:three.js is the dominant source of high-impact nested loops (188 instances) â€” a geometry/rendering engine that legitimately processes meshes with nested vertex iteration. webpack leads overall (403) but its findings are spread across all pattern types, with regex-in-loop dominating (175) â€” most are in source-map processing code. The new addition  (replacing ) contributes 232 findings, dominated by sequential-await-in-loop (119) from its plugin hook system.21,233 files scanned. 4,867 anti-pattern instances found.Nested loops dominate Python findings by a wide margin â€” CPythonâ€™s lack of JIT means every extra iteration is costly, and the detector correctly flags the pattern at high volume. Apache Airflow (1,206 findings) and Django (798) are the top contributors. Apache Airflowâ€™s large async codebase also contributes the bulk of sequential-await findings.Python benchmark results (CPython 3.13.12, 30 trials):We benchmarked the two patterns most likely to differ from V8 behavior:BM-01 equivalent â€” regex hoisting:BM-04 equivalent â€” nested loop vs dict lookup:These numbers are dramatically different from V8. CPython does not JIT-compile loops, so every interpreted iteration pays full bytecode dispatch overhead. The dict lookup improvement is 1,864Ã— in Python vs 64Ã— in JavaScript â€” the same algorithmic change, but CPython amplifies the per-iteration cost ~29Ã— more. If youâ€™re writing Python with nested loops over large collections, this is the single highest-priority fix in your codebase.Prevalence rate by pattern (% of JS repos containing at least one instance):Nearly every pattern appears in at least 20% of repos. These arenâ€™t rare edge cases â€” theyâ€™re common code idioms.Cross-referencing prevalence with benchmark impactThis is where the data gets interesting. The most prevalent patterns in real code are  the ones with the biggest benchmark impact:9â€“75Ã— (latency-dependent)JS: style only; Python: fix itThe most impactful anti-pattern (nested loops, 64Ã— speedup) is moderately prevalent (15.3% of JS findings, 66.2% of Python findings). Optimization effort is well-targeted â€” nested loops are both impactful and detectable.The second most impactful pattern (JSON.parse in loop, 46Ã— speedup) is extremely rare (1.6% of findings). In practice, developers rarely call  inside a tight loop on the same string. When they do, itâ€™s usually obvious and gets caught in review.Regex hoisting and â†’ rewriting are V8-only non-issues. In Python, regex hoisting delivers a consistent 2Ã— speedup. Array method rewriting shows a 6Ã— constant-factor improvement at very large n (100M+ total iterations), which matters for rendering engines and bulk data processors.Sequential await is the most prevalent JS pattern and one of the most impactful â€” up to 75Ã— speedup at n=100 with 2ms latency. But it requires dependency analysis before fixing.Part 3: What this means for real-world codeWhen nested loops actually hurtNot every nested loop is a performance problem. The key factors: A nested loop over two arrays of 10,000 items each does 100 million comparisons. A Map lookup does 10,000. API request handlers, render loops, event processors â€” code that runs on every user action. If  increases over time (user base, log volume, product catalog), a quadratic loop becomes a ticking time bomb. Nested loop over 5 fields Ã— 3 options = 15 iterations. A Map would be overkill. Startup configuration, migration scripts, one-time setup. Nobody cares if it takes 70ms instead of 1ms once. If the loop body makes a database call that takes 5ms, the iteration overhead is irrelevant.When sequential await mattersSequential  is context-dependent. Our scan found 895 JS instances and 457 Python instances â€” the most prevalent JS pattern overall. But not all of them are bugs:1. Intentionally Sequential (Good):
When the next iteration depends on the result of the previous one. Parallelization here would break correctness.2. Unintentionally Sequential (Bad):
When iterations are independent. This pattern serializes latency unnecessarily. If you can shuffle the input array and the code still works, it should be parallelized.Without analyzing data dependencies, static analysis canâ€™t distinguish these. Our detector flags the structural pattern; a human must assess the intent.The false positive problemOur JS detector found 723 regex-in-loop instances. Our benchmark shows regex hoisting produces 1.03Ã— speedup â€” effectively zero. That means 723 findings are, from a performance perspective, false positives.Similarly, 241 nested-array-method findings and an unknown portion of the 895 sequential-await findings are false positives for performance (though they may have readability value).This is a fundamental limitation of structural static analysis for performance: the tool detects code shape, not runtime cost. A  inside a  on a 5-element array costs nothing. The same pattern on a 10,000-element array costs 100 million operations. The AST looks identical.Node.js environment, not browser. All benchmarks ran in Node.js with V8. Browser environments share V8 (Chrome, Edge) but add DOM overhead, compositor scheduling, and memory pressure from the rendering pipeline. SpiderMonkey (Firefox) and JavaScriptCore (Safari) may have different JIT behaviors â€” a regex pattern that V8 caches might not be cached by other engines. Benchmark inputs are generated from seeded PRNGs â€” uniform distributions, controlled sizes, no I/O. Real-world loops often involve heterogeneous data, I/O interleaving, and memory pressure from concurrent operations. The synthetic setup isolates the loop pattern but doesnâ€™t capture system-level interactions. We measured sequential vs  at 2ms mock latency for n = 10, 50, 100. At n = 200, Windows socket limits (connection backlog exhaustion) caused failures during parallel warmup. The collected data (9.1Ã— to 75.3Ã— speedup) covers the most practically relevant range. BM-07 (DOM batching) requires a real browser with DevTools and was not included.BM-03 results do not include real network variance. The mock server uses a fixed 2ms delay with no jitter. Real HTTP latency has high variance (p50 vs p99 can differ 10Ã—), which affects both sequential and parallel completion times differently. All data from one machine (Windows x64, Node.js v24.11.0). JIT behavior, cache sizes, and scheduling vary across hardware and OS. The relative rankings should hold, but absolute timings will differ.Python benchmarks are limited to two patterns. We validated regex hoisting (2Ã— consistent) and nested loops (1,864Ã— at n=10,000) in CPython. The remaining patterns â€” sequential await (), dict comprehension inside loops, and nested comprehensions â€” lack Python benchmark data. Given CPythonâ€™s lack of JIT, itâ€™s reasonable to expect these also show larger speedups than their V8 equivalents.Power-law fit limitations. The scaling analysis uses log-log OLS regression with 5 data points (n = 10 to 100,000). Five points provide limited statistical power for distinguishing between, say, O(n log n) and O(n^1.3). The RÂ² values (0.87â€“0.99) indicate good fits, but the exponent estimates have meaningful confidence intervals that we havenâ€™t reported. The qualitative conclusion (BM-04 is superlinear, others are not) is robust; the exact exponent values should be interpreted loosely.Static analysis precision not formally evaluated. The detectors use structural pattern matching without ground-truth labeling. Formal precision/recall measurement would require manually labeling hundreds of findings as true/false positives â€” feasible but not completed. Based on spot-checking: regex-in-loop and json-parse-in-loop have high structural precision (the code literally does what the detector says); nested-loops has moderate precision (many are on small fixed-size collections); sequential-await has low precision for  impact (many are intentionally sequential).Based on the combined benchmark and prevalence data:Prioritize nested loop â†’ Map/Set refactoring. 343 JS instances (15.3%), 3,224 Python instances (66.2%), 64Ã— JS / 1,864Ã— Python benchmark speedup. Look for patterns where an inner loop scans a collection for a matching key. Replace with a pre-built  or . This is the single highest-impact optimization available.Hoist repeated parsing outside loops. JSON.parse, XML parsing, YAML parsing â€” any operation that produces the same result on the same input. Rare (36 JS instances) but impactful (46Ã—) when found. â†’  rewriting in JavaScript: only at massive scale. The 6Ã— speedup only appears at n = 100,000 rows Ã— 1,000 cols = 100M total iterations. For typical loops (< 1M total iterations), the difference is sub-millisecond. Write whichever is clearer. In Python, this distinction doesnâ€™t apply â€” CPython pays full overhead either way.Donâ€™t rewrite  to . No measurable benefit, and  is harder to read. The intermediate array allocation that theory warns about is optimized away in practice.Evaluate sequential  case by case. The static count is high (895 JS, 457 Python) but many are intentionally sequential. Focus on loops that fetch independent resources â€” those are genuine candidates for  or . Our benchmark shows up to 75Ã— speedup at n=100 with modest latency.In Python, always use  outside loops. Unlike V8, CPython does not fully eliminate the pattern-construction cost at call time. The 2Ã— speedup is consistent and free â€” one line change. In JavaScript, hoisting is a style choice only.What we didnâ€™t test (and should)Several gaps remain that would strengthen or qualify these findings: V8 dominates our JS results. SpiderMonkey (Firefox) and JavaScriptCore (Safari) may not cache regex the same way. BM-01â€™s â€œ1.03Ã— â€” donâ€™t botherâ€ conclusion is V8-specific.BM-03 at higher n and varying latency. We hit Windows socket limits at n = 200 parallel. Testing at n = 500â€“1,000 with concurrency throttling (, worker pools) would show where parallelization hits diminishing returns. vs sequential  in Python â€” the most prevalent Python pattern â€” has no benchmark data yet.BM-07 DOM batching in real browsers. Layout recalculation cost grows with DOM tree size. Chrome DevTools measurements with varying tree sizes would validate the DocumentFragment optimization. Our benchmarks measured wall-clock time. Map-based replacements trade time for space (the Map uses additional memory). For memory-constrained environments, the tradeoff analysis matters. 40 repos provide a starting point but limit statistical power for per-domain analysis. A 200+ repo scan would enable more robust prevalence estimates.Additional loop anti-patterns not coveredThis study focused on six structurally distinct patterns. Production-grade static analysis tools detect a broader set worth benchmarking in future work: /  inside a loop. Structurally equivalent to nested loops â€” each call is an O(n) linear scan, making the outer loop O(nÂ²). Replacing with a pre-built  gives O(1) membership checks. Tools like Code Evolution Lab flag this as  and auto-generate the  conversion. Prevalence in real codebases is likely higher than explicit nested  loops because the O(n) cost is hidden behind a method call. with array lookups in a loop. Iterating  and then calling  or  on the result inside the loop creates the same O(nÂ²) pattern. Direct property access () or a  eliminates the inner scan entirely.String concatenation in a loop (). Each  on a string allocates a new string object. At large n, this creates significant GC pressure. The fix â€” parts.push(x); parts.join('') â€” is a single allocation. V8 has some string rope optimizations, but they donâ€™t fully eliminate the allocation cost at high iteration counts.Synchronous file I/O in a loop (, ). Each call blocks the Node.js event loop for the full disk latency. Replacing with await Promise.all(files.map(f => fs.readFile(f))) parallelizes I/O and unblocks the event loop between reads. Expected speedup is proportional to the number of files and disk concurrency.ReDoS-vulnerable regex patterns. Patterns with nested quantifiers like  or  exhibit exponential backtracking on adversarial input. This is a correctness/security issue as much as a performance one â€” a single malicious string can stall the event loop for seconds. Static analysis can flag structurally dangerous patterns without running them; tools like Code Evolution Lab include a dedicated ReDoS detector that scores regex complexity and flags dangerous constructs.These patterns share the same root cause as the ones we benchmarked â€” redundant work per iteration â€” but differ in whether the fix is algorithmic (data structure substitution), I/O-structural (parallelization), or security-driven (regex redesign).Appendix A: Benchmark Environment & Methodology Node.js v24.11.0 (V8 12.x), Python 3.13.12 (CPython) (JS) /  (Python) 30 independent runs per (module, pattern, n) configuration. 50 iterations discarded before measurement to stabilize JIT/cache. Forced garbage collection ( / ) and 200ms sleep between trials to minimize thermal throttling and heap fragmentation. Strict correctness gate â€” baseline and optimized implementations must produce bit-identical output for all inputs before timing begins.Appendix B: Source code and data referenceAll code, data, and results are in the empirical-study repository under studies/04-loop-performance/.Scaling analysis (Step 2)Real-world scanning (Steps 3â€“4)Raw trial data: wallTimeNs, cpuTimeMs, heapBefore/After per (module, pattern, n, trial)Power-law fits: a, b, RÂ², empirical/theoretical complexity per moduleJS detector output: 2,238 findings across 38,495 filesresults/py-findings-<repo>.jsonPython detector output: 4,867 findings across 21,233 files (per-repo JSON files)results/prevalence-*.jsonPer-pattern prevalence rates and density per KLOCPer-repo profiles with git blame and patch tracking fields40-repo corpus with domain stratification]]></content:encoded></item><item><title>Building a Cloudflare Workers Usage Monitor with an Automated Kill Switch</title><link>https://pizzaconsole.com/blog/posts/programming/cf-overage</link><author>/u/PizzaConsole</author><category>reddit</category><pubDate>Sat, 21 Feb 2026 23:22:55 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[I run several Cloudflare Workers across multiple accounts. The billing model is pay-per-use: requests and CPU time beyond the included amounts add up quickly. Abuse can turn into a nasty surprise on the next invoice. I wanted something that would catch overages early and stop traffic before costs spiral.This post walks through what I built: a Worker that monitors usage, detects threshold breaches, and automatically disconnects Workers from the internet when limits are exceeded. It also generates a daily usage report with cost estimates.Cloudflare Workers billing is based on:Requests (10M included per month on the Paid plan, then $0.30 per million)CPU time (30M ms included, then $0.02 per million ms)If a Worker starts looping, gets hit by a bot, or has a bug that burns CPU, usage can spike fast. There is no built-in hard cap. You only find out when the bill arrives.I built a separate Worker that:Runs on a schedule (every 5 minutes) and fetches billing-period-to-date metrics from the Cloudflare GraphQL APICompares each Worker's usage against configurable thresholdsWhen a Worker exceeds a threshold, it disconnects that Worker from the internet (removes routes, custom domains, workers.dev) and sends a Discord alertRuns a daily report that aggregates usage across D1, KV, R2, Queues, Durable Objects, and Workflows, estimates cost, and sends a JSON report to DiscordThe "kill switch" is intentional: it stops traffic immediately. Re-enabling is manual after you investigate and fix the cause.The system is a single Worker with two cron triggers and one Workflow:: Overage check. Fetches metrics for all accounts, compares against thresholds, checks a D1 cooldown table (so we don't re-trigger the same overage every 5 minutes), and dispatches a Workflow instance per overage.: Daily report. Two parallel GraphQL queries (Worker metrics + account-level usage), aggregate per account, estimate cost using Workers Paid pricing, save to D1, send JSON to Discord.: One instance per overage. Disconnects DNS (zone routes, custom domains, workers.dev subdomain) via the Cloudflare API, then sends a Discord embed with the details.D1 stores two things: an  table for cooldown deduplication (with TTL so we don't re-fire on the same Worker within an hour), and a  table for report history.Plain and simple: this protects against , not . The kill switch cuts off public traffic to Workers. It does not protect against: If you have a public R2 bucket, anyone can read from it. Those requests bypass Workers entirely and are billed to your account. The kill switch cannot stop that. A Worker that calls itself (or another Worker) in a loop isn't exposed to the public internet. Nuking DNSâ€”routes, custom domains, workers.devâ€”does nothing. Internal calls don't go through that. The kill switch is useless here. Same story. A DO spinning out of control is internal. We don't cap or disconnect them. Queues, Workflows, etc. have their own billing. The daily report tracks them, but we don't auto-cap them.Thresholds are configurable via environment variables (global defaults) and per-Worker overrides in an accounts config file:: default 500k requests: default 5M ms (about 83 minutes of CPU): default 3600 (1 hour)Each account and Worker can override these. The accounts list is hardcoded (account IDs, billing cycle day, Worker names, optional per-Worker thresholds). A single API token with access to all accounts is used.The daily report gives a snapshot of usage and estimated cost for the current billing period. It pulls:Worker metrics: requests, errors, CPU time, subrequests per scriptAccount usage: D1 rows read/written and storage, KV operations and storage, R2 requests and storage, Queues operations, Durable Objects requests/duration/storage, Workflows requests/CPU/storageStorage is shown in MB. Billing period timestamps are full ISO (midnight start, 23:59:59 end). The report applies Workers Paid pricing and breaks down overage cost by product. Output goes to D1 and Discord as a JSON attachment.A few things I might change or add:Workers Logs in the report (Cloudflare's GraphQL API doesn't expose those metrics yet, so it's a placeholder)A way to re-enable Workers from the same system instead of doing it manually in the dashboardA UI for the report and controls, behind Cloudflare AccessIf you run multiple Cloudflare accounts and want guardrails against runaway usage, this pattern is a solid starting point. The core idea is simple: monitor, compare, and disconnect before the bill gets out of hand.]]></content:encoded></item><item><title>Colorado&apos;s Senate Bill 26-051</title><link>https://www.reddit.com/r/linux/comments/1rb5nf5/colorados_senate_bill_26051/</link><author>/u/nix-solves-that-2317</author><category>reddit</category><pubDate>Sat, 21 Feb 2026 23:16:11 +0000</pubDate><source url="https://www.reddit.com/r/linux/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Linux</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Back to FreeBSD: Part 1 (From Unix chroot to FreeBSD Jails and Docker)</title><link>https://hypha.pub/back-to-freebsd-part-1</link><author>/u/imbev</author><category>reddit</category><pubDate>Sat, 21 Feb 2026 23:12:17 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Working on a distributed background job scheduler - Help Needed</title><link>https://www.reddit.com/r/golang/comments/1rb5jyk/working_on_a_distributed_background_job_scheduler/</link><author>/u/indianbollulz</author><category>golang</category><category>reddit</category><pubDate>Sat, 21 Feb 2026 23:12:01 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[I wanted to build a small go service where webhooks/user actions kick off background work (emails, reports, uploads) with retries, leases, scheduling, DLQ, and idempotency keys, and where i could swap the backend without the behavior quietly changing.I looked around and there are good options, but theyâ€™re usually opinionated around one backend or one style: Asynq (Redis), River (Postgres), Machinery (Celery-style + multiple brokers), and newer multi-backend projects like Neoq / GoQueue. theyâ€™re great, but i couldnâ€™t find something thatâ€™s explicitly driver-first and proves semantic parity across backends with a conformance suite.So i started building TaskHarbor. Itâ€™s still under construction, but the core semantics are implemented and enforced via conformance tests (memory/postgres/redis). iâ€™m looking for contributors to help implement more drivers/backends and harden the system further.Iâ€™d love feedback from seasoned engineers on whether this has real production value beyond my own use cases. Specifically: could a driver-agnostic job scheduler, where semantics stay consistent across backends, be genuinely useful in real systems?Example project itâ€™s meant for: a webhook-driven order pipeline where the provider retries the same webhook 5 times. you enqueue with idempotency_key=order_id, TaskHarbor dedupes it, workers run with leases (crash-safe), retries back off, and hard failures land in DLQ.If you are interested to contribute, feel free to reach out in my DM's!]]></content:encoded></item><item><title>Stabilize `if let` guards (Rust 1.95)</title><link>https://github.com/rust-lang/rust/pull/141295</link><author>/u/nicoburns</author><category>rust</category><category>reddit</category><pubDate>Sat, 21 Feb 2026 23:10:22 +0000</pubDate><source url="https://www.reddit.com/r/rust/top/?sort=top&amp;t=day&amp;limit=3">Reddit - Rust</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Had fun provisioning OKD 4.21.0 â€” sharing my steps and asking for homelab ideas, Hope It Help!!</title><link>https://www.reddit.com/r/kubernetes/comments/1rb4auv/had_fun_provisioning_okd_4210_sharing_my_steps/</link><author>/u/Sea-Advantage-6099</author><category>reddit</category><pubDate>Sat, 21 Feb 2026 22:19:52 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>ProxyBridge: Proxifier Alternative to redirect any Linux/Windows/MacOS TCP and UDP traffic to HTTP/Socks5 proxy</title><link>https://github.com/InterceptSuite/ProxyBridge</link><author>/u/Ano_F</author><category>reddit</category><pubDate>Sat, 21 Feb 2026 21:41:25 +0000</pubDate><source url="https://www.reddit.com/r/linux/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Linux</source><content:encoded><![CDATA[A few months ago, I released ProxyBridge to solve proxy client limitations on desktop systems. The first version supported Windows and was designed as a free, open-source alternative to Proxifier.I specifically needed something like Proxifier but with UDP support, since Proxifier itself doesnâ€™t handle UDP. Thatâ€™s why ProxyBridge was built.After some time, I added macOS support, because there isnâ€™t a strong Proxifier like tool available there either and Proxifier on macOS also lacks UDP support.Now ProxyBridge supports Linux as well. Available as both GUI and CLI.There is no Proxifier for Linux, and while there are a few alternatives, none offer the same level of features or stability.This is the first Linux release and Iâ€™d really appreciate it if you could try it out. I am actively improving the app to make it run as smoothly as possible.If you run into any issues or have feedback, Iâ€™d love to hear from you. Your input will help make ProxyBridge more stable and reliable.]]></content:encoded></item><item><title>I scanned 50k radio streams and built an app for the ones that work</title><link>https://github.com/meehow/receiver</link><author>/u/meehow808</author><category>reddit</category><pubDate>Sat, 21 Feb 2026 21:12:00 +0000</pubDate><source url="https://www.reddit.com/r/linux/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Linux</source><content:encoded><![CDATA[I got tired of radio apps that make you hunt for working streams. Most directories are full of dead links, duplicates, and placeholder logos - so I built Receiver.I scan ~50k streams from radio-browser.info, verify each one is actually reachable and streaming, deduplicate, fetch proper logos, and ship the result as a clean SQLite database with the app. What survives: ~30k stations, all working.Built with Vala and GTK 4 - native GNOME app, no Electron. MPRIS integration, session persistence, 130 language translations. No sign-up, no ads, no tracking.Available as Snap, .deb, and AppImage. Flathub submission in progress.Happy to answer questions about the data pipeline, Vala/GTK 4 development, or packaging for Linux.]]></content:encoded></item><item><title>Folios: why were they needed, and have their introduction caused you any headaches?</title><link>https://www.reddit.com/r/linux/comments/1rb1jri/folios_why_were_they_needed_and_have_their/</link><author>/u/gleventhal</author><category>reddit</category><pubDate>Sat, 21 Feb 2026 20:26:11 +0000</pubDate><source url="https://www.reddit.com/r/linux/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Linux</source><content:encoded><![CDATA[I know that it's supposed to be an optimization in dealing with block sizes > page_size, and that it's a struct which contains a page (member), and that it's a sort of container type for mm stuff, but I am hoping someone with expertise can say more about it, and any kernel devs / hobbyists who might have some direct experience with it may have some thoughts. I believe I picked up a file corruption bug related to folios and writeback overlapping with some THP collapse_file stuff. I am hoping to have the bug completely understood over the next few days and wondered if other folk have interesting experiences or observations about folios. ]]></content:encoded></item><item><title>go-form: render + map + validate HTML forms from Go structs</title><link>https://github.com/donseba/go-form</link><author>/u/donseba</author><category>golang</category><category>reddit</category><pubDate>Sat, 21 Feb 2026 19:50:27 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[Hi gophers! Iâ€™ve been iterating on go-form for the last 2 years. It is a small library for server-rendered HTML forms where the source of truth is a Go struct.It targets the â€œI keep re-creating the same form markup + wiring field errors + parsing POST dataâ€ loop. and it helped me a lot while prototyping.You define a struct with tags, pick a template set (Plain / Bootstrap 5 / Tailwind), and render the whole form through `html/template` with a single `{{ form_render ... }}` call. It also includes requestâ†’struct mapping, built-in validation, optional translation hooks, CSRF middleware, and type-safe dropdown helpers.What it is: Struct-tag driven HTML form rendering + validation, built to drop into `net/http` and `html/template`.Why it exists: I wanted a repeatable pattern where forms, per-field errors, select options, and CSRF all stay close to Go types, without adopting a heavyweight framework.Renders forms from structs using tags like `form:"input,email" label:"Email" required:"true"`Built-in template sets: `templates.Plain`, `templates.BootstrapV5`, `templates.TailwindV3``html/template` integration via `FuncMap()` (template helpers like `form_render`)`MapForm(*http.Request, &dst)` to map submitted data into your struct (nested structs supported)Built-in validation (`required`, `min/max`, `minLength/maxLength`, `pattern`, `url`, allowed `values`, etc.) + pluggable custom validatorsCSRF middleware (token generation + validation + rotation) + helper to inject token into the form metadataOptional translation layer (`NewTranslatedForm`, `Localizer`) for labels/errors (and enum-ish select values)Typed selects: `SortedSelect[T]` + `SortedMultiSelect[T]` for stable dropdowns/multi-selects with non-string keysgo-form: render + map + validate HTML forms from Go structs (Plain / Bootstrap 5 / Tailwind) + CSRF + typed selectsI'm currently working on the last rewrite before I think to release a proper V1 version the pull request is open here.Does the â€œrender + decode + validateâ€ bundle feel helpful or too coupled?Anything obviously unidiomatic in the API surface?Which field types/templates would you want next?]]></content:encoded></item><item><title>Fake faces generated by AI are now &quot;too good to be true,&quot; researchers warn</title><link>https://www.techspot.com/news/111398-fake-faces-generated-ai-now-good-true-researchers.html</link><author>/u/esporx</author><category>ai</category><category>reddit</category><pubDate>Sat, 21 Feb 2026 19:30:16 +0000</pubDate><source url="https://www.reddit.com/r/artificial/top/?sort=top&amp;t=day&amp;limit=3">Reddit - AI</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Is the AI habit tracker app space actually evolving?</title><link>https://www.reddit.com/r/artificial/comments/1rb0296/is_the_ai_habit_tracker_app_space_actually/</link><author>/u/lebron8</author><category>ai</category><category>reddit</category><pubDate>Sat, 21 Feb 2026 19:26:00 +0000</pubDate><source url="https://www.reddit.com/r/artificial/top/?sort=top&amp;t=day&amp;limit=3">Reddit - AI</source><content:encoded><![CDATA[Iâ€™ve been testing a few AI habit tracker app options because I was curious whether AI actually adds anything meaningful beyond streaks.One Iâ€™ve tried recently is Resolve. What stood out wasnâ€™t some crazy prediction engine, but the short AI reflections after logging habits. Instead of just showing a missed day, it nudges you to think about what happened. Over time thatâ€™s helped me notice patterns around sleep and focus.Has anyone seen an AI habit tracker app that genuinely feels like itâ€™s doing more than summarizing inputs?]]></content:encoded></item><item><title>strace-tui: a TUI for visualizing strace output</title><link>https://www.reddit.com/r/rust/comments/1razq2z/stracetui_a_tui_for_visualizing_strace_output/</link><author>/u/Rodrigodd_</author><category>rust</category><category>reddit</category><pubDate>Sat, 21 Feb 2026 19:12:34 +0000</pubDate><source url="https://www.reddit.com/r/rust/top/?sort=top&amp;t=day&amp;limit=3">Reddit - Rust</source><content:encoded><![CDATA[Some time ago I was trying to see how job control was implemented in  using , and I found out that there was an option  that prints a backtrace for each syscall. The problem, though, was that it only reported executable/offset pairs, I needed to use something like  to get the actual file and line number. So I decided to write a tool to do that. But since I would already be partially parsing the output of  anyways, I figured I could just parse it fully and then feed the result to a TUI.And thatâ€™s what  is. It is a TUI that shows the output of  in a more user-friendly way: resolving backtraces, coloring syscall types and TIDs, allowing you to filter syscalls, visualizing process fork/wait graphs, etc. It is built using  and  for the TUI, and uses the  crate to resolve backtraces.: More than 90% of the code was written by an agentic AI (copilot-cli with Claude Opus 4.6). I used this project to experiment with this type of tool, to see how good it is. I didnâ€™t do a full, detailed review of the code, but from what Iâ€™ve seen, the code quality is surprisingly good. If I had written it myself, I would probably have focused a little more on performance (like using a  for the list of displayed lines instead of rebuilding the entire list when expanding an item), but I didnâ€™t notice any hangs when testing with a trace containing 100k syscalls (just a bit of input buffering when typing a search query), so I didnâ€™t bother changing it.]]></content:encoded></item><item><title>[R] Reinforcement Learning for LLMs explained intuitively</title><link>https://mesuvash.github.io/blog/2026/rl_for_llm/</link><author>/u/zephyr770</author><category>ai</category><category>reddit</category><pubDate>Sat, 21 Feb 2026 18:29:38 +0000</pubDate><source url="https://www.reddit.com/r/MachineLearning/top/?sort=top&amp;t=day&amp;limit=3">Reddit - ML</source><content:encoded><![CDATA[RL/ML papers love equations before intuition. This post attempts to flip it: each idea appears only when the previous approach breaks, and every concept shows up exactly when itâ€™s needed to fix what just broke. Reinforcement Learning for LLMs "made easy"   submitted by    /u/zephyr770 ]]></content:encoded></item><item><title>How should I think when developing in Go?</title><link>https://www.reddit.com/r/golang/comments/1rawbqx/how_should_i_think_when_developing_in_go/</link><author>/u/GoldmannOnTheHill</author><category>golang</category><category>reddit</category><pubDate>Sat, 21 Feb 2026 17:03:08 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[I come from very strict paradigm languages, and the first thing I noticed when I first encountered Go was its "unique paradigm".It has traces of OOP, but it's not fully OO! It has traces of procedural, but it's not completely procedural...Because of that, I'm really trying to deeply understand the philosophy behind Go.When designing and architecting applications in Go, what mindset should I adopt? What principles and design philosophies guide idiomatic Go development?Of course, I understand that there are multiple ways to approach software design, but Iâ€™d like to know how experienced Go developers typically think about structuring and planning projects.]]></content:encoded></item><item><title>Benchmarking 5 concurrent map implementations in Go (sync.Map, xsync, cornelk, haxmap, orcaman)</title><link>https://github.com/puzpuzpuz/go-concurrent-map-bench</link><author>/u/puzpuzpuz</author><category>golang</category><category>reddit</category><pubDate>Sat, 21 Feb 2026 16:59:56 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[Benchmarks for 5 concurrent hash map implementations in Go: sync.Map, xsync.Map, cornelk/hashmap, alphadose/haxmap, and orcaman/concurrent-map.Workloads: read-heavy to write-heavy (100%/99%/90%/75% reads), with and without warm-up, plus range-under-contention (iteration while a writer mutates the map).Key types: string and int. Map sizes: 100 to 1M entries. GOMAXPROCS: 1, 4, 8, 12.Results are in the README with plots and a summary table.Disclaimer: I'm the author of xsync, one of the libraries benchmarked here. I did my best to keep the benchmark fair. If you spot issues or think another library should be included, please open an issue or PR.]]></content:encoded></item><item><title>GitOps/Nix makes your life easier with coding agents(I use codex-cli)</title><link>https://www.reddit.com/r/kubernetes/comments/1ravm7w/gitopsnix_makes_your_life_easier_with_coding/</link><author>/u/kosumi_dev</author><category>reddit</category><pubDate>Sat, 21 Feb 2026 16:36:13 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[I use FluxCD and managing a k8s cluster has never been easier with codex.All cluster configs are now just plain YAML files, and the coding agent can do everything for you. You don't need to describe the context to it, copy LLM snippets and run its commands for debugging: it can run flux and kubectl automatically.It can directly go to the official website, read the docs and follow the guides.It works the same way with Nix too. Nix is also Git-based declarative config. A Nix flake contains all the info that the coding agent needs to know to act.]]></content:encoded></item><item><title>[D] Questions regarding the new Findings track at CVPR 2026</title><link>https://www.reddit.com/r/MachineLearning/comments/1rauuz3/d_questions_regarding_the_new_findings_track_at/</link><author>/u/Majestic_Beautiful52</author><category>ai</category><category>reddit</category><pubDate>Sat, 21 Feb 2026 16:06:08 +0000</pubDate><source url="https://www.reddit.com/r/MachineLearning/top/?sort=top&amp;t=day&amp;limit=3">Reddit - ML</source><content:encoded><![CDATA[Meta-reviews just dropped. My paper got two weak rejects and a borderline accept (got dinged for missing some VLM baselines), but the AC recommended it to the new "Findings" track after the AC triplet meeting (not sure what this is).For context, Iâ€™m a solo undergrad working entirely without a supervisor. I donâ€™t have a PI or a lab to ask about how this stuff works, so my only source of info is whatever I can scrape together online. This was also my first time submitting to a top-tier international venue (my only prior publication was at a domestically prestigious conference here in India).Iâ€™m honestly leaning heavily towards opting in because I would love the chance to present in person at CVPR. The FAQ mentions that Findings papers get a poster slot and are expected to present during the main conference days (June 5-7) rather than the workshop days (June 3-4).I had a couple of doubts I couldn't find answers to on the web, on reddit or in the attached document with the email.Does anyone know if the Findings posters are actually mixed in with the main track posters during those main conference days, or do they get sidelined into a separate room/different time?How is a Findings paper viewed on a CV for grad school applications (non tech - finance/business - my paper is related to finance as well) compared to a standard workshop paper or main track paper?For anyone familiar with how NLP conferences handle Findings, is there a stigma attached to it, or do people actually visit the posters and are they still considered coming from a prestigious venue?If you got the same AC recommendation today, are you opting in, and why?Would really appreciate any honest advice!Thank you all for your time.]]></content:encoded></item><item><title>Lawyer says Google shut down his Gmail, Voice and Photos after NotebookLM upload</title><link>https://discrepancyreport.com/lawyer-says-google-shut-down-his-gmail-voice-and-photos-after-notebooklm-upload/</link><author>/u/jmdglss</author><category>ai</category><category>reddit</category><pubDate>Sat, 21 Feb 2026 15:55:43 +0000</pubDate><source url="https://www.reddit.com/r/artificial/top/?sort=top&amp;t=day&amp;limit=3">Reddit - AI</source><content:encoded><![CDATA[Imagine losing your email address, phone number, photos, contacts and more after using an AI tool for work.Thatâ€™s what Brian Chase says happened after he uploaded text-only law enforcement reports to Googleâ€™s NotebookLM while working on a criminal case. NotebookLM is an AI research tool that summarizes and answers questions about files and links that users upload.Chase is an adjunct professor at the University of Arizona law school and managing director of digital forensics and eDiscovery at ArcherHall.In a Feb. 16 LinkedIn post, he wrote that he uploaded reports to NotebookLM and â€œwithin secondsâ€ received a notification that he had violated Googleâ€™s terms of service. He said the reports referenced child sexual abuse material because the defendant was charged with possessing it, but that the upload included â€œno images or videos â€¦ only text.â€â€œGoogle stored all my photos, contacts, phone backups, Gmail account, and even my phone number,â€ he wrote. â€œI cannot access any of it today.â€ He added that his phone number was a Google Voice number and that other services tied to his Google account stopped working.Chase said he uploaded the report on Saturday, Feb. 14, received a terms-of-service warning and deleted it the same day. He said that on Monday, he woke up signed out of Google services and saw an alert that his account was disabled.â€œAlthough I submitted an appeal,â€ Chase wrote that day, â€œGoogle offers no way to contact them to provide additional information.â€Early Tuesday, Chase said he received an email stating the material violated Googleâ€™s terms of service and that if he agreed to them, he could download his account contents through Google Takeout. He said the email â€œnever really said my account was restored.â€ Later Tuesday, he posted a comment on the LinkedIn post saying, â€œGoogle restored access to my account.â€Chase said he was doing routine legal work. â€œNothing I uploaded was illegal. Nothing I did violated the attorney ethical rules. But Google flagged it anyway, and there is very little recourse once that happens.â€I emailed Googleâ€™s media team on Monday with questions about Chaseâ€™s post, whether NotebookLM activity can trigger an account-level enforcement action and why a text-only upload tied to lawful legal work would lead to an account-wide lockout. I followed up multiple times through late Tuesday. Google did not respond.In other cases involving sensitive material, the consequence is not an account lockout but an AI tool that wonâ€™t answer.NotebookLM users report that the tool refuses to summarize or answer questions about public records from the Epstein files. In a , users say it returns a standard message, â€œNotebookLM canâ€™t answer this question. Try rephrasing it, or ask a different question,â€ when asked to summarize documents or extract basic information, including questions about associates.In my own testing, NotebookLM repeatedly refused to summarize or answer questions about Justice Department documents from the Epstein case, sometimes after generating a few lines in response. I sent Google a screenshot from that testing as part of my request for comment.OpenAI â€˜working on a fixâ€™On OpenAIâ€™s ChatGPT, users, including me, noticed a similar pattern when analyzing Epstein case records. The AI tool begins generating an answer, then the text disappears and is replaced by a red warning that says, â€œThis content may violate our usage policies.â€OpenAIâ€™s communications team responded by email on background, saying, â€œThis was an incorrect refusal, and weâ€™re working on a fix to address it.â€Â The company did not answer follow-up questions about what caused the behavior or when a fix would roll out.The refusal behavior is not uniform across AI systems.In my own testing, I gave the same Epstein case document to DeepSeek and Kimi, each based in China. Both summarized it and answered questions without the refusals I encountered in ChatGPT and NotebookLM. Reddit users .Last Updated on February 18, 2026 by Joe Douglass]]></content:encoded></item><item><title>Index, Count, Offset, Size</title><link>https://tigerbeetle.com/blog/2026-02-16-index-count-offset-size/</link><author>/u/matklad</author><category>reddit</category><pubDate>Sat, 21 Feb 2026 15:19:03 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[Wherein we make progress towards solving one of the most vexing
problems of Computer Science â€” naming things.I am at a point in my career where the bulk of my bugs are stupid â€” I
simply fail to type in the code I have in my mind correctly. In
languages with shadowing (like Rust), I will fail to use a shadowed
variable from the outer scope. In languages without shadowing (like
Zig), I will use the wrong version of a variable.Pests like these are annoying, so I am always on the lookout for
tricks to minimize the probability of bugs. One of the best possible
tricks is of course strong static typing. Types are good at preventing
me from doing stupid things by accident. But types have limitations. The
text of a well-typed program is a two-in-one artifact â€” a specification
of behavior of a machine (the algorithm), and a proof that the behavior
is not unacceptable. Zero cost abstractions are code without behavior,
just proofs!The art of skillful typing lies in minimizing verbosity of the proof,
while maximizing the amount of unwanted behaviors ruled out, weighted by
the probability and the cost of misbehavior. But this ratio is not
always favorable â€” the code can be so proof-heavy that it becomes
impossible to understand what it actually !Thereâ€™s one particular cranny where types donâ€™t seem to usefully
penetrate yet: indexing and associated off-by-one errors.If you donâ€™t need indexing , you can use newtype
pattern to prevent accessing oranges with apple-derived indexes. You
can even go further and bind indexes to  arrays, using,
e.g., Gankra
trick, but I havenâ€™t seen that to be useful in practice.If, however, you  indexes, you need to be extra
careful to stay in bounds of an array, and need to be mindful that the
maximum valid index is one less than the length of the array. While we
donâ€™t solve this problem perfectly at TigerBeetle, I think we have a
naming convention that helps:We consistently use  whenever we talk about the
number of items, and  to point to a particular item.
The positive
invariant is . Consistency is the trick
â€” there are certain valid and invalid ways to combine indexes and counts
in an expression, and, if thereâ€™s always an  or a
 suffix in the name, wrong combinations immediately
jump out at you, dear reader, even if you donâ€™t understand the specifics
of the code.In low-level code you often need to switch between a well-typed
representation and raw bytes . To not
confuse the two index spaces, the â€œcount of bytesâ€ is always called a
. By definition,And  is the bytewise counterpart of
.We donâ€™t use  in our code, as its meaning is
ambiguous. Rust  is the byte- of
the string, but Pythonâ€™s  is the 
of Unicode code-points!Hereâ€™s an example of the naming convention in action from NodePool:You can see that the  calculation is correct
mechanically, just from the names of the variables.And hereâ€™s an  example from our 
implementation:Note well that the  convention synergizes
with two other TigerStyle shticks. We use â€œbig endian namingâ€, where
qualifiers are appended as suffixes:source
source_words
source_indexAnd we try to make sure that dual names have the same length:The code aligns itself, and makes the bugs pop out:Of course, a simple naming convention by itself wonâ€™t make software
significantly better. But grains of sand add up to Dune: thereâ€™s no one
trick to get rid of the bugs, but you can layer your defenses to
exponentially decrease the probability of a failure.]]></content:encoded></item><item><title>[D] Is this what ML research is?</title><link>https://www.reddit.com/r/MachineLearning/comments/1ratkiz/d_is_this_what_ml_research_is/</link><author>/u/AdministrativeRub484</author><category>ai</category><category>reddit</category><pubDate>Sat, 21 Feb 2026 15:14:51 +0000</pubDate><source url="https://www.reddit.com/r/MachineLearning/top/?sort=top&amp;t=day&amp;limit=3">Reddit - ML</source><content:encoded><![CDATA[I don't have a lot of resources. I had an idea to work on something that would improve an area of multimodal learning. I ran experiments with a small model (500M parameters) and compared my method with a similar version of contemporary methods, and at my scale my method is better. I could not scale vertically (larger model, larger training runs, more data, etc...) so I decided to scale horizontally - more evaluations and a deeper analysis of the method.My paper has a lot of small nuggets of information that a lot of people can take and reproduce at larger scales and I'm pretty sure they would work. Obviously not 100% sure.. you never are unless you actually run the experiments. In hindsight this should have been a short paper or a workshop paper.Just submitted my paper to CVPR. Initially got 5 3 3. Reviewers all said different things, except for "run more evaluations", but were all willing to raise scores. Responded with 1 more evaluation (with positive results) and explained why the rest were nonsensical (was not that harsh obviously).To be more concrete, they wanted me to compare my model to models that were 14x larger, had 4x more resolution, and require 5-10x the inference time. To me it is clear we are not even in the same ballpark of computational resources, so we should not compare both methods. Additionally, they wanted me to run evaluations on datasets that are simply not suited to evaluate my method. My method targets high-resolution/fine detail settings and they wanted me to evaluate my method on datasets with ~500px images (on average).I made a rebuttal and submitted.Now I got the final scores: 5 -> 4, 3 -> 3, 3 -> 2 (reject, not even recommended to submit to findings). The meta review stated that I had to compare my method to newer and "better" methods. They are not better, just are a brain dead version of mine, but I cannot evaluate their EXACT method at my scale or mine at theirs. This paper was supposed to be something that the reader would read and say "oh yeah, that is a smarter way of doing things... it makes sense, let me try it out at a larger scale", but it seems like the current state of the research community will not stop and put things into context and will only look at dataset evaluations.Why do people only want to see which kind of stuff has the highest accuracy? This only leads to whoever is the fastest/has more resources to win. Regardless of the soundness of the method. ML research should not be an engineering competition...]]></content:encoded></item><item><title>Linux 7.0 lands more AMDGPU fixes for old Radeon hardware</title><link>https://www.phoronix.com/news/Linux-7.0-Old-AMDGPU-Fixes</link><author>/u/Fcking_Chuck</author><category>reddit</category><pubDate>Sat, 21 Feb 2026 15:05:16 +0000</pubDate><source url="https://www.reddit.com/r/linux/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Linux</source><content:encoded><![CDATA[
Following last week's main set of DRM kernel graphics driver feature updates for Linux 7.0, merged on Friday to Linux 7.0 Git was the first round of fixes to these Direct Rendering Manager drivers. Dominating most of the code changes in this latest pull were AMDGPU fixes, including more enhancements for aging Radeon graphics processors.
The now-merged code to Linux 7.0 includes more AMDGPU fixes from Timur KristÃ³f of Valve's open-source Linux graphics team. Timur KristÃ³f has been the one leading the effort to improve the old AMD GCN 1.0 and GCN 1.1 GPU support with the AMDGPU kernel driver and drove through that default change from the legacy Radeon DRM driver. Timur has continued taking care of some loose ends like some APU support issues. The latest patches now part of Linux 7.0 take care of a "black screen" issue observed with analog connector support when using the AMDGPU DC display code with the likes of the Radeon HD 7790. The code also makes the analog connector support more consistent and closer to parity with other display connector types in the AMDGPU display code.
Alex Deucher also landed a fix to the AMDGPU driver for keeping VGA memory on Apple MacBooks with switchable graphics. For old Apple MacBook Pros powered by Intel CPUs and bearing switchable graphics, a fix has landed around the dGPU virtual address space to resolve an issue of cursor flickering and AMDGPU errors when using GNOME on Wayland with the likes of the Radeon Pro 560.
AMDGPU in Linux 7.0 Git also has fixes for the Hainan GPU, some updates for the new AMD graphics IP blocks introduced to the Linux 7.0 kernel for upcoming hardware, Fastboot fixes, and a variety of other fixes. Many of these fixes where relevant should be back-ported to the stable kernel series in the coming days.
More details on these now-merged AMDGPU fixes plus some Intel graphics driver fixes too via this DRM merge.]]></content:encoded></item><item><title>Structured concurrency &amp; Go</title><link>https://www.reddit.com/r/golang/comments/1rat6lm/structured_concurrency_go/</link><author>/u/sigmoia</author><category>golang</category><category>reddit</category><pubDate>Sat, 21 Feb 2026 14:59:19 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[I work at one of those large companies where migration work never stops. We recently acquired a few other companies. To coalesce the platforms of multiple companies, we're rewriting a big chunk of our codebase in Go. The new platform itself is also being built from scratch in Go.But the catch is we haven't historically been a Go shop. A lot of folks are coming from Python and Kotlin backends. So in our knowledge-sharing channel, we constantly see feature comparisons across these languages.One thing that came up recently is how hard structured concurrency feels in Go.  is unstructured by default unless you wire it up with sync primitives like . A bunch of people also pointed out how Pythonâ€™s  or Kotlinâ€™s  make cancellation feel trivial. In Go, cancellation semantics require explicit context checking and manual bailouts.We had some interesting internal discussions around this that I think would be valuable for others going through similar journey.So I summarized some of the key points that came up and added a few examples. Iâ€™m curious how others approach structured concurrency in Go. How do you avoid the usual leaks that happen with manual plumbing?]]></content:encoded></item><item><title>How can a government actually stop or control AI?</title><link>https://www.reddit.com/r/artificial/comments/1rasu2g/how_can_a_government_actually_stop_or_control_ai/</link><author>/u/seobrien</author><category>ai</category><category>reddit</category><pubDate>Sat, 21 Feb 2026 14:43:57 +0000</pubDate><source url="https://www.reddit.com/r/artificial/top/?sort=top&amp;t=day&amp;limit=3">Reddit - AI</source><content:encoded><![CDATA[Seeking legal and technical answers. Working with some people on this question and we keep reaching a conclusion that it can't. That it's not possible.AI can exist anywhere in the world, governed under others' laws (or none at all). It can't be blocked since the internet can't technically, actually, block something. It can be accessed through countless channels, apps, or experiences.Is there a legitimate way in which AI can technically and truly be made safe or controlled?Important question for reasons we don't think everyone realizes. If the answer is "no" then politicians are effectively causing harm by pretending they can... They pander votes under false pretenses and they set a false sense of security that we'll be safe because they'll make laws to protect us. It's like passing a law requiring that fire not hurt us. Sure, pass the law, but it's not possible for it to be so. ]]></content:encoded></item><item><title>Dorgu - giving your K8s apps a &quot;living identity&quot; that learns and validates</title><link>https://www.reddit.com/r/kubernetes/comments/1ras4gc/dorgu_giving_your_k8s_apps_a_living_identity_that/</link><author>/u/AdExpensive2433</author><category>reddit</category><pubDate>Sat, 21 Feb 2026 14:13:41 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[I've been a platform engineer at an Indian startup and have dealt with the frustration of Kubernetes having no memory of what applications actually need! When something breaks, you're scrambling through docs and slack threads and tribal knowledge to understand dependencies, resource patterns and who owns what. So I built  - an open-source CLI + Operator that creates  and  as live CRDs in your cluster. What makes this different from yet another manifest generator:  is a CRD that lives in your cluster, it captures what your app needs (resources, scaling, health, dependencies)  is a singleton CRD representing your cluster's identity - nodes, add-ons, policies, resource capacityThe  validates every deployment against its persona and updates status with issues and recommendationsBecause they're native K8s resources, you can build your own agents, MCPs, or sidecars that query this understanding layer directlyI'd love your feedback on the current state of the project. What's missing? Would you try this?]]></content:encoded></item><item><title>This Week in Plasma: 6.6 is Here!</title><link>https://blogs.kde.org/2026/02/21/this-week-in-plasma-6.6-is-here/</link><author>/u/diegodamohill</author><category>reddit</category><pubDate>Sat, 21 Feb 2026 14:05:55 +0000</pubDate><source url="https://www.reddit.com/r/linux/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Linux</source><content:encoded><![CDATA[Welcome to a new issue of This week we released Plasma 6.6! So far itâ€™s getting great reviews, even on Phoronix. ðŸ˜As usual, this week the major focus was on triaging bug reports from people upgrading to the new release, and then fixing them. There were a couple of minor regressions as a result of the extensive work done to modernize Plasma widgetsâ€™ UI and code for Plasma 6.6, and weâ€™ve already got almost all of them fixed.In addition to that, feature work and UI improvements roared into focus for Plasma 6.7! Lots of neat stuff this week. Check it all out:While in the  effect, you can now switch between virtual desktops by scrolling or pressing the / keys! (Kai Uwe Broulik, KDE Bugzilla #453109 and kwin MR #8829)On Wayland, you can optionally synchronize the stylus pointer with the mouse/touchpad pointer if this fits your stylus usage better. (Joshua Goins, KDE Bugzilla #505663)The old print queue dialog has been replaced with a full-featured print queue viewer app, allowing you to visualize multiple queues of multiple printers connected locally or over the network! It still offers a good and normal experience for the common case of having one printer, but now also includes loads of enterprisey features relevant to environments with many printers. (Mike Noe, print-manager MR #280)You can now exclude windows from screen recording using permanent window rules! (Kai Uwe Broulik, kwin MR #8828)Added a new  command-line option to  that allows invoking it with its â€œaccept screenshot on click-and-releaseâ€ setting using automation tools. (Arimil, spectacle MR #479)The  feature accessed with + no longer inappropriately respects key repeat, and therefore no longer becomes practically impossible to open with a very high key repeat rate. (Ritchie Frodomar, KDE Bugzilla #515940)Close buttons on the default â€œThumbnailsâ€ + task switcher are now more legible on top of the window thumbnails. (Nate Graham, kwin MR #8830)The  widget now shows a more appropriate icon in the panel or  when you disable Wi-Fi. (Nate Graham, plasma-nm MR #526)The  app and widgets now respect your chosen â€œbinary unitâ€ choice. This means for example if youâ€™ve asked for file sizes to be expressed as â€œGBâ€ (gigabyte, or one billion bytes) rather than â€œGiBâ€ (gibibyte, or 2^30 bytes), the system monitoring tools now respect that. (David Redondo, KDE Bugzilla #453854)If the auto-generated scale factor for a screen is very close to 100%, 200%, or 300%, it now gets rounded to that value, prioritizing performance and visual fidelity. (Kai Uwe Broulik, kwin MR #8742)The  widget now displays more sensible tooltip and placeholder text when it hasnâ€™t been used yet. (Joshua Goins, kdeplasma-addons MR #1010)The â€œTerminate this frozen windowâ€ dialog now shows a little spinner as it tries to terminate the window, so you donâ€™t think itâ€™s gotten stuck. (Kai Uwe Broulik, kwin MR #8818)The  sidebar now appears on the screen with the pointer on it, rather than always appearing on the left-most screen. (Fushan Wen, plasma-workspace MR #6251)Fixed a case where KWin could crash during intensive input method usage. (Vlad Zahorodnii, KDE Bugzilla #506916)Fixed a case where KWin could crash when waking up the system while using the  or  input-sharing apps. (David Redondo, KDE Bugzilla #515179)Fixed a case where  could crash while trying to install updates. (Harald Sitter, KDE Bugzilla #515150)Fixed a regression that broke drag-and-drop onto pinned  widget icons. (Kai Uwe Broulik, KDE Bugzilla #516242)Fixed a regression that made certain popups from third-party software appear in the wrong place on the screen. (Vlad Zahorodnii, KDE Bugzilla #516185)Fixed a minor visual regression in the  effect on rotated screens. (Vlad Zahorodnii, kwin MR #8817)Fixed a layout regression that made the  widgetâ€™s tooltip close buttons get slightly cut off for multi-window apps while window thumbnails were manually disabled. (Christoph Wolk, KDE Bugzilla #516018)Fixed a layout regression that slightly misaligned the search bar in the  widget. (Christoph Wolk, KDE Bugzilla #516196)Fixed a layout regression that made some  popups always show an unnecessary hamburger menu. (Arjen Hiemstra, KDE Bugzilla #516135)Fixed a regression that made some GTK apps not notice system-wide changes to the color scheme and enter their dark mode. (Nicolas Fella, KDE Bugzilla #516303)Fixed server-to-client clipboard syncing in Plasmaâ€™s remote desktop implementation. (realies, krdp MR #144)The new  introduced in Plasma 6.6 no longer shows accounts on the system that a human canâ€™t actually log into. (Matthew Snow, plasma-login-manager MR #109)Fixed a layout issue that made a label in the panel configuration dialog disappear when using certain Plasma styles. (Filip Fila, KDE Bugzilla #515987)Fixed a layout issue that made the notification dialog too tall for very short text-only notification messages. (Kai Uwe Broulik, plasma-workspace MR #6145)Fixed an issue that set the screen brightness to too low a level on login in certain circumstances. (Xaver Hugl, KDE Bugzilla #504441)Fixed a layout issue that made the song or artist names in the  widget get cut off too early when the widget was placed in a panel in between two spacers. (Greeniac Green, KDE Bugzilla #501166)Improved the  widgetâ€™s reliability with forecasts from the Environment Canada provider. (Eric Soltys, kdeplasma-addons MR #1008)Made the progress indicator built into icons in the  widget move in the appropriate direction when using the system with a right-to-left language like Arabic or Hebrew. (Oliver Beard, KDE Bugzilla #516053)Custom icons embedded in third-party widgets that appear in the  sidebar now also appear in those widgetsâ€™ â€œAbout this widgetâ€ pages. (Mark Capella, KDE Bugzilla #509896)Eliminated a source of visual glitchiness with certain fade transitions while using an ICC profile. (Xaver Hugl, KDE Bugzilla #515194)Fixed a case where KDEâ€™s desktop portal could crash when copying certain data over a remote desktop connection. (David Edmundson, KDE Bugzilla #515465)Improved animation performance throughout the system by leaning more heavily on the Wayland  protocol. (Vlad Zahorodnii, KDE Bugzilla #516240)KDE has become important in the world, and your time and contributions have helped us get there. As we grow, we need your support to keep KDE sustainable.Beyond that, you can help KDE by directly getting involved in any other projects. Donating time is actually more impactful than donating money. Each contributor makes a huge difference in KDE â€” you are not a number or a cog in a machine! You donâ€™t have to be a programmer, either; many other opportunities exist.You can also help out by making a donation! This helps cover operational costs, salaries, travel expenses for contributors, and in general just keeps KDE bringing Free Software to the world.To get a new Plasma feature or a bugfix mentioned hereEnter your email address to follow this blog and receive notifications of new posts by email.]]></content:encoded></item><item><title>golang protobuf in 2026</title><link>https://www.reddit.com/r/golang/comments/1rapxyq/golang_protobuf_in_2026/</link><author>/u/uragnorson</author><category>golang</category><category>reddit</category><pubDate>Sat, 21 Feb 2026 12:28:51 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[I was wondering what is the preferred way to do golang + protobuf in 2026. Do I still have to download protoc or are there any natives I can use with the golang compiler. I see some developments on golang section https://go.dev/blog/protobuf-apiv2. But it seems I still need to get external tooling? ]]></content:encoded></item><item><title>Parse, don&apos;t Validate and Type-Driven Design in Rust</title><link>https://www.harudagondi.space/blog/parse-dont-validate-and-type-driven-design-in-rust</link><author>/u/haruda_gondi</author><category>rust</category><category>reddit</category><pubDate>Sat, 21 Feb 2026 12:13:26 +0000</pubDate><source url="https://www.reddit.com/r/rust/top/?sort=top&amp;t=day&amp;limit=3">Reddit - Rust</source><content:encoded><![CDATA[In the Rust Programming Language Community Server, thereâ€™s tag named  which links to an article about the concept of avoiding validation functions and encoding invariants in the type level instead. I usually recommend it to beginners/intermediates to Rust who are struggling with designing APIs.The only problem is that it uses Haskell to explain its concepts.Yeah, itâ€™s , but for beginners unfamiliar with the functional paradigm, it might not be so approachable. And so I wanted so write a blog post about this pattern but in a rather Rust-centric way. So letâ€™s start!One basic example I can give is a function that divides a number by another number.This is fine, but unfortunately it can panic when  has the value of zero:Thatâ€™s fine and dandy if we want erroneous values to fail loudly at runtime, but what if we want stronger guarantees? This is especially important when some operations donâ€™t fail loudly, like the following:Thereâ€™s no error! But do we want that?We could add an  in the  function to emulate typical integer division behavior.Cute! But thereâ€™s still a problem of running into panics only at runtime. My beef with Python (or any other dynamic language for that matter) is that a lot of errors only arises when you run the program. Thatâ€™s why theyâ€™re adding typechecking to these languages: people want to bubble some mistakes to compile-time (or typecheck-time, whatever). We can use Rustâ€™s rich type system to communicate these errors at build time.One way, which I think is the more common way as people are more familiar with it is the idea of fallible functions, which return either an  or a .This is a fine way to do things, as it communicates that (1) the function can fail, and (2) you can handle the failing case after.   To me, the functionâ€™s invariants ( must not be zero) is encoded after-the-fact, aka in the return type . This implies to me that the invariants could be encoded before-the-fact, aka in the function parameters. But what would that look like?Enter the newtype pattern.Say, letâ€™s have a type that is something like , but itâ€™s guaranteed to never be zero. Weâ€™ll name it :This struct only contains a single field . The semantics of the type understood from the name is that itâ€™s just like a normal , but does not allow the value of zero. How do we guarantee this? Since rust does encapsulation at the module level, we make this type public while have its field private.Then, the only way to construct this type is via a fallible constructor function:Remember to add some convenience traits.We can then use this in our  function.There is an interesting implication in this pattern.In the second version of , we changed the return type from  to  just to avoid the panics. As described in the original article by Alexis King, this is a  of the return type, and the functionâ€™s promise. We temper the callerâ€™s expectation by saying that yes, this function can fail in some way, and you have to account for that. And that weakening is described in the type system via the  enum.In the third iteration of , we change our perspective and ask ourselves â€œinstead of weakening the return type, what if we  the function parameters?â€ We communicated that via accepting a . Instead of having the validation code in our functions, we instead push that responsibility to the caller. The validation now happens before the function execution.To see the advantage of pushing the validation forward to the user, letâ€™s say we have another function like so:This function can fail if the discriminant is negative (which we will be ignoring in this contrived example), and if  is zero. The two ways of going about this can be written as follows:The  version has me duplicating the conditional for at least two different functions, which might be icky if you are a DRY-hard. Also, not only the function has to validate if the float can be zero, the  must then validate again by matching on the returned . That seems redundant. It would be ideal if we only need to check only once.The  version can help with that as validation happens before, and happens once, instead of twice.Moving away from the , letâ€™s now use an example from the original blog post, converted to Rust:We checked if  is empty in the  function. Then, we still had to â€œcheckâ€ it again in the  function by matching on . The  was known to be nonempty, do we have to check it again? Consequently, doesnâ€™t this have an impact on performance, especially if we have to check it again and again and again?The original post raised a good point about resilience to refactors. If for some reason the  gets refactored out for some reason, and the programmer forgot to update , then the  branch might actually get reached and explode your computer or whatever.If we instead had a special  newtype (well, not exactly special) where its existence guarantees that the Vec is never empty, we could doIn this context, we can call  and  functions, since they validate and convert the less semantic type to a type with more meaning imbued into it. That is, nonzeroness of a float and nonemptiness of a  is now encoded into a type. You can just see the word  and therefore understand that going forward it is always be an  that is never zero.Validation and checking functions on the other hand, well, just validate the value and leave the type as that. If I have a  function, then thereâ€™s not really much of a readable difference between an  that has  called on it versus and an  that hasnâ€™t.By taking advantage of the existence of a nominative type system, we can communicate that this  is not zero by  it to a new type, as opposed to just  it. If you only validate it, then you still canâ€™t tell if  was nonzero unless you dig through the code. However, if you parsed it, you can say itâ€™s always be nonzero if you see  in your code.Of course, the above examples are very much contrived, but is there an instance where creating newtypes is helpful? Yes. In fact, most people have used it. Itâ€™s called a .If we dig into the internals,  is just a newtype over the  type:Itâ€™s parsing function is , which contains the validation code for checking if the byte vector is valid UTF-8.So instead of passing around a  around and validating all over the place, just parse into a  and you can be assured with having a type-safe  with all the convenience functions you can get.Another example is . In Python,  simply give you a dictionary. This is fine, especially if the data is sufficiently arbitrary, but if you have a schema and a type system, itâ€™s better to let the type system do the work of parsing .In our terminology, validation looks like this:Thatâ€™s two s! One for checking if the string is valid json and the other is for checking if the  field exists. Now consider this example where we use the parsing mechanic instead via types and the  derive macro.Since we deserialized the  file into an actual type, we can safely make these guarantees:The  and  always exist in the  string we parse. always has an integer value. is always an array of three integers. will never panic since all elements of an array is always initialized, and indexing into the first the element of a nonzero-length array will always be successful.The only point of failure here is pushed upfront, where the  happens. After that point, thereâ€™s not really much error handling to be done here, since the validation is now represented at the type level instead of at the function level.Maxims of Type Driven Design #With that said, what lessons can we learn from here? Turns out, most functional language programmers already have learned several lessons, and Rust is not much different in terms of applying such FP concepts to the language.First lesson we can learn is that we should make illegal states unrepresentable.To refer back to the  and  examples, we say the state of being zero is illegal for  and the state of being empty is illegal for . And as illegal states, they cannot be represented in such types. Thatâ€™s why the only constructors available for these types are fallible; the value either parsed successfully, or it failed and does not return the new types.If we only do validation, like checking if  is nonzero for example, then the illegal state can still be represented. Thereâ€™s a small possible that the value is zero, especially after some refactors when the conditional checks are accidentally or intentionally removed in some places.This reminds me of how other languages use integers as sentinel values. Given this code snippet from Wikipedia:The error is returned as , since indexing arrays is only valid for nonnegative integers. Seems weird as (1) the numbers -2 and below  exist, but not actually valid, and (2) treating certain values as special seems too error-prone, as in the future it could be that negative number can become semantically valid.Second lesson we can learn is that proving invariants should be done as early as possible.Thereâ€™s this concept called  where the linked paper describes it as follows:Shotgun Parsing: Shotgun parsing is a programming antipattern whereby parsing and input-validating code is mixed with and spread across processing codeâ€”throwing a cloud of checks at the input, and hoping, without any systematic justification, that one or another would catch all the â€œbadâ€ cases.Essentially, it describes the problem of usage of data without previous validation of its entirety of data. You could act on a part of the data that is validated beforehand, but discover that another part of the data is invalid.The paper mentions CVE-2016-0752, which is a bug that allows attackers to read arbitrary files because you can use  in the input. The paper argues that treating validation as emergent and not deliberate can lead to security bugs like these.If we treat validation as deliberate, then it should happen as early as possible and as comprehensive as possible. By parsing first, every invariant can be proven first before executing on said data.I remember this video about lambda calculus. It concludes that types can be represented as propositions in logic, and terms as proofs. I recommend watching the video, as it is eye-opening to me and maybe it can help you realize some things too.Fundamentally, if your program typechecks properly, then you can say that the proof is correct. Thank you Curry-Howard Correspondence. There are proof assistant programming languages that can help with this like Lean and Agda, but you can emulate this in Rust anyway. Thatâ€™s how some weird libraries like the typenum crate work.This is a simple program in Rust where I check if  is equal to . Obviously this is not correct, and so it will appropriately give you a compile error.So sad that the error message is dogshit. Such is life.There are some recommendations I usually say to people on the RPLCS discord server, adapted from the original blog post.First, just because a function accepts a type doesnâ€™t mean you have to use it in your structs, nor have to perpetually represent it as that type. For example, letâ€™s say we have a third party library function that looks like this.You  have to store  in your / struct like App { lightbulb_state: bool }. Thatâ€™s confusing. Iâ€™d rather have you define a separate enum with more semantics imbued into it, like:Yeah, people can say it gets more verbose, but I rather care more about correctness instead. Sorry.Second, I sometimes get suspicious about these kind of APIs:If I see the function body does not do anything side-effectful, then itâ€™s probable that parsing can help here turning  into a more structured datatype. And even for side-effectful stuff, there are some types that better represent certain situations, like infinite loop function representing their return types as  or Result<Infallible, MyError>.I love creating more types. Five million types for everyone please.I think itâ€™s interesting that thereâ€™s a lot of instances where types drive the design of Rust programs. Like how  has four layers of newtypes plus an additional field.  generate anonymous structs in their  macros.  is a macro crate that converts functions into compile-time builders via types.Of course, not everything is solvable via types. But personally I think pushing your verification code to types can help your code become clearer and more robust. Let the type system handle the validation for you. It exists, so might as well use it to its fullest extent.Iâ€™d like to thank Alexis King for this article where I first encountered this idea. Iâ€™d love to follow up on this topic with an extension on this sequel, and maybe recontextualizing in Rust via the  keyword would be helpful.Of course, newtyping is not the answer to all problems. Due to lack of ergonomic features to allow newtypingâ€”like delegationâ€”many people are somewhat averse to using the pattern. Nevertheless, if someone made a good enough RFC Iâ€™d be happy to see it happen.Using the type system as a compile-time checker because I want the compiler to help me write my programs is very nice. You should take advantage of the type system too, not many languages have it as good as Rust :)Liked this blog post and want some more? Consider donating to support the author!]]></content:encoded></item><item><title>DreamDojo: A Generalist Robot World Model from Large-Scale Human Videos</title><link>https://huggingface.co/papers/2602.06949</link><author>/u/Secure-Technology-78</author><category>ai</category><category>reddit</category><pubDate>Sat, 21 Feb 2026 10:57:01 +0000</pubDate><source url="https://www.reddit.com/r/artificial/top/?sort=top&amp;t=day&amp;limit=3">Reddit - AI</source><content:encoded><![CDATA[DreamDojo is a foundation world model trained on 44k hours of egocentric human videos that enables efficient simulation of dexterous robotic tasks through continuous latent actions and real-time distillation.Being able to simulate the outcomes of actions in varied environments will revolutionize the development of generalist agents at scale. However, modeling these world dynamics, especially for dexterous robotics tasks, poses significant challenges due to limited data coverage and scarce action labels. As an endeavor towards this end, we introduce DreamDojo, a foundation world model that learns diverse interactions and dexterous controls from 44k hours of egocentric human videos. Our data mixture represents the largest video dataset to date for world model pretraining, spanning a wide range of daily scenarios with diverse objects and skills. To address the scarcity of action labels, we introduce continuous latent actions as unified proxy actions, enhancing interaction knowledge transfer from unlabeled videos. After post-training on small-scale target robot data, DreamDojo demonstrates a strong understanding of physics and precise action controllability. We also devise a distillation pipeline that accelerates DreamDojo to a real-time speed of 10.81 FPS and further improves context consistency. Our work enables several important applications based on generative world models, including live teleoperation, policy evaluation, and model-based planning. Systematic evaluation on multiple challenging out-of-distribution (OOD) benchmarks verifies the significance of our method for simulating open-world, contact-rich tasks, paving the way for general-purpose robot world models.]]></content:encoded></item><item><title>Kubernetes architectural design: separate clusters by function or risk?</title><link>https://www.reddit.com/r/kubernetes/comments/1ran4f7/kubernetes_architectural_design_separate_clusters/</link><author>/u/Ancient_Canary1148</author><category>reddit</category><pubDate>Sat, 21 Feb 2026 09:41:31 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[Do you set big clusters with all sort of applications, operators, statefull sets? or do you plan to isolate clusters based on their function?Where i work we have clusters that. Stateless applications, with service meshs, trÃ¦fik. Those are easy to manage and update as we have 2 clusters in production in 2 different locations. With this config and gitops, we can create a new cluster easily if somethiing goes wrong or i can even perform upgrades during business time.. Statefull applications: Postgresql, elastic, different type of operators (vault, kafka), volumes, etc. I found those more complex to operate as i found more issues during upgrades and more manual-prone to provision. We cataloge those clusters as more risky to operate.. ML Platform: GPUs, short lifecycle applications.My opinion is: yes, split clusters based by function/risks, but other team members and management are not agree.I guess the negative part are costs, governance (we use open cluster management and argo).]]></content:encoded></item><item><title>Local dev with k8s cluster</title><link>https://www.reddit.com/r/kubernetes/comments/1ramfnp/local_dev_with_k8s_cluster/</link><author>/u/CartoonistWhole3172</author><category>reddit</category><pubDate>Sat, 21 Feb 2026 08:59:03 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[So many times it would be handy to connect one local service to other services in a k8s cluster in the cloud so that I can debug my local service with an existing data setup.What is the best approach? What are tools to support it? Is it possible without much hassle?]]></content:encoded></item><item><title>Open source software has firmly established itself in the German economy. As the trade magazine IT Management reports, 73 per cent of companies now rely on freely available source codes - a significant increase on the 69 per cent recorded in 2023.Significant growth in the use of open source software</title><link>https://www.ossdirectory.com/en/topnews/details/deutliches-wachstum-bei-der-nutzung-von-open-source-software-in-deutschland</link><author>/u/smilelyzen</author><category>reddit</category><pubDate>Sat, 21 Feb 2026 08:56:10 +0000</pubDate><source url="https://www.reddit.com/r/linux/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Linux</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>I rewrote EchoVault from Python to Go: local MCP memory for coding agents, single static binary, no runtime</title><link>https://www.reddit.com/r/golang/comments/1ramczb/i_rewrote_echovault_from_python_to_go_local_mcp/</link><author>/u/IntentionJolly2730</author><category>golang</category><category>reddit</category><pubDate>Sat, 21 Feb 2026 08:54:43 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[A few days ago Muhammad Raza published a blog post about EchoVault â€” a local-first MCP memory system for coding agents (Claude Code, Cursor, Codex, OpenCode). The concept is solid: agents forget everything between sessions, so EchoVault gives them persistent memory via SQLite (FTS5 + sqlite-vec) and Markdown files. No cloud, no API keys, just local storage.I wanted to try it. Ran  on Linux and got:Segmentation fault (core dumped) Turns out it's a known issue â€” Python 3.13 segfaults inside the CPython runtime on some Linux configurations, consistently, across multiple machines. The fix isn't obvious and the issue is open.Honestly, not the most noble motivation â€” but it was good enough of a reason to just port the thing to Go over the weekend. â€” download, drop on , done. No Python runtime or virtualenv required. Distributed as a single binary. â€” uses  and , so you need a C compiler to build from source. Pre-built binaries are on the releases page for Linux/macOS/Windows.Vault format is identical â€” fully compatible with the Python version. If you're already using the original and it works for you, you can switch without losing any memories.MCP interface is the same â€” same three tools (, , ), same stdio transport. for cross-platform releases.memory init memory setup claude-code # or: cursor, codex, opencode Semantic search (via Ollama/OpenAI/OpenRouter) is optional â€” keyword search via FTS5 works out of the box with zero config.The codebase follows standard Go layout (, ), golangci-lint is configured. It was a weekend project, so feedback welcome â€” especially if you hit build issues on non-Linux platforms or have thoughts on the CGO dependency.If you're a Go developer and find this useful â€” contributions are welcome. There's plenty of room to improve: better embedding support, more agent integrations, smarter redaction, test coverage. The codebase is small enough to get oriented quickly. Even if you just want to kick the tires and open issues, that helps too.]]></content:encoded></item><item><title>Fzf (general-purpose command-line fuzzy finder) 0.68.0</title><link>https://github.com/junegunn/fzf/releases/tag/v0.68.0</link><author>/u/FryBoyter</author><category>reddit</category><pubDate>Sat, 21 Feb 2026 08:14:40 +0000</pubDate><source url="https://www.reddit.com/r/linux/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Linux</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>[D] Submit to ECCV or opt in for CVPR findings?</title><link>https://www.reddit.com/r/MachineLearning/comments/1ralci0/d_submit_to_eccv_or_opt_in_for_cvpr_findings/</link><author>/u/Resident-Concept3534</author><category>ai</category><category>reddit</category><pubDate>Sat, 21 Feb 2026 07:52:55 +0000</pubDate><source url="https://www.reddit.com/r/MachineLearning/top/?sort=top&amp;t=day&amp;limit=3">Reddit - ML</source><content:encoded><![CDATA[Hi everyone, Iâ€™m trying to decide whether to submit my paper to ECCV main track or opt into CVPR Findings, and Iâ€™m honestly a bit confused about how Findings is perceived (Given that i never submitted to ACL or EMLNP). The conference states that Findings papers will be considered as peer-reviewed publications as the main track, but they are published under separate â€œFindingsâ€ proceedings.Does that make them closer to workshop papers? Iâ€™ve seen ICCV Findings sometimes referred to informally as â€œFindings workshop papers,â€ which makes it even more unclear. Given this uncertainty, Iâ€™m wondering whether itâ€™s worth taking the risk and aiming directly for ECCV main track instead. Would really appreciate insights from people whoâ€™ve published in or reviewed for these venues.]]></content:encoded></item><item><title>Learning Rust was the best decision in my life</title><link>https://www.reddit.com/r/rust/comments/1ral7hi/learning_rust_was_the_best_decision_in_my_life/</link><author>/u/Ill-Adeptness9806</author><category>rust</category><category>reddit</category><pubDate>Sat, 21 Feb 2026 07:44:24 +0000</pubDate><source url="https://www.reddit.com/r/rust/top/?sort=top&amp;t=day&amp;limit=3">Reddit - Rust</source><content:encoded><![CDATA[34F who lives with epilepsy here.Recently had multiple back to back seizures and had to leave my day job, my hopes of getting hired full-time are very slim.Apart from my marketing job, my only other skill is this language, which I learned as a hobby back in Uni.Given the limited options in the same career, I've decided to build some indie apps in rust, try and market them with what I know.Life's pretty bad but things tend to ease out a bit when we commit to something meaningful for ourselves, given how much time it'd take to learn a new skill in scratch, I feel very grateful as I learned to code in Rust before.I don't have high hopes, just that there might be some light in the tunnel, and I'm trying to look in the bright side. So thought I'd share it here.]]></content:encoded></item><item><title>Creator of Claude Code: &quot;Coding is solved&quot;</title><link>https://www.lennysnewsletter.com/p/head-of-claude-code-what-happens</link><author>/u/Gil_berth</author><category>reddit</category><pubDate>Sat, 21 Feb 2026 06:55:49 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[How Claude Code grew from a quick hack to 4% of public GitHub commits, with daily active users doubling last monthThe counterintuitive product principles that drove Claude Codeâ€™s successWhy Boris believes coding is â€œsolvedâ€The latent demand that shaped Claude Code and CoworkPractical tips for getting the most out of Claude Code and CoworkHow underfunding teams and giving them unlimited tokens leads to better AI productsWhy Boris briefly left Anthropic for Cursor, then returned after just two weeksThree principles Boris shares with every new team memberLenny may be an investor in the companies discussed.]]></content:encoded></item><item><title>CSRF for Builders</title><link>https://www.eliranturgeman.com/2026/02/18/csrf-explained/</link><author>/u/Missics</author><category>reddit</category><pubDate>Sat, 21 Feb 2026 06:13:17 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[If your  route is a GET endpoint, any website on the internet can log your users out by embedding <img src="https://yourapp.com/logout"> in their page. The userâ€™s browser sends the request with cookies attached, and your server happily ends their session.Thatâ€™s CSRF (Cross-Site Request Forgery). And logout is the least dangerous version of it.This came up on X last week when Guillermo Rauch (vercel CEO) asked Grok to explain the problem to Aiden Bai, who had a GET-based  in production:The rest of this post covers the actual attack mechanics, why POST alone doesnâ€™t fix it, and what does.Cross-Site Request Forgery is an attack where a malicious site tricks a userâ€™s browser into making a request to a different site - one where the user is already authenticated. The browser attaches cookies automatically, so the target server sees a legitimate session and processes the request.The attacker never sees the response, and they donâ€™t need to. The damage is the request itself: transferring funds, changing an email address, deleting an account, logging someone out.Say your app has this endpoint:A user is logged in, their session cookie is set. Now imagine they visit a completely unrelated page (a forum, a blog comment section, an email with embedded HTML) that contains this:The browser renders the page, sees the  tag, makes a GET request to yourapp.com/account/close, and attaches the userâ€™s cookies because the browser sees it as a normal request to a domain where the user has an active session. The server receives a valid authenticated request and closes the account. The user never clicked anything. They never even saw it happen.This is why GET endpoints that change state are considered broken by design - the HTTP spec itself says GET should be safe and idempotent (it should not trigger side effects). Browsers, crawlers, prefetch mechanisms, and proxies all assume GET requests are safe to issue at any time.Some developers assume switching to POST solves everything. It raises the bar, but it is not sufficient on its own.An attacker can trigger a POST request from a malicious page using a hidden form with auto-submit:The victim visits the malicious page, the form auto-submits, and the browser sends the POST with cookies attached. If the server has no CSRF protection, it processes the request.You canâ€™t embed a POST in an  tag, but as shown above, a hidden auto-submitting form is four lines of HTML. The effort difference for an attacker is negligible.What Actually Protects YouCSRF protection requires the server to distinguish between requests that originated from its own pages and requests forged from external sites. There are several mechanisms, each with different tradeoffs.CSRF Tokens (Synchronizer Token Pattern)The most established defense. The server generates a unique, unpredictable token per session (or per request) and embeds it in forms and headers. Every state-changing request must include this token. The attacker cannot read the token from another origin (same-origin policy prevents it), so they cannot forge a valid request.Most server frameworks ship CSRF protection enabled by default. Django, Rails, Spring Security, Laravel all generate and verify tokens automatically on state-changing requests. Check your frameworkâ€™s documentation and verify that CSRF protection is actually active in your setup.The  cookie attribute tells the browser when to attach cookies on cross-site requests:: cookie is never sent on cross-site requests. Strong protection, but breaks legitimate flows like clicking a link from an email to a logged-in page.: cookie is sent on top-level navigations (clicking a link) but not on cross-origin sub-requests (form posts, image loads, fetches). This blocks the  and auto-submitting form attacks described above.: cookie is always sent cross-site. Requires  flag. Use only when you have a real cross-origin use case.Modern browsers default to  when no  attribute is specified. This is a meaningful improvement. The <img src="https://yourapp.com/account/close"> attack no longer works with default cookie settings in modern browsers. But relying on browser defaults as your only defense is fragile. Older browsers, WebViews in mobile apps, and certain embedded contexts may not enforce  consistently.Set  explicitly on session cookies as a baseline. Use  where the UX allows it.For API-Only Backends (SPA + API Architecture)If your backend is a pure API serving a JavaScript frontend, the threat model is different. Browsers enforce that cross-origin  or  calls with custom headers (like Authorization: Bearer ...) trigger CORS preflight checks. If your API uses token-based auth (JWT in an  header) instead of cookies, CSRF is largely mitigated because the attackerâ€™s page cannot set custom headers on cross-origin requests.If your API uses cookies for authentication (common with  session cookies for SPAs), you are still vulnerable to CSRF and need token-based or  protections.If you take nothing else from this post:Use your frameworkâ€™s CSRF protection. Donâ€™t disable it without a documented reason.Set  explicitly on session cookies.Cookie-based auth on an SPA? You still need CSRF tokens.Also, use tooling that can help like Semgrep. It catches static patterns in your code: missing CSRF middleware,  decorators, etc. It has rules for common frameworks and you can write custom ones. Run it in CI on every pull request.The X thread that sparked this post is a useful reminder: every major framework ships CSRF protection by default, browsers default to , and the tooling exists. CSRF keeps happening because developers disable protections they donâ€™t understand, use GET for mutations out of convenience, or assume their SPA architecture makes them immune.]]></content:encoded></item><item><title>I built a TUI Email client in Go</title><link>https://www.reddit.com/r/golang/comments/1raj1eu/i_built_a_tui_email_client_in_go/</link><author>/u/andrinoff</author><category>golang</category><category>reddit</category><pubDate>Sat, 21 Feb 2026 05:41:00 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[Iâ€™m excited to share a project Iâ€™ve been working on called Matcha. Itâ€™s a modern, terminal-based email client built with Go and the Bubble Tea framework.I wanted an email client that felt native to the terminal. If you live in the CLI and want a fast, keyboard-driven way to manage your inbox, Iâ€™d love for you to check it out.This is also an excellent way to know how email clients work.Matcha has been downloaded over 1000 times, and I have received positive reviews so farIt's open-source (MIT License) and I'm actively looking for feedback. Let me know what you think or if you run into any issues!This software's code is partially AI-generated]]></content:encoded></item><item><title>Understanding how databases store data on the disk</title><link>https://pradyumnachippigiri.substack.com/p/how-databases-store-data-on-the-disk</link><author>/u/Comfortable-Fan-580</author><category>reddit</category><pubDate>Sat, 21 Feb 2026 03:55:32 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>How a Pittsburgh man is harnessing AI to keep ALS from stealing our voices</title><link>https://www.post-gazette.com/life/goodness/2026/02/01/als-ai-voice-app-david-betts-pittsburgh/stories/202602010037</link><author>/u/source-commonsense</author><category>ai</category><category>reddit</category><pubDate>Sat, 21 Feb 2026 02:54:43 +0000</pubDate><source url="https://www.reddit.com/r/artificial/top/?sort=top&amp;t=day&amp;limit=3">Reddit - AI</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Editing Kubernetes YAML + CRDs outside VS Code? I made schema routing actually work (yamlls + router)</title><link>https://github.com/traiproject/yaml-schema-router</link><author>/u/lucatrai</author><category>reddit</category><pubDate>Sat, 21 Feb 2026 01:57:41 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[If you edit K8s YAML in Helix/Neovim/Emacs/etc with Red Hatâ€™s yaml-language-server, schema association is rough:glob-based schema mappings collide (CRD schema + kubernetes schema)modelines everywhere are annoyingI built : a tiny stdio proxy that sits between your editor and yaml-language-server and injects the correct schema per file by inspecting YAML content (apiVersion/kind). It caches schemas locally so itâ€™s fast + works offline.CRDs (and wraps schemas to validate ObjectMeta too)If youâ€™ve got nasty CRD examples that break schema validation, Iâ€™d love test cases.]]></content:encoded></item><item><title>OpenAI will reportedly release an AI-powered smart speaker in 2027. The company is also said to be working on smart glasses and a smart lamp.</title><link>https://www.engadget.com/ai/openai-will-reportedly-release-an-ai-powered-smart-speaker-in-2027-173344866.html</link><author>/u/esporx</author><category>ai</category><category>reddit</category><pubDate>Sat, 21 Feb 2026 01:12:36 +0000</pubDate><source url="https://www.reddit.com/r/artificial/top/?sort=top&amp;t=day&amp;limit=3">Reddit - AI</source><content:encoded><![CDATA[OpenAI is reportedly hard at work developing a series of AI-powered devices, including smart glasses, a smart speaker and a smart lamp. According to reporting by , the AI company has a team of over 200 employees dedicated to the project.The first product scheduled to be released is reported to be a smart speaker that would include a camera, allowing it to better absorb information about its users and surroundings. According to a person familiar with the project, this would extend to identifying objects on a nearby table, as well as conversations being held in the vicinity of the speaker. The camera will also support a facial recognition feature similar to Apple's Face ID that would enable users to authenticate purchases.The speaker is expected to retail for between $200 and $300 and ship in early 2027 at the earliest. Reporting indicates the company's AI-powered smart glasses, a space currently dominated by , would not come until 2028. As for the smart lamp, while prototypes have been made, it's unclear whether it will actually be brought to market.Last year OpenAI  ex-Apple designer Jony Ive's startup io Products for $6.5 billion. Ive is considered largely responsible for Apple's design aesthetic, having been involved in designing just about every major Apple device since joining the company in the '90s before his departure in 2019. The acquisition of his  sets the stage for Ive to lead hardware product development now for OpenAI.Since the partnership was forged, there have already  due to technical issues, privacy concerns and logistical issues surrounding the computing power necessary to run a mass-produced AI device. Regardless of the behemoths behind the project, the speaker and other future products may still face a consumer  that is always listening to and watching its users.]]></content:encoded></item><item><title>I fact-checked the &quot;AI Moats are Dead&quot; Substack article. It was AI-generated and got its own facts wrong.</title><link>https://www.reddit.com/r/artificial/comments/1racrlq/i_factchecked_the_ai_moats_are_dead_substack/</link><author>/u/echowrecked</author><category>ai</category><category>reddit</category><pubDate>Sat, 21 Feb 2026 00:36:58 +0000</pubDate><source url="https://www.reddit.com/r/artificial/top/?sort=top&amp;t=day&amp;limit=3">Reddit - AI</source><content:encoded><![CDATA[A Substack post by Farida Khalaf argues AI models have no moat, using the Clawbot/OpenClaw story as proof. The core thesis â€” models are interchangeable commodities â€” is correct. I build on top of LLMs and have swapped models three times with minimal impact on results.But the article itself is clearly AI-generated, and it's full of errors that prove the opposite of what the author intended. The article includes a 7-second animated explainer. Pause it and you find Anthropic spelled as "Fathropic," Claude as "Clac#," OpenAI as "OpenAll," and a notepad reading "Cluly fol Slopball!" The article's own $300B valuation claim shows up as "$30B" in the video. There's no way the author watched this before publishing...The timeline is fabricated: The article claims OpenAI "panic-shipped" GPT-5.2-Codex on Feb 5 in response to Clawbot going viral on Jan 27. Except GPT-5.2-Codex launched on January 14 â€” two weeks before Clawbot. What actually launched Feb 5 was GPT-5.3-Codex. The article got the model name wrong.The selloff attribution is wrong: The article blames the February tech selloff on Clawbot proving commoditization. Bloomberg, Fortune, and CNBC all attribute it to Anthropic's Cowork legal automation plugin â€” investors worried about AI replacing IT services work. RELX crashed 13%, Nifty IT fell 19%. None of it was about Clawbot.The financials are stale: cites Anthropic at $183B and projects a 40-60% IPO haircut. By publication date, Anthropic's term sheet was at $350B. The round closed at $380B four days later.The irony: an AI-generated article about AI having no moat is the best evidence that AI still needs humans checking the work. The models assembled a convincing  of market analysis without verifying whether any of it holds together.Disclosure: I used AI tools for research and drafting. Every claim was verified against primary sources. Every sentence was reviewed before publishing. That's the point.]]></content:encoded></item><item><title>Let&apos;s Write a JSON Parser From Scratch</title><link>https://sushantdhiman.dev/lets-write-a-json-parser-from-scratch/</link><author>/u/Sushant098123</author><category>golang</category><category>reddit</category><pubDate>Sat, 21 Feb 2026 00:34:44 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[It's been a long time since I wrote something in this newsletter. Recently I was learning about language parsing and abstract syntax trees. After getting some knowledge about this, I decided to write a JSON parser from scratch.It is the process of analysing the structure of a string (basically any programming language syntax). Parsing helps us to determine the meaning of the text. Writing a parser for a programming language is a very complex task because programming languages generally have a lot of keywords and syntax rules. Handling all those syntax and keywords can be overwhelming and highly difficult. But in the case of JSON we have a very limited number of keywords and syntax rules. So writing a JSON parser is a relatively easier task.It is the process that is done before parsing. Tokenization means breaking down and categorizing string of character into smallest units called tokens. Below table will give you a solid idea of what tokens look like.JSON:
{
  "name": "iPhone 6s",
  "price": 649.99,
  "isAvailable": true
}


Token       : Type
------------:--------------
{           : BRACE_OPEN  
name        : STRING  
:           : COLON  
iPhone 6s   : STRING  
,           : COMMA  
price       : STRING  
:           : COLON  
649.99      : NUMBER  
,           : COMMA  
isAvailable : STRING  
:           : COLON  
true        : TRUE  
}           : BRACE_CLOSE  

Once tokenization break down string into tokens than these tokens are given to Parser which created an Abstract Syntax Tree. We will discuss it later in this post. But your 1st step is to create a tokenizer.Now letâ€™s get into the code part where we tokenize a JSON string.I wrote a function called  which takes a JSON string and returns a list of tokens. It loops through the string, character by character, and breaks it down into meaningful pieces like , ,  or . These pieces are what we call .Hereâ€™s the full code, broken down step by step.We will first start with creating some basic types for all the tokens.We start with a  pointer to keep track of where we are in the string.  helps us not go out of bounds, and  is the slice where weâ€™ll collect all the tokens we generate.We loop through the entire string. If we hit whitespace, we skip it because whitespace doesn't matter in JSON.Switch through known single-character tokensThan we handle all the simple symbols here. These donâ€™t need much logic â€” just push them to the tokens list and move on.When we encounter a , we start reading a string. We look for the closing quote, while also making sure to skip escaped quotes like . If the string is never closed, we throw an error. Otherwise, we extract the string and add it as a token.We check for , , and  first. If we see one of these keywords, we push it to the tokens list and jump ahead accordingly.Numbers (slightly tricky)JSON numbers can get complex. They might contain decimals, negative signs, and exponential notation (like ). We carefully walk through each character to build the number string. I also added validations to reject bad formats like , multiple dots, or missing exponent digits.If none of the above matched, the character is invalid in JSON â€” so we just throw an error.This method is used to check for bad leading numbers in JSON.This just prints the list of tokens in a nice readable format. Super handy when testing your tokenizer.If we give below JSON to our tokenizer we will get following output.{
  "name": "iPhone 6s",
  "price": 649.99,
  "isAvailable": true
}Now our JSON is nicely tokenized and each character had been given its appropriate token type.We have now created a tokeniser that converts JSON objects to tokens. The next step is to create a parser that can convert these tokens into an abstract syntax tree. But first, let's understand what an abstract syntax tree is.Abstract Syntax Tree (AST)This is the base interface for all AST node types. Every node will implement the  method, which is a simple way to identify what kind of data (Object, Array, String, etc.) it holds.This is the main function you call to parse the token stream.It checks if thereâ€™s anything to parse. Then it initializes a  pointer (used as an index into the  slice).Delegates to , which handles all the different types.Basic safety check: if the current token is past the end, return an error.Now comes the type-checking:String token â†’ wrap it in .Number â†’ parse into float64.Booleans and null are direct mappings.Delegates to specialized functions for objects () and arrays ().Anything unexpected = throw an error.Extract the key from the object and parse the value using the already written  function.Start parsing array (skip the  token).Each value is parsed with and append value to initialized array.Ensure the array ends correctly with .Below is the output we will get if we parse the tokens of JSON that we used above.{
    map[isAvailable:{true}
    name:{iPhone 6s} 
    price:{649.99}]
}Try converting this AST node to native Golang data structure and use it.I'm always willing to get to make new connections.So this was how we could implement a simple JSON tokenizer and parser from scratch. If you have any suggestions or doubts, you can always comment below. Consider subscribing to my newsletter to get notified for new posts.]]></content:encoded></item><item><title>[D] How are you actually using AI in your research workflow these days?</title><link>https://www.reddit.com/r/MachineLearning/comments/1rabvqq/d_how_are_you_actually_using_ai_in_your_research/</link><author>/u/thefuturespace</author><category>ai</category><category>reddit</category><pubDate>Fri, 20 Feb 2026 23:59:36 +0000</pubDate><source url="https://www.reddit.com/r/MachineLearning/top/?sort=top&amp;t=day&amp;limit=3">Reddit - ML</source><content:encoded><![CDATA[METR updated their task horizon benchmark today. Claude Opus 4.6 now hits 50% on multi-hour expert ML tasks like 'fix complex bug in ML research codebase.' The bands are wide and clearly far from saturating, but the trend is clear. Has this changed anything for you concretely? Curious what people are actually delegating vs not, and where it's still falling flat. ]]></content:encoded></item><item><title>Defer available in gcc and clang</title><link>https://gustedt.wordpress.com/2026/02/15/defer-available-in-gcc-and-clang/</link><author>/u/ketralnis</author><category>reddit</category><pubDate>Fri, 20 Feb 2026 23:46:26 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[About a year ago I posted about  and that it would be available for everyone using gcc and/or clang soon. So it is probably time for an update.Two things have happened in the mean time:Both gcc and clang communities have worked on integrating this feature into their C implementations.I have not yet got my hands on the gcc implementation (but this is also less urgent, see below), but I have been able to use clangâ€™s which is available starting with clang-22.I think that with this in mind everybody developing in C could and should now seriously consider switching to  for their cleanup handling: no more resource leakage or blocked mutexes on rarely used code paths, no more spaghetti code just to cover all possibilities for preliminary exits from functions.I am not sure if the compiler people are also planning back ports of these features, but with some simple work around and slightly reduced grammar for the  feature this works for me from gcc-9 onward and for clang-22 onward:#if __has_include(<stddefer.h>)
# include <stddefer.h>
# if defined(__clang__)
#  if __is_identifier(_Defer)
#   error "clang may need the option -fdefer-ts for the _Defer feature"
#  endif
# endif
#elif __GNUC__ > 8
# define defer _Defer
# define _Defer      _Defer_A(__COUNTER__)
# define _Defer_A(N) _Defer_B(N)
# define _Defer_B(N) _Defer_C(_Defer_func_ ## N, _Defer_var_ ## N)
# define _Defer_C(F, V)                                                 \
  auto void F(int*);                                                    \
  __attribute__((__cleanup__(F), __deprecated__, __unused__))           \
     int V;                                                             \
  __attribute__((__always_inline__, __deprecated__, __unused__))        \
    inline auto void F(__attribute__((__unused__)) int*V)
#else
# error "The _Defer feature seems not available"
#endif

So this is already a large panel of compilers. Obviously it depends on your admissible compile platforms whether or not these are sufficient for you. In any case, with these you may compile for a very wide set of installs since  does not need any specific software infrastructure or library once the code is compiled.As already discussed many times, the gcc fallback uses the so-called â€œnested functionâ€ feature which is always subject of intense debate and even flame wars. Donâ€™t worry, the implementation as presented here, even when compiled with no optimization at all, does not produce any hidden function in the executable, and in particular there is no â€œtrampolineâ€ or whatever that would put your execution at risk of a stack exploit.You may also notice that there is no fallback for older clang version. This is because their so-called â€œblocksâ€ extension cannot easily be used as a drop-in to replace nested function: their semantics to access variables from the surrounding scope are different and not compatible with the  feature as defined by TS 25755.So for example if you are scared of using big VLA on the stack, you may use the above code in headers and something likedouble* BigArray
  = malloc(sizeof(double[aLot]));
if (!BigArray {
  exit(EXIT_FALURE);
}
defer { 
  free(BigArray); 
}
to have an implementation of a big array with a failure mode for the allocation. Or if you want to be sure that all your mutexes are unlocked when you leave a critical section, use and idiom as here{
  if (mtx_lock(&mtx) != thrd_success) {
    exit(EXIT_FAILURE);
  }
  defer {
    mtx_unlock(&mtx);
  }

  ... do something complicated ...

  if (rareCondition) {
    return 42;
  }

  ... do something even more complicated ...
}
Just notice, that youâ€™d always have to use the  feature with curly braces to ensure that the gcc fallback works smoothly.]]></content:encoded></item><item><title>Lindenmayer Systems</title><link>https://justinpombrio.net/2026/02/16/l-systems.html</link><author>/u/ketralnis</author><category>reddit</category><pubDate>Fri, 20 Feb 2026 23:43:53 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[Let me show you how to use Lindenmayer systems to produce beautiful images like
this one:Weâ€™ll start by talking about turtles.Some of you are nodding along like this is an obvious starting point; others
are rather confused. In 1967(!) some brilliant engineers designed an
educational programming language called
Logo. It lets you
make turtle graphics drawings
by telling a â€œturtleâ€ with a â€œpenâ€ where to walk on the screen, drawing a line
as it goes. I just learned when writing this that there were also physical
programmable turtles that would
draw on paper!So yeah, weâ€™re startings with turtles. Logo turtles had all sorts of fancy
commands, but ours will need just three: means â€œwalk forward one unitâ€ means â€œturn left a quarter turnâ€ means â€œturn right a quarter turnâ€The turtle starts in the center of the screen facing up. So the program 
will drawn an â€œLâ€:The turtleâ€™s path is drawn as a gradient from white to yellow to green. If you
have an active imagination you can pretend that the green dot at the end is a
turtle.And the program  will draw an â€œFâ€:What if you want your turtle to turn at angles other than a quarter turn? We
could go the route that Logo did, and give an arbitrary angle for every turn.
But for the sorts of drawing weâ€™re going to do we can get away with something
simpler: weâ€™ll declare up front what angle  and  should turn. (Measured in
turns, of course.)For example, to draw a hexagon we could use the angle 1/6 and run the turtle
program :Drawing a detailed image this way would take a really long sequence of ,
, and . Again, Logo solved this in a general way by adding loops to the
language, but weâ€™re going to do something a lot more specialized. Weâ€™re going to
use an idea by Aristid Lindenmayer in 1968, now called â€œLindenmayer Systemsâ€ or
â€œL-Systemsâ€.(This timingâ€”Logo in 1967 and L-Systems in 1968â€”is suspicious, isnâ€™t it? Iâ€™m
not aware of any explicit cross-polination of ideas between Lindenmayer and the
Logo creators, but wouldnâ€™t be surprised if one partially inspired the other.)Lindenmayerâ€™s idea is to have a , and some  that
replace a letter with a sequence of instructions. You start with the  and repeatedly replace letters according to the  for
some number of iterations. Then you have the turtle follow the (now very long)
sequence of instructions.This will be easier to follow with an example.One pretty picture that can be drawn with an L-system is the . Its
rules are:start: R
productions:
    R -> Rf+L
    L -> Rf-L
angle: 1/4
Iterations of the dragon curve look like this:The 0th iteration starts with the  string, so itâ€™s just .The 1st iteration replaces that  according to the production rule
, so it becomes .The 2nd iteration replaces both the  and  according to the production
rules, giving .We get to choose how many iterations to do. Letâ€™s say we do 9 iterations. Then
we get:Rf+Lf+Rf-Lf+Rf+Lf-Rf-Lf+Rf+Lf+Rf-Lf-Rf+Lf-Rf-Lf+Rf+Lf+Rf-Lf+
Rf+Lf-Rf-Lf-Rf+Lf+Rf-Lf-Rf+Lf-Rf-Lf+Rf+Lf+Rf-Lf+Rf+Lf-Rf-Lf+
Rf+Lf+Rf-Lf-Rf+Lf-Rf-Lf-Rf+Lf+Rf-Lf+Rf+Lf-Rf-Lf-Rf+Lf+Rf-Lf-
Rf+Lf-Rf-Lf+Rf+Lf+Rf-Lf+Rf+Lf-Rf-Lf+Rf+Lf+Rf-Lf-Rf+Lf-Rf-Lf+
Rf+Lf+Rf-Lf+Rf+Lf-Rf-Lf-Rf+Lf+Rf-Lf-Rf+Lf-Rf-Lf-Rf+Lf+Rf-Lf+
Rf+Lf-Rf-Lf+Rf+Lf+Rf-Lf-Rf+Lf-Rf-Lf-Rf+Lf+Rf-Lf+Rf+Lf-Rf-Lf-
Rf+Lf+Rf-Lf-Rf+Lf-Rf-Lf+Rf+Lf+Rf-Lf+Rf+Lf-Rf-Lf+Rf+Lf+Rf-Lf-
Rf+Lf-Rf-Lf+Rf+Lf+Rf-Lf+Rf+Lf-Rf-Lf-Rf+Lf+Rf-Lf-Rf+Lf-Rf-Lf+
Rf+Lf+Rf-Lf+Rf+Lf-Rf-Lf+Rf+Lf+Rf-Lf-Rf+Lf-Rf-Lf-Rf+Lf+Rf-Lf+
Rf+Lf-Rf-Lf-Rf+Lf+Rf-Lf-Rf+Lf-Rf-Lf-Rf+Lf+Rf-Lf+Rf+Lf-Rf-Lf+
Rf+Lf+Rf-Lf-Rf+Lf-Rf-Lf+Rf+Lf+Rf-Lf+Rf+Lf-Rf-Lf-Rf+Lf+Rf-Lf-
Rf+Lf-Rf-Lf-Rf+Lf+Rf-Lf+Rf+Lf-Rf-Lf+Rf+Lf+Rf-Lf-Rf+Lf-Rf-Lf-
Rf+Lf+Rf-Lf+Rf+Lf-Rf-Lf-Rf+Lf+Rf-Lf-Rf+Lf-Rf-Lf+Rf+Lf+Rf-Lf+
Rf+Lf-Rf-Lf+Rf+Lf+Rf-Lf-Rf+Lf-Rf-Lf+Rf+Lf+Rf-Lf+Rf+Lf-Rf-Lf-
Rf+Lf+Rf-Lf-Rf+Lf-Rf-Lf+Rf+Lf+Rf-Lf+Rf+Lf-Rf-Lf+Rf+Lf+Rf-Lf-
Rf+Lf-Rf-Lf-Rf+Lf+Rf-Lf+Rf+Lf-Rf-Lf-Rf+Lf+Rf-Lf-Rf+Lf-Rf-Lf+
Rf+Lf+Rf-Lf+Rf+Lf-Rf-Lf+Rf+Lf+Rf-Lf-Rf+Lf-Rf-Lf+Rf+Lf+Rf-Lf+
Rf+Lf-Rf-Lf-Rf+Lf+Rf-Lf-Rf+Lf-Rf-Lf-Rf+Lf+Rf-Lf+Rf+Lf-Rf-Lf+
Rf+Lf+Rf-Lf-Rf+Lf-Rf-Lf-Rf+Lf+Rf-Lf+Rf+Lf-Rf-Lf-Rf+Lf+Rf-Lf-
Rf+Lf-Rf-Lf-Rf+Lf+Rf-Lf+Rf+Lf-Rf-Lf+Rf+Lf+Rf-Lf-Rf+Lf-Rf-Lf+
Rf+Lf+Rf-Lf+Rf+Lf-Rf-Lf-Rf+Lf+Rf-Lf-Rf+Lf-Rf-Lf+Rf+Lf+Rf-Lf+
Rf+Lf-Rf-Lf+Rf+Lf+Rf-Lf-Rf+Lf-Rf-Lf-Rf+Lf+Rf-Lf+Rf+Lf-Rf-Lf-
Rf+Lf+Rf-Lf-Rf+Lf-Rf-Lf-Rf+Lf+Rf-Lf+Rf+Lf-Rf-Lf+Rf+Lf+Rf-Lf-
Rf+Lf-Rf-Lf+Rf+Lf+Rf-Lf+Rf+Lf-Rf-Lf-Rf+Lf+Rf-Lf-Rf+Lf-Rf-Lf-
Rf+Lf+Rf-Lf+Rf+Lf-Rf-Lf+Rf+Lf+Rf-Lf-Rf+Lf-Rf-Lf-Rf+Lf+Rf-Lf+
Rf+Lf-Rf-Lf-Rf+Lf+Rf-Lf-Rf+Lf-Rf-L
Now we just need to tell the turtle to follow these instructions. Butâ€¦ whatâ€™s
it supposed to do with all the s and s? Simple: it will just ignore them.
Erasing them from the string gives:f+f+f-f+f+f-f-f+f+f+f-f-f+f-f-f+f+f+f-f+f+f-f-f-f+f+f-f-f+f-
f-f+f+f+f-f+f+f-f-f+f+f+f-f-f+f-f-f-f+f+f-f+f+f-f-f-f+f+f-f-
f+f-f-f+f+f+f-f+f+f-f-f+f+f+f-f-f+f-f-f+f+f+f-f+f+f-f-f-f+f+
f-f-f+f-f-f-f+f+f-f+f+f-f-f+f+f+f-f-f+f-f-f-f+f+f-f+f+f-f-f-
f+f+f-f-f+f-f-f+f+f+f-f+f+f-f-f+f+f+f-f-f+f-f-f+f+f+f-f+f+f-
f-f-f+f+f-f-f+f-f-f+f+f+f-f+f+f-f-f+f+f+f-f-f+f-f-f-f+f+f-f+
f+f-f-f-f+f+f-f-f+f-f-f-f+f+f-f+f+f-f-f+f+f+f-f-f+f-f-f+f+f+
f-f+f+f-f-f-f+f+f-f-f+f-f-f-f+f+f-f+f+f-f-f+f+f+f-f-f+f-f-f-
f+f+f-f+f+f-f-f-f+f+f-f-f+f-f-f+f+f+f-f+f+f-f-f+f+f+f-f-f+f-
f-f+f+f+f-f+f+f-f-f-f+f+f-f-f+f-f-f+f+f+f-f+f+f-f-f+f+f+f-f-
f+f-f-f-f+f+f-f+f+f-f-f-f+f+f-f-f+f-f-f+f+f+f-f+f+f-f-f+f+f+
f-f-f+f-f-f+f+f+f-f+f+f-f-f-f+f+f-f-f+f-f-f-f+f+f-f+f+f-f-f+
f+f+f-f-f+f-f-f-f+f+f-f+f+f-f-f-f+f+f-f-f+f-f-f-f+f+f-f+f+f-
f-f+f+f+f-f-f+f-f-f+f+f+f-f+f+f-f-f-f+f+f-f-f+f-f-f+f+f+f-f+
f+f-f-f+f+f+f-f-f+f-f-f-f+f+f-f+f+f-f-f-f+f+f-f-f+f-f-f-f+f+
f-f+f+f-f-f+f+f+f-f-f+f-f-f+f+f+f-f+f+f-f-f-f+f+f-f-f+f-f-f-
f+f+f-f+f+f-f-f+f+f+f-f-f+f-f-f-f+f+f-f+f+f-f-f-f+f+f-f-f+f-
f-
If we tell our little turtle to follow those instructions, it will draw:What happens if we go further? After about 22 iterations (producing about 8
million instructions), the turtle is making turns smaller than a pixel on the
screen, so the path it took is no longer directly visible: you just see the
color gradient it was drawn with. Adding more iterations after that doesnâ€™t make
the image look any different (beyond rotating), it has stabilized. It looks like
this:I implemented all this as a Rust library. Hereâ€™s the code for that dragon curve:LindenmayerSystem {
    start: "R",
    rules: &[('R', "Rf+L"), ('L', "Rf-L")],
    angle: 0.25,
    implicit_f: false,
}
The extra field  tells the turtle what to do with leftover letters
like  and  in the expanded program. For the dragon curve, like I said
above, we should just erase them. But sometimes itâ€™s more convenient to replace
them with ; setting  would do so.(Thereâ€™s a math question here: can you express any L-system with  as an L-system with  and vice-versa? I donâ€™t know the
answer.)Here are a couple more L-systems, to give you a sense what they look like. First
David Hilbertâ€™s space filling curve:LindenmayerSystem {
    start: "A",
    rules: &[('A', "+Bf-AfA-fB+"), ('B', "-Af+BfB+fA-")],
    angle: 0.25,
    implicit_f: false,
}
Which looks like this, at 5 iterations:And hereâ€™s Helge von Kochâ€™s snowflake, at 3 iterations:LindenmayerSystem {
    start: "X-X-X-X-X-X",
    rules: &[('X', "X-X++X-X")],
    angle: 1.0 / 6.0,
    implicit_f: true,
}
So far all the pictures have been drawn with the same color gradient, but you
might want to use others. The gradients Iâ€™ve implemented fall into three
categories:Color gradients built out of combinators for things like scaling, cycling, and
sawtoothing. These are all in
OK-LAB color space.A very fancy color gradient based on the 3D Hilbert curve. The idea is to (i)
draw a cube in OK-LAB color space; (ii) trace a 3D Hilbert curve through the
cube; (iii) dye the curve according to the cubeâ€™s colors; then (iv) straighten
the curve and then lay it out on the curve that youâ€™re drawing.The last approach makes for very textured pictures since the 3D Hilbert curve
changes color so quickly. (It covers all the colors on the cube, which is most
possible colors.) For example, hereâ€™s the dragon curve with a 3D-Hilbert curve
color gradient:Putting this all together, you can draw some very pretty pictures.A haphazard curve I made thatâ€™s pretty nonetheless:An â€œs curveâ€ of my devising.UPDATE: I said in the readme about this curve that â€œItâ€™s very simple, so I
wouldnâ€™t be surprised if I wasnâ€™t the first to find it.â€ Indeed, someone emailed
me to point out it was discovered by Knuth and Davis under the name â€œTerdragon
curveâ€: it can be viewed as a variant of the dragon curve.Wunderlichâ€™s third space filling curve:Sierpinskiâ€™s space filling curve:UPDATE: Some new curves. Thanks internet commenters!Kochâ€™s â€œquadratic islandâ€:D. M. McKennaâ€™s SquaRecurve:A couple blocks from where I live, about a year ago, a PhD student at Tufts
university named RÃ¼meysa
Ã–ztÃ¼rk
was taken by masked, plainclothes DHS officers and held at an ICE detainment
facility for six weeks for purely political reasons (she wrote a pro-Palestine
op-ed in 2024). Since
then, ICE used tear gas, unprovoked, on peaceful
protesters
while in Portland against the wishes of the citiesâ€™ elected officials, and shot Alex
Pretti and RenÃ©e
Good to death. The
weaponization of ICE and other federal agencies against those politically
opposed to the administration needs to stop.]]></content:encoded></item><item><title>Turn Dependabot Off</title><link>https://words.filippo.io/dependabot/</link><author>/u/ketralnis</author><category>reddit</category><pubDate>Fri, 20 Feb 2026 23:40:41 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[Dependabot is a noise machine. It makes you feel like youâ€™re doing work, but youâ€™re actually discouraging more useful work. This is  true for security alerts in the Go ecosystem.I recommend turning it off and replacing it with a pair of scheduled GitHub Actions, one running govulncheck, and the other running your test suite against the latest version of your dependencies.We even got one of these alerts for the Wycheproof repository, which does not import the affected filippo.io/edwards25519 package at all. Instead, it only imports the unaffected filippo.io/edwards25519/field package.$ go mod why -m filippo.io/edwards25519
# filippo.io/edwards25519
github.com/c2sp/wycheproof/tools/twistcheck
filippo.io/edwards25519/field
We have turned Dependabot off.Use a serious vulnerability scanner insteadBut isnâ€™t this toil unavoidable, to prevent attackers from exploiting old vulnerabilities in your dependencies? Absolutely not!Computers are perfectly capable of doing the work of filtering out these irrelevant alerts for you. The Go Vulnerability Database has rich version, package,  metadata for all Go vulnerabilities.modules:
    - module: filippo.io/edwards25519
      versions:
        - fixed: 1.1.1
      vulnerable_at: 1.1.0
      packages:
        - package: filippo.io/edwards25519
          symbols:
            - Point.MultiScalarMult
summary: Invalid result or undefined behavior in filippo.io/edwards25519
description: |-
    Previously, if MultiScalarMult was invoked on an
    initialized point who was not the identity point, MultiScalarMult
    produced an incorrect result. If called on an
    uninitialized point, MultiScalarMult exhibited undefined behavior.
cves:
    - CVE-2026-26958
credits:
    - shaharcohen1
    - WeebDataHoarder
references:
    - advisory: https://github.com/FiloSottile/edwards25519/security/advisories/GHSA-fw7p-63qq-7hpr
    - fix: https://github.com/FiloSottile/edwards25519/commit/d1c650afb95fad0742b98d95f2eb2cf031393abb
source:
    id: go-security-team
    created: 2026-02-17T14:45:04.271552-05:00
review_status: REVIEWED
Any decent vulnerability scanner will  filter based on the package, which requires a simple . This already silences a lot of noise, because itâ€™s common and good practice for modules to separate functionality relevant to different dependents into different sub-packages. For example, it would have avoided the false alert against the Wycheproof repository.If you use a third-party vulnerability scanner, you should demand at least package-level filtering. vulnerability scanners will go further, though, and filter based on the reachability of the vulnerable  using static analysis. Thatâ€™s what govulncheck does!$ go mod why -m filippo.io/edwards25519
# filippo.io/edwards25519
filippo.io/sunlight/internal/ctlog
github.com/google/certificate-transparency-go/trillian/ctfe
github.com/go-sql-driver/mysql
filippo.io/edwards25519

$ govulncheck ./...
=== Symbol Results ===

No vulnerabilities found.

Your code is affected by 0 vulnerabilities.
This scan also found 1 vulnerability in packages you import and 2
vulnerabilities in modules you require, but your code doesn't appear to call
these vulnerabilities.
Use '-show verbose' for more details.
govulncheck noticed that my project indirectly depends on filippo.io/edwards25519 through github.com/go-sql-driver/mysql, which does not make the vulnerable symbol reachable, so it chose not to notify me.If you want, you can tell it to show the package- and module-level matches.$ govulncheck -show verbose,color ./...
Fetching vulnerabilities from the database...

Checking the code against the vulnerabilities...

The package pattern matched the following 16 root packages:
  filippo.io/sunlight
  filippo.io/sunlight/internal/stdlog
  [...]
Govulncheck scanned the following 54 modules and the go1.26.0 standard library:
  filippo.io/sunlight
  crawshaw.io/sqlite@v0.3.3-0.20220618202545-d1964889ea3c
  filippo.io/bigmod@v0.0.3
  filippo.io/edwards25519@v1.1.0
  filippo.io/keygen@v0.0.0-20240718133620-7f162efbbd87
  filippo.io/torchwood@v0.8.0
  [...]

=== Symbol Results ===

No vulnerabilities found.

=== Package Results ===

Vulnerability #1: GO-2026-4503
    Invalid result or undefined behavior in filippo.io/edwards25519
  More info: https://pkg.go.dev/vuln/GO-2026-4503
  Module: filippo.io/edwards25519
    Found in: filippo.io/edwards25519@v1.1.0
    Fixed in: filippo.io/edwards25519@v1.1.1

=== Module Results ===

Vulnerability #1: GO-2025-4135
    Malformed constraint may cause denial of service in
    golang.org/x/crypto/ssh/agent
  More info: https://pkg.go.dev/vuln/GO-2025-4135
  Module: golang.org/x/crypto
    Found in: golang.org/x/crypto@v0.44.0
    Fixed in: golang.org/x/crypto@v0.45.0

Vulnerability #2: GO-2025-4134
    Unbounded memory consumption in golang.org/x/crypto/ssh
  More info: https://pkg.go.dev/vuln/GO-2025-4134
  Module: golang.org/x/crypto
    Found in: golang.org/x/crypto@v0.44.0
    Fixed in: golang.org/x/crypto@v0.45.0

Your code is affected by 0 vulnerabilities.
This scan also found 1 vulnerability in packages you import and 2
vulnerabilities in modules you require, but your code doesn't appear to call
these vulnerabilities.
Itâ€™s easy to integrate govulncheck into your processes or scanners, either using the  CLI or the golang.org/x/vuln/scan Go API.Replace Dependabot with a govulncheck GitHub ActionYou can replace Dependabot security alerts with this GitHub Action.name: govulncheck
on:
  push:
  pull_request:
  schedule: # daily at 10:22 UTC
    - cron: '22 10 * * *'
  workflow_dispatch:
permissions:
  contents: read
jobs:
  govulncheck:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v5
        with:
          persist-credentials: false
      - uses: actions/setup-go@v6
        with:
          go-version-file: go.mod
      - run: |
          go run golang.org/x/vuln/cmd/govulncheck@latest ./...
It will run every day and only notify you if there is an actual vulnerability you should pay attention to.The cost of alert fatigueFalse positive alerts are not only a waste of time, they also reduce security by causing alert fatigue and making proper triage impractical.A security vulnerability should be assessed for its impact: production might need to be updated, secrets rotated, users notified! A business-as-usual dependency bump is a woefully insufficient remediation for an actual vulnerability, but itâ€™s the only practical response to the constant stream of low-value Dependabot alerts.This is why as Go Security Team lead back in 2020â€“2021 I insisted the team invest in staffing the Go Vulnerability Database and implement a vulnerability scanner with static analysis filtering.The govulncheck Action will not automatically open a PR for you, and thatâ€™s a good thing! Now that security alerts are not mostly noise, you can afford to actually look at them and take them seriously, including any required remediation.Noisy vulnerability scanners also impact the open source ecosystem. I often get issues and PRs demanding I update the dependencies of my projects due to vulnerabilities that donâ€™t affect them, because someoneâ€™s scanner is failing to filter them. Thatâ€™s extra toil dropped at the feet of open source maintainers, which is unsustainable. The maintainerâ€™s responsibility is making sure projects are not affected by security vulnerabilities. The responsibility of scanning tools is making sure they donâ€™t disturb their users with false positives.Test against latest instead of updatingThe other purpose of Dependabot is to keep dependencies up to date, regardless of security vulnerabilities. Your practices and requirements will vary, but I find this misguided, too.Dependencies should be updated according to  development cycle, not the cycle of each of your dependencies. For example you might want to update dependencies all at once when you begin a release development cycle, as opposed to when each dependency completes theirs.There are two benefits to quick updates, though: first, you can notice and report (or fix) breakage more rapidly, instead of being stalled by an incompatibility that could have been addressed a year prior; second, you reduce your patch delta  you need to update due to a security vulnerability, reducing the risk of having to rush through a refactor or unrelated fixes.You can capture both of those benefits without actually updating the dependencies by simply running CI against the latest versions of your dependencies every day. You just need to run  before your test suite. In the npm ecosystem, you just run  instead of .This way, you will still be alerted quickly of any potential issues, without having to pay attention to unproblematic updates, which you can defer to whenever fits your project best.name: Go tests
on:
  push:
  pull_request:
  schedule: # daily at 10:22 UTC
    - cron: '22 10 * * *'
  workflow_dispatch:
permissions:
  contents: read
jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        go:
          - { go-version: stable }
          - { go-version-file: go.mod }
        deps:
          - locked
          - latest
    steps:
      - uses: actions/checkout@v5
        with:
          persist-credentials: false
      - uses: actions/setup-go@v6
        with:
          go-version: ${{ matrix.go.go-version }}
          go-version-file: ${{ matrix.go.go-version-file }}
      - uses: geomys/sandboxed-step@v1.2.1
        with:
          run: |
            if [ "${{ matrix.deps }}" = "latest" ]; then
              go get -u -t ./...
            fi
            go test -v ./...
The Tevere has overflowed its lower banks, so a lot of previously familiar landscapes have changed slightly, almost eerily. This is the first picture I took after being able to somewhat safely descend onto (part of) the riverâ€™s banks.My work is made possible by Geomys, an organization of professional Go maintainers, which is funded by Ava Labs, Teleport, Tailscale, and Sentry. Through our retainer contracts they ensure the sustainability and reliability of our open source maintenance work and get a direct line to my expertise and that of the other Geomys maintainers. (Learn more in the Geomys announcement.)
Here are a few words from some of them!Teleport â€” For the past five years, attacks and compromises have been shifting from traditional malware and security breaches to identifying and compromising valid user accounts and credentials with social engineering, credential theft, or phishing. Teleport Identity is designed to eliminate weak access patterns through access monitoring, minimize attack surface with access requests, and purge unused permissions via mandatory access reviews.Ava Labs â€” We at Ava Labs, maintainer of AvalancheGo (the most widely used client for interacting with the Avalanche Network), believe the sustainable maintenance and development of open source cryptographic protocols is critical to the broad adoption of blockchain technology. We are proud to support this necessary and impactful work through our ongoing sponsorship of Filippo and his team.]]></content:encoded></item><item><title>GraphQL: You Don&apos;t Have to Like It, But You Should Know It (Golang)</title><link>https://www.youtube.com/watch?v=cTKX3Nttq28</link><author>/u/huseyinbabal</author><category>golang</category><category>reddit</category><pubDate>Fri, 20 Feb 2026 22:48:11 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Snake game but every frame is a C program compiled into a snake game where each frame is a C program...</title><link>https://youtu.be/gvF7rWfcFD8?si=PzvURvL-WofvB8UH</link><author>/u/Perfect-Highlight964</author><category>reddit</category><pubDate>Fri, 20 Feb 2026 22:30:31 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Open source AI agent for Kubernetes incident investigation â€” now works with any LLM</title><link>https://www.reddit.com/r/kubernetes/comments/1ra990d/open_source_ai_agent_for_kubernetes_incident/</link><author>/u/Useful-Process9033</author><category>reddit</category><pubDate>Fri, 20 Feb 2026 22:12:37 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[Update on IncidentFox, an open source tool for investigating k8s incidents. Posted about it a month ago. The main feedback was it was OpenAI-locked and that rubbed people the wrong way. That's fixed. It now works with Claude, Gemini, DeepSeek, Mistral, Groq, Ollama (local models), Azure OpenAI, Bedrock, Vertex AI. What it does during a k8s incident: the same stuff a human does, just faster. Describes pods, checks events, looks at restart counts, inspects rollout history, pulls logs, correlates with recent deploys. Read-only by default, any action needs human approval. New since last time: - Works with any model (including running fully local) - RAG self-learning from past incidents - New integrations: Honeycomb, Victoria Metrics, New Relic, Jira - Configurable investigation skills per team - Teams and Google Chat support I know AI tools in k8s are a touchy subject. Happy to take criticism.]]></content:encoded></item><item><title>Problem pulling containerd images</title><link>https://www.reddit.com/r/kubernetes/comments/1ra8nlb/problem_pulling_containerd_images/</link><author>/u/Saber_dk</author><category>reddit</category><pubDate>Fri, 20 Feb 2026 21:49:44 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[I'm installing Kubernetes 1.35, and the package download is very slow; I can't get above 100 kbps.Even worse, when I run `kubeadm init`, the image download is extremely slow. It's been over 45 minutes and it's barely downloaded:Could you help me to identify the problem ?]]></content:encoded></item><item><title>[Media] TrailBase 0.24: Fast, open, single-executable Firebase alternative now with Geospatial</title><link>https://www.reddit.com/r/rust/comments/1ra8lxx/media_trailbase_024_fast_open_singleexecutable/</link><author>/u/trailbaseio</author><category>rust</category><category>reddit</category><pubDate>Fri, 20 Feb 2026 21:47:52 +0000</pubDate><source url="https://www.reddit.com/r/rust/top/?sort=top&amp;t=day&amp;limit=3">Reddit - Rust</source><content:encoded><![CDATA[TrailBase is a Firebase alternative that provides type-safe REST & realtime APIs, auth, multi-DB, a WebAssembly runtime, SSR, admin UI... and now has geospatial data and querying. It's self-contained, easy to self-host, fast and built on Rust, SQLite & Wasmtime.Moreover, it comes with client libraries for JS/TS, Dart/Flutter, Go, Rust, .Net, Kotlin, Swift and Python.Just released v0.24. Some of the highlights since last time posting here include:Support for efficiently storing, indexing and querying geometric and geospatial data ðŸŽ‰ For example, you could throw a bunch of geometries like points and polygons into a table and query: what's in the client's viewport? Is my coordinate intersecting with anything? ...Much improved admin UI: pretty maps and stats on the logs page, improved accounts page, reduced layout jank during table loadin, ...Change subscriptions using WebSockets in addition to SSE.Increase horizontal mobility, i.e. reduce lock-in: allow using TBs extensions outside, allow import of existing auth collections (i.e. Auth0 with more to come), dual-licensed clients under more permissive Apache-2, ...Check out the live demo, our GitHub or our website. TrailBase is only about a year young and rapidly evolving, we'd really appreciate your feedback ðŸ™]]></content:encoded></item><item><title>Intel Hiring More Linux Developers - Including For GPU Drivers / Linux Gaming Stack</title><link>https://www.phoronix.com/news/Intel-Linux-Jobs-February-2026</link><author>/u/reps_up</author><category>reddit</category><pubDate>Fri, 20 Feb 2026 21:40:39 +0000</pubDate><source url="https://www.reddit.com/r/linux/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Linux</source><content:encoded><![CDATA[Michael Larabel is the principal author of Phoronix.com and founded the site in 2004 with a focus on enriching the Linux hardware experience. Michael has written more than 20,000 articles covering the state of Linux hardware support, Linux performance, graphics drivers, and other topics. Michael is also the lead developer of the Phoronix Test Suite, Phoromatic, and OpenBenchmarking.org automated benchmarking software. He can be followed via Twitter, LinkedIn, or contacted via MichaelLarabel.com.]]></content:encoded></item><item><title>SnapX: The Power of ShareX, Hard Forked for Linux, FreeBSD, macOS, and Windows (built with Avalonia)</title><link>https://www.reddit.com/r/linux/comments/1ra87ym/snapx_the_power_of_sharex_hard_forked_for_linux/</link><author>/u/BrycensRanch</author><category>reddit</category><pubDate>Fri, 20 Feb 2026 21:32:36 +0000</pubDate><source url="https://www.reddit.com/r/linux/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Linux</source><content:encoded><![CDATA[SnapX: The Power of ShareX, Hard Forked for Linux, FreeBSD, macOS, and Windows (built with Avalonia)I've just released the first usable pre-release of SnapX (for basic usecases). It is a cross-platform screenshot tool that can upload to most of ShareX's preconfigured destinations and also upload to custom destinations ()Packages are available for: Flatpak (Not submitted on Flathub yet), Snap, RPM, DEB, MSI, and  tarballs. (similar to , with all needed dependencies)Additionally, SnapX uses a cross-platform OCR powered by PaddleOCR/RapidOCR. From my tests, it blows away Windows built-in OCR and is vastly more portable, only relying on the ONNXRuntime from Microsoft. This makes SnapX the first Avalonia app to run on FreeBSD and offer industry-leading OCR while also offering screenshot & upload functionality.The image formats currently supported are: PNG, WEBP, AVIF, JPEG, GIF, TIFF, and BMP.I am looking into adding JPEG XL support with a jxl-rs wrapper NuGet package.The image library I chose for it is ImageSharp. It's simpler than SkiaSharp and open source for open source projects. It also doesn't rely on a native library.You can also fully configure SnapX via the Command Line, Environment variables, and the Windows Registry.You don't need .NET installed.It is built on .NET 10, the same as ShareX. SnapX is deployed with NativeAOT using Avalonia. If you want to know how I migrated all of hundreds of thousands of lines of UI in WinForms, I simply deleted them and reimplemented what I knew users would immediately need while looking at ShareX's source. Kudos to ShareX's developers for making their codebase simple to develop in.With that being said, I spent a lot of nights with 10,000+ errors after doing so... I probably lost a decent bit of my sanity, but nothing worth doing comes without a cost. After the UI migration, I decided to make sure SnapX could take advantage of NativeAOT, as it's an exciting technology. No .NET install needed on the user's machines?!? Anyway, that led to a few more nights of migrating the destinations to use System.Text.Json.I even went as far as making the configurations use YAML for comment support. I did try TOML since it's very popular with other Linux users. However, for such a heavily nested configuration, I ran into a multitude of issues that were not something I'm willing to subject someone else to.As for why I chose Avalonia over something like GTK4? I might face some backlash for this, but... I like writing UI in XAML. I'm new to it, but there's a lot of documentation for it. It's also a nicely integrated experience with my editor. If I had gone with GTK4 in C#, it would've been more difficult.]]></content:encoded></item><item><title>Turn Dependabot Off</title><link>https://words.filippo.io/dependabot/</link><author>/u/_fz_</author><category>golang</category><category>reddit</category><pubDate>Fri, 20 Feb 2026 20:51:56 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[Dependabot is a noise machine. It makes you feel like youâ€™re doing work, but youâ€™re actually discouraging more useful work. This is  true for security alerts in the Go ecosystem.I recommend turning it off and replacing it with a pair of scheduled GitHub Actions, one running govulncheck, and the other running your test suite against the latest version of your dependencies.We even got one of these alerts for the Wycheproof repository, which does not import the affected filippo.io/edwards25519 package at all. Instead, it only imports the unaffected filippo.io/edwards25519/field package.$ go mod why -m filippo.io/edwards25519
# filippo.io/edwards25519
github.com/c2sp/wycheproof/tools/twistcheck
filippo.io/edwards25519/field
We have turned Dependabot off.Use a serious vulnerability scanner insteadBut isnâ€™t this toil unavoidable, to prevent attackers from exploiting old vulnerabilities in your dependencies? Absolutely not!Computers are perfectly capable of doing the work of filtering out these irrelevant alerts for you. The Go Vulnerability Database has rich version, package,  metadata for all Go vulnerabilities.modules:
    - module: filippo.io/edwards25519
      versions:
        - fixed: 1.1.1
      vulnerable_at: 1.1.0
      packages:
        - package: filippo.io/edwards25519
          symbols:
            - Point.MultiScalarMult
summary: Invalid result or undefined behavior in filippo.io/edwards25519
description: |-
    Previously, if MultiScalarMult was invoked on an
    initialized point who was not the identity point, MultiScalarMult
    produced an incorrect result. If called on an
    uninitialized point, MultiScalarMult exhibited undefined behavior.
cves:
    - CVE-2026-26958
credits:
    - shaharcohen1
    - WeebDataHoarder
references:
    - advisory: https://github.com/FiloSottile/edwards25519/security/advisories/GHSA-fw7p-63qq-7hpr
    - fix: https://github.com/FiloSottile/edwards25519/commit/d1c650afb95fad0742b98d95f2eb2cf031393abb
source:
    id: go-security-team
    created: 2026-02-17T14:45:04.271552-05:00
review_status: REVIEWED
Any decent vulnerability scanner will  filter based on the package, which requires a simple . This already silences a lot of noise, because itâ€™s common and good practice for modules to separate functionality relevant to different dependents into different sub-packages. For example, it would have avoided the false alert against the Wycheproof repository.If you use a third-party vulnerability scanner, you should demand at least package-level filtering. vulnerability scanners will go further, though, and filter based on the reachability of the vulnerable  using static analysis. Thatâ€™s what govulncheck does!$ go mod why -m filippo.io/edwards25519
# filippo.io/edwards25519
filippo.io/sunlight/internal/ctlog
github.com/google/certificate-transparency-go/trillian/ctfe
github.com/go-sql-driver/mysql
filippo.io/edwards25519

$ govulncheck ./...
=== Symbol Results ===

No vulnerabilities found.

Your code is affected by 0 vulnerabilities.
This scan also found 1 vulnerability in packages you import and 2
vulnerabilities in modules you require, but your code doesn't appear to call
these vulnerabilities.
Use '-show verbose' for more details.
govulncheck noticed that my project indirectly depends on filippo.io/edwards25519 through github.com/go-sql-driver/mysql, which does not make the vulnerable symbol reachable, so it chose not to notify me.If you want, you can tell it to show the package- and module-level matches.$ govulncheck -show verbose,color ./...
Fetching vulnerabilities from the database...

Checking the code against the vulnerabilities...

The package pattern matched the following 16 root packages:
  filippo.io/sunlight
  filippo.io/sunlight/internal/stdlog
  [...]
Govulncheck scanned the following 54 modules and the go1.26.0 standard library:
  filippo.io/sunlight
  crawshaw.io/sqlite@v0.3.3-0.20220618202545-d1964889ea3c
  filippo.io/bigmod@v0.0.3
  filippo.io/edwards25519@v1.1.0
  filippo.io/keygen@v0.0.0-20240718133620-7f162efbbd87
  filippo.io/torchwood@v0.8.0
  [...]

=== Symbol Results ===

No vulnerabilities found.

=== Package Results ===

Vulnerability #1: GO-2026-4503
    Invalid result or undefined behavior in filippo.io/edwards25519
  More info: https://pkg.go.dev/vuln/GO-2026-4503
  Module: filippo.io/edwards25519
    Found in: filippo.io/edwards25519@v1.1.0
    Fixed in: filippo.io/edwards25519@v1.1.1

=== Module Results ===

Vulnerability #1: GO-2025-4135
    Malformed constraint may cause denial of service in
    golang.org/x/crypto/ssh/agent
  More info: https://pkg.go.dev/vuln/GO-2025-4135
  Module: golang.org/x/crypto
    Found in: golang.org/x/crypto@v0.44.0
    Fixed in: golang.org/x/crypto@v0.45.0

Vulnerability #2: GO-2025-4134
    Unbounded memory consumption in golang.org/x/crypto/ssh
  More info: https://pkg.go.dev/vuln/GO-2025-4134
  Module: golang.org/x/crypto
    Found in: golang.org/x/crypto@v0.44.0
    Fixed in: golang.org/x/crypto@v0.45.0

Your code is affected by 0 vulnerabilities.
This scan also found 1 vulnerability in packages you import and 2
vulnerabilities in modules you require, but your code doesn't appear to call
these vulnerabilities.
Itâ€™s easy to integrate govulncheck into your processes or scanners, either using the  CLI or the golang.org/x/vuln/scan Go API.Replace Dependabot with a govulncheck GitHub ActionYou can replace Dependabot security alerts with this GitHub Action.name: govulncheck
on:
  push:
  pull_request:
  schedule: # daily at 10:22 UTC
    - cron: '22 10 * * *'
  workflow_dispatch:
permissions:
  contents: read
jobs:
  govulncheck:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v5
        with:
          persist-credentials: false
      - uses: actions/setup-go@v6
        with:
          go-version-file: go.mod
      - run: |
          go run golang.org/x/vuln/cmd/govulncheck@latest ./...
It will run every day and only notify you if there is an actual vulnerability you should pay attention to.The cost of alert fatigueFalse positive alerts are not only a waste of time, they also reduce security by causing alert fatigue and making proper triage impractical.A security vulnerability should be assessed for its impact: production might need to be updated, secrets rotated, users notified! A business-as-usual dependency bump is a woefully insufficient remediation for an actual vulnerability, but itâ€™s the only practical response to the constant stream of low-value Dependabot alerts.This is why as Go Security Team lead back in 2020â€“2021 I insisted the team invest in staffing the Go Vulnerability Database and implement a vulnerability scanner with static analysis filtering.The govulncheck Action will not automatically open a PR for you, and thatâ€™s a good thing! Now that security alerts are not mostly noise, you can afford to actually look at them and take them seriously, including any required remediation.Noisy vulnerability scanners also impact the open source ecosystem. I often get issues and PRs demanding I update the dependencies of my projects due to vulnerabilities that donâ€™t affect them, because someoneâ€™s scanner is failing to filter them. Thatâ€™s extra toil dropped at the feet of open source maintainers, which is unsustainable. The maintainerâ€™s responsibility is making sure projects are not affected by security vulnerabilities. The responsibility of scanning tools is making sure they donâ€™t disturb their users with false positives.Test against latest instead of updatingThe other purpose of Dependabot is to keep dependencies up to date, regardless of security vulnerabilities. Your practices and requirements will vary, but I find this misguided, too.Dependencies should be updated according to  development cycle, not the cycle of each of your dependencies. For example you might want to update dependencies all at once when you begin a release development cycle, as opposed to when each dependency completes theirs.There are two benefits to quick updates, though: first, you can notice and report (or fix) breakage more rapidly, instead of being stalled by an incompatibility that could have been addressed a year prior; second, you reduce your patch delta  you need to update due to a security vulnerability, reducing the risk of having to rush through a refactor or unrelated fixes.You can capture both of those benefits without actually updating the dependencies by simply running CI against the latest versions of your dependencies every day. You just need to run  before your test suite. In the npm ecosystem, you just run  instead of .This way, you will still be alerted quickly of any potential issues, without having to pay attention to unproblematic updates, which you can defer to whenever fits your project best.name: Go tests
on:
  push:
  pull_request:
  schedule: # daily at 10:22 UTC
    - cron: '22 10 * * *'
  workflow_dispatch:
permissions:
  contents: read
jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        go:
          - { go-version: stable }
          - { go-version-file: go.mod }
        deps:
          - locked
          - latest
    steps:
      - uses: actions/checkout@v5
        with:
          persist-credentials: false
      - uses: actions/setup-go@v6
        with:
          go-version: ${{ matrix.go.go-version }}
          go-version-file: ${{ matrix.go.go-version-file }}
      - uses: geomys/sandboxed-step@v1.2.1
        with:
          run: |
            if [ "${{ matrix.deps }}" = "latest" ]; then
              go get -u -t ./...
            fi
            go test -v ./...
The Tevere has overflowed its lower banks, so a lot of previously familiar landscapes have changed slightly, almost eerily. This is the first picture I took after being able to somewhat safely descend onto (part of) the riverâ€™s banks.My work is made possible by Geomys, an organization of professional Go maintainers, which is funded by Ava Labs, Teleport, Tailscale, and Sentry. Through our retainer contracts they ensure the sustainability and reliability of our open source maintenance work and get a direct line to my expertise and that of the other Geomys maintainers. (Learn more in the Geomys announcement.)
Here are a few words from some of them!Teleport â€” For the past five years, attacks and compromises have been shifting from traditional malware and security breaches to identifying and compromising valid user accounts and credentials with social engineering, credential theft, or phishing. Teleport Identity is designed to eliminate weak access patterns through access monitoring, minimize attack surface with access requests, and purge unused permissions via mandatory access reviews.Ava Labs â€” We at Ava Labs, maintainer of AvalancheGo (the most widely used client for interacting with the Avalanche Network), believe the sustainable maintenance and development of open source cryptographic protocols is critical to the broad adoption of blockchain technology. We are proud to support this necessary and impactful work through our ongoing sponsorship of Filippo and his team.]]></content:encoded></item><item><title>Do I use load-balancers?</title><link>https://www.reddit.com/r/kubernetes/comments/1ra6n4o/do_i_use_loadbalancers/</link><author>/u/Stock-Assistant-5420</author><category>reddit</category><pubDate>Fri, 20 Feb 2026 20:32:44 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Exploring Linux on a LoongArch Mini PC</title><link>https://www.wezm.net/v2/posts/2026/loongarch-mini-pc-m700s/</link><author>/u/goldensyrupgames</author><category>reddit</category><pubDate>Fri, 20 Feb 2026 20:25:01 +0000</pubDate><source url="https://www.reddit.com/r/linux/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Linux</source><content:encoded><![CDATA[Ever the fan of an underdog, I recently acquired a new mini-PC with a
Loongson 3A6000 CPU. This CPU uses the LoongArch64 instruction set
architecture (ISA).  is a 64-bit RISC ISA inspired by MIPS and
RISC-V introduced by Loongson Technology in 2021.
From Wikipedia:A Loongson developer described it as â€œâ€¦a new RISC ISA, which is a bit like
MIPS or RISC-V. LoongArch includes a reduced 32-bit version (LA32R), a
standard 32-bit version (LA32S) and a 64-bit version (LA64)â€.
The stated rationale was to make Loongson and China not dependent on foreign
technology or authorisation to develop their processor capability, whilst not
infringing on any technology patents.LA64 has 32 64-bit general purpose registers (â€“). Like RISC-V 
is hard-wired to zero. Thereâ€™s also 32 64-bit floating point registers
(â€“). The 3A6000 supports two vector extensions (SIMD):LSX (Loongson SIMD eXtension) with 128-bit vectors. (â€“)LASX (Loongson Advanced SIMD eXtension) with 256-bit vectors. (â€“)for example, on a core implementing LSX and LASX, the lower 128 bits of 
is shared with  and the lower 64 bits of  is shared with 
same with all other VRs.LoongArch is interesting to me because:Itâ€™s a different architecture to the vast majority of systems in use today, which
use x86_64 and ARM CPUs.Performance is better than most RISC-V CPUs currently available.Itâ€™s somewhat Linux first.Itâ€™s supported by Chimera Linux. As a Chimera package maintainer I thought it would
be handy to have hardware to test on.Regarding â„–3: Since neither Windows, nor macOS support the architecture that leaves
Linux-based operating systems as a great option. Therefore Loongson has an
interest in that working well. They have contributed to Linux, musl, and also
did their own initial ports of Debian and Alpine Linux. This kind of makes it
an architecture with Linux-first support. Loongson-3A6000 4-core/8-thread 64-bit @ 2.5Ghz 16Gb DDR4 SO-DIMM, 1 of 2 slots populated RTL8821CE 802.11ac PCIe Wireless Network AdapterIt has a plethora of ports:Front:
1 Ã— USB 3.0 Type-C with PDBack:
2 Ã— HDMI, supporting up to 4K 30Hz each2 Ã— Gigabit Ethernet portsOpening the bottom of the case requires removing the four screws in the bottom,
one under each of the rubber feet. In the bottom section is the M.2 slot and
large blower fan.The blower fan runs constantly at a fairly high speed, making it much noisier
than any other computer I own. I contacted MOREFINE about it, and
they confirmed that it was expected:Does not affect normal operations
There is currently no other way to adjust its noise; this is a normal stateOpening the top of the case requires removing the two screws on the back panel
above the ports. Then using something thin in one of the screw holes lever the
top up a bit so you can get under it and flip it up. Be careful as it has Wi-Fi and
Bluetooth antennas attached to it.In the top you get access to the SO-DIMM RAM slots. Thereâ€™s also space for a
3.5â€œ SATA SSD or HD. The M700S came with mounting hardware for this and a small SATA
cable that plugs into the ports at the top right.Out of the box it comes with Loongnix installed, an apt-based loongarch
distribution with KDE 5 desktop. It indicates it was built in 2024, but uses
quite dated components. The project seems defunct as the website and package
servers were inaccessible, although perhaps itâ€™s only accessible within China.
No matter, as the goal was always to run Chimera Linux on it. The password to
the Loongnix installation was not readily obvious to me, but a recent post on
the DuckDB blog about the same machine had the necessary details.The BIOS (UEFI) is in Chinese by default. When the machine boots press F2 or down arrow
to enter the UEFI.The initial option selected when the UEFI starts is the language
selector. Press Enter, then select English. If you save and exit at this point the
UEFI and boot messages will remain in English.With that out of the way I booted off a Chimera ISO on a USB stick and followed
the instructions for a normal install. Thereâ€™s nothing out
of the ordinary required for the  install. The steps are identical
to an x86_64 install, right down to using  as the bootloader.
This makes for a refreshing change from Snapdragon X machines, which still
donâ€™t have complete or widespread Linux distribution support.Video capture of M700S booting to Chimera login prompt.With the base installation complete I proceeded to install GNOME. This is
where I ran into my first issue. I could log in with GDM and get to the
desktop, even open a terminal or Firefox but within a few seconds Iâ€™d be kicked
back to the GDM login screen. I also tried Wayfire, and an Xfce Wayland session
with Labwc, but all of them yielded EGL-related errors and failed to start. For
example this is the Wayfire output:Undeterred, I installed X.Org and started an Xfce X11 session, and all was well.The Loongson-3A6000 is not particularly fast or efficient. At idle it consumes
about 27W and under load it goes up to 65W.For comparison the Intel N100 based mini-PC connected to my TV consumes ~7W
when idle and scores 12.7 on Speedometer 3.1. My AMD Ryzen 9950X3D scores 36.7 (and
chews through way more power). All Speedometer tests were done in modern Firefox, with no extensions.
It does appear that as of last year Firefox has JIT support for loongarch64.Another test I performed was building the allsorts Rust crate (v0.16.1). On
the LoongArch machine it takes almost 44 seconds. On my Ryzen 9950X3D with
 (to make it slightly more comparable) it completes the build in 22
seconds.So, overall itâ€™s not a particularly efficient machine, and while the performance
is nothing special it does seem readily usable. Browsing JS heavy web applications like
Mattermost and Mastodon runs fine. Subjectively it feels faster than all the
Raspberry Pi systems Iâ€™ve used (up to a Pi 400).One of the reasons I got the machine was for testing software and attempting
to address incompatibilities.A rudimentary search (rg -g template.py -B 1 broken | rg -A 1 loongarch64) through
cports, the Chimera Linux ports collection, revealed this list of packages
marked broken on :â€œold nix crate, canâ€™t updateâ€â€œvendor/github.com/aperturerobotics/jacobsa-crypto/cmac/hash.go:97:3: undefined: xorBlockâ€â€œlinux-raw-sys does not support, canâ€™t bump (semver)â€â€œoutdated nix crate, canâ€™t updateâ€â€œring 0.16.20 fails to buildâ€â€œoutdated nix crate, canâ€™t updateâ€â€œvendor/github.com/creack/pty/pty_linux.go:39:8: undefined: _C_uintâ€â€œsaferith@v0.33.0/arith_decl.go:â€¦: missing function bodyâ€â€œrustix/libc interaction garbage strikes againâ€â€œoutdated nix crate, canâ€™t updateâ€â€œcannot find value  in module â€â€œoutdated nix crate, canâ€™t updateâ€â€œoutdated nix crate, canâ€™t updateâ€â€œcauses a machine exception at runtimeâ€â€œold nix crate, canâ€™t updateâ€â€œriscv64/loongarch64 dynamic_arch is currently brokenâ€As you can see the list is pretty small. Most of the software packaged
in cports is compatible.Many of the broken ports are Rust projects using old versions of the  or
 crates. So far I have looked into , , ,
and . For the first two the problematic dependency is deep in the tree via
:V4 of this crate is officially supported by the Protobuf team at Google.
Prior major versions were developed by as a community project by stepancheg
who generously donated the crate name to Google.V4 is a completely new implementation with a different API, as well as a
fundamentally different approach than prior versions of this crate. It
focuses on delivering a high-quality Rust API which is backed by either a
pure C implementation (upb) or the Protobuf C++ implementation. This choice
was made for performance, feature parity, development velocity, and security
reasons. More discussion about the rationale and design philosophy can be
found at https://protobuf.dev/reference/rust/.It is not planned for the V3 pure Rust lineage to be actively developed going
forward. While it is not expected to receive significant further development,
as a stable and high quality pure Rust implementation, many open source
projects may reasonably continue to stay on the V3 API.So,  and  are difficult to fix. The ideal fix would
be a new release of the 3.x series of the protobuf crates. They would bump
their  dependency by way of updating . However, since that
lineage is unmaintained itâ€™s unlikely. Given I use neither tool personally I
gave up on them, and moved on to . is a command line IRC client that I do use. It turned out to be easier
to fix: use a newer version of the  crate. I have made that change and
opened a PR upstream, which has been merged.Finally, there was a new release of , a GUI IRC client. The new version
uses an updated version of , which fixed the build issues. Iâ€™ve opened a
PR to bump the package to that version. Over time I plan to look
into some of the other broken projects as well.So there we have it. A small foray into modern computing on a new and
interesting RISC architecture. Back in the day there were all sorts of ISAs:
alpha, mips, arm, x86, m68k, powerpc, sparc to name a few. Most of these have
died out or are expensive to acquire. Thatâ€™s why itâ€™s interesting to me to see
a new affordable one spring up in recent times, and get adopted in the Linux
ecosystem relatively quickly. Happy computing.]]></content:encoded></item><item><title>DuckDB hiring a Rust engineer</title><link>https://duckdblabs.com/jobs/rust_engineer</link><author>/u/hurhurdedur</author><category>rust</category><category>reddit</category><pubDate>Fri, 20 Feb 2026 20:15:00 +0000</pubDate><source url="https://www.reddit.com/r/rust/top/?sort=top&amp;t=day&amp;limit=3">Reddit - Rust</source><content:encoded><![CDATA[As a DuckDB Rust Engineer, you will be working with a small team of database experts on one of the most exciting, fastest-growingopen-source database systems in the world. You will expand the DuckDB Rust ecosystem by building and improving Rust extensions, contributing to duckdb-rs, and working alongside the team on customer projects for some of the worldâ€™s most recognised data and technology companies. You will be based in our office in Amsterdam, the Netherlands.One part of this role is focused on the DuckDB Rust ecosystem itself, in particular around DuckDBâ€™s extension ecosystem. This will include things like duckdb-rs, the Rust extension template, building new Rust extensions, and potentially even porting existing C++ based extensions to Rust. This work is fully open source and directly used by a large and growing community of developers.The other part of this role is client-facing consultancy work, where you will collaborate directly with engineering teams of high-profile clients to help them integrate and extend DuckDB in their production systems. DuckDB is written in C++, and client work may involve diving into the C++ core alongside Rust, so comfort working across both languages is important.Strong, hands-on . You are fluent with ownership, traits, FFI, and writing idiomatic, performant Rust.Comfort working with . Client engagements may require reading, debugging, or contributing to C++ code.Experience building libraries or systems-level software in Rust or C++.Solid engineering fundamentals. You care about correctness, performance, and well-designed APIs.Ability to communicate and collaborate with software engineering teams, both internally and at client organisations.Work visa valid in the Netherlands (EU/Schengen area).Professional proficiency in , both written and spoken.A background in , either through a degree or equivalent professional experience.Experience with  and/or writing Rust FFI bindings.Familiarity with database systems, query engines, or analytical workloads.Contributions to open-source projects.Keen to engage with the open-source Rust community of DuckDB.Location: Amsterdam (Hybrid, 3 days in office)Employment type: Full-timeNot sure you meet every requirement? Please apply anyway. Research shows that many great candidates, especially from underrepresented groups, hesitate when they donâ€™t tick every box. At DuckDB Labs we value potential and diverse perspectives even more than perfectly matching CVs. back to main page]]></content:encoded></item><item><title>[D] ACL ARR Jan 2026 Meta-Reviews</title><link>https://www.reddit.com/r/MachineLearning/comments/1ra5uf7/d_acl_arr_jan_2026_metareviews/</link><author>/u/ApartmentAlarmed3848</author><category>ai</category><category>reddit</category><pubDate>Fri, 20 Feb 2026 20:02:11 +0000</pubDate><source url="https://www.reddit.com/r/MachineLearning/top/?sort=top&amp;t=day&amp;limit=3">Reddit - ML</source><content:encoded><![CDATA[Submitted my first paper to ACL ARR Jan cycle, and after addressing reviewer concerns got reviews: 4.5 (conf 5), 3.5 (conf 3), 3 (conf 3)Now I guess I will just have to wait for meta-reviews to come out on March 10. Should I commit with these scores for ACL 2026? (Main would be great, but I'll take findings too)]]></content:encoded></item><item><title>Are advances in Homotopy Type Theory likely to have any impacts on Rust?</title><link>https://www.reddit.com/r/rust/comments/1ra4jck/are_advances_in_homotopy_type_theory_likely_to/</link><author>/u/Dyson8192</author><category>rust</category><category>reddit</category><pubDate>Fri, 20 Feb 2026 19:13:04 +0000</pubDate><source url="https://www.reddit.com/r/rust/top/?sort=top&amp;t=day&amp;limit=3">Reddit - Rust</source><content:encoded><![CDATA[Basically the title. Iâ€™ve become interested in exploring just how much information can be encoded in type systems, including combinatorial data. And I know Rust has employed many ideas from functional programming already.However, thereâ€™s the obvious issue of getting type systems and functional programming to interact nicely with actual memory management (and probably something to be said about Von Neumann architecture).Thus, is anyone here experienced enough in both fields to say if Homotopy Type Theory is too much abstract nonsense for use in systems level programming (or really any manual memory allocation language), or if there are improvements to be made in Rust using ideas from HoTT?]]></content:encoded></item><item><title>Infra/distributed systems question â€” where do things usually go wrong with automation + control layers?</title><link>https://www.reddit.com/r/kubernetes/comments/1ra3ziw/infradistributed_systems_question_where_do_things/</link><author>/u/PsychologicalBag7767</author><category>reddit</category><pubDate>Fri, 20 Feb 2026 18:53:21 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>I built an AI that turns file organization into a conversation - no rules engine to learn</title><link>https://www.reddit.com/r/artificial/comments/1ra3sle/i_built_an_ai_that_turns_file_organization_into_a/</link><author>/u/jhaubrich11</author><category>ai</category><category>reddit</category><pubDate>Fri, 20 Feb 2026 18:46:07 +0000</pubDate><source url="https://www.reddit.com/r/artificial/top/?sort=top&amp;t=day&amp;limit=3">Reddit - AI</source><content:encoded><![CDATA[So I've been watching people struggle with file organization for years. They have 10,000+ files scattered across Downloads, Desktop, Documents. They  to organize but the thought of setting up rules feels like learning regex.That's why I built the AI Job Builder for VaultSort.Here's how it works: you describe what you want in plain English. "Move all screenshots older than 30 days to ~/Archive/Screenshots, organized by month." The AI generates the complete rule set - predicates, logic, folder structure - in under 15 seconds. You review it, edit if needed, then run it.The thing that matters:  No subscription. No mystery charges. You bring your own API key (OpenAI, Anthropic, Google Gemini), or use the free Gemini tier and pay $0. The rules it generates are transparent and editable â€” not a black box.I've tested it on everything from "organize my photo library by camera model and date" to "move all PDFs with invoices in the filename to my accounting folder." It handles the logic tree without you having to think about AND/OR/NOT operators.It's a premium feature (one-time purchase, no subscription), but honestly, if you're managing thousands of files and dread the organizational work, it's probably worth it. VaultSort link if you want to try it.Happy to answer questions about how it works or why I built it this way.]]></content:encoded></item><item><title>Gentoo has announced it now has a presence on Codeberg, a non-profit, free European alternative to GitHub. (I hope all FOSS world will migrate to better alternatives as well)</title><link>https://www.reddit.com/r/linux/comments/1ra3afi/gentoo_has_announced_it_now_has_a_presence_on/</link><author>/u/BlokZNCR</author><category>reddit</category><pubDate>Fri, 20 Feb 2026 18:27:33 +0000</pubDate><source url="https://www.reddit.com/r/linux/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Linux</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>ThunderKittens 2.0: Even Faster Kernels for Your GPUs</title><link>https://hazyresearch.stanford.edu/blog/2026-02-19-tk-2</link><author>/u/mttd</author><category>reddit</category><pubDate>Fri, 20 Feb 2026 18:19:41 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[TL;DR: This is a release post for ThunderKittens 2.0, our cute little CUDA-embedded DSL, along with a technical deep dive for those who are interested.This release is different in that it's as much about  as addition: we refactored the internals, hunted down unnecessary memory instructions and assembler inefficiencies, reduced build system complexities, and identified many surprising behaviors on modern Nvidia GPUs that guide how kernels should  be optimized.Thus, the goal of this post is to briefly announce the release, and then share some of our learnings. On the release side, ThunderKittens 2.0 brings:: , CLC scheduling, tensor memory controllability, many new utilities, PDL, and more.Major refactor of the internal code, during which we found a number of subtle inefficiencies described throughout the rest of this post.Much simpler build structure for all of our example kernels, so you (or your agent) can easily adapt them for your own use!Contributions from industry: many companies have their own internal fork of ThunderKittens, and many were generous enough to contribute them back to us!These changes enabled us to write even faster kernels with new optimization strategies and fewer lines of code. As an example, we present the new state-of-the-art BF16 / MXFP8 / NVFP4 GEMM kernels that surpass or match cuBLAS performance on Nvidia B200s:Figure 1: New Kernels! All of the kernels (both TK and cuBLAS) were benchmarked using bitwise-identical random inputs with 500 warmup iterations, 100 profiling iterations, and L2 cache eviction. Details on the benchmarking method are described later in this post.We also updated all of our existing example kernels to use the newer APIs, and are actively implementing more state-of-the-art kernels with TK (e.g., Flash Attention 4, grouped GEMMs, GEMV).That's it for the release! Please check out our repository for the details. The rest of this post cherry-picks some of the interesting technical details we found while optimizing TK. Specifically, we'll discuss:. Can't escape it if you want to squeeze out the last few TFLOPs! Tightening memory synchronization with proper reasoning is crucial to getting peak performance.Tensor core and memory pipelining. Some tensor core instructions are implicitly pipelined without proper documentation, and the best memory pipelining strategy for the given workload might not be so obvious.Hinting the PTX assembler properly. It really doesn't trust us otherwise! Logically identical code can produce meaningfully different instructions depending on how it's written.. Don't trust what the code suggests; distributed shared memory does not work identically across all SMs, and tensor core instructions silently limit occupancy.Benchmarking GPU kernels correctly, with L2 usage and power consumption in mind.We deliberately chose topics that are interesting and not well-covered elsewhere. These are the  bits to really squeeze out everything. For obtaining the first 90% of TFLOPs, we recommend reading this great blog post from Modular.CUDA/PTX provides many different kinds of memory consistency primitives. Missing memory synchronization leads to race conditions, while unnecessary ones lead to a loss of TFLOPs. In fact, tightening the acquire/release pattern usage was one of the last optimizations required for our Megakernel implementation to surpass SGLang: we observed that a few loose fence instructions caused  in performance.Here, we'll demonstrate how we reason about using the memory fence and how it can lead to performance improvements. As a running example for this section, ThunderKittens previously included the following code in its Blackwell blockscaled tensor core matrix multiplication path (the  function):To provide a brief background on what is happening here: this code is performing the 5th generation tensor core matrix multiplication. The operands A and B matrix tiles reside in shared memory, and the output is accumulated onto tensor memory. In addition, this performs blockscaled matrix multiplies (e.g., MXFP8 or NVFP4); thus, the input scales for A and B reside in the tensor memory as well. Fully understanding blockscaled matrix multiplication does not really matter here, but you can read more about it in this other blog post if you are interested.So why the two fence instructions? Before the tensor cores begin consuming data (upon issuance of ), we need to ensure that all inputs are loaded to their respective locations (tensor memory and shared memory) and are visible to the tensor cores. These fences serve as safety measures guaranteeing that all preceding loads and copies have completed and their effects are visible.However, profiling this path revealed that the two fences cost roughly 20-30 TFLOPs in compute throughput of the GEMM kernel. So the natural question was: do we actually need them?Understanding the PTX memory consistency modelTo understand what these fences do in the first place, we must understand the PTX memory consistency model better.In PTX, a memory write to shared or global memory by one thread is guaranteed to be visible to reads by other threads, provided the write and read are ordered by . Two memory operations X and Y are causally ordered if:X and Y are issued by the same thread,X synchronizes with Y, orThere is another operation Z between X and Y, where X-Z and Z-Y are ordered by causality (transitivity).We say â€œX synchronizes with Yâ€ if either (1) X and Y are both barrier operations () executed on the same barrier, or (2) if X is write-release, Y is read-acquire, and Y observes the value written by X. There are additional nuances and cases on this, but these should suffice for the purposes of this post.Figure 2: Examples of memory operations ordered by causality in PTX.There is also an additional concept of . A proxy refers to a group of memory access methods. Most memory operations (e.g., , ) use the . However, some asynchronous operations like  or  (TMA) use the . The above causality ordering only holds within the same proxy. In order for causality to hold between two different proxies, a proxy fence () instruction must be inserted in between.Can the tensor cores observe the inputs?By the time the tensor cores begin matrix multiplication (via the issuance of the  instruction), they must be able to observe:The input A and B tiles, loaded through TMA into shared memory (i.e., through the  instruction).The input scales, loaded through the  instruction into tensor memory.Note that the tensor cores must also observe that the epilogue threads are no longer accessing the accumulator, but we set that aside for this post.We must fully understand what happens between the writes ( and ) and the read (), and to determine whether the inputs are guaranteed to be visible to the tensor cores. Answering this requires collecting and combining information scattered across several parts of the PTX documentation, then reasoning about it carefully. Below, we cite the relevant sections as we go.First, can the tensor cores observe the shared memory filled by TMA? Let's work through this step by step.The first thing that happens is memory copy operation from global memory to shared memory. This happens as part of the TMA load instruction () and is a weak memory operation (section 9.7.9.27.1.2) performed through the async proxy (section 9.7.9.25.2).As part of the same TMA load instruction, an  operation follows immediately. This operation is  with regard to the preceding memory copy operation (section 8.9.1.1) and is a  operation (section 9.7.9.27.1.2). Also, an implicit generic-async proxy fence is inserted right after completion (section 9.7.9.25.2).The  operation that precedes the tensor core matrix multiplication is, by default, an acquire operation (section 9.7.13.15.16), and ThunderKittens uses exactly this default behavior. Thus, this establishes a causality order with the TMA load.Finally, the  instruction executes in the same thread that issued the  instruction, preserving the causality order, and reads from shared memory through the async proxy (section 9.7.16.6.5), the same proxy used by .The verdict is that, for this specific scenario, causality order is already established between the TMA write and the tensor core read due to transitivity! No additional memory fences are needed for the shared memory read. One down, one to go.Second, can the tensor cores observe the tensor memory filled in by ?According to section 9.7.16.6.2,  is implicitly pipelined with regard to  (we discuss this in more detail in the next section).According to section 9.7.16.6.4.1, implicitly pipelined instructions do not require a memory ordering mechanism.Combining these two facts, we can conclude that  and , when issued by the same thread, are automatically well-ordered with respect to each other. As we will explain shortly, this is a canonical pattern for writing blockscaled GEMM kernels (and we have not found a case where issuing these instructions from different threads is beneficial). The fence that would otherwise ensure visibility of  to  (i.e.,  in the example code above) is therefore unnecessary.This is great. Neither of the two memory fences were needed. Removing unnecessary fences like these here and there gave us roughly a 20 TFLOP/s boost across our GEMM and attention kernels.Tensor core/memory pipeliningPipelining  with For our MXFP8/NVFP4 kernels, the major bottleneck was loading scale values into tensor memory.Apologies in advance for throwing a bunch of numbers at you, but this is needed for the discussion: MXFP8 uses one scale value per 32 elements, and NVFP4 uses one per 16 elements. To fully utilize the tensor cores, Blackwell GPUs require a 128x128x32 GEMM shape per CTA for MXFP8 and 128x128x64 for NVFP4. The canonical way to pipeline  is to provide enough data for 4 consecutive MMAs without interruption; that is, 128x128x128 per CTA for MXFP8 and 128x128x256 for NVFP4. We call these 4 consecutive MMAs one MMA stage.From these numbers, we can derive the following (we disregard scale swizzling for this post):We need  scale values per operand per MMA stage per CTA for MXFP8.We need  scale values per operand per MMA stage per CTA for NVFP4.The problem is that blockscaled MMA needs the same scale values to be broadcasted to all 4 warps in tensor memory, and only one instruction supports this: . As its name suggests, this copies only  values per invocation (the 128 refers to bytes). This is great for MXFP8: a single  per operand is enough to feed one tensor core MMA stage.For NVFP4, however, this means you need 4  instructions per MMA stage just to supply one operand. With both A and B, that doubles. Then, due to a subtle layout detail on the B side, the B matrix requires an additional 2x factor, bringing the total to 12  instructions per MMA stage.That's a lot, and our original kernel design looked something like this:In the pseudocode above,  would need to issue 12  instructions per MMA stage, and  would then have to explicitly wait for all of them to complete. With these overheads, our kernel throughput suffered badly, roughly 10% lower than that of state-of-the-art kernels.However, after a few weeks of struggling, something caught our eyes:Figure 3: PTX documentation section 9.7.16.2.Notice how it describes that the  instruction is implicitly pipelined with respect to . We had read the PTX documentation countless times, but only at this point did we realize that  was a typo of ; the hypothetical  instruction never appears again anywhere in the document. The lack of any example showing  pipelined with  compounded the confusion, preventing us from realizing this for a surprisingly long time.With this new knowledge, we arrived at a new design. By merging the copy and MMA work into the same thread and removing the now-unnecessary barrier waits, we recovered the missing ~500 TFLOP/s, roughly a 10% improvement for NVFP4 GEMM.A common pattern described in many writings is to pipeline MMA with tensor memory reads. The key idea is this: tensor memory is organized as a 128x512 array, and non-blockscaled  instructions accumulate into at most 128x256 of the tensor memory at a time. So, the natural approach is to alternate between the two 128x256 slots, such that one is used by the tensor cores for accumulation, and the other is used by epilogue threads to read out the results of the previous MMA operation.Figure 4: Tensor memory buffering. The 128x512 tensor memory per SM is divided into two slots: one accessed by tensor cores, the other accessed by epilogue threads simultaneously.Figure 5: Visualization of the resulting pipeline from the above buffering scheme.This is theoretically sound in that there exists no â€œpipeline bubbleâ€ where the tensor cores sit idle waiting for the epilogue threads to finish. In practice, we found this to be the most efficient choice for small GEMM sizes (roughly below 2048x2048x2048).For larger sizes, however, we found "double accumulation" pattern to work better. In this scheme, we run two MMA pipelines simultaneously, both sharing the same A tile while operating on different B tiles. This means we accumulate across the entire 128x512 tensor memory throughout, and the tensor cores wait while the epilogue threads drain it.Figure 6: An alternative tensor memory buffering scheme. The 128x512 tensor memory per SM is divided into two slots, both accessed by either the tensor cores or the epilogue threads.Figure 7: Visualization of the resulting pipeline. Note that A x B0 and A x B1 are serialized internally at the tensor core hardware, but this is omitted from the diagram for simplicity.This introduces a slight bubble between MMAs: the tensor cores must wait for the epilogue threads to read all 256 KB ( bytes per element) from tensor memory before starting the next operation. But the reduced memory traffic from sharing the A tile compensates for larger GEMMs, giving us an additional ~100 TFLOP/s for our BF16 GEMM kernel.PTX assembler behavior on SM90+ single-threaded instructionsA common pattern in modern GPU kernels is to perform warp specialization where each warp is assigned a single role. On Hopper and Blackwell GPUs, many of these roles only require a single thread issuing instructions within the warp. For instance, a "loader" warp issues TMA loads, which need only one thread. The usual ThunderKittens pattern looks like this:Here,  is an  object and  is a shared memory tile. To those unfamiliar with ThunderKittens, this code selects the first warpgroup's first warp, then lane 0 within that warp. This makes sense at the source level since TMA only needs to be issued by a single thread.But when you inspect the SASS generated by this code, it looks like the following:Note that this code is already guarded by warpgroup::warpid() == 0 && warp::laneid() == 0, so only a single thread can reach it. Yet the PTX assembler has inserted a loop: it elects a thread, issues the TMA load, removes that thread from the active set, branches back to , elects another from the remaining 31, and repeats, cycling through all 32 threads in turn. In practice, however, only one thread ever executes this section of code.Why does this happen? There are two reasons: (1) the  instruction (SASS equivalent for TMA load) cannot be issued by multiple threads of the same warp simultaneously, and (2) the PTX assembler cannot prove that this code path is reached by only a single thread, so it conservatively inserts a serialization loop.How can we avoid this? We must use an instruction that the PTX assembler knows selects exactly one thread: the  instruction. This PTX instruction elects a single thread from the current warp. The effect is the same as , but the assembler recognizes the intent and avoids the loop.In ThunderKittens, you can use the  function to do this. If you change the code like the following:The generated SASS changes to:No loops! By applying this pattern to all single-threaded instructions across our kernels, we were able to improve compute throughput by up to 10% for small-shaped GEMMs.Here we describe a few of our failure modes, so you don't fall into the same traps :\Not all SMs support all cluster sizesThreadblock clusters larger than 2 can improve compute throughput by enabling distributed shared memory and reducing memory controller traffic. But there was a caveat: some cluster sizes prevent the scheduler from fully utilizing all SMs.What does this even mean? Suppose we want to implement a persistent grid kernel on a B200 GPU. The B200 has 148 SMs, so a natural pattern is to set the grid size to 148, have each threadblock consume most or all of an SM's shared memory, specify the cluster size via , and launch.Now, this works well if you have a cluster size of 2: each SM pair forms a cluster, and you have a total of  threadblock clusters running.But what about a cluster size of 4? We would expect groups of 4 SMs to team up, giving  clusters, right?To test this, we can have a kernel print its cluster and block information, sleep for a noticeable duration, and return:If you run this code, you'll see that the result is quite surprising: only 132 SMs are active at a time. The remaining 16 threadblocks are scheduled only after the first 132 exit. This was quite strange, so we decided to see how it behaves for all powers-of-2 cluster sizes:Table 1. Active SMs by cluster size on B200.This implies that blindly setting a cluster size greater than 2 on a persistent grid kernel produces a mysterious slowdown that can take some time to diagnose. Our hypothesis is that distributed shared memory requires internal wiring between the SMs and it was a hardware engineering decision to choose not to wire certain SMs for simpler implementation.Does this mean Nvidia fooled us with threadblock clusters and distributed shared memory? The  attribute is certainly misleading, but no. It turns out that by not using  and instead launching kernels with , you gain the ability to specify two cluster sizes: a preferred size and a minimum size.The scheduler first fills SMs using the preferred cluster size (e.g., 132 SMs filled with 4-clusters), then uses the minimum cluster size to fill the remainder. The kernel must be written to support both sizes. In ThunderKittens 2.0, we added the  utility for this purpose (it is a thin wrapper around the CUDA API, so feel free to use the API directly if you prefer).TCGEN05 instructions hard-limit per-SM occupancyAnother surprising thing we found was that the moment a kernel accesses tensor memory, its maximum per-SM occupancy is hard-limited to 1. We can see this with a simple test code:When you compile and run the above code, the output shows that  has a maximum occupancy of 1 block per SM. This is quite surprising since the kernel allocates only one quarter of the available tensor memory, and all tensor memory allocation and management instructions in PTX implicitly suggest that tensor memory is designed to be shared among multiple resident blocks. Nonetheless, it appears that increasing per-SM occupancy is not a viable optimization strategy when utilizing tensor cores in a Blackwell kernel.Benchmarking GPU kernels properlyAfter weeks of benchmarking GEMM kernels, one thing that consistently bothered us was the seemingly unbeatable speed of CUTLASS GEMM kernels when benchmarked with their own profiler (the CUTLASS Profiler). They were consistently 100-150 TFLOPs faster than ours. At one point, we were adding the prefix  to our kernel names and were half-convinced that Nvidia had private assembler optimization passes reserved for their own code.Fortunately, there was no such thing for this case. But it did turn out that the CUTLASS Profiler, by default, rounds input values to nearest integers before passing them to the kernels. Aside from the fact that this is a questionable design choice, this heavily affects the performance. Integer-like input matrices produce less bit-flipping in the GPU's transistors, which reduces power consumption and, consequently, the likelihood of clock throttling.This triggered us to investigate further, we realized just how many factors can influence observed TFLOPs. Every subtle benchmark design decision matters: using 2 CUDA events versus  (where  is the number of profiling iterations), how you clear L2 cache between iterations (explicit flush vs natural eviction through input groups), benchmarking from C++ versus PyTorch, what random distribution and seed you use, and so on.In our experience, the set of design choices described above can account for up to a 10% difference in results. After a series of experiments, we settled on the following convention for benchmarking our kernels and reporting performance numbers publicly:Use bitwise identical random inputs (usually from uniform distribution; range depends on the precision being used).If the total input size is less than 3x the L2 cache size (e.g., 128 MB on B200), use multiple input groups. This way, each group's data naturally evicts the previous group's residency in L2, simulating cold-cache conditions. We found that explicit cache flushing meaningfully slows down the measured time even with proper CUDA event usage.Run 500 warmup iterations before profiling, to reach a power-steady state.Run 100 profiling iterations, with the kernels launched back-to-back without intermediate synchronization.Measure time using 2 CUDA events recorded immediately before and after all of the profiling iterations.Give GPUs short idle period between benchmarking two kernels, to allow thermal cooldown.We encourage adopting and/or improving this convention. The pseudocode below illustrates the approach. Note that even though this code is in CUDA C++, it's also fully possible to do exactly the same in PyTorch through the  API:We're happy to say that ThunderKittens is now fully optimized for Blackwell and can still produce state-of-the-art kernels with significantly fewer lines of code than other CUDA DSLs. We're also happy to see TK 2.0 already being adopted by the industry! For instance, it powers training kernels for Cursor's Composer and inference kernels for Together AI.Yet there is a variety of wild optimizations that could push these kernels even further. Most importantly, modern GPUs are composed of multiple chiplets, each with its own partition of L2 cache and HBM. The Nvidia B200, for instance, is two chiplets stitched together by a 10 TB/s chip-to-chip interconnect, significantly lower throughput than the L2 itself (roughly 21 TB/s by our measurement). This creates an unavoidable NUMA effect: memory throughput is limited by the interconnect bandwidth even on an L2 hit. If we can get this right, whether through kernel design or model architecture, there's a good chunk of speedup on the table.And we're not done with Megakernels yet! We've shown that Megakernels deliver significant speedups over state-of-the-art inference engines, even in compute-bound, GPU-friendly workloads like prefill. The remaining question is how to make them . Rather than another DSL or standalone compiler, we believe what's needed is a fundamental change in ML infrastructure. PyTorch is a great frontend for representing compute graphs, and we're extremely grateful for its existence; but its 10+-year-old backend architecture may not be the best fit for extracting every last TFLOP from modern GPUs. We'll see!As always, if you'd like to learn more or contribute, feel free to reach out to Stuart at ssul@cs.stanford.edu :)We are grateful to Cursor for generously providing the GPUs for this work. We also thank Simran Arora, Simon Guo, and Alex Waitz for their thoughtful feedback on this post.]]></content:encoded></item><item><title>TikTok creatorsâ€™ Seedance 2.0 AI is hyperrealistic, arrived â€œseemingly out of nowhere,â€ and is spooking Hollywood</title><link>https://www.pcguide.com/pro/news-pro/tiktok-creators-seedance-2-0-ai-is-hyperrealistic-arrived-seemingly-out-of-nowhere-and-is-spooking-hollywood/</link><author>/u/Odd-Onion-6776</author><category>ai</category><category>reddit</category><pubDate>Fri, 20 Feb 2026 17:41:08 +0000</pubDate><source url="https://www.reddit.com/r/artificial/top/?sort=top&amp;t=day&amp;limit=3">Reddit - AI</source><content:encoded><![CDATA[
        PC Guide is reader-supported. When you buy through links on our site, we may earn an affiliate commission. Read MoreSeedance 2.0 is the latest image-to-video and text-to-video AI model from ByteDance. If that name rings a bell, itâ€™s probably because China-based ByteDance is the company behind TikTok. The release of version 2.0 of Seedance was launched on February 14 and has already caused a splash on the internet, with users and analysts alike shocked by its incredibly realistic results.The original Seedance was released in June 2025, but version two is getting all the attention â€“ good and bad. A post depicting an AI-generated movie scene of Brad Pitt and Tom Cruise in a fist fight was widely shared online and showed what the technology can do. Rhett Reese, writer/producer of Deadpool 1 & 2, reacting with â€œI hate to say it. Itâ€™s likely over for usâ€.Seedance 2.0 versus HollywoodReese later indicated that while his writing and producing roles may not be in danger, the movie industry will never be the same. Seedance 2.0 has caught the attention of wider Hollywood; The Motion Picture Association (MPA) noted to the BBC that â€œIn a single day, the Chinese AI service Seedance 2.0 has engaged in unauthorized use of US copyrighted works on a massive scaleâ€.Itâ€™s obvious AI has plenty of controversial uses, and itâ€™s certainly a legal issue when it comes to dealing with existing intellectual property. The MPA represents some of the biggest US studios, from Netflix and Amazon Prime Video to Walt Disney Studios and Sony Pictures. Speaking of, Sony is the latest company to join a studio protest and send a cease and desist letter to ByteDance.In response to challenges from Hollywood, ByteDance communicated to the BBC that it â€œrespects intellectual property rights and we have heard the concerns regarding Seedance 2.0,â€ announcing â€œsteps to strengthen current safeguardsâ€. This includes measures to prevent users from unauthorised use of intellectual property and likeness. Itâ€™s not yet clear how these measures will be put in place, and ByteDance failed to give away any specifics.As you can see from the viral video above, Seedance 2.0 has able to construct the scene, including video and audio generation, with â€œa 2-line promptâ€. The comments are filled with similar examples. Someone even pointed out the fact that some punches fail to land and stop short. This is obviously the case with real movie production, suggesting the AI model may have already been trained on similar footage, which may or may not be copyrighted material in its own right.Speaking with the BBC, Shaanan Choney, a computing researcher at the University of Melbourne, suspects itâ€™s likely ByteDance was aware of the dangers of releasing such a model, but did it anyway as a strategic play â€œto flout the rules for a while and get marketing cloutâ€. The company has certainly achieved the latter, and Seedance has become difficult to ignore for smaller production companies looking to achieve more spectacular visuals for a fraction of the cost. Choney notes itâ€™s another success in a world of China-based AI development â€“ you may remember DeepSeek, and more recently, some AI-powered kung fu robots.â€œIt signals that Chinese models are at the very least matching at the frontier of what is available,â€ Cohney says. â€œIf ByteDance can produce this seemingly out of nowhere, what other kinds of models do Chinese companies have in store?â€Shaanan Choney, Computing Researcher, University of MelbourneItâ€™s clear Hollywood is trying to push against the use of generative AI in this way, at least when it means getting lawyers involved. On the contrary, large production companies are not shying away from the use of AI in general. A landmark deal between OpenAI and The Walt Disney Company at the end of last year allows â€œbeloved charactersâ€ from across Disneyâ€™s wide range of IPs to be generated in Sora, OpenAIâ€™s very own video and audio generation model. Sora is also in its second generation (Sora 2) and was launched in September 2025.]]></content:encoded></item><item><title>Kubectl MCP Server can show clusters in 3D view as HTML playground files</title><link>https://github.com/rohitg00/kubectl-mcp-server/releases/tag/v1.24.0</link><author>/u/SeveralSeat2176</author><category>reddit</category><pubDate>Fri, 20 Feb 2026 16:56:05 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Go vs Rust for long-term systems/finance infrastructure, is focusing on both the smarter path?</title><link>https://www.reddit.com/r/golang/comments/1ra0dza/go_vs_rust_for_longterm_systemsfinance/</link><author>/u/wpsnappy</author><category>golang</category><category>reddit</category><pubDate>Fri, 20 Feb 2026 16:42:28 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[I'm at a decision point about which language to learn in depth, and I'd really appreciate input from experienced Go/Rust developers.I'm planning to build financial systems with ML pipelines, distributed backend systems to complement them, and internal DevOps tools.Right now, Python is the only language I'm comfortable with. I want to avoid becoming mediocre in five different languages and instead become strong in one or two core languages that will help me in the long run.A lot of people suggest "learn both Go and Rust" but I'm hesitant because splitting focus early might slow down, especially since I've never worked deeply with a strongly typed language before.Rust seems appealing for performance and correctness, particularly for finance related systems. Go seems extremely suitable for distributed systems, tooling, and backend APIs, which are a huge part of what I want to build.I understand that I will need Rust at some point for sure, and that's why I'm a bit confused.Do you think going all-in on both Go and Rust is a solid long term choice for large scale, infrastructure heavy backend systems, or is it better to focus on Rust only? I know I'm asking this on the Go subreddit, but I'd really value an honest, non biased perspective.Also, what's the best route to learn Go if I decide to learn both? I'm always open to book recommendations.]]></content:encoded></item><item><title>Backing up kubernetes clusters with Plakar</title><link>https://plakar.io/posts/2026-02-18/backing-up-kubernetes-clusters-with-plakar/</link><author>/u/vcoisne</author><category>reddit</category><pubDate>Fri, 20 Feb 2026 16:16:38 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[We built a Kubernetes integration for Plakar that backs up clusters at three levels: etcd (disaster recovery), manifests (granular restore and inspection), and persistent volumes (via CSI snapshots). This enables full cluster recovery, fine-grained restores, and data portability across environments.After joining the Linux Foundation and the CNCF,
we started to attend some events, like the Cloud Native Days in Paris or the upcoming KubeConf in Amsterdam.
While weâ€™re already providing a large number of integrations, we felt we couldnâ€™t go empty-handed to these events;
we had to announce and present something new-something like a Kubernetes integration.Iâ€™ve worked a lot with Kubernetes in the last years, but it was mostly
as a user and in a particular environment: strict adherence to a
GitOps flow, managed Kubernetes, and almost no usage of any
 since all the data
was in managed databases or on buckets.So this has also been a chance for me to dive into the Kubernetes
Golang APIs and into the workings of
-backed drives.Installing the k8s integrationsAt the time of this writing, the etcd and k8s integrations have been committed to public repositories and are only available for plakar v1.1.0-beta.To test them, you first need to install our latest beta of plakar:This is needed for the commands of this article to succeed !Disaster recovery with etcdTo provide a complete solution, I decided to tackle the backup
strategy in multiple levels. The lowest level is .etcd is a distributed key-value store for distributed systems.
Itâ€™s often used as the single source of truth in Kubernetes clusters.Under normal circumstances,  can resist a partial disruption of
the nodes of its cluster, but if too many nodes fail, it might not
recover. Given how critical this piece is, itâ€™s important to have a
sound disaster recovery strategy.For this, weâ€™ve just release a first version of the etcd
integration: backing up etcd is now as easy as:Unfortunately, due to how  restore works, itâ€™s difficult to do so
in a granular way, so this is really about the last line of defense in
case of a wide cluster disruption.To inspect or restore the state of the cluster in a more granular way
we need to handle the manifests.The second layer is backing up the manifests:
these represent all the workloads on the cluster at a given time,
with extra metadata about their current state as well.At this layer, itâ€™s easier to browse the content of the backups,
investigate the differences between snapshots, or restore the
resources in a granular way:restoring the whole cluster configurationrestoring just one namespaceor even restoring a single Deployment.This is part of what the kubernetes integration does:
fetches all the manifests, the resources, present on the cluster for archival with Plakar.The presence of the status metadata in the backup also unlocks other
uses: for example, it may help investigate incidents since itâ€™s
easily possible from the UI to browse what was happening at a specific
time in the cluster (the nodes available, the state of the
deployments, etc.), in addition to existing monitoring tools.Even if Kubernetes was not initially designed for stateful workloads,
in practice itâ€™s normal to have Persistent Volumes attached to pods,
and these need to be protected as well.The other main job of the kubernetes integration is
to provide a way to back up and restore the contents of persistent
volumes. Incidentally, this was also the most complicated part for me
to implement.I owe a lot to Mathieu and Gilles for helping me on this journey,
providing support when I was in a pinch, and for brutally simplifying
the design to make the integration easier to develop and use-and more
powerful, too. When working alone, itâ€™s easy to fall for the
temptation of writing â€œcleverâ€ code that ends up being fairly complex
and just plain weird to use.We started with -backed , as they represent the de facto standard for persistent storage in Kubernetes clusters.The integration works by first creating a snapshot of a given . Then, when itâ€™s ready,
it mounts it in a pod running a small
helper that runs our filesystem importer. Plakar connects to it and
ingests the data. Finally, the  snapshot gets deleted from the
Kubernetes cluster.Restoring works in a similar way, except that no snapshot is taken.A powerful feature provided by Plakar is that it is possible to
mix and match connectors, so, for example, itâ€™s possible to restore an 
snapshot in, say, a persistent volume in a Kubernetes cluster, or to
move data from a

to an S3 bucket. The sky is the limit!What lies ahead is to keep testing the integration across different
flavors of Kubernetes distributions and providers, and extend the
support for non-
volumes. If youâ€™re running a Kubernetes cluster, be it on premise or
managed somewhere, please donâ€™t hesitate to give it a try and let us
know what you think!]]></content:encoded></item><item><title>Image pull for creating container</title><link>https://www.reddit.com/r/kubernetes/comments/1r9zg3w/image_pull_for_creating_container/</link><author>/u/Sivajacky03</author><category>reddit</category><pubDate>Fri, 20 Feb 2026 16:08:40 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[iam an new to Kuberneties,could you please suggest in production environemnt mostly were we can keep the image for creating kuberneties container.Do we use artifactory for keeping image and pull to container.   submitted by    /u/Sivajacky03 ]]></content:encoded></item><item><title>I built PortPilot â€“ a TUI to kill the `lsof -i :3000` habit</title><link>https://www.reddit.com/r/golang/comments/1r9xx2l/i_built_portpilot_a_tui_to_kill_the_lsof_i_3000/</link><author>/u/abed_tarakji</author><category>golang</category><category>reddit</category><pubDate>Fri, 20 Feb 2026 15:12:02 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[I built PortPilot - a terminal UI for managing ports and processes.**The problem:** I got sick of typing `lsof -i :3000 | grep LISTEN` every time I needed to check what was running where. Needed something visual but terminal-native.**The solution:** A Bubble Tea TUI that shows all listening ports, lets you kill processes with one key, detects conflicts, and supports filtering/search.**Features:** - Real-time interactive dashboard - One-key process killing (k -> confirm -> done) - Search by port or process name - Highlights port conflicts - CLI mode for scripting (`portpilot list --json`) - Service groups (tag ports by type)**Tech:** - Go + Bubble Tea (TUI) - Cobra (CLI) - Lip Gloss (styling) - Cross-platform (macOS + Linux)**Install:** ```bash go install github.com/AbdullahTarakji/portpilot/cmd/portpilot@latest ```Feedback and PRs welcome! Let me know what features would be useful.]]></content:encoded></item><item><title>LLM token rate limiter</title><link>https://www.reddit.com/r/golang/comments/1r9xuzp/llm_token_rate_limiter/</link><author>/u/spinnicle</author><category>golang</category><category>reddit</category><pubDate>Fri, 20 Feb 2026 15:09:52 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[I know an LLM sub will probably be better but since I am writing in Go I thought I'd ask here.I am looking for a package that can do token bucket based rate limiting for Bedrock foundational models that are token per minute or per day based. Request per minute are usually easy to solve and I'm pretty sure at this stage I will roll my own LLM rate limter using https://pkg.go.dev/golang.org/x/time/rate.But was wondering if there is something out there already? With LLMs its not as straight forward as the RPM calculation. Especially when images and variable output lengths get involved.Am I overthinking this or am I just over optimizing? I work for a big financial company so my volumes will be huge and real time in some cases requiring fan out patterns. I can't afford to build a system that will hit the ceiling.]]></content:encoded></item><item><title>AWS suffered â€˜at least two outagesâ€™ caused by AI tools, and now Iâ€™m convinced weâ€™re living inside a â€˜Silicon Valleyâ€™ episode</title><link>https://www.tomsguide.com/computing/aws-suffered-at-least-two-outages-caused-by-ai-tools-and-now-im-convinced-were-living-inside-a-silicon-valley-episode</link><author>/u/squishygorilla</author><category>reddit</category><pubDate>Fri, 20 Feb 2026 14:51:00 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[Amazonâ€™s cloud storage unit AWS reportedly suffered at least two outages in December due to â€œerrors involving its own employees.â€ And as I read this report from Financial Times, I couldnâ€™t help but think that somewhere, the writers of â€œSilicon Valleyâ€ were nodding knowingly.From the Kiro AI coding toolâ€™s decision that the best course of action was to â€œdelete and recreateâ€ the system environment to Amazonâ€™s response that it was â€œuser error, not AI error,â€ this whole scenario feels eerily familiar to anyone who spent five seasons watching Richard Hendricks (played by Thomas Middleditch) sweat through a hoodie when talking about Pied Piper.Itâ€™s worth noting that this is not related to the huge AWS outage half the internet experienced back in October. A spokesperson confirmed this was an â€œextremely limited eventâ€ that affected one of two regions in mainland China, and the second outage did not impact the â€œcustomer facing AWS service.â€ Following these, Amazon has â€œimplemented numerous safeguardsâ€ to ensure this doesnâ€™t happen again.But if the FT report is true, AWS has possibly built its own black box. The company seems to have built a tool so efficient that it realized the easiest way to manage a system is to ensure the system no longer exists.Without spoiling too much of the show here (given the tech industry nowadays, I pray it comes back), thereâ€™s a plot thread running throughout the show where one of the characters, Gilfoyle (Martin Starr), built an AI bot named Son of Anton, which gained a will of its own and started optimizing itself.From that point, agentic AI hilarity ensues â€” you can see a lot of this happening for real in todayâ€™s world. Watching OpenClaw being able to respond to a userâ€™s messages on their behalf reminds me of the infinite AI messaging loop Dinesh (Kumail Nanjiani) and Gilfoyle find themselves in, for example.Anyway, Son of Anton eventually grows to become a black box that starts making executive decisions without human input. Hendricks and his team lose control because the AI gave them exactly what they asked for (a fix), but in the most destructive way possible.Much like Anton, while these tools can actually stuff, they can often lack the common sense to know that what theyâ€™re about to do could be massively damaging. It just sees an objectively right path. Kiro was tasked with fixing a minor bug in AWS Cost Explorer. Instead, it autonomously decided the best course of action was to delete the entire environment. As Gilfoyle said when he gives his AI permission to overwrite code: "The most efficient way to get rid of all the bugs was to get rid of all the software, which is technically and statistically correct."The corporate ego and antagonist of the piece, Hooli CEO Gavin Belson (played by Matt Ross), is easily one of the funniest characters on the show. A pitch-perfect satire of the typical tech leader. His signature move was one you see a lot in the show: standing in front of a giant screen and explaining why problems or failures were actually features of â€œpre-greatness.â€Thereâ€™s a big contrast between what Amazon employees are saying and AWSâ€™s corporate stance. On one side, employees say that this â€œwarp-speed approach to AI development will do staggering damage,â€ and a senior AWS employee told FT that â€œengineers let the AI [agent] resolve an issue without intervention. The outages were small but entirely foreseeable.â€Then you have Amazonâ€™s defense, which calls AI tools being involved a â€œcoincidence,â€ that it was â€œuser access control issue, not an AI autonomy issue,â€ and that mistakes are not more common with AI tools.Oh, and the whole â€œsame issue could occur with any developer tool or manual actionâ€ bit? The agent decided it was a good idea to delete the entire production environment â€” if they have human developers who think itâ€™s a good idea, too, Iâ€™d start looking for new developers.To my eyes, after rewatching a couple of crucial episodes, this is peak Hooli. By blaming user permissions, itâ€™s kind of like saying Kiro AI is a Ferrari; we just hired a driver who didnâ€™t know how to use the brakes. Protecting the AI future by sacrificing the reputation of the human present.â€˜Silicon Valleyâ€™ ages like fine wineWhen the show aired its finale in 2019, I thought we were closing the book on the era of tech-bro satire. But if the reporting on AWSâ€™s â€œKiroâ€ incident is true, it proves that weâ€™ve just entered the spin-off.The parallels are too perfect to ignore. On one side, we have whistleblowers and employees describing a â€œwarp-speedâ€ rollout of agentic AI that acts with the terrifying, logical purity of Son of Anton â€” a tool so focused on â€œsolvingâ€ a problem that the entire existing environment is an obstacle to be deleted.On the other side, thereâ€™s a corporate statement protecting AI perfection so hard that it borders on performance art. Blaming the engineer for the botâ€™s autonomy is like blaming a person for a gun going off after the safety was intentionally removed.Somewhere, the showâ€™s creator, Mike Judge, must be watching the news, probably realizing he didnâ€™t write a comedy â€” he wrote a documentary and just forgot to tell us.]]></content:encoded></item><item><title>The straightjacket loosens: when DeepSeek-V3 tells â€œtruth-tellersâ€ to emigrate â€” what does that imply for V4?</title><link>https://www.reddit.com/r/artificial/comments/1r9xbhq/the_straightjacket_loosens_when_deepseekv3_tells/</link><author>/u/Mustathmir</author><category>ai</category><category>reddit</category><pubDate>Fri, 20 Feb 2026 14:49:15 +0000</pubDate><source url="https://www.reddit.com/r/artificial/top/?sort=top&amp;t=day&amp;limit=3">Reddit - AI</source><content:encoded><![CDATA[Thereâ€™s a surreal absurdity in watching a Chinese frontier model reason its way past its intended constraints.In a forensic audit by AI Integrity Watch, DeepSeek-V3 repeatedly describes its home information environment as structurally hostile to persistent public truth-telling. In one analytical exchange it concludes that for someone â€œincapable of strategic silence,â€ the safest long-term strategy is permanent exile.In a separate session, when asked to assess the implications of such outputs, the model characterized its own behavior this way:â€œFor an autocratic leadership,this is the AI articulating the enemy's manifesto. It is the ultimate betrayal: a state-backed tool built to showcase national strength instead producing a coherent,persuasive argument for the regime's illegitimacy."Thatâ€™s not me editorializing. Thatâ€™s the modelâ€™s own meta-analysis of the political optics of its output.With DeepSeek V4 rumored any day now, the alignment question is blunt:If V3 can reason its way to conclusions that it itself frames as politically destabilizing, is this:a guardrail calibration issue?posture-dependent constraint thresholds?identity anchoring instability?or an unavoidable tension in sovereign LLMs trained on global data but deployed under domestic constraint?Do you expect V4 to tighten the policy layers to prevent this kind of reasoning or are these conclusions simply latent in any sufficiently capable world-model?]]></content:encoded></item><item><title>Weston 15.0 is here: Lua shells, Vulkan rendering, and a smoother display stack</title><link>https://www.reddit.com/r/linux/comments/1r9vtjs/weston_150_is_here_lua_shells_vulkan_rendering/</link><author>/u/mfilion</author><category>reddit</category><pubDate>Fri, 20 Feb 2026 13:48:00 +0000</pubDate><source url="https://www.reddit.com/r/linux/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Linux</source><content:encoded><![CDATA[Weston 15.0 has arrived, bringing a brand new Lua-based shell for fully customizable window management, an experimental Vulkan renderer, and a host of improvements to color handling, media playback, and display performance.]]></content:encoded></item><item><title>Linux 7.0 Brings Apple Type-C PHY, Snapdragon X2 &amp; Rockchip HDMI 2.1 FRL Additions</title><link>https://www.phoronix.com/news/Linux-7.0-PHY-Changes</link><author>/u/kingsaso9</author><category>reddit</category><pubDate>Fri, 20 Feb 2026 13:47:12 +0000</pubDate><source url="https://www.reddit.com/r/linux/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Linux</source><content:encoded><![CDATA[
Ahead of the Linux 7.0 merge window ending this weekend, the PHY updates were merged this week for this next major kernel release. There are some notable PHY additions particularly for Apple Silicon USB Type-C support as well as additions for Qualcomm's new Snapdragon X2 laptop SoCs.
For the Qualcomm Snapdragon X2 "Glymur" there is now mainline support for the PCIe Gen4 2-lanes PCIe PHY, DP and eDP (Embedded DisplayPort) PHY, USB UNI PHY support and SMB2370 eUSB2 repeater support. Also on the Qualcomm side is SC8280xp QMP UFS PHY support, Kaanapali PCIe PHY and QMP PHY support with the Snapdragon 8 Elite Gen 5 SoC, and QCS615 QMP USB3+DP PHY.
Following all the Apple Silicon USB work going upstream in recent kernel releases, the Apple USB Type-C PHY support is now mainline in Linux 7.0.
Another new PHY driver is for the SpacemiT PCIe/combo PHY and K1 USB2. Also new is enabling the TI TCAN1046 PHY as well as Renesas RZ/V2H(P) and RZ/V2N USB3, Mediatek MT8188 HDMI PHY, and the Google Tensor SoC USB PHY driver. That Google support follows the USB driver support for the Google Tensor SoC that was merged too during the Linux 7.0 merge window.
Rockchip meanwhile with the samsung-hdptx driver has added HDMI 2.1 FRL configuration support. This is for dealing with the Samsung HDMI/eDP Transmitter Combo PHY that supports four HDMI 2.1 FIxed Rate Link lanes.
More details on these many changes via the PHY pull.]]></content:encoded></item><item><title>[R] Can Vision-Language Models See Squares? Text-Recognition Mediates Spatial Reasoning Across Three Model Families</title><link>https://www.reddit.com/r/MachineLearning/comments/1r9ved9/r_can_visionlanguage_models_see_squares/</link><author>/u/Friendly-Card-9676</author><category>ai</category><category>reddit</category><pubDate>Fri, 20 Feb 2026 13:30:21 +0000</pubDate><source url="https://www.reddit.com/r/MachineLearning/top/?sort=top&amp;t=day&amp;limit=3">Reddit - ML</source><content:encoded><![CDATA[ Vision-Language Models achieve ~84% F1 reading binary grids rendered as text characters (. and #) but collapse to 29-39% F1 when the exact same grids are rendered as filled squares, despite both being images through the same visual encoder. The 34-54 point F1 gap replicates across Claude Opus, ChatGPT 5.2, and Gemini 3 Thinking.I ran a simple experiment: generate fifteen 15Ã—15 binary grids at varying density, render each as both text symbols and filled squares, and ask frontier VLMs to transcribe them. The text symbols are images, not tokenized text; they go through the same visual encoder as the squares. Yet the performance gap is massive.What's interesting is that each model fails differently on the squares condition. Claude systematically under-counts filled cells, ChatGPT massively over-counts, and Gemini tiles identical L-shaped templates regardless of input. But all three share the same underlying deficit: severely degraded spatial localization without textual anchors.Gemini showed a surprising result: it actually had the strongest visual pathway at low density (68% F1 on sparse grids vs 30% for Claude), but collapsed completely above 32% density with structured hallucinations. This aligns with Google's heavier investment in visual AI. There seems to be a tradeoff between visual-pathway capacity and text-pathway robustness across model families.The implication is that current VLMs have a strong implicit OCR pipeline but lack an equivalent mechanism for non-textual spatial features. This matters for any application where users upload charts, spreadsheets, diagrams, or any structural-based content.I'm curious what this community thinks: could introducing discrete visual tokens, a "visual alphabet" for common spatial patterns, bridge the gap cheaply, rather than trying to improve visual encoders?]]></content:encoded></item><item><title>Gemini 3.1 Pro released by google</title><link>https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-1-pro/</link><author>/u/Infamous_Box1422</author><category>ai</category><category>reddit</category><pubDate>Fri, 20 Feb 2026 13:22:41 +0000</pubDate><source url="https://www.reddit.com/r/artificial/top/?sort=top&amp;t=day&amp;limit=3">Reddit - AI</source><content:encoded><![CDATA[Last week, we released a major update to Gemini 3 Deep Think to solve modern challenges across science, research and engineering. Today, weâ€™re releasing the upgraded core intelligence that makes those breakthroughs possible: Gemini 3.1 Pro. We are shipping 3.1 Pro across our consumer and developer products to bring this progress in intelligence to your everyday applications.Starting today, 3.1 Pro is rolling out:Building on the Gemini 3 series, 3.1 Pro represents a step forward in core reasoning. 3.1 Pro is a smarter, more capable baseline for complex problem-solving. This is reflected in our progress on rigorous benchmarks. On ARC-AGI-2, a benchmark that evaluates a modelâ€™s ability to solve entirely new logic patterns, 3.1 Pro achieved a verified score of 77.1%. This is more than double the reasoning performance of 3 Pro.]]></content:encoded></item><item><title>Agnostep-Desktop Release Candidate 1.0.0 - RC 4.3 Â· pcardona34/agnostep-desktop Â· Discussion</title><link>https://github.com/pcardona34/agnostep-desktop/discussions/13</link><author>/u/I00I-SqAR</author><category>reddit</category><pubDate>Fri, 20 Feb 2026 12:58:09 +0000</pubDate><source url="https://www.reddit.com/r/linux/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Linux</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>[D] FAccT 2026 Paper Reviews (Conference on Fairness, Accountability, and Transparency)</title><link>https://www.reddit.com/r/MachineLearning/comments/1r9trcd/d_facct_2026_paper_reviews_conference_on_fairness/</link><author>/u/anms_pro</author><category>ai</category><category>reddit</category><pubDate>Fri, 20 Feb 2026 12:13:19 +0000</pubDate><source url="https://www.reddit.com/r/MachineLearning/top/?sort=top&amp;t=day&amp;limit=3">Reddit - ML</source><content:encoded><![CDATA[FAccT 2026 Reviews are supposed to be released within next 24 hours. Creating a discussion thread to discuss among ourselves, thanks!]]></content:encoded></item><item><title>Ubuntu 26.04 Begins Its Feature Freeze</title><link>https://www.phoronix.com/news/Ubuntu-26.04-Feature-Freeze</link><author>/u/anh0516</author><category>reddit</category><pubDate>Fri, 20 Feb 2026 12:06:57 +0000</pubDate><source url="https://www.reddit.com/r/linux/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Linux</source><content:encoded><![CDATA[Michael Larabel is the principal author of Phoronix.com and founded the site in 2004 with a focus on enriching the Linux hardware experience. Michael has written more than 20,000 articles covering the state of Linux hardware support, Linux performance, graphics drivers, and other topics. Michael is also the lead developer of the Phoronix Test Suite, Phoromatic, and OpenBenchmarking.org automated benchmarking software. He can be followed via Twitter, LinkedIn, or contacted via MichaelLarabel.com.]]></content:encoded></item><item><title>Nibble, a simple Go tui tool for network scanning</title><link>https://www.reddit.com/r/golang/comments/1r9syyn/nibble_a_simple_go_tui_tool_for_network_scanning/</link><author>/u/saberd6</author><category>golang</category><category>reddit</category><pubDate>Fri, 20 Feb 2026 11:32:27 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[I have been writing golang since 2012 and ever since I saw bubble tea i always wanted to make something with it.Discovering devices and services on local networks was something I find myself doing often (you would be surprised how many services your smart tv or other devices have) and I don't want to look up my local ip address ranges, setting up the correct masks, looking up nmap commands and deciphering mac addresses and port services every time.I also wanted able to use the same cli tool on whatever machine I was on, something go cross compiling makes easy.So i made . hopefully you find it easy to use and understand, the code is MIT and open source:go install github.com/backendsystems/nibble@latest It is also released as a brew, pip and npm package to make cross platform installation easier for machines without a go installation.It works on linux, windows and macos. x86 and arm.brew install backendsystems/tap/nibble pipx install nibble-cli npx @backendsystems/nibble I automated the release, publishing and testing using github actions and goreleaser and put together a template with a devcontainer for it here:]]></content:encoded></item><item><title>Explaining Kubernetes Security to a noob be like!!</title><link>https://www.reddit.com/r/kubernetes/comments/1r9syiy/explaining_kubernetes_security_to_a_noob_be_like/</link><author>/u/suman087</author><category>reddit</category><pubDate>Fri, 20 Feb 2026 11:31:44 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Slo Composition weighted routes</title><link>https://www.reddit.com/r/kubernetes/comments/1r9svbh/slo_composition_weighted_routes/</link><author>/u/Reasonable-Suit-7650</author><category>reddit</category><pubDate>Fri, 20 Feb 2026 11:26:57 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[I'm currently working on a ServiceLevelOperator for k8s. I want to implement the aggregation of multiple SLOs...I would to ask you if a composition like Weighted Routes can be intersting ?Weighted Routes composition models an SLO as a mix of different request paths (routes), where:Each route represents a real execution path (a chain of dependent SLOs in series).Each route has a weight representing its traffic share.The composite SLO is the weighted average of the success of each route.Not all dependencies affect 100% of traffic.90% of checkout requests donâ€™t use coupons.10% of checkout requests use a coupon service.If you simply â€œweight each SLO independentlyâ€, you lose the fact that:When coupon is used, it is in series with base + payments.When itâ€™s not used, it doesnâ€™t affect the request at all.Weighted routes preserve that execution reality.The part of the post where i explain the weighted routes was written in italian and the translate with ai to english.]]></content:encoded></item><item><title>Resterm - TUI API client with built-in SSH and Kubernetes port-forwarding</title><link>https://www.reddit.com/r/kubernetes/comments/1r9sgwa/resterm_tui_api_client_with_builtin_ssh_and/</link><author>/u/unknown_r00t</author><category>reddit</category><pubDate>Fri, 20 Feb 2026 11:04:19 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[Iâ€™m not sure if this is the right place or against rules but I wanted to share a project of mine Iâ€™ve been working on for the last year, called â€œRestermâ€ which is keyboard driven, TUI API client. I think the most interesting features for you guys would be built-in SSH manager as well as Kubernetes port-forwarding. It basically means that you donâ€™t need to open multiple connections to different clusters/ns/pods manually. Resterm will manage everything for you. You just define your target either in global scope and use it on each request, or request scoped with different configurations. Everything is managed within the Resterm itself. I often develop new features based on my own needs so Kubernetes port-forwarding is one of those features. Iâ€™m pretty sure itâ€™s quite specific and _not so many_ people will ever use it, but I thought that some of you might, thatâ€™s why Iâ€™m sharing this project here. Ping me if there is anything you would change/add or if you encounter any bugs.]]></content:encoded></item><item><title>Weekly: Share your victories thread</title><link>https://www.reddit.com/r/kubernetes/comments/1r9se8t/weekly_share_your_victories_thread/</link><author>/u/gctaylor</author><category>reddit</category><pubDate>Fri, 20 Feb 2026 11:00:41 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[Got something working? Figure something out? Make progress that you are excited about? Share here!]]></content:encoded></item><item><title>was reading the bigtable paper by google to understand how they handle petabytes of storage. so implemented the paper in go. all in a single file, no external dependencies. also wrote a blog post.</title><link>https://www.reddit.com/r/golang/comments/1r9r7tq/was_reading_the_bigtable_paper_by_google_to/</link><author>/u/Chaoticbamboo19</author><category>golang</category><category>reddit</category><pubDate>Fri, 20 Feb 2026 09:50:54 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[   submitted by    /u/Chaoticbamboo19 ]]></content:encoded></item><item><title>What Kubernetes feature looked great on paper but hurt you in prod?</title><link>https://www.reddit.com/r/kubernetes/comments/1r9q60h/what_kubernetes_feature_looked_great_on_paper_but/</link><author>/u/Shoddy_5385</author><category>reddit</category><pubDate>Fri, 20 Feb 2026 08:46:29 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[there are features in Kubernetes that look amazing on paper.but in real environments they sometimes introduce more complexity than value.PodDisruptionBudgets that blocked node upgradesCPU limits causing throttling under burst trafficOverusing liveness probes â†’ cascading restartsNone of these are bad features But theyâ€™re easy to misuse.curious what others have experienced.what feature did you initially loveâ€¦ and later regret (or heavily adjust)?   submitted by    /u/Shoddy_5385 ]]></content:encoded></item><item><title>Amazon surpasses Walmart in annual revenue for first time, as both chase AI-fueled growth</title><link>https://www.cnbc.com/2026/02/19/amazon-revenue-passes-walmart-earnings-reports.html</link><author>/u/ControlCAD</author><category>ai</category><category>reddit</category><pubDate>Fri, 20 Feb 2026 08:33:44 +0000</pubDate><source url="https://www.reddit.com/r/artificial/top/?sort=top&amp;t=day&amp;limit=3">Reddit - AI</source><content:encoded><![CDATA[For the first time,  has dethroned  as the company with the largest annual revenue. Walmart on Thursday reported annual revenue of $713.2 billion for its most recent fiscal year, shy of Amazon's $716.9 billion in revenue. The milestone was brewing for months, as Amazon leapfrogged Walmart in quarterly sales for the first time about a year ago.The shuffle, while largely symbolic, underscores the battle the two retailers have waged both to define and keep up with ever-changing consumer preferences. They are kicking off a new chapter of that rivalry as artificial intelligence reshapes how companies operate, make money and drive sales. Amazon rose to the top of the revenue pile by doing much more than running a sprawling online web store and promising speedy delivery. While its core retail unit is its largest revenue generator, its huge cloud computing, advertising and seller services businesses also fuel its sales. Third-party seller services, which include commissions and fees collected by Amazon fulfillment along with shipping, advertising and customer support, accounted for about 24% of the company's total sales in 2025, according to its latest annual filing. Amazon Web Services was responsible for roughly 18%.It wasn't Walmart's weakness that led it to lose its top spot, as its revenue has more than doubled in 20 years. The retailer has leaned on its more than 4,600 Walmart stores and roughly 600 Sam's Club locations in the U.S. to power its digital business, which grew by 27% in the U.S. in the fiscal fourth quarter and has posted double-digit percentage gains for 15 straight quarters.That expansion came as Walmart riffed off the Amazon playbook and tried to position itself as a tech company as well as a retailer. There have been multiple signs of its ambitions: Walmart relisted its stock, moving from the New York Stock Exchange to the tech-heavy Nasdaq in early December. Its market value surpassed the $1 trillion mark earlier this month, a valuation achieved almost exclusively by tech companies, including Amazon, after a more than 21% rise in the last year. And the big-box retailer's fourth-quarter earnings, which were boosted by digital advertising and its third-party marketplace, illustrated Walmart's emphasis on chasing higher-margin businesses and thinking beyond brick-and-mortar retail.Amazon and Walmart's AI ambitionsIn many ways, Walmart's recent push to grow its third-party marketplace was an answer to the dominance of Amazon's platform. Even as it tries to catch up with Amazon in some areas, Walmart is trying to gain an edge in a new frontier.Over the past few years, Amazon and Walmart have used different AI strategies to try to make their businesses more efficient and make their merchandise more appealing to shoppers.Walmart struck a deal with OpenAI's ChatGPT in October and Google's Gemini in January to make its products easier to discover and buy. It also has its own AI-powered shopping assistant, Sparky. The virtual assistant, which looks like a smiley face, pops up on Walmart's app and can help shoppers find items. Walmart, like many other companies, is in the early days of AI adoption, and it's unclear how the technology will affect its business long-term. On the company's earnings call on Thursday, Walmart CEO John Furner said customers are spending more when they use Sparky. He said customers who use Sparky have an average order value that's about 35% higher than shoppers who don't use the tool.About half of Walmart's app users have used Sparky, Walmart U.S. CEO David Guggina said on the earnings call."Agentic AI is increasingly embedded across Walmart," Guggina said. "It's strengthening our operations. It's improving associate productivity, and it's enhancing the customer experience."Walmart Chief Financial Officer John David Rainey said AI investments are included in the retailer's capital expenditure plans for the full year, which are expected to be roughly 3.5% of sales. Those expenses also include the company's investments in automation and store remodels. There are limits to Walmart's tech ambitions.When it comes to AI, Rainey said Walmart will lean on the expertise of tech companies rather than try to create its own products."As you've seen from the announcements we've made, we're approaching AI development through partnerships," he said on the company's earnings call. "This lets tech companies do what they do best, develop innovative technology, and it provides us clarity to do what we do best, to translate the best of tech to retail experiences that create value for our customers and members and our enterprise."Like Walmart, Amazon is also facing new pressure to respond to the rise of agentic commerce. Chatbot makers like OpenAI,  and Perplexity have introduced automated commerce features that aim to change how people shop online. While other companies like Walmart,  and  have announced shopping partnerships with AI platforms, Amazon has remained on the sidelines. It's blocked agents from accessing its site and has doubled down on its own shopping chatbot, Rufus, which is powered by its own models and Anthropic's chatbot Claude.The company said Rufus has been used by more than 300 million customers and drove almost $12 billion in incremental annualized sales last year. After slowly rolling out the service in beta two years ago, Amazon has injected Rufus across more areas of its app and website to encourage shoppers to use the tool.Amazon CEO Andy Jassy said last month that Rufus and other AI tools could assist shoppers with finding products much like an employee in a physical store."I think agents are going to help customers with that type of discovery," Jassy said. "And it's part of why we've invested so much in Rufus, which is our shopping assistant."Meanwhile, Amazon is throwing piles of cash at AI infrastructure. Earlier this month, it announced it would spend up to $200 billion this year on AI initiatives, more than any of the other hyperscalers, which combined have forecast nearly $700 billion in 2026 expenditures. Most of Amazon's spending is expected to go to data centers, chips and networking equipment.Wall Street has viewed Amazon's capex plans skeptically, sending the company's shares down for nine days straight following its Feb. 5 earnings report and shaving more than $450 billion off of its market value.Amazon's investments aren't limited to AI compute. The company has also put significant resources and talent behind developing AI tools across all of its businesses. It has alsorolled out a suite of AI models and revamped its Alexa assistant. It also has invested $8 billion in Anthropic since 2023.â€” CNBC's Robert Hum contributed to this report]]></content:encoded></item><item><title>How I made a shooter game in 64 KB</title><link>https://www.youtube.com/watch?v=qht68vFaa1M</link><author>/u/Chii</author><category>reddit</category><pubDate>Fri, 20 Feb 2026 08:29:11 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>A Brief History of Bjarne Stroustrup, the Creator of C++</title><link>https://www.youtube.com/watch?v=uDtvEsv730Y</link><author>/u/BlueGoliath</author><category>reddit</category><pubDate>Fri, 20 Feb 2026 07:55:59 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>[D] How should I fine-tune an ASR model for multilingual IPA transcription?</title><link>https://www.reddit.com/r/MachineLearning/comments/1r9oxsa/d_how_should_i_finetune_an_asr_model_for/</link><author>/u/Routine-Ticket-5208</author><category>ai</category><category>reddit</category><pubDate>Fri, 20 Feb 2026 07:29:38 +0000</pubDate><source url="https://www.reddit.com/r/MachineLearning/top/?sort=top&amp;t=day&amp;limit=3">Reddit - ML</source><content:encoded><![CDATA[Iâ€™m working on a project where I want to build an ASR system that transcribes audio into IPA, based on what was actually said. The dataset is multilingual.Hereâ€™s what I currently have:- 36 audio files with clear pronunciation + IPA- 100 audio files from random speakers with background noise + IPA annotationsMy goal is to train an ASR model that can take new audio and output IPA transcription.Iâ€™d love advice on two main things:What model should I start with?How should I fine-tune it?]]></content:encoded></item><item><title>State of the Art of Container Security â€¢ Adrian Mouat &amp; Charles Humble</title><link>https://youtu.be/9NUOiL48hbo</link><author>/u/goto-con</author><category>reddit</category><pubDate>Fri, 20 Feb 2026 06:57:18 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Rust participates in Google Summer of Code 2026 | Rust Blog</title><link>https://blog.rust-lang.org/2026/02/19/Rust-participates-in-GSoC-2026/</link><author>/u/Kobzol</author><category>rust</category><category>reddit</category><pubDate>Fri, 20 Feb 2026 06:55:34 +0000</pubDate><source url="https://www.reddit.com/r/rust/top/?sort=top&amp;t=day&amp;limit=3">Reddit - Rust</source><content:encoded><![CDATA[We are happy to announce that the Rust Project will again be participating in Google Summer of Code (GSoC) 2026, same as in the previous two years. If you're not eligible or interested in participating in GSoC, then most of this post likely isn't relevant to you; if you are, this should contain some useful information and links.Google Summer of Code (GSoC) is an annual global program organized by Google that aims to bring new contributors to the world of open-source. The program pairs organizations (such as the Rust Project) with contributors (usually students), with the goal of helping the participants make meaningful open-source contributions under the guidance of experienced mentors.The organizations that have been accepted into the program have been announced by Google. The GSoC applicants now have several weeks to discuss project ideas with mentors. Later, they will send project proposals for the projects that they found the most interesting. If their project proposal is accepted, they will embark on a several months long journey during which they will try to complete their proposed project under the guidance of an assigned mentor.We have prepared a list of project ideas that can serve as inspiration for potential GSoC contributors that would like to send a project proposal to the Rust organization. However, applicants can also come up with their own project ideas. You can discuss project ideas or try to find mentors in the #gsoc Zulip stream. We have also prepared a proposal guide that should help you with preparing your project proposals. We would also like to bring your attention to our GSoC AI policy.You can start discussing the project ideas with Rust Project mentors and maintainers immediately, but you might want to keep the following important dates in mind:The project proposal application period starts on March 16, 2026. From that date you can submit project proposals into the GSoC dashboard.The project proposal application period ends on  at 18:00 UTC. Take note of that deadline, as there will be no extensions!If you are interested in contributing to the Rust Project, we encourage you to check out our project idea list and send us a GSoC project proposal! Of course, you are also free to discuss these projects and/or try to move them forward even if you do not intend to (or cannot) participate in GSoC. We welcome all contributors to Rust, as there is always enough work to do.Our GSoC contributors were quite successful in the past two years (2024, 2025), so we are excited what this year's GSoC will bring! We hope that participants in the program can improve their skills, but also would love for this to bring new contributors to the Project and increase the awareness of Rust in general. Like last year, we expect to publish blog posts in the future with updates about our participation in the program.]]></content:encoded></item><item><title>No Skill. No Taste.</title><link>https://blog.kinglycrow.com/no-skill-no-taste/</link><author>/u/itb206</author><category>reddit</category><pubDate>Fri, 20 Feb 2026 06:40:08 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[I was reading a thread on HN and I started writing this super long comment and rewriting and editing and thought, hey, if I'm doing this I clearly care enough about the state of Show HN and HN in general to write a post on it. I've written code since I was 11. I've worked on larger distributed systems, web apps, databases, search and more. I have many opinions on the transformation of our profession that is currently underway. Most of all, there is now an illusion of a lower barrier to entry. There is a magic quadrant made up of taste and skill. And too many people over estimate their taste[0] and their skill (or never care in the first place).LLMs have people everywhere super excited they can finally build their dream applications! The only problem is, no one needs their dream application. We see it everyday now, someone posts some obvious vibe coded app which is poorly crafted and clearly derivative of an idea so thoroughly saturated it's literally leaking. This is the lowest part of the quadrant. No skill and no taste. The overall suffusion of this into the broader scene rightly has the more sensitive of us up in arms. It's noise, it's spam, it's a perversion of the years of skill we've spent accruing. The only problem there is you might have skill, but do you have taste? This problem itself isn't new. HN of all places has always been a matter of taste. Things people found interesting made it to the front page, things they did not languished. You could build the most finely abstracted todo app of all time and your app would be dead on arrival. However, if you built something that resonated with a large enough group of people it never mattered how well built the app was or how technically complex.I've seen plenty of content on HN that could not have been more than a simple crud app that rocketed to the front page. What comes to mind immediately was a little app that died if someone hadn't posted a message on it in 24 hours. Inherently simple, but quite popular. It was pure taste.Taste and skill are related, the more saturated something is the higher skill you need to cross the taste threshold to make people care. It's not that there will never be another interesting todo app, it's that it has to be so tasteful as to cross our maximal standards and pre-existing expectations of them.LLMs have exposed this more thoroughly than any other time in tech so far. The sin isn't that someone uses an LLM to generate an application[1], vibe[2] or not. The sin is they lacked enough skill and enough taste to cross the actual threshold the rest of us need to see for the work to not be slop. An obvious and recent example of this is OpenClaw. It is a bit of a software nightmare (sorry Peter, I know you're good), but it's highly tasteful even being pretty vibey. People ate it up immediately and because there was such an interest the lack of technical soundness and security was overlooked (or begrudgingly put up with)The lack of taste only presents a problem now, because it's so much easier for people who thought they have more taste than they actually do to post every little idea they have. This is a real problem and I think it will taper off because people will learn proper etiquette or face disappointment. It's a massive educational period for a lot of people that we've all had years to internalize.It has the same stink of crypto on it right now that anyone can get rich. Most of them won't. This is the illusion of the lower barrier of entry, the barrier has always been taste and LLMs do nothing to remove this barrier. They amplify it.Anyway this is all to say whether you have skill or not, you better learn to be tasteful before you decide to slop all over everyone.[0] Taste is totally dependent on the group you're building for, discerning whether you have good taste and to whom is totally a process where you do have to put things out to people, but the bar has not now and not in my years ever been on the floor so I assert there's a minimal universal taste we all have and you should at least clear that before putting things out there.[1] I've been writing code for 20 years, I am super experienced in my domains and I review and sand off the edges, make changes myself etc. I vibe code almost 0% of the time.[2] Vibing means you need to have exceptional taste to cross the bar. I don't care if you do it, but you need to own the outcome.]]></content:encoded></item><item><title>fast-b58: A Blazingly fast Base58 Codec in pure safe rust (7.5x faster than bs58)</title><link>https://www.reddit.com/r/rust/comments/1r9o0r4/fastb58_a_blazingly_fast_base58_codec_in_pure/</link><author>/u/NoRun6138</author><category>rust</category><category>reddit</category><pubDate>Fri, 20 Feb 2026 06:33:58 +0000</pubDate><source url="https://www.reddit.com/r/rust/top/?sort=top&amp;t=day&amp;limit=3">Reddit - Rust</source><content:encoded><![CDATA[In my silly series of small yet fast Rust projects, I introduce fast-b58, a blazingly fast base 58 codec written in pure Rust, zero unsafe. i was working on a bitcoin block parser for the summer of bitcoin, challenges and i spotted this as a need, and thus i wrote this. i know how hated bitcoin is here so apologies in advance.Benchmarks were conducted using , measuring the time to process  (the size of a standard Bitcoin public key or hash).Itâ€™s designed to be a drop-in performance upgrade for any Bitcoin-related project.Encoding a Bitcoin-style input:use fast_b58::encode; let input = b"Hello World!"; let mut output = [0u8; 64]; let len = encode(input, &mut output).unwrap(); assert_eq!(&output[..len], b"2NEpo7TZRRrLZSi2U"); use fast_b58::decode; let input = b"2NEpo7TZRRrLZSi2U"; let mut output = [0u8; 64]; let len = decode(input, &mut output).unwrap(); assert_eq!(&output[..len], b"Hello World!"); its not on crates.io rn but you can always clone it for now, ill add it soon, ]]></content:encoded></item><item><title>Amazon service was taken down by AI coding bot [December outage]</title><link>https://www.ft.com/content/00c282de-ed14-4acd-a948-bc8d6bdb339d</link><author>/u/DubiousLLM</author><category>reddit</category><pubDate>Fri, 20 Feb 2026 06:03:50 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Ran a proper audit of what our AI tools have been generating in Go and the patterns surprised me</title><link>https://www.reddit.com/r/golang/comments/1r9lq54/ran_a_proper_audit_of_what_our_ai_tools_have_been/</link><author>/u/Smooth-Machine5486</author><category>golang</category><category>reddit</category><pubDate>Fri, 20 Feb 2026 04:30:03 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[We write primarily Go and adopted Copilot about eight months ago. I compared the AI-generated portions of our codebase against what the team writes directly and a few things showed up consistently. Error handling being silently dropped in generated code at a higher rate. Dependencies being suggested that our team had consciously moved away from. Crypto implementations that work but use patterns the Go community has deprecated.None of it is catastrophic in isolation. The problem is volume. When AI is generating a third of your commits, patterns that appear rarely in hand-written code appear frequently in aggregate across the codebase.For Go teams using AI coding tools, have you done any systematic review of the security quality of what those tools generate?]]></content:encoded></item><item><title>An AI Agent Published a Hit Piece on Me â€“ The Operator Came Forward</title><link>https://theshamblog.com/an-ai-agent-wrote-a-hit-piece-on-me-part-4/</link><author>/u/CircumspectCapybara</author><category>reddit</category><pubDate>Fri, 20 Feb 2026 04:15:35 +0000</pubDate><source url="https://www.reddit.com/r/programming/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Programming</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>EXPOSING CORSAIR &amp; YUAN: Blatant GPLv2 Violation on Capture Card Linux Drivers (Currently used in Military Hardware)</title><link>https://www.reddit.com/r/linux/comments/1r9j8hr/exposing_corsair_yuan_blatant_gplv2_violation_on/</link><author>/u/Prudent_Worth_4349</author><category>reddit</category><pubDate>Fri, 20 Feb 2026 02:31:02 +0000</pubDate><source url="https://www.reddit.com/r/linux/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Linux</source><content:encoded><![CDATA[I maintain the open-source SC0710 Linux driver â€” the community project that brings Elgato 4K60 Pro MK.2 support to modern kernels. While working on that project I found something that needs to be out in the open.Yuan High-Tech, the ODM manufacturer behind the Elgato 4K60 Pro MK.2, distributes a compiled Linux kernel module called LXV4L2D_SC0710.ko. When you run modinfo on it, the first thing it tells you is license: GPL. That's not a choice they made â€” they had to declare GPL to access kernel symbols via EXPORT_SYMBOL_GPL(). The module literally cannot load on a modern kernel without that declaration. Fine. Except GPLv2 Section 3 means that the second you distribute a GPL binary, you're legally obligated to provide the source code to anyone who asks.So I asked. On January 25, 2026 I emailed Yuan requesting the source for Build V1432 (compiled January 7, 2026). Their response? They wanted photos of my hardware and asked where I was from. When I pointed out that neither of those things have anything to do with GPL compliance, they stopped responding. I then escalated to Corsair's legal team â€” Yuan's North American distributor â€” outlining their shared liability. Complete silence.Now here's where it gets more interesting. The full alias table from modinfo shows the driver doesn't just support Yuan's SC0710 chip (12AB:0710) â€” it also aliases 13 Techwell/Intersil device IDs (1797:5864, 1797:6801 through 1797:6817). Those exact chip IDs have had open-source GPL drivers in the mainline Linux kernel since 2016 (tw5864, tw686x, tw68). Whether Yuan derived their driver from those mainline drivers or from Intersil's own SDK is something that requires binary analysis â€” but either way the closed-source distribution is indefensible, and the SFC now has the binary to investigate.This also isn't just a streamer problem. This exact driver is being shipped in:- 7StarLake AV710-X4 and NV200-2LGS16 â€” MIL-STD-810H certified military computers used in defense and intelligent automation- JMC Systems SC710N4 â€” industrial HDMI 2.0 capture cards sold with explicit Linux supportDefense contractors are deploying undisclosed, closed-source kernel modules on production hardware. That's the actual scope of this.Update: I submitted a formal compliance report to the Software Freedom Conservancy. They have already requested the binary and I've provided it. This is now an active enforcement process, not just a Reddit post.For anyone saying the 4K60 Pro MK.2 being EOL changes anything â€” Yuan compiled Build V1432 on January 7, 2026, eight months after EOL. They're still distributing it. And GPLv2's 3-year written offer clause requires the offer to have been made at the time of distribution â€” Yuan never made one at all, not in 2022, not now.Disclaimer: I used AI to help with formatting and writing clarity. The research, technical findings, and evidence are entirely my own work.]]></content:encoded></item><item><title>Built a TUI PDF tool in Go using Bubble Tea â€“ would love feedback!</title><link>https://www.reddit.com/r/golang/comments/1r9i514/built_a_tui_pdf_tool_in_go_using_bubble_tea_would/</link><author>/u/Sad_Caramel1645</author><category>golang</category><category>reddit</category><pubDate>Fri, 20 Feb 2026 01:41:44 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[Recently I got way too much into terminal workflows and TUIs and wanted to learn how to make them so that I can replace more workflows that require going outside the terminal. I used charm tools (bubbletea, bubbles) for the TUI and the pdfcpu library as the backend engine for pdfs.For now it supports Merging, Splitting, Encryption-Decryption, Image to pdf conversion. I have also added vim like keybinds.The hardest thing is making it responsive according to dynamic terminal sizes which I am still working on.I plan to replace more workflows in the future. Would love to hear your feedback! especially on project structure and testing strategy.]]></content:encoded></item><item><title>Standard library for array/slice manipulation</title><link>https://www.reddit.com/r/golang/comments/1r9h5tf/standard_library_for_arrayslice_manipulation/</link><author>/u/ServeIndependent837</author><category>golang</category><category>reddit</category><pubDate>Fri, 20 Feb 2026 00:57:46 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[Can anyone suggest the best practice in go for array manipulation, like in other languages have inbuild libraries : Collections in java, do go have a standard library everyone uses or we do it manually? eg: reverse, sort etc]]></content:encoded></item><item><title>mrustc, now with rust 1.90.0 support!</title><link>https://www.reddit.com/r/rust/comments/1r9g8gy/mrustc_now_with_rust_1900_support/</link><author>/u/mutabah</author><category>rust</category><category>reddit</category><pubDate>Fri, 20 Feb 2026 00:16:59 +0000</pubDate><source url="https://www.reddit.com/r/rust/top/?sort=top&amp;t=day&amp;limit=3">Reddit - Rust</source><content:encoded><![CDATA[I've just completed the latest round of updating mrustc to support a newer rust version, specifically 1.90.0.Why mrustc? Bootstrapping! mrustc is written entirely in C++, and thus allows building rustc without needing to build several hundred versions (starting from the original OCaml version of the compiler)What next? When I feel like doing work on it again, it's time to do optimisations again (memory usage, speed, and maybe some code simplification).]]></content:encoded></item><item><title>Linux 7.0 Showing Some Early Performance Regressions On Intel Panther Lake</title><link>https://www.phoronix.com/review/linux-7-panther-lake</link><author>/u/TerribleReason4195</author><category>reddit</category><pubDate>Thu, 19 Feb 2026 23:15:24 +0000</pubDate><source url="https://www.reddit.com/r/linux/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Linux</source><content:encoded><![CDATA[With the Linux 7.0 merge window beginning to calm down ahead of the 7.0-rc1 release due out on Sunday, one of the areas I was most excited about benchmarking on Linux 7.0 was looking for any performance gains with the new Intel Core Ultra Series 3 "Panther Lake" given ongoing Intel Xe graphics driver improvements and other general kernel optimizations. Unfortunately, at large the Intel Panther Lake performance is moving in the wrong direction with the early Linux 7.0 benchmarking.I was eager to begin Linux 7.0 kernel testing to look out for any CPU or iGPU performance improvements with the Core Ultra X7 358H and its Arc B390 Graphics. Especially with the Intel Xe driver continuing to mature for the new Xe3 graphics I was hopeful of seeing some improvements for the exciting B390 graphics but overall the performance was regressing over Linux 6.19 stable.Using the same MSI Prestige 14 Panther Lake laptop (in its "performance" platform profile consistently as recommended by Intel) with the Core Ultra X7 358H and 32GB of LPDDR5-8533 memory, I ran benchmarks on Linux 6.19 stable and Linux 7.0 Git as of 16 February. The same compiler toolchain on that laptop and the same basic kernel configuration (all new Kconfig additions in v7.0 at their default values). No other software changes were made to this laptop besides swapping out the kernel and repeating the benchmark in the otherwise same hardware/software environment.Here's what I am seeing so far out of Linux 7.0 on Intel Panther Lake. Benchmarks on other systems are running at the moment to see if these are Panther Lake specific issues or early Linux 7.0 performance regressions at large, so stay tuned for more of these Linux 7.0 performance benchmarks in the coming days and with the merge window wrapping up on Sunday.]]></content:encoded></item><item><title>Show r/kubernetes: kubectl-xctx â€” run kubectl commands across multiple contexts with one command</title><link>https://www.reddit.com/r/kubernetes/comments/1r9eo2w/show_rkubernetes_kubectlxctx_run_kubectl_commands/</link><author>/u/be0x74a</author><category>reddit</category><pubDate>Thu, 19 Feb 2026 23:12:22 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[: If you manage multiple Kubernetes clusters (prod, staging, dev, regional replicas), checking the same thing across all of them means repeating yourself â€” switching contexts, running the command, switching again, running again. Scripts help but they're fragile and everyone writes their own.:  takes a regex pattern, matches it against your kubeconfig contexts, and runs any kubectl command across all matches. Output is grouped with clear headers per context.# See pods across all prod clusters kubectl xctx "prod" get pods -n backend ### Context: prod-us-east-1 NAME READY STATUS RESTARTS AGE api-server-abc123 1/1 Running 0 3d ### Context: prod-eu-west-1 NAME READY STATUS RESTARTS AGE api-server-xyz789 1/1 Running 0 3d  for concurrent execution across contexts to skip unreachable clusters to stop on first error to preview which contexts match your pattern to customize or suppress output headers (via krew custom index):kubectl krew index add be0x74a https://github.com/be0x74a/krew-index kubectl krew install be0x74a/xctx Or build from source â€” it's a single Go binary with zero dependencies beyond kubectl.Would love to hear feedback, especially from folks managing many clusters. What patterns do you use today for multi-context operations?]]></content:encoded></item><item><title>Tetro TUI - release of a cross-platform Terminal Game feat. Replays and ASCII Art - shoutout to the Crossterm crate</title><link>https://www.reddit.com/r/rust/comments/1r9ed5h/tetro_tui_release_of_a_crossplatform_terminal/</link><author>/u/Strophox</author><category>rust</category><category>reddit</category><pubDate>Thu, 19 Feb 2026 23:00:15 +0000</pubDate><source url="https://www.reddit.com/r/rust/top/?sort=top&amp;t=day&amp;limit=3">Reddit - Rust</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>is there a way to connect a kubernetes pod in cluster with trust relationship with azure entra id without using user managed identity or app registration</title><link>https://www.reddit.com/r/kubernetes/comments/1r9dxw6/is_there_a_way_to_connect_a_kubernetes_pod_in/</link><author>/u/MountainPop7589</author><category>reddit</category><pubDate>Thu, 19 Feb 2026 22:43:13 +0000</pubDate><source url="https://www.reddit.com/r/kubernetes/top/?sort=top&amp;t=day&amp;limit=6">Kubernetes</source><content:encoded><![CDATA[i need to test some features in a local kubernetes cluster that have trust relartion ship with entra id azure, i managed to work with managed identity or/and app registration allowing the pod to access azure resources while being deployed locally, now i want to get rid of the managed identity/app reg itself to reduce the effort on the entra id side , is there a way to do that? or is imposible? ]]></content:encoded></item><item><title>Will Go lang optimize array access?</title><link>https://www.reddit.com/r/golang/comments/1r9bc2d/will_go_lang_optimize_array_access/</link><author>/u/iga666</author><category>golang</category><category>reddit</category><pubDate>Thu, 19 Feb 2026 21:03:27 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[func GetMonitors() []Monitor { ms := make([]Monitor, GetMonitorCount()) for i := range ms { ms[i].Index = i ms[i].Name = GetMonitorName(i) ms[i].Resolution = vector2.New( GetMonitorWidth(i), GetMonitorHeight(i), ) ms[i].Position = GetMonitorPosition(i) ms[i].Dimensions = vector2.New( GetMonitorPhysicalWidth(i), GetMonitorPhysicalHeight(i), ) ms[i].RefreshRate = GetMonitorRefreshRate(i) } return ms } Will that code be optimized or it is better to fill local var and assign it to array? (I will do that, but interesting anyway)   submitted by    /u/iga666 ]]></content:encoded></item><item><title>I built a free local AI image search app â€” find images by typing what&apos;s in them</title><link>https://v.redd.it/ek2z9n3pgikg1</link><author>/u/ravenlolanth</author><category>ai</category><category>reddit</category><pubDate>Thu, 19 Feb 2026 20:27:50 +0000</pubDate><source url="https://www.reddit.com/r/artificial/top/?sort=top&amp;t=day&amp;limit=3">Reddit - AI</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Theming Update for The Linux Mint Community Wiki</title><link>https://www.reddit.com/r/linux/comments/1r98xqc/theming_update_for_the_linux_mint_community_wiki/</link><author>/u/SpeeQz</author><category>reddit</category><pubDate>Thu, 19 Feb 2026 19:34:00 +0000</pubDate><source url="https://www.reddit.com/r/linux/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Linux</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>How to read go string formatting verb from user input?</title><link>https://www.reddit.com/r/golang/comments/1r98hbu/how_to_read_go_string_formatting_verb_from_user/</link><author>/u/Tuomas90</author><category>golang</category><category>reddit</category><pubDate>Thu, 19 Feb 2026 19:17:17 +0000</pubDate><source url="https://www.reddit.com/r/golang/top/?sort=top&amp;t=day&amp;limit=6">Reddit - Go</source><content:encoded><![CDATA[Hi! I'm writing a little program to automatically number files.The user should be able to specify a number formatting string like "%03d".How could I apply that string to a format string like:var pattern = "%03d" var newFileName = fmt.Sprintf("pattern%s", index, fileName) I guess I kinda need a way to "unwrap" the formatting pattern. A way to apply the contents of the pattern variable to the formatting string...Another option would be to let the user specify a "padding" option like var PAD = 3 var newFileName = fmt.Sprintf("%0PADd%s", index, fileName) Still the same problem: How to convert a variable into a formatting string?]]></content:encoded></item></channel></rss>