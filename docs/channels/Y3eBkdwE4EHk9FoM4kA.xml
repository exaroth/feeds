<?xml version="1.0" encoding="utf-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Trending Repos</title><link>https://konrad.website/feeds/</link><description></description><item><title>go-playground/validator</title><link>https://github.com/go-playground/validator</link><author></author><category>trending</category><pubDate>Sat, 15 Feb 2025 02:26:24 +0000</pubDate><source url="http://mshibanami.github.io/GitHubTrendingRSS">Dev - Github Trending</source><content:encoded><![CDATA[ðŸ’¯Go Struct and Field validation, including Cross Field, Cross Struct, Map, Slice and Array divingPackage validator implements value validations for structs and individual fields based on tags.It has the following  features:Cross Field and Cross Struct validations by using validation tags or custom validators.Slice, Array and Map diving, which allows any or all levels of a multidimensional field to be validated.Ability to dive into both map keys and values for validationHandles type interface by determining it's underlying type prior to validation.Handles custom field types such as sql driver Valuer see ValuerAlias validation tags, which allows for mapping of several validations to a single tag for easier defining of validations on structsExtraction of custom defined Field Name e.g. can specify to extract the JSON name while validating and have it available in the resulting FieldErrorCustomizable i18n aware error messages.Default validator for the gin web framework; upgrading from v8 to v9 in gin see herePlease read the discussiong started here if you are interested in contributing/helping maintain this package.go get github.com/go-playground/validator/v10
Then import the validator package into your own code.import "github.com/go-playground/validator/v10"
Validation functions return type errorThey return type error to avoid the issue discussed in the following, where err is always != nil:Validator returns only InvalidValidationError for bad validation input, nil or ValidationErrors as type error; so, in your code all you need to do is check if the error returned is not nil, and if it's not check if error is InvalidValidationError ( if necessary, most of the time it isn't ) type cast it to type ValidationErrors like so:err := validate.Struct(mystruct)
validationErrors := err.(validator.ValidationErrors)
If new to using validator it is highly recommended to initialize it using the WithRequiredStructEnabled option which is opt-in to new behaviour that will become the default behaviour in v11+. See documentation for more details.validate := validator.New(validator.WithRequiredStructEnabled())
Field Equals Another Field (relative)Field Equals Another FieldCheck the indicated characters are present in the FieldCheck the indicated characters are not present in the fieldField Greater Than Another Relative FieldField Greater Than or Equal To Another Relative FieldField Greater Than or Equal To Another FieldField Greater Than Another FieldLess Than Another Relative FieldLess Than or Equal To Another Relative FieldLess Than or Equal To Another FieldField Does Not Equal Another Field (relative)Field Does Not Equal Another FieldClassless Inter-Domain Routing CIDRClassless Inter-Domain Routing CIDRv4Classless Inter-Domain Routing CIDRv6Full Qualified Domain Name (FQDN)Internet Protocol Address IPInternet Protocol Address IPv4Internet Protocol Address IPv6Internet Protocol Address IPInternet Protocol Address IPv4Internet Protocol Address IPv6Media Access Control Address MACTransmission Control Protocol Address TCPv4Transmission Control Protocol Address TCPv6Transmission Control Protocol Address TCPUser Datagram Protocol Address UDPv4User Datagram Protocol Address UDPv6User Datagram Protocol Address UDPUnix domain socket end point AddressBusiness Identifier Code (ISO 9362)Bitcoin Bech32 Address (segwit)mongodb_connection_stringMongoDB Connection StringSpiceDb ObjectID/Permission/Typee164 formatted phone numberInternational Standard Book NumberInternational Standard Book Number 10International Standard Book Number 13International Standard Serial NumberTwo-letter country code (ISO 3166-1 alpha-2)Three-letter country code (ISO 3166-1 alpha-3)Numeric country code (ISO 3166-1 numeric)Country subdivision code (ISO 3166-2)Luhn Algorithm Checksum (for strings and (u)int)postcode_iso3166_alpha2_fieldSocial Security Number SSNUniversally Unique Identifier UUIDUniversally Unique Identifier UUID v3Universally Unique Identifier UUID v3 RFC4122Universally Unique Identifier UUID v4Universally Unique Identifier UUID v4 RFC4122Universally Unique Identifier UUID v5Universally Unique Identifier UUID v5 RFC4122Universally Unique Identifier UUID RFC4122Semantic Versioning 2.0.0Universally Unique Lexicographically Sortable Identifier ULIDCommon Vulnerabilities and Exposures Identifier (CVE id)hexcolor|rgb|rgba|hsl|hslaiso3166_1_alpha2|iso3166_1_alpha3|iso3166_1_alpha_numericRun on MacBook Pro Max M3go version go1.23.3 darwin/arm64
goos: darwin
goarch: arm64
cpu: Apple M3 Max
pkg: github.com/go-playground/validator/v10
BenchmarkFieldSuccess-16                                                42461943                27.88 ns/op            0 B/op          0 allocs/op
BenchmarkFieldSuccessParallel-16                                        486632887                2.289 ns/op           0 B/op          0 allocs/op
BenchmarkFieldFailure-16                                                 9566167               121.3 ns/op           200 B/op          4 allocs/op
BenchmarkFieldFailureParallel-16                                        17551471                83.68 ns/op          200 B/op          4 allocs/op
BenchmarkFieldArrayDiveSuccess-16                                        7602306               155.6 ns/op            97 B/op          5 allocs/op
BenchmarkFieldArrayDiveSuccessParallel-16                               20664610                59.80 ns/op           97 B/op          5 allocs/op
BenchmarkFieldArrayDiveFailure-16                                        4659756               252.9 ns/op           301 B/op         10 allocs/op
BenchmarkFieldArrayDiveFailureParallel-16                                8010116               152.9 ns/op           301 B/op         10 allocs/op
BenchmarkFieldMapDiveSuccess-16                                          2834575               421.2 ns/op           288 B/op         14 allocs/op
BenchmarkFieldMapDiveSuccessParallel-16                                  7179700               171.8 ns/op           288 B/op         14 allocs/op
BenchmarkFieldMapDiveFailure-16                                          3081728               384.4 ns/op           376 B/op         13 allocs/op
BenchmarkFieldMapDiveFailureParallel-16                                  6058137               204.0 ns/op           377 B/op         13 allocs/op
BenchmarkFieldMapDiveWithKeysSuccess-16                                  2544975               464.8 ns/op           288 B/op         14 allocs/op
BenchmarkFieldMapDiveWithKeysSuccessParallel-16                          6661954               181.4 ns/op           288 B/op         14 allocs/op
BenchmarkFieldMapDiveWithKeysFailure-16                                  2435484               490.7 ns/op           553 B/op         16 allocs/op
BenchmarkFieldMapDiveWithKeysFailureParallel-16                          4249617               282.0 ns/op           554 B/op         16 allocs/op
BenchmarkFieldCustomTypeSuccess-16                                      14943525                77.35 ns/op           32 B/op          2 allocs/op
BenchmarkFieldCustomTypeSuccessParallel-16                              64051954                20.61 ns/op           32 B/op          2 allocs/op
BenchmarkFieldCustomTypeFailure-16                                      10721384               107.1 ns/op           184 B/op          3 allocs/op
BenchmarkFieldCustomTypeFailureParallel-16                              18714495                69.77 ns/op          184 B/op          3 allocs/op
BenchmarkFieldOrTagSuccess-16                                            4063124               294.3 ns/op            16 B/op          1 allocs/op
BenchmarkFieldOrTagSuccessParallel-16                                   31903756                41.22 ns/op           18 B/op          1 allocs/op
BenchmarkFieldOrTagFailure-16                                            7748558               146.8 ns/op           216 B/op          5 allocs/op
BenchmarkFieldOrTagFailureParallel-16                                   13139854                92.05 ns/op          216 B/op          5 allocs/op
BenchmarkStructLevelValidationSuccess-16                                16808389                70.25 ns/op           16 B/op          1 allocs/op
BenchmarkStructLevelValidationSuccessParallel-16                        90686955                14.47 ns/op           16 B/op          1 allocs/op
BenchmarkStructLevelValidationFailure-16                                 5818791               200.2 ns/op           264 B/op          7 allocs/op
BenchmarkStructLevelValidationFailureParallel-16                        11115874               107.5 ns/op           264 B/op          7 allocs/op
BenchmarkStructSimpleCustomTypeSuccess-16                                7764956               151.9 ns/op            32 B/op          2 allocs/op
BenchmarkStructSimpleCustomTypeSuccessParallel-16                       52316265                30.37 ns/op           32 B/op          2 allocs/op
BenchmarkStructSimpleCustomTypeFailure-16                                4195429               277.2 ns/op           416 B/op          9 allocs/op
BenchmarkStructSimpleCustomTypeFailureParallel-16                        7305661               164.6 ns/op           432 B/op         10 allocs/op
BenchmarkStructFilteredSuccess-16                                        6312625               186.1 ns/op           216 B/op          5 allocs/op
BenchmarkStructFilteredSuccessParallel-16                               13684459                93.42 ns/op          216 B/op          5 allocs/op
BenchmarkStructFilteredFailure-16                                        6751482               171.2 ns/op           216 B/op          5 allocs/op
BenchmarkStructFilteredFailureParallel-16                               14146070                86.93 ns/op          216 B/op          5 allocs/op
BenchmarkStructPartialSuccess-16                                         6544448               177.3 ns/op           224 B/op          4 allocs/op
BenchmarkStructPartialSuccessParallel-16                                13951946                88.73 ns/op          224 B/op          4 allocs/op
BenchmarkStructPartialFailure-16                                         4075833               287.5 ns/op           440 B/op          9 allocs/op
BenchmarkStructPartialFailureParallel-16                                 7490805               161.3 ns/op           440 B/op          9 allocs/op
BenchmarkStructExceptSuccess-16                                          4107187               281.4 ns/op           424 B/op          8 allocs/op
BenchmarkStructExceptSuccessParallel-16                                 15979173                80.86 ns/op          208 B/op          3 allocs/op
BenchmarkStructExceptFailure-16                                          4434372               264.3 ns/op           424 B/op          8 allocs/op
BenchmarkStructExceptFailureParallel-16                                  8081367               154.1 ns/op           424 B/op          8 allocs/op
BenchmarkStructSimpleCrossFieldSuccess-16                                6459542               183.4 ns/op            56 B/op          3 allocs/op
BenchmarkStructSimpleCrossFieldSuccessParallel-16                       41013781                37.95 ns/op           56 B/op          3 allocs/op
BenchmarkStructSimpleCrossFieldFailure-16                                4034998               292.1 ns/op           272 B/op          8 allocs/op
BenchmarkStructSimpleCrossFieldFailureParallel-16                       11348446               115.3 ns/op           272 B/op          8 allocs/op
BenchmarkStructSimpleCrossStructCrossFieldSuccess-16                     4448528               267.7 ns/op            64 B/op          4 allocs/op
BenchmarkStructSimpleCrossStructCrossFieldSuccessParallel-16            26813619                48.33 ns/op           64 B/op          4 allocs/op
BenchmarkStructSimpleCrossStructCrossFieldFailure-16                     3090646               384.5 ns/op           288 B/op          9 allocs/op
BenchmarkStructSimpleCrossStructCrossFieldFailureParallel-16             9870906               129.5 ns/op           288 B/op          9 allocs/op
BenchmarkStructSimpleSuccess-16                                         10675562               109.5 ns/op             0 B/op          0 allocs/op
BenchmarkStructSimpleSuccessParallel-16                                 131159784                8.932 ns/op           0 B/op          0 allocs/op
BenchmarkStructSimpleFailure-16                                          4094979               286.6 ns/op           416 B/op          9 allocs/op
BenchmarkStructSimpleFailureParallel-16                                  7606663               157.9 ns/op           416 B/op          9 allocs/op
BenchmarkStructComplexSuccess-16                                         2073470               576.0 ns/op           224 B/op          5 allocs/op
BenchmarkStructComplexSuccessParallel-16                                 7821831               161.3 ns/op           224 B/op          5 allocs/op
BenchmarkStructComplexFailure-16                                          576358              2001 ns/op            3042 B/op         48 allocs/op
BenchmarkStructComplexFailureParallel-16                                 1000000              1171 ns/op            3041 B/op         48 allocs/op
BenchmarkOneof-16                                                       22503973                52.82 ns/op            0 B/op          0 allocs/op
BenchmarkOneofParallel-16                                                8538474               140.4 ns/op             0 B/op          0 allocs/op
Here is a list of software that complements using this library either pre or post validation.form - Decodes url.Values into Go value(s) and Encodes Go value(s) into url.Values. Dual Array and Full map support.mold - A general library to help modify or set data within data structures and other objectsMaintenance and support for SDK major versionsSee prior discussion here for more details.This package is aligned with the Go release policy in that support is guaranteed for the two most recent major versions.This does not mean the package will not work with older versions of Go, only that we reserve the right to increase the MSGV(Minimum Supported Go Version) when the need arises to address Security issues/patches, OS issues & support or newly introduced functionality that would greatly benefit the maintenance and/or usage of this package.If and when the MSGV is increased it will be done so in a minimum of a  release bump.Distributed under MIT License, please see license file within the code for more details.This project has grown large enough that more than one person is required to properly support the community. If you are interested in becoming a maintainer please reach out to me https://github.com/deankarn]]></content:encoded></item><item><title>GitHubDaily/GitHubDaily</title><link>https://github.com/GitHubDaily/GitHubDaily</link><author></author><category>trending</category><pubDate>Sat, 15 Feb 2025 02:26:24 +0000</pubDate><source url="http://mshibanami.github.io/GitHubTrendingRSS">Dev - Github Trending</source><content:encoded><![CDATA[åšæŒåˆ†äº« GitHub ä¸Šé«˜è´¨é‡ã€æœ‰è¶£å®žç”¨çš„å¼€æºæŠ€æœ¯æ•™ç¨‹ã€å¼€å‘è€…å·¥å…·ã€ç¼–ç¨‹ç½‘ç«™ã€æŠ€æœ¯èµ„è®¯ã€‚A list cool, interesting projects of GitHub.å¤šå¹´ä»¥å‰ï¼Œæˆ‘æ›¾çœ‹åˆ° GitHub å¼€æºé¡¹ç›®ä½œè€…ã€å…¨æ ˆå·¥ç¨‹å¸ˆ TJ Holowaychunk è¯´è¿‡è¿™ä¹ˆä¸€å¥è¯ï¼š"I don't read books, never went to school, I just read other people's code and always wonder how things work"ã€‚ä»Žé‚£æ—¶èµ·ï¼Œæˆ‘ä¾¿è®¤ä¸ºï¼Œé€šè¿‡é˜…è¯»æºç ï¼Œç«™åœ¨å‰è¾ˆçš„è§’åº¦ä¸Šï¼ŒåŽ»æ€è€ƒä»£ç æž¶æž„ä¸Žç¨‹åºé€»è¾‘ï¼Œä¹ƒæ˜¯æå‡ç¼–ç¨‹æŠ€å·§æœ€å¥½çš„æ–¹å¼ã€‚å› æ­¤ï¼ŒGitHub ä¹Ÿè‡ªç„¶è€Œç„¶çš„ï¼Œæˆä¸ºæˆ‘æœ€å–œçˆ±çš„å¼€å‘è€…å¹³å°ã€‚ç§‰ç€æŒ–æŽ˜å¼€æºä»·å€¼çš„åˆè¡·ï¼ŒGitHubDaily è‡ª 2015 å¹´ 10 æœˆ 10 æ—¥æ­£å¼æˆç«‹ã€‚æˆ‘ä»¬å¸Œæœ›èƒ½é€šè¿‡è¿™ä¸€ä¸¾æŽªï¼Œå¸®åŠ©å¼€å‘è€…ä»¬å‘çŽ°å½“ä¸‹æœ€ç«çš„å¼€æºé¡¹ç›®ï¼ŒæŽŒæŽ§æœ€æ–°æŠ€æœ¯åŠ¨æ€, æ‰©å¤§æŠ€æœ¯è§†é‡Ž, å¹¶ä»Žå¼€æºé¡¹ç›®çš„å­¦ä¹ ä¸­èŽ·å¾—ç¼–ç¨‹èƒ½åŠ›çš„æå‡ã€‚ç›®å‰ï¼ŒGitHubDaily å·²ç´¯ç§¯åˆ†äº«è¶…è¿‡ 8000 ä¸ªå¼€æºé¡¹ç›®ï¼Œå†…å®¹åŒ…æ‹¬ä½†ä¸é™äºŽ GitHub ä¸Šçš„å¼€æºæŠ€æœ¯èµ„æ–™ã€å¼€å‘è€…å·¥å…·ã€ç¼–ç¨‹ç½‘ç«™ä»¥åŠæˆç†Ÿåº”ç”¨ã€‚é™¤äº† GitHub ä¹‹å¤–ï¼Œæˆ‘ä»¬ä¹Ÿå¼€å§‹åœ¨ä¸‹é¢å¤šä¸ªç¤¾äº¤åª’ä½“å¹³å°ï¼Œå¸®åŠ©å¼€å‘è€…ä¼ æ’­ä¸Žåˆ†äº«ä¼˜è´¨å¼€æºé¡¹ç›®ï¼ŒæŒ–æŽ˜å…¶æœªæ¥çš„æŠ€æœ¯åº”ç”¨å‰æ™¯ã€‚å¦‚æžœä½ æƒ³æŽ¥æ”¶æœ€æ–°çš„ GitHub å¼€æºé¡¹ç›®èµ„è®¯ï¼Œå¯ä»¥å…³æ³¨ä¸€ä¸‹ðŸ‘‡æœ‰ä¸é”™çš„å¼€æºé¡¹ç›®ï¼Œä¹Ÿæ¬¢è¿Žåˆ°æœ¬ä»“åº“çš„ issues æŽ¨èæˆ–è‡ªèé¡¹ç›®ï¼Œæˆ‘ä»¬æœŸå¾…ä½ çš„åˆ†äº«ã€‚ä¸‹é¢æ˜¯å¯¹ GitHubDaily åœ¨ 2024 å¹´æ‰€æŽ¨èçš„é¡¹ç›®è¿›è¡Œåˆ†ç±»æ•´ç†ï¼Œæ–¹ä¾¿å¤§å®¶æŸ¥æ‰¾ä»¥å¾€åˆ†äº«è¿‡çš„å†…å®¹ã€‚]]></content:encoded></item><item><title>microsoft/markitdown</title><link>https://github.com/microsoft/markitdown</link><author></author><category>trending</category><pubDate>Sat, 15 Feb 2025 02:26:24 +0000</pubDate><source url="http://mshibanami.github.io/GitHubTrendingRSS">Dev - Github Trending</source><content:encoded><![CDATA[Python tool for converting files and office documents to Markdown.[!IMPORTANT] MarkItDown 0.0.2 alpha 1 (0.0.2a1) introduces a plugin-based architecture. As much as was possible, command-line and Python interfaces have remained the same as 0.0.1a3 to support backward compatibility. Please report any issues you encounter. Some interface changes may yet occur as we continue to refine MarkItDown to a first non-alpha release.MarkItDown is a utility for converting various files to Markdown (e.g., for indexing, text analysis, etc). It supports:Images (EXIF metadata and OCR)Audio (EXIF metadata and speech transcription)Text-based formats (CSV, JSON, XML)ZIP files (iterates over contents)To install MarkItDown, use pip: . Alternatively, you can install it from the source:git clone git@github.com:microsoft/markitdown.git
cd markitdown
pip install -e packages/markitdown
markitdown path-to-file.pdf > document.md
Or use  to specify the output file:markitdown path-to-file.pdf -o document.md
You can also pipe content:cat path-to-file.pdf | markitdown
MarkItDown also supports 3rd-party plugins. Plugins are disabled by default. To list installed plugins:markitdown --list-plugins
markitdown --use-plugins path-to-file.pdf
To find available plugins, search GitHub for the hashtag . To develop a plugin, see packages/markitdown-sample-plugin.Azure Document IntelligenceTo use Microsoft Document Intelligence for conversion:markitdown path-to-file.pdf -o document.md -d -e "<document_intelligence_endpoint>"
More information about how to set up an Azure Document Intelligence Resource can be found herefrom markitdown import MarkItDown

md = MarkItDown(enable_plugins=False) # Set to True to enable plugins
result = md.convert("test.xlsx")
print(result.text_content)
Document Intelligence conversion in Python:from markitdown import MarkItDown

md = MarkItDown(docintel_endpoint="<document_intelligence_endpoint>")
result = md.convert("test.pdf")
print(result.text_content)
To use Large Language Models for image descriptions, provide  and :from markitdown import MarkItDown
from openai import OpenAI

client = OpenAI()
md = MarkItDown(llm_client=client, llm_model="gpt-4o")
result = md.convert("example.jpg")
print(result.text_content)
docker build -t markitdown:latest .
docker run --rm -i markitdown:latest < ~/your-file.pdf > output.md
This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.You can help by looking at issues or helping review PRs. Any issue or PR is welcome, but we have also marked some as 'open for contribution' and 'open for reviewing' to help facilitate community contributions. These are ofcourse just suggestions and you are welcome to contribute in any way you like.Navigate to the MarkItDown package:Install  in your environment and run tests:pip install hatch  # Other ways of installing hatch: https://hatch.pypa.io/dev/install/
hatch shell
hatch test
(Alternative) Use the Devcontainer which has all the dependencies installed:# Reopen the project in Devcontainer and run:
hatch test
Run pre-commit checks before submitting a PR: pre-commit run --all-filesContributing 3rd-party PluginsYou can also contribute by creating and sharing 3rd party plugins. See packages/markitdown-sample-plugin for more details.This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow Microsoft's Trademark & Brand Guidelines. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party's policies.]]></content:encoded></item><item><title>zaidmukaddam/scira</title><link>https://github.com/zaidmukaddam/scira</link><author></author><category>trending</category><pubDate>Sat, 15 Feb 2025 02:26:24 +0000</pubDate><source url="http://mshibanami.github.io/GitHubTrendingRSS">Dev - Github Trending</source><content:encoded><![CDATA[Scira (Formerly MiniPerplx) is a minimalistic AI-powered search engine that helps you find information on the internet. Powered by Vercel AI SDK! Search with models like Grok 2.0.A minimalistic AI-powered search engine that helps you find information on the internet.Tavily AI - For search grounding and web search capabilities: Get answers to your questions using Anthropic's Models.: Search the web using Tavily's API.: Get information from a specific URL.: Get the current weather for any location using OpenWeather's API.: Run code snippets in multiple languages using E2B's API.: Get the location of any place using Google Maps API, Mapbox API, and TripAdvisor API.: Track flights using AviationStack's API.Trending Movies and TV Shows: Get information about trending movies and TV shows.: Get information about any movie or TV show.Set Scira as your default search engineOpen the Chrome browser settings:Click on the three vertical dots in the upper right corner of the browser.Select "Settings" from the dropdown menu.Go to the search engine settings:In the left sidebar, click on "Search engine."Then select "Manage search engines and site search."Click on "Add" next to "Site search."Set the search engine name:Enter  in the "Search engine" field.Set the search engine URL:Enter  in the "URL with %s in place of query" field.Set the search engine shortcut:Enter  in the "Shortcut" field.Click on the three dots next to the search engine you just added.Select "Make default" from the dropdown menu.After completing these steps, you should be able to use Scira as your default search engine in Chrome.To run the example locally you need to:Sign up for accounts with the AI providers you want to use. OpenAI and Anthropic are required, Tavily is required for the web search feature.Obtain API keys for each provider.Set the required environment variables as shown in the  file, but in a new file called . to install the required dependencies. to launch the development server.This project is licensed under the MIT License - see the LICENSE file for details.]]></content:encoded></item><item><title>kuchin/awesome-cto</title><link>https://github.com/kuchin/awesome-cto</link><author></author><category>trending</category><pubDate>Sat, 15 Feb 2025 02:26:24 +0000</pubDate><source url="http://mshibanami.github.io/GitHubTrendingRSS">Dev - Github Trending</source><content:encoded><![CDATA[â€” Hello, my name is Dima and I'm a CTO]]></content:encoded></item><item><title>golang/go</title><link>https://github.com/golang/go</link><author></author><category>trending</category><pubDate>Sat, 15 Feb 2025 02:26:24 +0000</pubDate><source url="http://mshibanami.github.io/GitHubTrendingRSS">Dev - Github Trending</source><content:encoded><![CDATA[The Go programming languageGo is an open source programming language that makes it easy to build simple, reliable, and efficient software.Unless otherwise noted, the Go source files are distributed under the BSD-style license found in the LICENSE file.If a binary distribution is not available for your combination of operating system and architecture, visit https://go.dev/doc/install/source for source installation instructions.Go is the work of thousands of contributors. We appreciate your help!Note that the Go project uses the issue tracker for bug reports and proposals only. See https://go.dev/wiki/Questions for a list of places to ask questions about the Go language.]]></content:encoded></item><item><title>Zipstack/unstract</title><link>https://github.com/Zipstack/unstract</link><author></author><category>trending</category><pubDate>Sat, 15 Feb 2025 02:26:24 +0000</pubDate><source url="http://mshibanami.github.io/GitHubTrendingRSS">Dev - Github Trending</source><content:encoded><![CDATA[No-code LLM Platform to launch APIs and ETL Pipelines to structure unstructured documentsPrompt Studio's primary reason for existence is so you can develop the necessary prompts for document data extraction super efficiently. It is a purpose-built environment that makes this not just easy for youâ€”but, lot of fun! The document sample, its variants, the prompts you're developing, outputs from different LLMs, the schema you're developing, costing details of the extraction and various tools that let you measure the effectiveness of your prompts are just a click away and easily accessible. Prompt Studio is designed for effective and high speed development and iteration of prompts for document data extraction. Welcome to IDP 2.0!ðŸ§˜â€â™€ï¸ Three step nirvana with Workflow StudioAutomate critical business processes that involve complex documents with a human in the loop. Go beyond RPA with the power of Large Language Models.ðŸŒŸ : Add documents to no-code Prompt Studio and do prompt engineering to extract required fields  ðŸŒŸ : Configure Prompt Studio project as API deployment or configure input source and output destination for ETL Pipeline ðŸŒŸ : Deploy Workflows as unstructured data APIs or unstructured data ETL Pipelines!Linux or MacOS (Intel or M-series)Docker Compose (if you need to install it separately)Next, either download a release or clone this repo and do the following:That's all there is to it!Follow these steps to change the default username and password.See user guide for more details on managing the platform. Another really quick way to experience Unstract is by signing up for our hosted version. It comes with a 14 day free trial!Unstract comes well documented. You can get introduced to the basics of Unstract, and learn how to connect various systems like LLMs, Vector Databases, Embedding Models and Text Extractors to it. The easiest way to wet your feet is to go through our Quick Start Guide where you actually get to do some prompt engineering in Prompt Studio and launch an API to structure varied credit card statements!Contributions are welcome! Please see CONTRIBUTING.md for further details to get started easily.ðŸ‘‹ Join the LLM-powered automation communityDo copy the value of  config in either  or  file to a secure location.Adapter credentials are encrypted by the platform using this key. Its loss or change will make all existing adapters inaccessible!In full disclosure, Unstract integrates Posthog to track usage analytics. As you can inspect the relevant code here, we collect the minimum possible metrics. Posthog can be disabled if desired by setting  to  in the frontend's .env file.]]></content:encoded></item><item><title>OpenZeppelin/openzeppelin-contracts</title><link>https://github.com/OpenZeppelin/openzeppelin-contracts</link><author></author><category>trending</category><pubDate>Fri, 14 Feb 2025 02:27:05 +0000</pubDate><source url="http://mshibanami.github.io/GitHubTrendingRSS">Dev - Github Trending</source><content:encoded><![CDATA[OpenZeppelin Contracts is a library for secure smart contract development.A library for secure smart contract development. Build on a solid foundation of community-vetted code.Not sure how to get started? Check out Contracts Wizard â€” an interactive smart contract generator.Want to scale your decentralized application? Check out OpenZeppelin Defender â€” a mission-critical developer security platform to code, audit, deploy, monitor, and operate with confidence.[!IMPORTANT] OpenZeppelin Contracts uses semantic versioning to communicate backwards compatibility of its API and storage layout. For upgradeable contracts, the storage layout of different major versions should be assumed incompatible, for example, it is unsafe to upgrade from 4.9.3 to 5.0.0. Learn more at Backwards Compatibility.$ npm install @openzeppelin/contracts
[!WARNING] When installing via git, it is a common error to use the  branch. This is a development branch that should be avoided in favor of tagged releases. The release process involves security measures that the  branch does not guarantee.[!WARNING] Foundry installs the latest version initially, but subsequent  commands will use the  branch.$ forge install OpenZeppelin/openzeppelin-contracts
Add @openzeppelin/contracts/=lib/openzeppelin-contracts/contracts/ in Once installed, you can use the contracts in the library by importing them:pragma solidity ^0.8.20;

import {ERC721} from "@openzeppelin/contracts/token/ERC721/ERC721.sol";

contract MyCollectible is ERC721 {
    constructor() ERC721("MyCollectible", "MCO") {
    }
}
If you're new to smart contract development, head to Developing Smart Contracts to learn about creating a new project and compiling your contracts.To keep your system secure, you should  use the installed code as-is, and neither copy-paste it from online sources nor modify it yourself. The library is designed so that only the contracts and functions you use are deployed, so you don't need to worry about it needlessly increasing gas costs.The guides in the documentation site will teach about different concepts, and how to use the related contracts that OpenZeppelin Contracts provides:Access Control: decide who can perform each of the actions on your system.Tokens: create tradeable assets or collectives, and distribute them via Crowdsales.Utilities: generic useful tools including non-overflowing math, signature verification, and trustless paying systems.The full API is also thoroughly documented, and serves as a great reference when developing your smart contract application. You can also ask for help or follow Contracts' development in the community forum.Finally, you may want to take a look at the guides on our blog, which cover several common use cases and good practices. The following articles provide great background reading, though please note that some of the referenced tools have changed, as the tooling in the ecosystem continues to rapidly evolve.This project is maintained by OpenZeppelin with the goal of providing a secure and reliable library of smart contract components for the ecosystem. We address security through risk management in various areas such as engineering and open source best practices, scoping and API design, multi-layered review processes, and incident response preparedness.The security policy is detailed in  as well, and specifies how you can report security vulnerabilities, which versions will receive security patches, and how to stay informed about them. We run a bug bounty program on Immunefi to reward the responsible disclosure of vulnerabilities.The engineering guidelines we follow to promote project quality can be found in .Past audits can be found in .Smart contracts are a nascent technology and carry a high level of technical risk and uncertainty. Although OpenZeppelin is well known for its security audits, using OpenZeppelin Contracts is not a substitute for a security audit.OpenZeppelin Contracts is made available under the MIT License, which disclaims all warranties in relation to the project and which limits the liability of those that contribute and maintain the project, including OpenZeppelin. As set out further in the Terms, you acknowledge that you are solely responsible for any use of OpenZeppelin Contracts and you assume all risks associated with any such use.OpenZeppelin Contracts exists thanks to its contributors. There are many ways you can participate and help build high quality software. Check out the contribution guide!OpenZeppelin Contracts is released under the MIT License.]]></content:encoded></item><item><title>nocodb/nocodb</title><link>https://github.com/nocodb/nocodb</link><author></author><category>trending</category><pubDate>Fri, 14 Feb 2025 02:27:05 +0000</pubDate><source url="http://mshibanami.github.io/GitHubTrendingRSS">Dev - Github Trending</source><content:encoded><![CDATA[ðŸ”¥ ðŸ”¥ ðŸ”¥ Open Source Airtable Alternative NocoDB is the fastest and easiest way to build databases online. docker run -d \
  --name noco \
  -v "$(pwd)"/nocodb:/usr/app/data/ \
  -p 8080:8080 \
  nocodb/nocodb:latest
docker run -d \
  --name noco \
  -v "$(pwd)"/nocodb:/usr/app/data/ \
  -p 8080:8080 \
  -e NC_DB="pg://host.docker.internal:5432?u=root&p=password&d=d1" \
  -e NC_AUTH_JWT_SECRET="569a1821-0a93-45e8-87ab-eb857f20a010" \
  nocodb/nocodb:latest
nix run github:nocodb/nocodb
To use NocoDB as a NixOS module, a flake.nix would be as follows:{
  description = "Bane's NixOS configuration";

  inputs = {
    nixpkgs.url = "github:nixos/nixpkgs/nixos-unstable";
    nocodb.url = "github:nocodb/nocodb";
  };

  outputs = inputs@{ nixpkgs, nocodb, ... }: {
    nixosConfigurations = {
      hostname = nixpkgs.lib.nixosSystem {
        system = "x86_64-linux";
        modules = [
          ./configuration.nix
          nocodb.nixosModules.nocodb

          {
            services.nocodb.enable = true;
          }
        ];
      };
    };
  };
}
Auto-upstall is a single command that sets up NocoDB on a server for production usage. Behind the scenes it auto-generates docker-compose for you.bash <(curl -sSL http://install.nocodb.com/noco.sh) <(mktemp)
Auto-upstall does the following: ðŸ•ŠðŸ³ Automatically installs all pre-requisites like docker, docker-composeðŸš€ Automatically installs NocoDB with PostgreSQL, Redis, Minio, Traefik gateway using Docker Compose. ðŸ˜ ðŸ—„ï¸ ðŸŒðŸ”„ Automatically upgrades NocoDB to the latest version when you run the command again.ðŸ”’ Automatically setups SSL and also renews it. Needs a domain or subdomain as input while installation.Binaries are only for quick testing locally.curl http://get.nocodb.com/macos-arm64 -o nocodb -L && chmod +x nocodb && ./nocodbcurl http://get.nocodb.com/macos-x64 -o nocodb -L && chmod +x nocodb && ./nocodbcurl http://get.nocodb.com/linux-arm64 -o nocodb -L && chmod +x nocodb && ./nocodbcurl http://get.nocodb.com/linux-x64 -o nocodb -L && chmod +x nocodb && ./nocodbiwr http://get.nocodb.com/win-arm64.exe -OutFile Noco-win-arm64.exe && .\Noco-win-arm64.exeiwr http://get.nocodb.com/win-x64.exe -OutFile Noco-win-x64.exe && .\Noco-win-x64.exeFor more installation methods, please refer to our docsRich Spreadsheet Interfaceâš¡ Â Basic Operations: Create, Read, Update and Delete Tables, Columns, and Rowsâš¡ Â Fields Operations: Sort, Filter, Group, Hide / Unhide Columnsâš¡ Â Multiple Views Types: Grid (By default), Gallery, Form, Kanban and Calendar Viewâš¡ Â View Permissions Types: Collaborative Views, & Locked Viewsâš¡ Â Share Bases / Views: either Public or Private (with Password Protected)âš¡ Â Variant Cell Types: ID, Links, Lookup, Rollup, SingleLineText, Attachment, Currency, Formula, User, etcâš¡ Â Access Control with Roles: Fine-grained Access Control at different levelsApp Store for Workflow AutomationsWe provide different integrations in three main categories. See App Store for details.âš¡ Â Chat: Slack, Discord, Mattermost, and etcâš¡ Â Email: AWS SES, SMTP, MailerSend, and etcâš¡ Â Storage: AWS S3, Google Cloud Storage, Minio, and etcWe provide the following ways to let users programmatically invoke actions. You can use a token (either JWT or Social Auth) to sign your requests for authorization to NocoDB.Most internet businesses equip themselves with either spreadsheet or a database to solve their business needs. Spreadsheets are used by Billion+ humans collaboratively every single day. However, we are way off working at similar speeds on databases which are way more powerful tools when it comes to computing. Attempts to solve this with SaaS offerings have meant horrible access controls, vendor lock-in, data lock-in, abrupt price changes & most importantly a glass ceiling on what's possible in the future.Our mission is to provide the most powerful no-code interface for databases that is open source to every single internet business in the world. This would not only democratise access to a powerful computing tool but also bring forth a billion+ people who will have radical tinkering-and-building abilities on the internet. This project is licensed under AGPLv3. Thank you for your contributions! We appreciate all the contributions from the community.]]></content:encoded></item><item><title>ant-design/ant-design</title><link>https://github.com/ant-design/ant-design</link><author></author><category>trending</category><pubDate>Fri, 14 Feb 2025 02:27:05 +0000</pubDate><source url="http://mshibanami.github.io/GitHubTrendingRSS">Dev - Github Trending</source><content:encoded><![CDATA[An enterprise-class UI design language and React UI libraryðŸŒˆ Enterprise-class UI designed for web applications.ðŸ“¦ A set of high-quality React components out of the box.ðŸ›¡ Written in TypeScript with predictable static types.âš™ï¸ Whole package of design resources and development tools.ðŸŒ Internationalization support for dozens of languages.ðŸŽ¨ Powerful theme customization based on CSS-in-JS.import { Button, DatePicker } from 'antd';

export default () => (
  <>
    <Button type="primary">PRESS ME</Button>
    <DatePicker placeholder="select date" />
  </>
);
Use opensumi.run, a free online pure front-end dev environment.$ git clone git@github.com:ant-design/ant-design.git
$ cd ant-design
$ npm install
$ npm start
Let's build a better antd together.We use Polar.sh and Issuehunt to up-vote and promote specific features that you would like to see and implement. Check our backlog and help us:]]></content:encoded></item><item><title>netdata/netdata</title><link>https://github.com/netdata/netdata</link><author></author><category>trending</category><pubDate>Fri, 14 Feb 2025 02:27:05 +0000</pubDate><source url="http://mshibanami.github.io/GitHubTrendingRSS">Dev - Github Trending</source><content:encoded><![CDATA[Architected for speed. Automated for easy. Monitoring and troubleshooting, transformed!Monitor your servers, containers, and applicationsin high-resolution and in real-time. People get addicted to Netdata. Once you use it on your systems, Netdata: Real-time Observability, Simplified.Netdata is a high-performance observability platform designed to simplify modern infrastructure monitoring. With its innovative distributed architecture, Netdata delivers real-time insights into your systems, containers, and applications at a granular level.: Per-second data collection provides immediate visibility into your infrastructure's behavior.: Start monitoring in minutes with automatic detection and instant insights.: Automatic anomaly detection and pattern recognition, helping you identify issues before they become critical.: Scale from a single node to thousands while maintaining performance and ease of use.: From infrastructure to applications, logs to metrics, all in one solution.: Process and store metrics at the edge for superior performance and cost efficiency.: Rich, interactive dashboard for deep system insights and rapid troubleshooting.: This repository contains the Netdata Agent, the open-source core of the Netdata ecosystem. For information about other components, see below.This three-part architecture enables Netdata to scale seamlessly from single-node deployments to complex multi-cloud environments with thousands of nodes, supporting long-term data retention without compromising performance.â€¢ The heart of Netdata's monitoring capabilitiesâ€¢ Handles data collection, storage, querying, ML analysis, exports, and alertsâ€¢ Runs on physical/virtual servers, cloud, Kubernetes, and IoT devicesâ€¢ Optimized for zero production impactâ€¢ Core of all observability featuresâ€¢ Adds enterprise-grade features: â€ƒ - User management and RBAC â€ƒ - Centralized alert management â€ƒ - Access your infrastructure from anywhereâ€¢ Available as SaaS or on-premisesâ€¢ Includes free community tierâ€¢ Does not centralize metric storageâ€¢ Powers all dashboards and visualizationsâ€¢ Free to use with both Agent and Cloudâ€¢ Included in standard Netdata packagesâ€¢ Latest version available via CDNKey capabilities of the Netdata AgentWith these capabilities, Netdata Agent provides a powerful, automated monitoring solution that works right out-of-the-box while remaining highly customizable for specific needs.Comprehensive Data Collectionâ€¢ 800+ integrations out of the boxâ€¢ Collects metrics from systems, containers, VMs, hardware sensorsâ€¢ Supports OpenMetrics exporters, StatsD, and logsâ€¢ OpenTelemetry support coming soonâ€¢ Per-second data collectionâ€¢ Real-time visualization with 1-second latencyâ€¢ High-resolution metrics for precise monitoringâ€¢ Trains ML models directly at the edgeâ€¢ Automatic anomaly detection per metricâ€¢ Pattern recognition based on historical behaviorâ€¢ Direct systemd-journald and Windows Event Log integrationsâ€¢ Tools for log conversion (log2journal, systemd-cat-native)â€¢ Process logs at the edge - no centralization neededâ€¢ Rich log visualization dashboardsâ€¢ Build Parent-Child relationships between Agentsâ€¢ Create flexible centralization pointsâ€¢ Control data replication and retention at multiple levelsâ€¢ NIDL (Nodes, Instances, Dimensions & Labels) data modelâ€¢ Auto-generated, correlated dashboardsâ€¢ Filter and analyze data without query languageâ€¢ Free to use, powered by Netdata UIâ€¢ Hundreds of pre-configured alertsâ€¢ Detect common issues automaticallyâ€¢ Multiple notification methodsâ€¢ Proactive problem detectionâ€¢ Auto-detection of metricsâ€¢ Zero-touch machine learningâ€¢ CI/CD friendly deploymentâ€¢ Modular architectureâ€¢ Easy to extend and customizeâ€¢ Integrates with existing monitoring toolsâ€¢ Active community ecosystemWhat can be monitored with the Netdata AgentNetdata monitors all the following:CPU, Memory and system shared resourcesDisks, Mount points, Filesystems, RAID arraysNetwork Interfaces, Protocols, Firewall, etcFans, Temperatures, Controllers, GPUs, etcResources, Performance and StatusResources, Performance, OOM, and moreSystem and Application Yes, andEvent Tracing for WindowsLive TCP and UDP sockets per PIDDocker/containerd, LXC/LXD, Kubernetes, etc (from the host)KVM, qemu, libvirt, Proxmox, etcTest APIs, TCP ports, Ping, Certificates, etcnginx, apache, postgres, redis, mongodb,Cloud Provider InfrastructureAWS, GCP, Azure, and moreOpenMetrics, StatsD and soon OpenTelemetryWhen the Netdata Agent runs on Linux, it monitors every kernel feature available, providing full coverage of all kernel technologies and offers full  coverage, monitoring all components that provide hardware error reporting, like PCI AER, RAM EDAC, IPMI, S.M.A.R.T., NVMe, Fans, Power, Voltages, and more. Netdata is the most energy-efficient monitoring tool The impact of monitoring on the energy efficiency of Docker-based systemsThe impact of monitoring on Docker-based systems?ðŸš€ Netdata excels in energy efficiency: "... Netdata is the most energy-efficient tool ...", as the study says.ðŸš€ Netdata excels in CPU Usage, RAM Usage and Execution Time, and has a similar impact on Network Traffic as Prometheus.The study didnâ€™t normalize the results based on the number of metrics collected. Given that Netdata usually collects significantly more metrics than the other tools, Netdata managed to outperform the other tools, while ingesting a much higher number of metrics. Read the full study here.Netdata vs Prometheus 2025 ReviewNEW! On the same workload, Netdata uses , consumes , performes  and stores  while being up to  in query responses! Read the full 2025 review in our blog. Netdata actively supports and is a member of the Cloud Native Computing Foundation (CNCF), it is one of the most 'd projects in the CNCF landscape! 1. Install Netdata everywhereNetdata can be installed on all Linux, macOS, FreeBSD (and soon on Windows) systems. We provide binary packages for the most popular operating systems and package managers.By default, you will have immediately available a local dashboard. Netdata starts a web server for its dashboard at port . Open up your web browser of choice and navigate to , replacing  with the IP address or hostname of your Agent. If installed on localhost, you can access it through .Note: the binary packages we provide, install Netdata UI automatically. Netdata UI is closed-source, but free to use with Netdata Agents and Netdata Cloud.Netdata auto-detects and auto-discovers most operating system data sources and applications. However, many data sources require some manual configuration, usually to allow Netdata to get access to the metrics.For a detailed list of the 800+ collectors available, check this guide.To monitor Windows servers and applications, use this guide.Note that Netdata on Windows is at its final release stage, so at the next Netdata release Netdata will natively support Windows.3. Configure Alert NotificationsNetdata comes with hundreds of pre-configured alerts that automatically check your metrics immediately after they start getting collected.Netdata can dispatch alert notifications to multiple third party systems, including: , , , , , , , , , , , , , , , , , , , , , , .By default, Netdata will send e-mail notifications if there is a configured MTA on the system.4. Configure Netdata ParentsOptionally, configure one or more Netdata Parents. A Netdata Parent is a Netdata Agent that has been configured to accept streaming connections from other Netdata Agents.Infrastructure level dashboards, at http://parent.server.ip:19999/.Each Netdata Agent has an API listening at the TCP port 19999 of each server. When you hit that port with a web browser (e.g. ), the Netdata Agent UI is presented. When the Netdata Agent is also a Parent, the UI of the Parent includes data for all nodes that stream metrics to that Parent.Increased retention for all metrics of all your nodes.Each Netdata Agent maintains each own database of metrics. But Parents can be given additional resources to maintain a much longer database than individual Netdata Agents.Central configuration of alerts and dispatch of notifications.Using Netdata Parents, all the alert notifications integrations can be configured only once at the Parent and they can be disabled at the Netdata Agents.You can also use Netdata Parents to:Offload your production systems (the parents run ML, alerts, queries, etc. for all their children)Secure your production systems (the parents accept user connections for all their children)5. Sign-in to Netdata Cloud and connect your Netdata Agents and Parents. If you connect your Netdata Parents, there is no need to connect your Netdata Agents. They will be connected via the Parents.When your Netdata nodes are connected to Netdata Cloud, you can (on top of the above):Access your Netdata Agents from anywhereAccess sensitive Netdata Agent features (like "Netdata Functions": processes, systemd-journal)Organize your infra in spaces and RoomsCreate, manage, and share Invite your team and assign roles to them (Role-Based Access Control)Get infinite horizontal scalability (multiple independent Netdata Agents are viewed as one infra)Configure alerts from the UIConfigure data collection from the UINetdata Mobile App notifications Netdata Cloud doesnâ€™t prevent you from using your Netdata Agents and Parents directly, and vice versa. Your metrics are still stored in your network when you connect your Netdata Agents and Parents to Netdata Cloud.Netdata is built around a modular metrics processing pipeline.Of course, it is! We do our best to ensure it is! Will Netdata consume significant resources on my servers?No, it will not! We promise this will be fast! How much retention can I have? Does it scale? I really have a lot of servers!Netdata is designed to scale and can handle large volumes of data. My production servers are very sensitive in disk I/O. Can I use Netdata? How is Netdata different from a Prometheus and Grafana setup?Netdata is a "ready to use" monitoring solution. Prometheus and Grafana are tools to build your own monitoring solution.Netdata is also a lot faster, requires significantly fewer resources and puts almost no stress on the server it runs. For a performance comparison check this blog. How is Netdata different from DataDog, New Relic, Dynatrace, X SaaS Provider?With Netdata your data are always on-prem and your metrics are always high-resolution. How is Netdata different from Nagios, Icinga, Zabbix, etc.?Netdata offers real-time, comprehensive monitoring and the ability to monitor everything without any custom configuration required. I feel overwhelmed by the amount of information in Netdata. What should I do?Netdata is designed to provide comprehensive insights, but we understand that the richness of information might sometimes feel overwhelming. Here are some tips on how to navigate and use Netdata effectively... Do I have to subscribe to Netdata Cloud?Netdata Cloud delivers the full suite of features and functionality that Netdata offers, including a free community tier.While our default onboarding process encourages users to take advantage of Netdata Cloud, including a complimentary one-month trial of our full business product, it is not mandatory. Users can bypass this process entirely and still use the Netdata Agents along with the Netdata UI, without the need to sign up for Netdata Cloud. What does the anonymous telemetry collected by Netdata entail?Your privacy is our utmost priority. As part of our commitment to improving Netdata, we rely on anonymous telemetry data from our users who choose to leave it enabled. This data greatly informs our decision-making processes and contributes to the future evolution of Netdata.Should you wish to disable telemetry, instructions for doing so are provided in our installation guides.Netdata is a widely adopted project...The  is open-source, but the overall Netdata ecosystem is a hybrid solution, combining open-source and closed-source components. What is your monetization strategy?Netdata generates revenue through subscriptions to advanced features of Netdata Cloud and sales of on-premise and private versions of Netdata Cloud.This site also hosts a number of guides to help newer users better understand how to collect metrics, troubleshoot via charts, export to external databases, and more.Netdata is an inclusive open-source project and community. Please read our Code of Conduct.Join the Netdata community: The Netdata team and community members have regular online meetups.You are welcome to join us!Click here for the schedule.Contributions are essential to the success of open-source projects. In other words, we need your help to keep Netdata great!What is a contribution? All the following are highly valuable to Netdata:Let us know of the best practices you believe should be standardized Netdata should out-of-the-box detect as many infrastructure issues as possible. By sharing your knowledge and experiences, you help us build a monitoring solution that has baked into it all the best-practices about infrastructure monitoring.Let us know if Netdata is not perfect for your use case We aim to support as many use cases as possible and your feedback can be invaluable. Open a GitHub issue, or start a GitHub discussion about it, to discuss how you want to use Netdata and what you need.Although we can't implement everything imaginable, we try to prioritize development on use-cases that are common to our community, are in the same direction we want Netdata to evolve and are aligned with our roadmap.Support other community members Join our community on GitHub, Discord, and Reddit. Generally, Netdata is relatively easy to set up and configure, but still people may need a little push in the right direction to use it effectively. Supporting other members is a great contribution by itself!Add or improve integrations you need Integrations tend to be easier and simpler to develop. If you would like to contribute your code to Netdata, we suggest that you start with the integrations you need, which Netdata doesnâ€™t currently support.General information about contributions:Read our Contributing Guide, which contains all the information you need to contribute to Netdata, such as improving our documentation, engaging in the community, and developing new features. We've made it as frictionless as possible, but if you need help, just ping us on our community forums!Package maintainers should read the guide on building Netdata from source for instructions on building each Netdata component from the source and preparing a package.The Netdata ecosystem consists of three key parts:: The heart of the Netdata ecosystem, the Netdata Agent is an open-source tool that must be installed on all systems monitored by Netdata. It offers a wide range of essential features, including data collection via various plugins, an embedded high-performance time-series database (dbengine), unsupervised anomaly detection powered by edge-trained machine learning, alerting and notifications, as well as query and scoring engines with associated APIs. Additionally, it supports exporting data to third-party monitoring systems, among other capabilities.: A commercial, closed-source component, Netdata Cloud enhances the capabilities of the open-source Netdata Agent by providing horizontal scalability, centralized alert notification dispatch (including a mobile app), user management, role-based access control, and other enterprise-grade features. It is available both as a SaaS solution and for on-premises deployment, with a free-to-use community tier also offered.: The Netdata UI is closed-source, and handles all visualization and dashboard functionalities related to metrics, logs and other collected data, as well as the central configuration and management of the Netdata ecosystem. It serves both the Netdata Agent and Netdata Cloud. The Netdata UI is distributed in binary form with the Netdata Agent and is publicly accessible via a CDN, licensed under the Netdata Cloud UI License 1 (NCUL1). It integrates third-party open-source components, detailed in the Netdata UI third-party licenses.The binary installation packages provided by Netdata include the Netdata Agent and the Netdata UI. Since the Netdata Agent is open-source, it is frequently packaged by third parties (e.g., Linux Distributions) excluding the closed-source components (Netdata UI is not included). While their packages can still be useful in providing the necessary back-ends and the APIs of a fully functional monitoring solution, we recommend using the installation packages we provide to experience the full feature set of Netdata.]]></content:encoded></item><item><title>RexanWONG/text-behind-image</title><link>https://github.com/RexanWONG/text-behind-image</link><author></author><category>trending</category><pubDate>Fri, 14 Feb 2025 02:27:05 +0000</pubDate><source url="http://mshibanami.github.io/GitHubTrendingRSS">Dev - Github Trending</source><content:encoded><![CDATA[https://textbehindimage.rexanwong.xyz - create text behind image designs easilyNOTE: Here are the links associated with text-behind-image (where can you find and use this app):Recently, some copycats with the EXACT SAME landing page and design have been created. Please be aware of these sites.Thank you all! No audience, no show :)]]></content:encoded></item><item><title>cypress-io/cypress</title><link>https://github.com/cypress-io/cypress</link><author></author><category>trending</category><pubDate>Fri, 14 Feb 2025 02:27:05 +0000</pubDate><source url="http://mshibanami.github.io/GitHubTrendingRSS">Dev - Github Trending</source><content:encoded><![CDATA[Fast, easy and reliable testing for anything that runs in a browser. The web has evolved. Finally, testing has too.  Fast, easy and reliable testing for anything that runs in a browser. Install Cypress for Mac, Linux, or Windows, then get started.npm install cypress --save-dev
pnpm add cypress --save-dev
This project is licensed under the terms of the MIT license.Configure a badge for your project's README to show your test status or test count in the Cypress Cloud.Or let the world know your project is using Cypress with the badge below.[![Cypress.io](https://img.shields.io/badge/tested%20with-Cypress-04C38E.svg)](https://www.cypress.io/)
]]></content:encoded></item><item><title>Kong/kong</title><link>https://github.com/Kong/kong</link><author></author><category>trending</category><pubDate>Fri, 14 Feb 2025 02:27:05 +0000</pubDate><source url="http://mshibanami.github.io/GitHubTrendingRSS">Dev - Github Trending</source><content:encoded><![CDATA[ðŸ¦ The Cloud-Native API Gateway and AI Gateway. or  is a cloud-native, platform-agnostic, scalable API Gateway distinguished for its high performance and extensibility via plugins. It also provides advanced AI capabilities with multi-LLM support.By providing functionality for proxying, routing, load balancing, health checking, authentication (and more), Kong serves as the central layer for orchestrating microservices or conventional API traffic with ease.If you prefer to use a cloud-hosted Kong, you can sign up for a free trial of Kong Konnect and get started in minutes. If not, you can follow the instructions below to get started with Kong on your own infrastructure.Letâ€™s test drive Kong by adding authentication to an API in under 5 minutes.We suggest using the docker-compose distribution via the instructions below, but there is also a docker installation procedure if youâ€™d prefer to run the Kong API Gateway in DB-less mode.Whether youâ€™re running in the cloud, on bare metal, or using containers, you can find every supported distribution on our official installation page.To start, clone the Docker repository and navigate to the compose folder.  $ git clone https://github.com/Kong/docker-kong
  $ cd docker-kong/compose/
Start the Gateway stack using:  $ KONG_DATABASE=postgres docker-compose --profile database up
The Gateway is now available on the following ports on localhost: - send traffic to your service via Kong - configure Kong using Admin API or via decKBy centralizing common API functionality across all your organization's services, the Kong API Gateway creates more freedom for engineering teams to focus on the challenges that matter most.The top Kong features include:Advanced routing, load balancing, health checking - all configurable via a RESTful admin API or declarative configuration.Authentication and authorization for APIs using methods like JWT, basic auth, OAuth, ACLs and more.Proxy, SSL/TLS termination, and connectivity support for L4 or L7 traffic.Plugins for enforcing traffic controls, rate limiting, req/res transformations, logging, monitoring and including a plugin developer hub.Plugins for AI traffic to support multi-LLM implementations and no-code AI use cases, with advanced AI prompt engineering, AI observability, AI security and more.Sophisticated deployment models like Declarative Databaseless Deployment and Hybrid Deployment (control plane/data plane separation) without any vendor lock-in.Plugins provide advanced functionality that extends the use of the Gateway. Many of the Kong Inc. and community-developed plugins like AWS Lambda, Correlation ID, and Response Transformer are showcased at the Plugin Hub.Contribute to the Plugin Hub and ensure your next innovative idea is published and available to the broader community!We â¤ï¸ pull requests, and weâ€™re continually working hard to make it as easy as possible for developers to contribute. Before beginning development with the Kong API Gateway, please familiarize yourself with the following developer resources:Kong Inc. offers commercial subscriptions that enhance the Kong API Gateway in a variety of ways. Customers of Kong's Konnect Cloud subscription take advantage of additional gateway functionality, commercial support, and access to Kong's managed (SaaS) control plane platform. The Konnect Cloud platform features include real-time analytics, a service catalog, developer portals, and so much more! Get started with Konnect Cloud.Copyright 2016-2024 Kong Inc.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

   https://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
]]></content:encoded></item><item><title>juspay/hyperswitch</title><link>https://github.com/juspay/hyperswitch</link><author></author><category>trending</category><pubDate>Thu, 13 Feb 2025 02:27:07 +0000</pubDate><source url="http://mshibanami.github.io/GitHubTrendingRSS">Dev - Github Trending</source><content:encoded><![CDATA[An open source payments switch written in Rust to make payments fast, reliable and affordable
  Single API to access the payments ecosystem and its features 
 Juspay, founded in 2012, is a global leader in payment orchestration and checkout solutions, trusted by 400+ leading enterprises and brands worldwide. Hyperswitch is Juspay's new generation of composable, commercial open-source payments platform for merchant and brands. It is an enterprise-grade, transparent and modular payments platform designed to provide digital businesses access to the best payments infrastructure. 
Here are the key components of Hyperswitch that deliver the whole solution:Hyperswitch Backend: Hyperswitch backend enables seamless payment processing with comprehensive support for various payment flows - authorization, authentication, void and capture workflows along with robust management of post-payment processes like refunds and chargeback handling. Additionally, Hyperswitch supports non-payment use cases by enabling connections with external FRM or authentication providers as part of the payment flow. The backend optimizes payment routing with customizable workflows, including success rate-based routing, rule-based routing, volume distribution, fallback handling, and intelligent retry mechanisms for failed payments based on specific error codes.SDK (Frontend): The SDK, available for web, Android, and iOS, unifies the payment experience across various methods such as cards, wallets, BNPL, bank transfers, and more, while supporting the diverse payment flows of underlying PSPs. When paired with the locker, it surfaces the user's saved payment methods.Control Center: The Control Center enables users to manage the entire payments stack without any coding. It allows the creation of workflows for routing, payment retries, and defining conditions to invoke 3DS, fraud risk management (FRM), and surcharge modules. The Control Center provides access to transaction, refund, and chargeback operations across all integrated PSPs, transaction-level logs for initial debugging, and detailed analytics and insights into payment performance.You can run Hyperswitch on your system using Docker compose after cloning this repository.git clone --depth 1 --branch latest https://github.com/juspay/hyperswitch
cd hyperswitch
docker compose up -d
Check out the local setup guide for a more details on setting up the entire stack or component wise. This takes 15-mins and gives the following output[+] Running 2/2
âœ” hyperswitch-control-center Pulled 2.9s
âœ” hyperswitch-server Pulled 3.0s
[+] Running 6/0

âœ” Container hyperswitch-pg-1 Created 0.0s
âœ” Container hyperswitch-redis-standalone-1 Created 0.0s
âœ” Container hyperswitch-migration_runner-1 Created 0.0s
âœ” Container hyperswitch-hyperswitch-server-1 Created 0.0s
âœ” Container hyperswitch-hyperswitch-web-1 Created 0.0s
âœ” Container hyperswitch-hyperswitch-control-center-1 Created 0.0s

Attaching to hyperswitch-control-center-1, hyperswitch-server-1, hyperswitch-web-1, migration_runner-1, pg-1, redis-standalone-1
The fastest and easiest way to try Hyperswitch on AWS is via our CDK scriptsClick on the following button for a quick standalone deployment on AWS, suitable for prototyping. No code or setup is required in your system and the deployment is covered within the AWS free-tier setup.Sign-in to your AWS console.Follow the instructions provided on the console to successfully deploy Hyperswitch. This takes 30-45mins and gives the following outputhttp://hyperswitch-<host-id.region>.elb.amazonaws.comhttp://<cloudfront.host-id>/0.103.1/v0/HyperLoader.jsControl center server running onhttp://hyperswitch-control-center-<host-id.region>.elb.amazonaws.com, Login with Email: Hyperswitch Demo Store running onhttp://hyperswitch-sdk-demo-<host-id.region>.elb.amazonaws.comhttp://hyperswitch-logs-<host-id.region>.elb.amazonaws.com, Login with username: , password: We support deployment on GCP and Azure via Helm charts which takes 30-45mins. You can read more at Hyperswitch docs.You can experience the product by signing up for our hosted sandbox. The signup process accepts any email ID and provides access to the entire Control Center. You can set up connectors, define workflows for routing and retries, and even try payments from the dashboard.Support, Feature requests & BugsFor any support, join the conversation in SlackFor new product features, enhancements, roadmap discussions, or to share queries and ideas, visit our GitHub DiscussionsPayments are evolving rapidly worldwide, with hundreds of processors, fraud detection systems, authentication modules, and new payment methods and flows emerging. Businesses building or managing their own payment stacks often face similar challenges, struggle with comparable issues, and find it hard to innovate at the desired pace.Hyperswitch serves as a well-architected designed reference platform, built on best-in-class design principles, empowering businesses to own and customize their payment stack. It provides a reusable core payments stack that can be tailored to specific requirements while relying on the Hyperswitch team for enhancements, support, and continuous innovation.Embrace Payments Diversity: It will drive innovation in the ecosystem in multiple ways.Make it Open Source: Increases trust; Improves the quality and reusability of software.Be community driven: It enables participatory design and development.Build it like Systems Software: This sets a high bar for Reliability, Security and Performance SLAs.Maximise Value Creation: For developers, customers & partners.This project is being created and maintained by JuspayThe core team of 150+ engineers building Hyperswitch. Keep up the great work! ðŸ¥‚]]></content:encoded></item><item><title>Oliveriver/5d-diplomacy-with-multiverse-time-travel</title><link>https://github.com/Oliveriver/5d-diplomacy-with-multiverse-time-travel</link><author></author><category>trending</category><pubDate>Thu, 13 Feb 2025 02:27:07 +0000</pubDate><source url="http://mshibanami.github.io/GitHubTrendingRSS">Dev - Github Trending</source><content:encoded><![CDATA[5D Diplomacy With Multiverse Time TravelA new standard in measuring how galaxy-brained you are, 5D Diplomacy With Multiverse Time Travel combines the classic game of pure negotiation with the modern classic game of pure disorientation. Can you convince your opponent to support an attack in the present while simultaneously backstabbing them five years ago and seven timelines over?Inspired by and indebted to the board game Diplomacy and the video game 5D Chess With Multiverse Time Travel. Both are excellent in their own right, so we recommend picking up a copy of each to understand the rules for 5D Diplomacy. is a trademark of Avalon Hill. 5D Chess With Multiverse Time Travel is a trademark of Thunkspace, LLC. 5D Diplomacy With Multiverse Time Travel and its creators are not affiliated with either  or 5D Chess With Multiverse Time Travel.If you find a bug, please raise an issue.Note that official development of new features has come to an end. Issues requesting new or modified gameplay features will probably be rejected. Only bug fixes, performance improvements, and quality of life adjustments are likely to be accepted as suggestions.Feel free to fork this repo and modify the code there if you wish to experiment with more radical changes to the rules or UI. Visit the 5D Diplomacy Discord server to discuss new rules and theory with others.There are currently two options for installing 5D Diplomacy. Use quick installation if you just want to play the game. Use manual installation if you want to make code changes.The correct version of Docker for your operating system.Open Docker and leave it running.Open the CLI for your operating system and navigate inside the folder where you've downloaded this repository. If you don't know how to do this, use this tutorial.Via the CLI, run the command docker compose build frontend backend and wait for it to complete.Via the CLI, run the command  and wait for it to complete.Wait an extra few seconds for the server to start up. If you experience errors creating a game in the next step, try waiting longer.If you ever update the code (manually or via a pull from this repository), you will need to run docker compose down --rmi local, then run through the steps above again. Note that this may result in the database being wiped.To read server logs, run docker compose logs -f backend.The game consists of two components, found in the  and  directories. You must set up and run both to play 5D Diplomacy, unless you're connecting to someone else's server or have implemented a custom client.The  directory contains the original proof of concept from 2021. None of its contents are required for running the latest version of 5D Diplomacy.Navigate to the  directory.(Optional) If you want to connect to a custom database, copy  to create a new file in the same directory called appsettings.Development.json. Add your database's connection string as the value for the appropriate provider under , then set the value for  to match the name of the connection string.Run one of the following commands, depending on your configuration: 
  If you aren't using a custom database, i.e. if you didn't follow the optional step above, run dotnet ef database update --context SqliteGameContext.If you're using a custom SQLite database, run dotnet ef database update --context SqliteGameContext.If you're using a custom SQL Server database, run dotnet ef database update --context SqlServerGameContext.Run  to start the server.The server will print its address to the console, likely http://localhost:5000 but it may be different. Note this down for later.Note that if you ever update the code with changes that affect the database schema (e.g. if you pull a change from this repository that includes a new migration), you will have to run the appropriate dotnet ef database update command again.Navigate to the  directory.Copy  to create a new file in the same directory called .Inside , replace  with the address of the server noted earlier.Run  to start the client in the default browser.First see installation instructions above. 5D Diplomacy can be set to run normal games (where seven players join and enter orders individually) or sandbox games (where a single user enters all orders).If you wish to play a normal game or let other people see one of your sandbox games, you'll need to expose the domains of your client and/or server (if everyone has set up the client themselves, only a server needs to be exposed). There are various ways to do this, although this guide does not cover them.If you modify the code and host a game that others interact with, you must provide a link to your modified source code to comply with the terms of the AGPL license. We suggest updating the link to the source code in client/src/components/pages/LandingPage.tsx.To create a normal game, one player must choose the new game option from the main menu. They must choose the adjacency setting (see game rules below). After a game has been created, the initiating player enters the game and sees the game ID in the top left corner, which they must copy and send to other players.Other players can then use the join game option from the main menu to join with the supplied game ID.Note that 5D Diplomacy has no in-built messaging system. Unless you want to play without press, you require a separate program to send and receive press, e.g. a messaging app or voice calls.A possible exploit exists when playing multiplayer games. Since 5D Diplomacy has no user logins or verification, a player can join as someone else and enter their orders before them. The alternative - allowing each nation to join only once - would mean players can't rejoin after a break or connection issues. While Diplomacy is a game about breaking trust, you'll simply have to trust players not to be quite this devious.To create a sandbox game, select new game from the main menu and choose the sandbox option. Also set the adjacency setting (see game rules below).In sandbox mode, turns advance after submission whether all nations have orders or not.The rules of 5D Diplomacy generally extend the rules of regular Diplomacy. This guide covers only deviations from the rules of the base game.The game world consists of a grid of Diplomacy boards. Each row is a timeline, and each timeline progresses with boards following the standard Diplomacy turns (Spring 1901, then Fall 1901, then Winter 1901, then Spring 1902, etc.).At a given time, only units on the active boards (those furthest to the right in each timeline) can have new orders assigned. Other units are locked into their pre-existing orders, which can't be changed, though their resolution can.Units in spring or fall turns can be given hold, move, support or convoy orders. These are validated against standard Diplomacy adjacency rules, with extra possibilities for multiverse travel. The adjacency strictness setting (chosen when a new game is created) determines how units can move through the multiverse.With strict adjacencies, a unit can move/support/convoy to:Any adjacent region on its own board.The same region on a different board exactly one timeline up or down, e.g. moving from Paris in Timeline 2 to Paris in Timeline 1.The same region on a different board exactly one board in the past, e.g. moving from Berlin in Fall 1901 to Berlin in Spring 1901. Note that moving to winter boards is forbidden and these are skipped when determining board adjacencies, so Spring 1902 is adjacent to Fall 1901.Any region it is successfully convoyed to (see below).With loose adjacencies, a unit can move/support/convoy to:Any adjacent region on its own board.The same region on a different board exactly one timeline up or down, or any region adjacent to that region within its board, e.g. moving from Paris in Timeline 2 to Gascony in Timeline 1.The same region on a different board exactly one board in the past, or any region adjacent to that region within its board, e.g. moving from Berlin in Fall 1901 to Kiel in Spring 1901. Winter boards are still ignored.Any region it is successfully convoyed to (see below).In either case, note in particular that movement one board diagonally is not permitted (without a convoy).Convoys extend the quirk of standard Diplomacy that allows armies to move an arbitrary distance in a single turn if a chain of convoying fleets exists. Providing each fleet is adjacent to the next and all are ordered to perform the same convoy, an army could go almost anywhere.Units are however forbidden from moving into boards that don't exist yet, even with convoys. Convoys and supports though can anticipate a future unit moving back in time, so the player can use the ghost board to enter supports/convoys via an arbitrary location in the multiverse.Any units in (spring or fall) boards not assigned orders are given a hold order by default.The rule of thumb for adjudication: each time all orders for a turn are submitted, all orders in the entire world are adjudicated together, as if in a single enormous Diplomacy board.In particular, new orders could affect a prior resolution of existing orders, e.g. a unit that bounced now has support and so moves successfully. This extends to supports/convoys across time, e.g. convoys that were previously invalid may become valid if the future army appears and performs the expected move.If the new resolution matches an existing child board that spawned from this one, then no new timeline splits. So if two units bounced and both receive one new support from their relative future next turn, they still bounce and no new board is created (assuming no other changes elsewhere on this board).If the new resolution does not match an existing child board that spawned from this one, a new timeline appears. New timelines always appear below all existing timelines, and are always created in a canonical order (earliest board first; if boards are of equal age, lowest timeline number first).Note that this is different to 5D Chess where boards can spawn above or below existing timelines, potentially changing the coordinates of existing boards. There's no concept of a turn belonging to a player in Diplomacy (instead, they belong to everyone simultaneously) and 5D Diplomacy extends this thinking, so timelines spawn in only one direction. Board coordinates also never change.Main turns (spring and fall) and winter boards adjudicate simultaneously if all are at the end of their respective timelines. So a player may be creating builds on one board and creating moves on another in the same turn. Though of course these must be kept separate, so building is not permitted on movement boards and vice versa.Build/disband counts are per board. If a player controls fewer centres than they have units in one timeline but more in another, the difference does not cancel out: they must disband in the former and may build only in the latter. If they fail to enter enough disbands on a given board, units are removed from that board at random.If any board requires retreats, adjudication pauses for all boards without retreats. Retreats may only move to an adjacent region on the same board.A player achieves victory under one of the following conditions:They are the only player to control at least 18 unique supply centres across all active boards. Unique here means unique by region name, so controlling Serbia in Timeline 1 and Serbia in Timeline 2 counts as only one supply centre.If more than one player controls more than 18 unique supply centres, they are the only one with a clear majority. It's possible for two players to reach 18 centres in the same turn, e.g. if they have targeted different timelines.As with regular Diplomacy, it's possible for 5D Diplomacy to feature variant maps with completely different region arrangements. Other variants, such as variants with new rules, are not supported.Modifying the server to adjudicate custom variants in 5D is simple. First, edit the list of nations in . Then edit the JSON files in the folder  to match the intended board. Any subsequent run of the server will use those to create and adjudicate worlds.Modify  to change supply centres and starting/home centres.Modify  to change connections between regions.Modify  to change regions.Modify  to change starting units.Modifying the client is tricker as it is much more tied to this particular Diplomacy board. While client/src/data/regions.ts contains the list of regions and associated data, you will also need to replace the SVG files in  and then reference them in client/src/hooks/useRegionSvg.tsx.]]></content:encoded></item><item><title>Azure/Azure-Sentinel</title><link>https://github.com/Azure/Azure-Sentinel</link><author></author><category>trending</category><pubDate>Thu, 13 Feb 2025 02:27:07 +0000</pubDate><source url="http://mshibanami.github.io/GitHubTrendingRSS">Dev - Github Trending</source><content:encoded><![CDATA[Cloud-native SIEM for intelligent security analytics for your entire enterprise.Welcome to the unified Microsoft Sentinel and Microsoft 365 Defender repository! This repository contains out of the box detections, exploration queries, hunting queries, workbooks, playbooks and much more to help you get ramped up with Microsoft Sentinel and provide you security content to secure your environment and hunt for threats. The hunting queries also include Microsoft 365 Defender hunting queries for advanced hunting scenarios in both Microsoft 365 Defender and Microsoft Sentinel. You can also submit to issues for any samples or resources you would like to see here as you onboard to Microsoft Sentinel. This repository welcomes contributions and refer to this repository's wiki to get started. For questions and feedback, please contact AzureSentinel@microsoft.comWe value your feedback. Here are some channels to help surface your questions or feedback:This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit https://cla.microsoft.com.Add in your new or updated contributions to GitHubBrand new or update to a contribution via these methods:Details about the Proposed Changes are required, be sure to include a minimal level of detail so a review can clearly understand the reason for the change and what he change is related to in the code.Make changes as suggested and update your branch or explain why no change is needed. Resolve the comment when done.Pull Request Detection Template Structure Validation CheckAs part of the PR checks we run a structure validation to make sure all required parts of the YAML structure are included. For Detections, there is a new section that must be included. See the contribution guidelines for more information. If this section or any other required section is not included, then a validation error will occur similar to the below. The example is specifically if the YAML is missing the entityMappings section:A total of 1 test files matched the specified pattern.
[xUnit.net 00:00:00.95]     Kqlvalidations.Tests.DetectionTemplateStructureValidationTests.Validate_DetectionTemplates_HaveValidTemplateStructure(detectionsYamlFileName: "ExcessiveBlockedTrafficGeneratedbyUser.yaml") [FAIL]
  X Kqlvalidations.Tests.DetectionTemplateStructureValidationTests.Validate_DetectionTemplates_HaveValidTemplateStructure(detectionsYamlFileName: "ExcessiveBlockedTrafficGeneratedbyUser.yaml") [104ms]
  Error Message:
   Expected object to be <null>, but found System.ComponentModel.DataAnnotations.ValidationException with message "An old mapping for entity 'AccountCustomEntity' does not have a matching new mapping entry."
Pull Request KQL Validation CheckAs part of the PR checks we run a syntax validation of the KQL queries defined in the template. If this check fails go to Azure Pipeline (by pressing on the errors link on the checks tab in your PR)  In the pipeline you can see which test failed and what is the cause: A total of 1 test files matched the specified pattern.
[xUnit.net 00:00:01.81]     Kqlvalidations.Tests.KqlValidationTests.Validate_DetectionQueries_HaveValidKql(detectionsYamlFileName: "ExcessiveBlockedTrafficGeneratedbyUser.yaml") [FAIL]
  X Kqlvalidations.Tests.KqlValidationTests.Validate_DetectionQueries_HaveValidKql(detectionsYamlFileName: "ExcessiveBlockedTrafficGeneratedbyUser.yaml") [21ms]
  Error Message:
   Template Id:fa0ab69c-7124-4f62-acdd-61017cf6ce89 is not valid Errors:The name 'SymantecEndpointProtection' does not refer to any known table, tabular variable or function., Code: 'KS204', Severity: 'Error', Location: '67..93',The name 'SymantecEndpointProtection' does not refer to any known table, tabular variable or function., Code: 'KS204', Severity: 'Error', Location: '289..315'
If you are using custom logs table (a table which is not defined on all workspaces by default) you should verify your table schema is defined in json file in the folder Azure-Sentinel\.script\tests\KqlvalidationsTests\CustomTablesExample for table tablexyz.json{
  "Name": "tablexyz",
  "Properties": [
    {
      "Name": "SomeDateTimeColumn",
      "Type": "DateTime"
    },
    {
      "Name": "SomeStringColumn",
      "Type": "String"
    },
    {
      "Name": "SomeDynamicColumn",
      "Type": "Dynamic"
    }
  ]
}
Run KQL Validation LocallyIn order to run the KQL validation before submitting Pull Request in you local machine:Open Shell and navigate to Azure-Sentinel\\.script\tests\KqlvalidationsTests\Example of output (in Ubuntu):Welcome to .NET Core 3.1!
---------------------
SDK Version: 3.1.403

Telemetry
---------
The .NET Core tools collect usage data in order to help us improve your experience. The data is anonymous. It is collected by Microsoft and shared with the community. You can opt-out of telemetry by setting the DOTNET_CLI_TELEMETRY_OPTOUT environment variable to '1' or 'true' using your favorite shell.

Read more about .NET Core CLI Tools telemetry: https://aka.ms/dotnet-cli-telemetry

----------------
Explore documentation: https://aka.ms/dotnet-docs
Report issues and find source on GitHub: https://github.com/dotnet/core
Find out what's new: https://aka.ms/dotnet-whats-new
Learn about the installed HTTPS developer cert: https://aka.ms/aspnet-core-https
Use 'dotnet --help' to see available commands or visit: https://aka.ms/dotnet-cli-docs
Write your first app: https://aka.ms/first-net-core-app
--------------------------------------------------------------------------------------
Test run for /mnt/c/git/Azure-Sentinel/.script/tests/KqlvalidationsTests/bin/Debug/netcoreapp3.1/Kqlvalidations.Tests.dll(.NETCoreApp,Version=v3.1)
Microsoft (R) Test Execution Command Line Tool Version 16.7.0
Copyright (c) Microsoft Corporation.  All rights reserved.

Starting test execution, please wait...

A total of 1 test files matched the specified pattern.

Test Run Successful.
Total tests: 171
     Passed: 171
 Total time: 25.7973 Seconds
Detection schema validation testsSimilarly to KQL Validation, there is an automatic validation of the schema of a detection. The schema validation includes the detection's frequency and period, the detection's trigger type and threshold, validity of connectors Ids (valid connectors Ids list), etc. A wrong format or missing attributes will result with an informative check failure, which should guide you through the resolution of the issue, but make sure to look into the format of already approved detection.Run Detection Schema Validation LocallyIn order to run the KQL validation before submitting Pull Request in you local machine:Open Shell and navigate to Azure-Sentinel\\.script\tests\DetectionTemplateSchemaValidation\When you submit a pull request, a CLA-bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.For information on what you can contribute and further details, refer to the "get started" section on the project's wiki.]]></content:encoded></item><item><title>landing-ai/vision-agent</title><link>https://github.com/landing-ai/vision-agent</link><author></author><category>trending</category><pubDate>Thu, 13 Feb 2025 02:27:07 +0000</pubDate><source url="http://mshibanami.github.io/GitHubTrendingRSS">Dev - Github Trending</source><content:encoded><![CDATA[VisionAgent is a library that helps you utilize agent frameworks to generate code to solve your vision task. Check out our discord for updates and roadmaps! The fastest way to test out VisionAgent is to use our web application which you can find here.export ANTHROPIC_API_KEY="your-api-key"
export OPENAI_API_KEY="your-api-key"
 We found using both Anthropic Claude-3.5 and OpenAI o1 to be provide the best performance for VisionAgent. If you want to use a different LLM provider or only one, see 'Using Other LLM Providers' below.Counting cans in an imageYou can use VisionAgent to generate code to count the number of people in an image:from vision_agent.agent import VisionAgentCoderV2
from vision_agent.models import AgentMessage

agent = VisionAgentCoderV2(verbose=True)
code_context = agent.generate_code(
    [
        AgentMessage(
            role="user",
            content="Count the number of people in this image",
            media=["people.png"]
        )
    ]
)

with open("generated_code.py", "w") as f:
    f.write(code_context.code + "\n" + code_context.test)
VisionAgent produces code that utilizes our tools. You can also use the tools directly. For example if you wanted to detect people in an image and visualize the results:import vision_agent.tools as T
import matplotlib.pyplot as plt

image = T.load_image("people.png")
dets = T.countgd_object_detection("person", image)
# visualize the countgd bounding boxes on the image
viz = T.overlay_bounding_boxes(image, dets)

# save the visualization to a file
T.save_image(viz, "people_detected.png")

# display the visualization
plt.imshow(viz)
plt.show()
You can also use the tools for running on video files:import vision_agent.tools as T

frames_and_ts = T.extract_frames_and_timestamps("people.mp4")
# extract the frames from the frames_and_ts list
frames = [f["frame"] for f in frames_and_ts]

# run the countgd tracking on the frames
tracks = T.countgd_sam2_video_tracking("person", frames)
# visualize the countgd tracking results on the frames and save the video
viz = T.overlay_segmentation_masks(frames, tracks)
T.save_video(viz, "people_detected.mp4")
Using Other LLM ProvidersYou can use other LLM providers by changing  in the  directory. For example to change to Anthropic simply just run:cp vision_agent/configs/anthropic_config.py vision_agent/configs/config.py
 VisionAgent moves fast and we are constantly updating and changing the library. If you have any questions or need help, please reach out to us on our discord channel.]]></content:encoded></item><item><title>andrewyng/aisuite</title><link>https://github.com/andrewyng/aisuite</link><author></author><category>trending</category><pubDate>Thu, 13 Feb 2025 02:27:07 +0000</pubDate><source url="http://mshibanami.github.io/GitHubTrendingRSS">Dev - Github Trending</source><content:encoded><![CDATA[Simple, unified interface to multiple Generative AI providersSimple, unified interface to multiple Generative AI providers. makes it easy for developers to use multiple LLM through a standardized interface. Using an interface similar to OpenAI's,  makes it easy to interact with the most popular LLMs and compare the results. It is a thin wrapper around python client libraries, and allows creators to seamlessly swap out and test responses from different LLM providers without changing their code. Today, the library is primarily focussed on chat completions. We will expand it cover more use cases in near future.Currently supported providers are - OpenAI, Anthropic, Azure, Google, AWS, Groq, Mistral, HuggingFace Ollama, Sambanova and Watsonx. To maximize stability,  uses either the HTTP endpoint or the SDK for making calls to the provider.You can install just the base  package, or install a provider's package along with .This installs just the base package without installing any provider's SDK.This installs aisuite along with anthropic's library.pip install 'aisuite[anthropic]'
This installs all the provider-specific librariespip install 'aisuite[all]'
To get started, you will need API Keys for the providers you intend to use. You'll need to install the provider-specific library either separately or when installing aisuite.The API Keys can be set as environment variables, or can be passed as config to the aisuite Client constructor. You can use tools like  or  to set the environment variables manually. Please take a look at the  folder to see usage.Here is a short example of using  to generate chat completion responses from gpt-4o and claude-3-5-sonnet.export OPENAI_API_KEY="your-openai-api-key"
export ANTHROPIC_API_KEY="your-anthropic-api-key"
import aisuite as ai
client = ai.Client()

models = ["openai:gpt-4o", "anthropic:claude-3-5-sonnet-20240620"]

messages = [
    {"role": "system", "content": "Respond in Pirate English."},
    {"role": "user", "content": "Tell me a joke."},
]

for model in models:
    response = client.chat.completions.create(
        model=model,
        messages=messages,
        temperature=0.75
    )
    print(response.choices[0].message.content)

Note that the model name in the create() call uses the format - .  will call the appropriate provider with the right parameters based on the provider value. For a list of provider values, you can look at the directory - . The list of supported providers are of the format -  in that directory. We welcome providers adding support to this library by adding an implementation file in this directory. Please see section below for how to contribute.For more examples, check out the  directory where you will find several notebooks that you can run to experiment with the interface.aisuite is released under the MIT License. You are free to use, modify, and distribute the code for both commercial and non-commercial purposes.Adding support for a providerWe have made easy for a provider or volunteer to add support for a new platform.Naming Convention for Provider ModulesWe follow a convention-based approach for loading providers, which relies on strict naming conventions for both the module name and the class name. The format is based on the model identifier in the form .The provider's module file must be named in the format .The class inside this module must follow the format: the provider name with the first letter capitalized, followed by the suffix .: The provider class should be defined as:class HuggingfaceProvider(BaseProvider)
in providers/huggingface_provider.py.: The provider class should be defined as:class OpenaiProvider(BaseProvider)
in providers/openai_provider.pyThis convention simplifies the addition of new providers and ensures consistency across provider implementations.]]></content:encoded></item><item><title>MystenLabs/walrus-docs</title><link>https://github.com/MystenLabs/walrus-docs</link><author></author><category>trending</category><pubDate>Thu, 13 Feb 2025 02:27:07 +0000</pubDate><source url="http://mshibanami.github.io/GitHubTrendingRSS">Dev - Github Trending</source><content:encoded><![CDATA[Documentation and examples for the Walrus decentralized storage systemWelcome to the GitHub repository for Walrus, a decentralized storage and availability protocol designed specifically for large binary files, or "blobs". Walrus focuses on providing a robust solution for storing unstructured content on decentralized storage nodes while ensuring high availability and reliability even in the presence of Byzantine faults.You can also build and access the documentation locally (assuming you have Rust installed):cargo install mdbook
cargo install mdbook-admonish@1.18.0 --locked
cargo install mdbook-katex@0.9.0 --locked
cargo install mdbook-i18n-helpers --locked
mdbook serve
Using translated versionsIf there is a translated resource in  directory, it can be specified through the  environment variable. For example, to build or serve the Chinese translation:MDBOOK_BOOK__LANGUAGE=zh_CN mdbook build
MDBOOK_BOOK__LANGUAGE=zh_CN mdbook serve
Please consult TRANSLATING.md for further information on how to create and maintain translations.Get help and report issuesIf you experience any issues or bugs, please check for existing issues and file an issue if it hasn't been reported yet. Please include the version of the  binary in your bug report (you can obtain it with ).]]></content:encoded></item><item><title>datawhalechina/llm-cookbook</title><link>https://github.com/datawhalechina/llm-cookbook</link><author></author><category>trending</category><pubDate>Thu, 13 Feb 2025 02:27:07 +0000</pubDate><source url="http://mshibanami.github.io/GitHubTrendingRSS">Dev - Github Trending</source><content:encoded><![CDATA[é¢å‘å¼€å‘è€…çš„ LLM å…¥é—¨æ•™ç¨‹ï¼Œå´æ©è¾¾å¤§æ¨¡åž‹ç³»åˆ—è¯¾ç¨‹ä¸­æ–‡ç‰ˆæœ¬é¡¹ç›®æ˜¯ä¸€ä¸ªé¢å‘å¼€å‘è€…çš„å¤§æ¨¡åž‹æ‰‹å†Œï¼Œé’ˆå¯¹å›½å†…å¼€å‘è€…çš„å®žé™…éœ€æ±‚ï¼Œä¸»æ‰“ LLM å…¨æ–¹ä½å…¥é—¨å®žè·µã€‚æœ¬é¡¹ç›®åŸºäºŽå´æ©è¾¾è€å¸ˆå¤§æ¨¡åž‹ç³»åˆ—è¯¾ç¨‹å†…å®¹ï¼Œå¯¹åŽŸè¯¾ç¨‹å†…å®¹è¿›è¡Œç­›é€‰ã€ç¿»è¯‘ã€å¤çŽ°å’Œè°ƒä¼˜ï¼Œè¦†ç›–ä»Ž Prompt Engineering åˆ° RAG å¼€å‘ã€æ¨¡åž‹å¾®è°ƒçš„å…¨éƒ¨æµç¨‹ï¼Œç”¨æœ€é€‚åˆå›½å†…å­¦ä¹ è€…çš„æ–¹å¼ï¼ŒæŒ‡å¯¼å›½å†…å¼€å‘è€…å¦‚ä½•å­¦ä¹ ã€å…¥é—¨ LLM ç›¸å…³é¡¹ç›®ã€‚é’ˆå¯¹ä¸åŒå†…å®¹çš„ç‰¹ç‚¹ï¼Œæˆ‘ä»¬å¯¹å…±è®¡ 11 é—¨å´æ©è¾¾è€å¸ˆçš„å¤§æ¨¡åž‹è¯¾ç¨‹è¿›è¡Œäº†ç¿»è¯‘å¤çŽ°ï¼Œå¹¶ç»“åˆå›½å†…å­¦ä¹ è€…çš„å®žé™…æƒ…å†µï¼Œå¯¹ä¸åŒè¯¾ç¨‹è¿›è¡Œäº†åˆ†çº§å’ŒæŽ’åºï¼Œåˆå­¦è€…å¯ä»¥å…ˆç³»ç»Ÿå­¦ä¹ æˆ‘ä»¬çš„å¿…ä¿®ç±»è¯¾ç¨‹ï¼ŒæŽŒæ¡å…¥é—¨ LLM æ‰€æœ‰æ–¹å‘éƒ½éœ€è¦æŽŒæ¡çš„åŸºç¡€æŠ€èƒ½å’Œæ¦‚å¿µï¼Œå†é€‰æ‹©æ€§åœ°å­¦ä¹ æˆ‘ä»¬çš„é€‰ä¿®ç±»è¯¾ç¨‹ï¼Œåœ¨è‡ªå·±æ„Ÿå…´è¶£çš„æ–¹å‘ä¸Šä¸æ–­æŽ¢ç´¢å’Œå­¦ä¹ ã€‚å¦‚æžœæœ‰ä½ éžå¸¸å–œæ¬¢ä½†æˆ‘ä»¬è¿˜æ²¡æœ‰è¿›è¡Œå¤çŽ°çš„å´æ©è¾¾è€å¸ˆå¤§æ¨¡åž‹è¯¾ç¨‹ï¼Œæˆ‘ä»¬æ¬¢è¿Žæ¯ä¸€ä½å¼€å‘è€…å‚è€ƒæˆ‘ä»¬å·²æœ‰è¯¾ç¨‹çš„æ ¼å¼å’Œå†™æ³•æ¥å¯¹è¯¾ç¨‹è¿›è¡Œå¤çŽ°å¹¶æäº¤ PRï¼Œåœ¨ PR å®¡æ ¸é€šè¿‡åŽï¼Œæˆ‘ä»¬ä¼šæ ¹æ®è¯¾ç¨‹å†…å®¹å°†è¯¾ç¨‹è¿›è¡Œåˆ†çº§åˆå¹¶ã€‚æ¬¢è¿Žæ¯ä¸€ä½å¼€å‘è€…çš„è´¡çŒ®ï¼LLM æ­£åœ¨é€æ­¥æ”¹å˜äººä»¬çš„ç”Ÿæ´»ï¼Œè€Œå¯¹äºŽå¼€å‘è€…ï¼Œå¦‚ä½•åŸºäºŽ LLM æä¾›çš„ API å¿«é€Ÿã€ä¾¿æ·åœ°å¼€å‘ä¸€äº›å…·å¤‡æ›´å¼ºèƒ½åŠ›ã€é›†æˆLLM çš„åº”ç”¨ï¼Œæ¥ä¾¿æ·åœ°å®žçŽ°ä¸€äº›æ›´æ–°é¢–ã€æ›´å®žç”¨çš„èƒ½åŠ›ï¼Œæ˜¯ä¸€ä¸ªæ€¥éœ€å­¦ä¹ çš„é‡è¦èƒ½åŠ›ã€‚ç”±å´æ©è¾¾è€å¸ˆä¸Ž OpenAI åˆä½œæŽ¨å‡ºçš„å¤§æ¨¡åž‹ç³»åˆ—æ•™ç¨‹ï¼Œä»Žå¤§æ¨¡åž‹æ—¶ä»£å¼€å‘è€…çš„åŸºç¡€æŠ€èƒ½å‡ºå‘ï¼Œæ·±å…¥æµ…å‡ºåœ°ä»‹ç»äº†å¦‚ä½•åŸºäºŽå¤§æ¨¡åž‹ APIã€LangChain æž¶æž„å¿«é€Ÿå¼€å‘ç»“åˆå¤§æ¨¡åž‹å¼ºå¤§èƒ½åŠ›çš„åº”ç”¨ã€‚å…¶ä¸­ï¼Œã€ŠPrompt Engineering for Developersã€‹æ•™ç¨‹é¢å‘å…¥é—¨ LLM çš„å¼€å‘è€…ï¼Œæ·±å…¥æµ…å‡ºåœ°ä»‹ç»äº†å¯¹äºŽå¼€å‘è€…ï¼Œå¦‚ä½•æž„é€  Prompt å¹¶åŸºäºŽ OpenAI æä¾›çš„ API å®žçŽ°åŒ…æ‹¬æ€»ç»“ã€æŽ¨æ–­ã€è½¬æ¢ç­‰å¤šç§å¸¸ç”¨åŠŸèƒ½ï¼Œæ˜¯å…¥é—¨ LLM å¼€å‘çš„ç»å…¸æ•™ç¨‹ï¼›ã€ŠBuilding Systems with the ChatGPT APIã€‹æ•™ç¨‹é¢å‘æƒ³è¦åŸºäºŽ LLM å¼€å‘åº”ç”¨ç¨‹åºçš„å¼€å‘è€…ï¼Œç®€æ´æœ‰æ•ˆè€Œåˆç³»ç»Ÿå…¨é¢åœ°ä»‹ç»äº†å¦‚ä½•åŸºäºŽ ChatGPT API æ‰“é€ å®Œæ•´çš„å¯¹è¯ç³»ç»Ÿï¼›ã€ŠLangChain for LLM Application Developmentã€‹æ•™ç¨‹ç»“åˆç»å…¸å¤§æ¨¡åž‹å¼€æºæ¡†æž¶ LangChainï¼Œä»‹ç»äº†å¦‚ä½•åŸºäºŽ LangChain æ¡†æž¶å¼€å‘å…·å¤‡å®žç”¨åŠŸèƒ½ã€èƒ½åŠ›å…¨é¢çš„åº”ç”¨ç¨‹åºï¼Œã€ŠLangChain Chat With Your Dataã€‹æ•™ç¨‹åˆ™åœ¨æ­¤åŸºç¡€ä¸Šè¿›ä¸€æ­¥ä»‹ç»äº†å¦‚ä½•ä½¿ç”¨ LangChain æž¶æž„ç»“åˆä¸ªäººç§æœ‰æ•°æ®å¼€å‘ä¸ªæ€§åŒ–å¤§æ¨¡åž‹åº”ç”¨ï¼›ã€ŠBuilding Generative AI Applications with Gradioã€‹ã€ã€ŠEvaluating and Debugging Generative AIã€‹æ•™ç¨‹åˆ†åˆ«ä»‹ç»äº†ä¸¤ä¸ªå®žç”¨å·¥å…· Gradio ä¸Ž W&Bï¼ŒæŒ‡å¯¼å¼€å‘è€…å¦‚ä½•ç»“åˆè¿™ä¸¤ä¸ªå·¥å…·æ¥æ‰“é€ ã€è¯„ä¼°ç”Ÿæˆå¼ AI åº”ç”¨ã€‚ä¸Šè¿°æ•™ç¨‹éžå¸¸é€‚ç”¨äºŽå¼€å‘è€…å­¦ä¹ ä»¥å¼€å¯åŸºäºŽ LLM å®žé™…æ­å»ºåº”ç”¨ç¨‹åºä¹‹è·¯ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†è¯¥ç³»åˆ—è¯¾ç¨‹ç¿»è¯‘ä¸ºä¸­æ–‡ï¼Œå¹¶å¤çŽ°å…¶èŒƒä¾‹ä»£ç ï¼Œä¹Ÿä¸ºå…¶ä¸­ä¸€ä¸ªè§†é¢‘å¢žåŠ äº†ä¸­æ–‡å­—å¹•ï¼Œæ”¯æŒå›½å†…ä¸­æ–‡å­¦ä¹ è€…ç›´æŽ¥ä½¿ç”¨ï¼Œä»¥å¸®åŠ©ä¸­æ–‡å­¦ä¹ è€…æ›´å¥½åœ°å­¦ä¹  LLM å¼€å‘ï¼›æˆ‘ä»¬ä¹ŸåŒæ—¶å®žçŽ°äº†æ•ˆæžœå¤§è‡´ç›¸å½“çš„ä¸­æ–‡ Promptï¼Œæ”¯æŒå­¦ä¹ è€…æ„Ÿå—ä¸­æ–‡è¯­å¢ƒä¸‹ LLM çš„å­¦ä¹ ä½¿ç”¨ï¼Œå¯¹æ¯”æŽŒæ¡å¤šè¯­è¨€è¯­å¢ƒä¸‹çš„ Prompt è®¾è®¡ä¸Ž LLM å¼€å‘ã€‚æœªæ¥ï¼Œæˆ‘ä»¬ä¹Ÿå°†åŠ å…¥æ›´å¤š Prompt é«˜çº§æŠ€å·§ï¼Œä»¥ä¸°å¯Œæœ¬è¯¾ç¨‹å†…å®¹ï¼Œå¸®åŠ©å¼€å‘è€…æŽŒæ¡æ›´å¤šã€æ›´å·§å¦™çš„ Prompt æŠ€èƒ½ã€‚æ‰€æœ‰å…·å¤‡åŸºç¡€ Python èƒ½åŠ›ï¼Œæƒ³è¦å…¥é—¨ LLM çš„å¼€å‘è€…ã€‚ã€ŠChatGPT Prompt Engineering for Developersã€‹ã€ã€ŠBuilding Systems with the ChatGPT APIã€‹ç­‰æ•™ç¨‹ä½œä¸ºç”±å´æ©è¾¾è€å¸ˆä¸Ž OpenAI è”åˆæŽ¨å‡ºçš„å®˜æ–¹æ•™ç¨‹ï¼Œåœ¨å¯é¢„è§çš„æœªæ¥ä¼šæˆä¸º LLM çš„é‡è¦å…¥é—¨æ•™ç¨‹ï¼Œä½†æ˜¯ç›®å‰è¿˜åªæ”¯æŒè‹±æ–‡ç‰ˆä¸”å›½å†…è®¿é—®å—é™ï¼Œæ‰“é€ ä¸­æ–‡ç‰ˆä¸”å›½å†…æµç•…è®¿é—®çš„æ•™ç¨‹å…·æœ‰é‡è¦æ„ä¹‰ï¼›åŒæ—¶ï¼ŒGPT å¯¹ä¸­æ–‡ã€è‹±æ–‡å…·æœ‰ä¸åŒçš„ç†è§£èƒ½åŠ›ï¼Œæœ¬æ•™ç¨‹åœ¨å¤šæ¬¡å¯¹æ¯”ã€å®žéªŒä¹‹åŽç¡®å®šäº†æ•ˆæžœå¤§è‡´ç›¸å½“çš„ä¸­æ–‡ Promptï¼Œæ”¯æŒå­¦ä¹ è€…ç ”ç©¶å¦‚ä½•æå‡ ChatGPT åœ¨ä¸­æ–‡è¯­å¢ƒä¸‹çš„ç†è§£ä¸Žç”Ÿæˆèƒ½åŠ›ã€‚æœ¬æ•™ç¨‹é€‚ç”¨äºŽæ‰€æœ‰å…·å¤‡åŸºç¡€ Python èƒ½åŠ›ï¼Œæƒ³è¦å…¥é—¨ LLM çš„å¼€å‘è€…ã€‚è‡³å°‘ä¸€ä¸ª LLM APIï¼ˆæœ€å¥½æ˜¯ OpenAIï¼Œå¦‚æžœæ˜¯å…¶ä»– APIï¼Œä½ å¯èƒ½éœ€è¦å‚è€ƒå…¶ä»–æ•™ç¨‹å¯¹ API è°ƒç”¨ä»£ç è¿›è¡Œä¿®æ”¹ï¼‰èƒ½å¤Ÿä½¿ç”¨ Python Jupyter Notebookæœ¬æ•™ç¨‹å…±åŒ…æ‹¬ 11 é—¨è¯¾ç¨‹ï¼Œåˆ†ä¸ºå¿…ä¿®ç±»ã€é€‰ä¿®ç±»ä¸¤ä¸ªç±»åˆ«ã€‚å¿…ä¿®ç±»è¯¾ç¨‹æ˜¯æˆ‘ä»¬è®¤ä¸ºæœ€é€‚åˆåˆå­¦è€…å­¦ä¹ ä»¥å…¥é—¨ LLM çš„è¯¾ç¨‹ï¼ŒåŒ…æ‹¬äº†å…¥é—¨ LLM æ‰€æœ‰æ–¹å‘éƒ½éœ€è¦æŽŒæ¡çš„åŸºç¡€æŠ€èƒ½å’Œæ¦‚å¿µï¼Œæˆ‘ä»¬ä¹Ÿé’ˆå¯¹å¿…ä¿®ç±»è¯¾ç¨‹åˆ¶ä½œäº†é€‚åˆé˜…è¯»çš„åœ¨çº¿é˜…è¯»å’Œ PDF ç‰ˆæœ¬ï¼Œåœ¨å­¦ä¹ å¿…ä¿®ç±»è¯¾ç¨‹æ—¶ï¼Œæˆ‘ä»¬å»ºè®®å­¦ä¹ è€…æŒ‰ç…§æˆ‘ä»¬åˆ—å‡ºçš„é¡ºåºè¿›è¡Œå­¦ä¹ ï¼›é€‰ä¿®ç±»è¯¾ç¨‹æ˜¯åœ¨å¿…ä¿®ç±»è¯¾ç¨‹ä¸Šçš„æ‹“å±•å»¶ä¼¸ï¼ŒåŒ…æ‹¬äº† RAG å¼€å‘ã€æ¨¡åž‹å¾®è°ƒã€æ¨¡åž‹è¯„ä¼°ç­‰å¤šä¸ªæ–¹é¢ï¼Œé€‚åˆå­¦ä¹ è€…åœ¨æŽŒæ¡äº†å¿…ä¿®ç±»è¯¾ç¨‹ä¹‹åŽé€‰æ‹©è‡ªå·±æ„Ÿå…´è¶£çš„æ–¹å‘å’Œè¯¾ç¨‹è¿›è¡Œå­¦ä¹ ã€‚é¢å‘å¼€å‘è€…çš„ Prompt Engineeringã€‚åŸºäºŽå´æ©è¾¾è€å¸ˆã€ŠChatGPT Prompt Engineering for Developersã€‹è¯¾ç¨‹æ‰“é€ ï¼Œé¢å‘å…¥é—¨ LLM çš„å¼€å‘è€…ï¼Œæ·±å…¥æµ…å‡ºåœ°ä»‹ç»äº†å¯¹äºŽå¼€å‘è€…ï¼Œå¦‚ä½•æž„é€  Prompt å¹¶åŸºäºŽ OpenAI æä¾›çš„ API å®žçŽ°åŒ…æ‹¬æ€»ç»“ã€æŽ¨æ–­ã€è½¬æ¢ç­‰å¤šç§å¸¸ç”¨åŠŸèƒ½ï¼Œæ˜¯å…¥é—¨ LLM å¼€å‘çš„ç¬¬ä¸€æ­¥ã€‚æ­å»ºåŸºäºŽ ChatGPT çš„é—®ç­”ç³»ç»Ÿã€‚åŸºäºŽå´æ©è¾¾è€å¸ˆã€ŠBuilding Systems with the ChatGPT APIã€‹è¯¾ç¨‹æ‰“é€ ï¼ŒæŒ‡å¯¼å¼€å‘è€…å¦‚ä½•åŸºäºŽ ChatGPT æä¾›çš„ API å¼€å‘ä¸€ä¸ªå®Œæ•´çš„ã€å…¨é¢çš„æ™ºèƒ½é—®ç­”ç³»ç»Ÿã€‚é€šè¿‡ä»£ç å®žè·µï¼Œå®žçŽ°äº†åŸºäºŽ ChatGPT å¼€å‘é—®ç­”ç³»ç»Ÿçš„å…¨æµç¨‹ï¼Œä»‹ç»äº†åŸºäºŽå¤§æ¨¡åž‹å¼€å‘çš„æ–°èŒƒå¼ï¼Œæ˜¯å¤§æ¨¡åž‹å¼€å‘çš„å®žè·µåŸºç¡€ã€‚ä½¿ç”¨ LangChain å¼€å‘åº”ç”¨ç¨‹åºã€‚åŸºäºŽå´æ©è¾¾è€å¸ˆã€ŠLangChain for LLM Application Developmentã€‹è¯¾ç¨‹æ‰“é€ ï¼Œå¯¹ LangChain å±•å¼€æ·±å…¥ä»‹ç»ï¼Œå¸®åŠ©å­¦ä¹ è€…äº†è§£å¦‚ä½•ä½¿ç”¨ LangChainï¼Œå¹¶åŸºäºŽ LangChain å¼€å‘å®Œæ•´çš„ã€å…·å¤‡å¼ºå¤§èƒ½åŠ›çš„åº”ç”¨ç¨‹åºã€‚ä½¿ç”¨ LangChain è®¿é—®ä¸ªäººæ•°æ®ã€‚åŸºäºŽå´æ©è¾¾è€å¸ˆã€ŠLangChain Chat with Your Dataã€‹è¯¾ç¨‹æ‰“é€ ï¼Œæ·±å…¥æ‹“å±• LangChain æä¾›çš„ä¸ªäººæ•°æ®è®¿é—®èƒ½åŠ›ï¼ŒæŒ‡å¯¼å¼€å‘è€…å¦‚ä½•ä½¿ç”¨ LangChain å¼€å‘èƒ½å¤Ÿè®¿é—®ç”¨æˆ·ä¸ªäººæ•°æ®ã€æä¾›ä¸ªæ€§åŒ–æœåŠ¡çš„å¤§æ¨¡åž‹åº”ç”¨ã€‚ä½¿ç”¨ Gradio æ­å»ºç”Ÿæˆå¼ AI åº”ç”¨ã€‚åŸºäºŽå´æ©è¾¾è€å¸ˆã€ŠBuilding Generative AI Applications with Gradioã€‹è¯¾ç¨‹æ‰“é€ ï¼ŒæŒ‡å¯¼å¼€å‘è€…å¦‚ä½•ä½¿ç”¨ Gradio é€šè¿‡ Python æŽ¥å£ç¨‹åºå¿«é€Ÿã€é«˜æ•ˆåœ°ä¸ºç”Ÿæˆå¼ AI æž„å»ºç”¨æˆ·ç•Œé¢ã€‚è¯„ä¼°æ”¹è¿›ç”Ÿæˆå¼ AIã€‚åŸºäºŽå´æ©è¾¾è€å¸ˆã€ŠEvaluating and Debugging Generative AIã€‹è¯¾ç¨‹æ‰“é€ ï¼Œç»“åˆ wandbï¼Œæä¾›ä¸€å¥—ç³»ç»ŸåŒ–çš„æ–¹æ³•å’Œå·¥å…·ï¼Œå¸®åŠ©å¼€å‘è€…æœ‰æ•ˆåœ°è·Ÿè¸ªå’Œè°ƒè¯•ç”Ÿæˆå¼ AI æ¨¡åž‹ã€‚å¾®è°ƒå¤§è¯­è¨€æ¨¡åž‹ã€‚åŸºäºŽå´æ©è¾¾è€å¸ˆã€ŠFinetuning Large Language Modelã€‹è¯¾ç¨‹æ‰“é€ ï¼Œç»“åˆ lamini æ¡†æž¶ï¼Œè®²è¿°å¦‚ä½•ä¾¿æ·é«˜æ•ˆåœ°åœ¨æœ¬åœ°åŸºäºŽä¸ªäººæ•°æ®å¾®è°ƒå¼€æºå¤§è¯­è¨€æ¨¡åž‹ã€‚å¤§æ¨¡åž‹ä¸Žè¯­ä¹‰æ£€ç´¢ã€‚åŸºäºŽå´æ©è¾¾è€å¸ˆã€ŠLarge Language Models with Semantic Searchã€‹è¯¾ç¨‹æ‰“é€ ï¼Œé’ˆå¯¹æ£€ç´¢å¢žå¼ºç”Ÿæˆï¼Œè®²è¿°äº†å¤šç§é«˜çº§æ£€ç´¢æŠ€å·§ä»¥å®žçŽ°æ›´å‡†ç¡®ã€é«˜æ•ˆçš„æ£€ç´¢å¢žå¼º LLM ç”Ÿæˆæ•ˆæžœã€‚åŸºäºŽ Chroma çš„é«˜çº§æ£€ç´¢ã€‚åŸºäºŽå´æ©è¾¾è€å¸ˆã€ŠAdvanced Retrieval for AI with Chromaã€‹è¯¾ç¨‹æ‰“é€ ï¼Œæ—¨åœ¨ä»‹ç»åŸºäºŽ Chroma çš„é«˜çº§æ£€ç´¢æŠ€æœ¯ï¼Œæå‡æ£€ç´¢ç»“æžœçš„å‡†ç¡®æ€§ã€‚æ­å»ºå’Œè¯„ä¼°é«˜çº§ RAG åº”ç”¨ã€‚åŸºäºŽå´æ©è¾¾è€å¸ˆã€ŠBuilding and Evaluating Advanced RAG Applicationsã€‹è¯¾ç¨‹æ‰“é€ ï¼Œä»‹ç»æž„å»ºå’Œå®žçŽ°é«˜è´¨é‡RAGç³»ç»Ÿæ‰€éœ€çš„å…³é”®æŠ€æœ¯å’Œè¯„ä¼°æ¡†æž¶ã€‚LangChain çš„ Functionsã€Tools å’Œ Agentsã€‚åŸºäºŽå´æ©è¾¾è€å¸ˆã€ŠFunctions, Tools and Agents with LangChainã€‹è¯¾ç¨‹æ‰“é€ ï¼Œä»‹ç»å¦‚ä½•åŸºäºŽ LangChain çš„æ–°è¯­æ³•æž„å»º Agentã€‚Prompt é«˜çº§æŠ€å·§ã€‚åŒ…æ‹¬ CoTã€è‡ªæˆ‘ä¸€è‡´æ€§ç­‰å¤šç§ Prompt é«˜çº§æŠ€å·§çš„åŸºç¡€ç†è®ºä¸Žä»£ç å®žçŽ°ã€‚contentï¼šåŸºäºŽåŽŸè¯¾ç¨‹å¤çŽ°çš„åŒè¯­ç‰ˆä»£ç ï¼Œå¯è¿è¡Œçš„ Notebookï¼Œæ›´æ–°é¢‘çŽ‡æœ€é«˜ï¼Œæ›´æ–°é€Ÿåº¦æœ€å¿«ã€‚

docsï¼šå¿…ä¿®ç±»è¯¾ç¨‹æ–‡å­—æ•™ç¨‹ç‰ˆåœ¨çº¿é˜…è¯»æºç ï¼Œé€‚åˆé˜…è¯»çš„ mdã€‚

figuresï¼šå›¾ç‰‡æ–‡ä»¶ã€‚
é«˜ç«‹ä¸šï¼ˆå†…å®¹åˆ›ä½œè€…-DataWhaleæˆå‘˜-ç®—æ³•å·¥ç¨‹å¸ˆï¼‰é™ˆé€¸æ¶µ (å†…å®¹åˆ›ä½œè€…-Datawhaleæ„å‘æˆå‘˜-AIçˆ±å¥½è€…)æ›¾æµ©é¾™ï¼ˆå†…å®¹åˆ›ä½œè€…-Datawhale æ„å‘æˆå‘˜-JLU AI ç ”ç©¶ç”Ÿï¼‰ Datawhale æ˜¯ä¸€ä¸ªä¸“æ³¨äºŽæ•°æ®ç§‘å­¦ä¸Ž AI é¢†åŸŸçš„å¼€æºç»„ç»‡ï¼Œæ±‡é›†äº†ä¼—å¤šé¢†åŸŸé™¢æ ¡å’ŒçŸ¥åä¼ä¸šçš„ä¼˜ç§€å­¦ä¹ è€…ï¼Œèšåˆäº†ä¸€ç¾¤æœ‰å¼€æºç²¾ç¥žå’ŒæŽ¢ç´¢ç²¾ç¥žçš„å›¢é˜Ÿæˆå‘˜ã€‚å¾®ä¿¡æœç´¢å…¬ä¼—å·Datawhaleå¯ä»¥åŠ å…¥æˆ‘ä»¬ã€‚ 
]]></content:encoded></item><item><title>antonputra/tutorials</title><link>https://github.com/antonputra/tutorials</link><author></author><category>trending</category><pubDate>Thu, 13 Feb 2025 02:27:07 +0000</pubDate><source url="http://mshibanami.github.io/GitHubTrendingRSS">Dev - Github Trending</source><content:encoded><![CDATA[ðŸ”´ - To support my channel, I'd like to offer Mentorship/On-the-Job Support/Consulting. (me@antonputra.com)]]></content:encoded></item><item><title>microsoft/data-formulator</title><link>https://github.com/microsoft/data-formulator</link><author></author><category>trending</category><pubDate>Wed, 12 Feb 2025 02:26:49 +0000</pubDate><source url="http://mshibanami.github.io/GitHubTrendingRSS">Dev - Github Trending</source><content:encoded><![CDATA[ðŸª„ Create rich visualizations with AITransform data and create rich visualizations iteratively with AI ðŸª„. Try Data Formulator now![02-12-2025] More models supported now!Now supports OpenAI, Azure, Ollama, and Anthropic models (and more powered by LiteLLM);Models with strong code generation and instruction following capabilities are recommended (gpt-4o, claude-3-5-sonnet etc.);You can store API keys in  to avoid typing them every time (see template ).Let us know which models you have good/bad experiences with, and what models you would like to see supported! [comment here][11-07-2024] Minor fun update: data visualization challenges!We added a few visualization challenges with the sample datasets. Can you complete them all? [try them out!]Comment in the issue when you did, or share your results/questions with others! [comment here][10-11-2024] Data Formulator python package released!You can now install Data Formulator using Python and run it locally, easily. [check it out].Our Codespaces configuration is also updated for fast start up âš¡ï¸. [try it now!]New experimental feature: load an image or a messy text, and ask AI to parse and clean it for you(!). [demo][10-01-2024] Initial release of Data Formulator, check out our [blog] and [video]! is an application from Microsoft Research that uses large language models to transform data, expediting the practice of data visualization.Data Formulator is an AI-powered tool for analysts to iteratively create rich visualizations. Unlike most chat-based AI tools where users need to describe everything in natural language, Data Formulator combines user interface interactions (UI) and natural language (NL) inputs for easier interaction. This blended approach makes it easier for users to describe their chart designs while delegating data transformation to AI.Play with Data Formulator with one of the following options:Option 1: Install via Python PIPUse Python PIP for an easy setup experience, running locally (recommend: install it in a virtual environment).# install data_formulator
pip install data_formulator

# start data_formulator
data_formulator 

# alternatively, you can run data formulator with this command
python -m data_formulator
Update: you can specify the port number (e.g., 8080) by python -m data_formulator --port 8080 if the default port is occupied.Option 2: Codespaces (5 minutes)You can also run Data Formulator in Codespaces; we have everything pre-configured. For more details, see CODESPACES.md.Option 3: Working in the developer modeYou can build Data Formulator locally if you prefer full control over your development environment and the ability to customize the setup to your specific needs. For detailed instructions, refer to DEVELOPMENT.md.Once you've completed the setup using either option, follow these steps to start using Data Formulator:The basics of data visualizationProvide OpenAI keys and select a model (GPT-4o suggested) and choose a dataset.Choose a chart type, and then drag-and-drop data fields to chart properties (x, y, color, ...) to specify visual encodings.Create visualization beyond the initial dataset (powered by ðŸ¤–)You can type names of fields that do not exist in current data in the encoding shelf: 
  this tells Data Formulator that you want to create visualizations that require computation or transformation from existing data,you can optionally provide a natural language prompt to explain and clarify your intent (not necessary when field names are self-explanatory).Click the  button. 
  Data Formulator will transform data and instantiate the visualization based on the encoding and prompt.Inspect the data, chart and code.To create a new chart based on existing ones, follow up in natural language: 
  provide a follow up prompt (e.g., ),you may also update visual encodings for the new chart.Repeat this process as needed to explore and understand your data. Your explorations are trackable in the  panel.@article{wang2024dataformulator2iteratively,
      title={Data Formulator 2: Iteratively Creating Rich Visualizations with AI}, 
      author={Chenglong Wang and Bongshin Lee and Steven Drucker and Dan Marshall and Jianfeng Gao},
      year={2024},
      booktitle={ArXiv preprint arXiv:2408.16119},
}
@article{wang2023data,
  title={Data Formulator: AI-powered Concept-driven Visualization Authoring},
  author={Wang, Chenglong and Thompson, John and Lee, Bongshin},
  journal={IEEE Transactions on Visualization and Computer Graphics},
  year={2023},
  publisher={IEEE}
}
This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit https://cla.microsoft.com.When you submit a pull request, a CLA-bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repositories using our CLA.This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow Microsoft's Trademark & Brand Guidelines. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party's policies.]]></content:encoded></item><item><title>hoppscotch/hoppscotch</title><link>https://github.com/hoppscotch/hoppscotch</link><author></author><category>trending</category><pubDate>Wed, 12 Feb 2025 02:26:49 +0000</pubDate><source url="http://mshibanami.github.io/GitHubTrendingRSS">Dev - Github Trending</source><content:encoded><![CDATA[Open source API development ecosystem - https://hoppscotch.io (open-source alternative to Postman, Insomnia)â¤ï¸  Crafted with minimalistic UI design.âš¡ï¸  Send requests and get responses in real time.ðŸ—„ï¸  Request methods define the type of action you are requesting to be performed. - Requests retrieve resource information - The server creates a new entry in a database - Updates an existing resource - Very similar to  but makes a partial update on a resource - Deletes resource or related component - Retrieve response headers identical to those of a GET request, but without the response body. - Establishes a tunnel to the server identified by the target resource - Describe the communication options for the target resource - Performs a message loop-back test along the path to the target resource - Some APIs use custom request methods such as . Type in your custom methods.ðŸŒˆ  Customizable combinations for background, foreground, and accent colors â€” customize now.Choose a theme: System preference, Light, Dark, and BlackChoose accent colors: Green, Teal, Blue, Indigo, Purple, Yellow, Orange, Red, and PinkDistraction-free Zen modeCustomized themes are synced with your cloud/local session.Instant loading with Service WorkersLow RAM/memory and CPU usageðŸš€  Retrieve response from endpoint instantly.Copy/share public "Share URL"Generate/copy request code snippets for 10+ languages and frameworksðŸ”Œ  Establish full-duplex communication channels over a single TCP connection.ðŸ“¡  Receive a stream of updates from a server over an HTTP connection without resorting to polling.ðŸŒ©  Send and Receive data with the SocketIO server.ðŸ¦Ÿ  Subscribe and Publish to topics of an MQTT Broker.ðŸ”®  GraphQL is a query language for APIs and a runtime for fulfilling those queries with your existing data.Set endpoint and get schemaSet custom request headersðŸ”  Allows to identify the end-user.ðŸ“¢  Describes the format the body of your request is being sent in.ðŸ“«  Use request parameters to set varying parts in simulated requests.ðŸ“ƒ  Used to send and receive data via the REST API.FormData, JSON, and many moreToggle between key-value and RAW input parameter listðŸ“®  Contains the status line, headers, and the message/response body.Copy the response to the clipboardDownload the response as a fileView raw and preview HTML, image, JSON, and XML responsesâ°  Request entries are synced with your cloud/local session storage.ðŸ“  Keep your API requests organized with collections and folders. Reuse them with a single click.Unlimited collections, folders, and requestsExport and import as a file or GitHub gistCollections are synced with your cloud/local session storage.ðŸ“œ  Snippets of code associated with a request that is executed before the request is sent.Set environment variablesInclude timestamp in the request headersSend a random alphanumeric string in the URL parametersðŸ‘¨â€ðŸ‘©â€ðŸ‘§â€ðŸ‘¦  Helps you collaborate across your teams to design, develop, and test APIs faster.Create unlimited shared collectionsCreate unlimited team membersRole-based access controlðŸ‘¥  Organize your personal and team collections environments into workspaces. Easily switch between workspaces to manage multiple projects.Create unlimited workspacesSwitch between personal and team workspacesâŒ¨ï¸  Optimized for efficiency.ðŸŒ  Enable Proxy Mode from Settings to access blocked APIs.Fixes  (Cross-Origin Resource Sharing) issuesAccess APIs served in non-HTTPS () endpointsðŸŒŽ  Experience the app in your language.Help us to translate Hoppscotch. Please read  for details on our  and the process for submitting pull requests to us.â˜ï¸  Sign in and sync your data in real-time across all your devices.SSO (Single Sign-On)[^EE] Handoff to continue tasks on your other devices.âœ…  Write tests associated with a request that is executed after the request's response.Check the status code as an integerSet environment variablesðŸŒ±  Environment variables allow you to store and reuse values in your requests and scripts.Unlimited environments and variablesInitialize through the pre-request scriptExport as / import from GitHub gistðŸšš  Edit key-value pairs in bulk.Entries are separated by newlineKeys and values are separated by Prepend  to any row you want to add but keep disabledðŸŽ›ï¸  Manage your team and invite members.ðŸ“¦  Official add-ons for hoppscotch.Provide your API endpoint in the URL fieldClick "Send" to simulate the requestThis project owes its existence to the collective efforts of all those who contribute â€” contribute now.]]></content:encoded></item><item><title>codecrafters-io/build-your-own-x</title><link>https://github.com/codecrafters-io/build-your-own-x</link><author></author><category>trending</category><pubDate>Wed, 12 Feb 2025 02:26:49 +0000</pubDate><source url="http://mshibanami.github.io/GitHubTrendingRSS">Dev - Github Trending</source><content:encoded><![CDATA[What I cannot create, I do not understand â€” Richard Feynman.]]></content:encoded></item><item><title>labring/FastGPT</title><link>https://github.com/labring/FastGPT</link><author></author><category>trending</category><pubDate>Wed, 12 Feb 2025 02:26:49 +0000</pubDate><source url="http://mshibanami.github.io/GitHubTrendingRSS">Dev - Github Trending</source><content:encoded><![CDATA[FastGPT is a knowledge-based platform built on the LLMs, offers a comprehensive suite of out-of-the-box capabilities such as data processing, RAG retrieval, and visual AI workflow orchestration, letting you easily develop and deploy complex question-answering systems without the need for extensive setup or configuration.FastGPT æ˜¯ä¸€ä¸ªåŸºäºŽ LLM å¤§è¯­è¨€æ¨¡åž‹çš„çŸ¥è¯†åº“é—®ç­”ç³»ç»Ÿï¼Œæä¾›å¼€ç®±å³ç”¨çš„æ•°æ®å¤„ç†ã€æ¨¡åž‹è°ƒç”¨ç­‰èƒ½åŠ›ã€‚åŒæ—¶å¯ä»¥é€šè¿‡ Flow å¯è§†åŒ–è¿›è¡Œå·¥ä½œæµç¼–æŽ’ï¼Œä»Žè€Œå®žçŽ°å¤æ‚çš„é—®ç­”åœºæ™¯ï¼é¡¹ç›®æŠ€æœ¯æ ˆï¼šNextJs + TS + ChakraUI + MongoDB + PostgreSQL (PG Vector æ’ä»¶)/Milvusæˆ‘ä»¬éžå¸¸æ¬¢è¿Žå„ç§å½¢å¼çš„è´¡çŒ®ã€‚å¦‚æžœä½ å¯¹è´¡çŒ®ä»£ç æ„Ÿå…´è¶£ï¼Œå¯ä»¥æŸ¥çœ‹æˆ‘ä»¬çš„ GitHub Issuesï¼Œå¤§å±•èº«æ‰‹ï¼Œå‘æˆ‘ä»¬å±•ç¤ºä½ çš„å¥‡æ€å¦™æƒ³ã€‚]]></content:encoded></item><item><title>CodePhiliaX/Chat2DB</title><link>https://github.com/CodePhiliaX/Chat2DB</link><author></author><category>trending</category><pubDate>Wed, 12 Feb 2025 02:26:49 +0000</pubDate><source url="http://mshibanami.github.io/GitHubTrendingRSS">Dev - Github Trending</source><content:encoded><![CDATA[ðŸ”¥ðŸ”¥ðŸ”¥AI-driven database tool and SQL client, The hottest GUI client, supporting MySQL, Oracle, PostgreSQL, DB2, SQL Server, DB2, SQLite, H2, ClickHouse, and more.Chat2DB is an intelligent, universal SQL client and data reporting tool that integrates AI capabilities. Chat2DB helps you write SQL queries faster, manage databases, generate reports, explore data, and interact with multiple databases. Chat2DB is an open-source project, and we welcome your contributions.1. Intelligent SQL Generation: Chat2DB Pro supports AI-driven intelligent SQL development to help you write SQL queries faster.: Supports more than 10 databases, including MySQL, PostgreSQL, H2, Oracle, SQLServer, SQLite, MariaDB, ClickHouse, DM, Presto, DB2, OceanBase, Hive, KingBase, MongoDB, Redis, Snowflake, and more.3. Intelligent Report Generation: Chat2DB Pro supports AI-driven intelligent data reporting to help you generate dashboards faster.4. Data Structure Synchronization: Chat2DB Pro supports database table structure synchronization to help you sync database table structures faster.Requires AI ConfigurationDatabase Structure Import/ExportCopy Results as Insert/UpdateDownload and InstallationChat2DB is a cross-platform application that supports Windows, MacOS, and Linux. You can download Chat2DB from the following links:Community Edition Docker InstallationBefore installing Chat2DB, ensure your system meets the following requirements:Docker Compose 1.25.0 or later  docker rm chat2db
  
  docker run --name=chat2db -ti -p 10824:10824 -v ~/.chat2db-docker:/root/.chat2db  chat2db/chat2db:latest

  docker start chat2db
  
Note: If local debugging is needed:Clone the repository locally$ git clone git@github.com:chat2db/Chat2DB.git
Node version must be 16 or higher  
Use yarn only, npm is not supported
$ cd Chat2DB/chat2db-client
$ yarn
$ yarn run start:web
$ cd ../chat2db-server
$ mvn clean install # Maven version 3.8 or higher is required
$ cd chat2db-server/chat2db-server-start/target/
$ java -jar -Dloader.path=./lib -Dchatgpt.apiKey=xxxxx chat2db-server-start.jar  # éœ€è¦å®‰è£…java 17ä»¥ä¸Šç‰ˆæœ¬ï¼Œå¯åŠ¨åº”ç”¨ chatgpt.apiKey éœ€è¦è¾“å…¥ChatGPTçš„key,å¦‚æžœä¸è¾“å…¥æ— æ³•ä½¿ç”¨AIGCåŠŸèƒ½
# chat2db-client
$ npm run build:web:prod 
$ cp -r dist ../chat2db-server/chat2db-server-start/src/main/resources/static/front 
$ cp -r dist/index.html ../chat2db-server/chat2db-server-start/src/main/resources/thymeleaf
Thanks to everyone who has contributed to Chat2DB~~]]></content:encoded></item><item><title>Shubhamsaboo/awesome-llm-apps</title><link>https://github.com/Shubhamsaboo/awesome-llm-apps</link><author></author><category>trending</category><pubDate>Wed, 12 Feb 2025 02:26:49 +0000</pubDate><source url="http://mshibanami.github.io/GitHubTrendingRSS">Dev - Github Trending</source><content:encoded><![CDATA[Collection of awesome LLM apps with AI Agents and RAG using OpenAI, Anthropic, Gemini and opensource models.A curated collection of awesome LLM apps built with RAG and AI agents. This repository features LLM apps that use models from OpenAI, Anthropic, Google, and even open-source models like LLaMA that you can run locally on your computer.ðŸ’¡ Discover practical and creative ways LLMs can be applied across different domains, from code repositories to email inboxes and more.ðŸ”¥ Explore apps that combine LLMs from OpenAI, Anthropic, Gemini, and open-source alternatives with RAG and AI Agents.ðŸŽ“ Learn from well-documented projects and contribute to the growing open-source ecosystem of LLM-powered applications.RAG (Retrieval Augmented Generation)Advanced Tools and Frameworksgit clone https://github.com/Shubhamsaboo/awesome-llm-apps.git 
Navigate to the desired project directorycd awesome-llm-apps/chat_with_X_tutorials/chat_with_gmail
Install the required dependenciespip install -r requirements.txt
Follow the project-specific instructions in each project's  file to set up and run the app.ðŸ¤ Contributing to Open SourceContributions are welcome! If you have any ideas, improvements, or new apps to add, please create a new GitHub Issue or submit a pull request. Make sure to follow the existing project structure and include a detailed  for each new app.Thank You, Community, for the Support! ðŸ™ðŸŒŸ Donâ€™t miss out on future updates! Star the repo now and be the first to know about new and exciting LLM apps with RAG and AI Agents.]]></content:encoded></item><item><title>firefly-iii/firefly-iii</title><link>https://github.com/firefly-iii/firefly-iii</link><author></author><category>trending</category><pubDate>Tue, 11 Feb 2025 02:27:22 +0000</pubDate><source url="http://mshibanami.github.io/GitHubTrendingRSS">Dev - Github Trending</source><content:encoded><![CDATA[Firefly III: a personal finances manager"Firefly III" is a (self-hosted) manager for your personal finances. It can help you keep track of your expenses and income, so you can spend less and save more. Firefly III supports the use of budgets, categories and tags. Using a bunch of external tools, you can import data. It also has many neat financial reports available.Firefly III should give you  into and  over your finances. Money should be useful, not scary. You should be able to  where it is going, to  your expenses and to... wow, I'm going overboard with this aren't I?But you get the idea: this is your money. These are your expenses. Stop them from controlling you. I built this tool because I started to dislike money. Having money, not having money, paying bills with money, you get the idea. But no more. I want to feel "safe", whatever my balance is. And I hope this tool can help you. I know it helps me.Personal financial management is pretty difficult, and everybody has their own approach to it. Some people make budgets, other people limit their cashflow by throwing away their credit cards, others try to increase their current cashflow. There are tons of ways to save and earn money. Firefly III works on the principle that if you know where your money is going, you can stop it from going there.By keeping track of your expenses and your income you can budget accordingly and save money. Stop living from paycheck to paycheck but give yourself the financial wiggle room you need.You can read more about the purpose of Firefly III in the documentation.Firefly III is pretty feature packed. Some important stuff first:It is completely self-hosted and isolated, and will never contact external servers until you explicitly tell it to.It features a REST JSON API that covers almost every part of Firefly III.The most exciting features are:Then the things that make you go "yeah OK, makes sense".And the things you would hope for but not expect:And to organise everything:Clear views that should show you how you're doing.Easy navigation through your records.Lots of charts because we all love them.This application is for people who want to track their finances, keep an eye on their money without having to upload their financial records to the cloud. You're a bit tech-savvy, you like open source software and you don't mind tinkering with (self-hosted) servers.The Firefly III eco-systemThere are many ways to run Firefly IIISonarcloud scans the code of Firefly III. If you want to help improve Firefly III, check out the latest reports and take your pick!Support the development of Firefly IIIIf you like Firefly III and if it helps you save lots of money, why not send me a dime for every dollar saved! ðŸ¥³Do you need help, or do you want to get in touch?Do you want to contact me? You can email me at james@firefly-iii.org or get in touch through one of the following support channels:The Firefly III logo is made by the excellent Cherie Woo.]]></content:encoded></item><item><title>n0-computer/iroh</title><link>https://github.com/n0-computer/iroh</link><author></author><category>trending</category><pubDate>Tue, 11 Feb 2025 02:27:22 +0000</pubDate><source url="http://mshibanami.github.io/GitHubTrendingRSS">Dev - Github Trending</source><content:encoded><![CDATA[peer-2-peer that just works less net work for networks Iroh gives you an API for dialing by public key. You say â€œconnect to that phoneâ€, iroh will find & maintain the fastest connection for you, regardless of where it is.The fastest route is a direct connection, so if necessary, iroh tries to hole-punch. Should this fail, it can fall back to an open ecosystem of public relay servers. To ensure these connections are as fast as possible, we continuously measure iroh.Iroh uses Quinn to establish QUIC connections between nodes. This way you get authenticated encryption, concurrent streams with stream priorities, a datagram transport and avoid head-of-line-blocking out of the box.Use pre-existing protocols built on iroh instead of writing your own:iroh-blobs for BLAKE3-based content-addressed blob transfer scaling from kilobytes to terabytesiroh-gossip for establishing publish-subscribe overlay networks that scale, requiring only resources that your average phone can handleIt's easiest to use iroh from rust. Install it using , then on the connecting side:const ALPN: &[u8] = b"iroh-example/echo/0";

let endpoint = Endpoint::builder().discovery_n0().bind().await?;

// Open a connection to the accepting node
let conn = endpoint.connect(addr, ALPN).await?;

// Open a bidirectional QUIC stream
let (mut send, mut recv) = conn.open_bi().await?;

// Send some data to be echoed
send.write_all(b"Hello, world!").await?;
send.finish()?;

// Receive the echo
let response = recv.read_to_end(1000).await?;
assert_eq!(&response, b"Hello, world!");

// Close the endpoint and all its connections
endpoint.close().await;
And on the accepting side:let endpoint = Endpoint::builder().discovery_n0().bind().await?;

let router = Router::builder(endpoint)
    .accept(ALPN.to_vec(), Arc::new(Echo))
    .spawn()
    .await?;

// The protocol definition:
#[derive(Debug, Clone)]
struct Echo;

impl ProtocolHandler for Echo {
    fn accept(self: Arc<Self>, connecting: Connecting) -> BoxedFuture<Result<()>> {
        Box::pin(async move {
            let connection = connecting.await?;
            let (mut send, mut recv) = connection.accept_bi().await?;

            // Echo any bytes received back directly.
            let bytes_sent = tokio::io::copy(&mut recv, &mut send).await?;

            send.finish()?;
            connection.closed().await;

            Ok(())
        })
    }
}
The full example code with more comments can be found at .If you want to use iroh from other languages, make sure to check out iroh-ffi, the repository for FFI bindings.This repository contains a workspace of crates:: The core library for hole-punching & communicating with relays.: The relay server implementation. This is the code we run in production (and you can, too!).: Common types like , key types or .: DNS server implementation powering the  for NodeIds, running at dns.iroh.link.: Analyzes your host's networking ability & NAT.This project is licensed under either ofUnless you explicitly state otherwise, any contribution intentionally submitted for inclusion in this project by you, as defined in the Apache-2.0 license, shall be dual licensed as above, without any additional terms or conditions.]]></content:encoded></item><item><title>T8RIN/ImageToolbox</title><link>https://github.com/T8RIN/ImageToolbox</link><author></author><category>trending</category><pubDate>Tue, 11 Feb 2025 02:27:22 +0000</pubDate><source url="http://mshibanami.github.io/GitHubTrendingRSS">Dev - Github Trending</source><content:encoded><![CDATA[ðŸ–¼ï¸ Image Toolbox is a powerful app for advanced image manipulation. It offers dozens of features, from basic tools like crop and draw to filters, OCR, and a wide range of image processing optionsImageToolbox is a versatile image editing tool designed for efficient photo manipulation. It allows users to crop, apply filters, edit EXIF data, erase backgrounds, and even convert images to PDFs. Ideal for both photographers and developers, the tool offers a simple interface with powerful capabilities.Check out Image Toolbox Wiki for FAQ and useful info  Join our chat where you can discuss anything you want and also look into the CI channel where I post betas and announcements 
 This application is completely free, but if you want to support the project development, you can send a donation to the crypto wallets below17Pk1RurnkJxLV9V7mc6Y7dLyHFb9rvQDq <- TMPAu7a54NvQNEKnNWh3naXu3oYijqP3U7 <- Go to the Releases and the download latest apk or click one of the badges below.Clone the repository: git clone https://github.com/yourusername/ImageToolbox.git
Install dependencies using your preferred package manager (e.g., Gradle).Build the project: bash ./gradlew buildRun the application: bash ./gradlew runSelecting Emoji for top app barAbility to use Pixel like switch instead of Material YouMaximum brightness for selected screensEnabling or Disabling confettiCustom app color scheme 
  Controlling borders thicknessEnabling and disabling each existing shadowMonet implementation (Dynamic colors) even for Android versions less than 12 by Dynamic ThemeIcons Background shape selection 
  Custom fonts 
  Ability to import any font (OTF/TTF) to further useIn app font scale changingChanging between options list and grouped viewConfetti Type selection 
  Switch Type selection: 
  Slider Type Selection: 
  (Yes, the app supports dynamic coloring based on wallpapers for every android version)Dynamic Theme - library, which allows you to easily implement custom color theming.Modal Sheet - modal bottom sheet that follows M3 guidelines.Flow to emit values from data layer reactively.Decompose - KMP lifecycle-aware business logic components (aka BLoCs) with routing (navigation) and pluggable UIHilt for dependency injection.Konfetti to establish beautiful particle system.Compose - Modern Declarative UI style framework based on composable functions.Data Store - Store data asynchronously, consistently, and transactionally.Lifecycle - Observe Android lifecycles and handle UI states upon the lifecycle changes.GPU Image for creating and applying filters to the images.Aire and Trickle for creating and applying filters to the images on CPU using native cpp code.]]></content:encoded></item><item><title>albertan017/LLM4Decompile</title><link>https://github.com/albertan017/LLM4Decompile</link><author></author><category>trending</category><pubDate>Tue, 11 Feb 2025 02:27:22 +0000</pubDate><source url="http://mshibanami.github.io/GitHubTrendingRSS">Dev - Github Trending</source><content:encoded><![CDATA[Reverse Engineering: Decompiling Binary Code with Large Language ModelsReverse Engineering: Decompiling Binary Code with Large Language Models[2024-10-17]: Release decompile-ghidra-100k, a subset of 100k training samples (25k per optimization level). We provide a training script that runs in ~3.5 hours on a single A100 40G GPU. It achieves a 0.26 re-executability rate, with a total cost of under $20 for quick replication of LLM4Decompile.[2024-09-26]: Update a Colab notebook to demonstrate the usage of the LLM4Decompile model, including examples for the LLM4Decompile-End and LLM4Decompile-Ref models.[2024-06-19]: Release V2 series (LLM4Decompile-Ref). V2 (1.3B-22B), building upon , are trained on 2 billion tokens to  the decompiled pseudo-code from Ghidra. The 22B-V2 version outperforms the 6.7B-V1.5 by an additional 40.1%. Please check the ghidra folder for details.[2024-05-13]: Release V1.5 series (LLM4Decompile-End, directly decompile binary using LLM). V1.5 are trained with a larger dataset (15B tokens) and a maximum token , with remarkable performance (over ) compared to the previous model.[2024-03-16]: Add llm4decompile-6.7b-uo model which is trained without prior knowledge of the optimization levels (O0~O3), the average re-executability is around 0.219, performs the best in our models. is the pioneering open-source large language model dedicated to decompilation. Its current version supports decompiling Linux x86_64 binaries, ranging from GCC's O0 to O3 optimization levels, into human-readable C source code. Our team is committed to expanding this tool's capabilities, with ongoing efforts to incorporate a broader range of architectures and configurations. focuses on decompiling the binary directly.  refines the pseudo-code decompiled by Ghidra.During compilation, the Preprocessor processes the source code (SRC) to eliminate comments and expand macros or includes. The cleaned code is then forwarded to the Compiler, which converts it into assembly code (ASM). This ASM is transformed into binary code (0s and 1s) by the Assembler. The Linker finalizes the process by linking function calls to create an executable file. Decompilation, on the other hand, involves converting binary code back into a source file. LLMs, being trained on text, lack the ability to process binary data directly. Therefore, binaries must be disassembled by  into assembly language (ASM) first. It should be noted that binary and disassembled ASM are equivalent, they can be interconverted, and thus we refer to them interchangeably. Finally, the loss is computed between the decompiled code and source code to guide the training. To assess the quality of the decompiled code (SRC'), it is tested for its functionality through test assertions (re-executability). evaluates whether the decompiled code can execute properly and pass all the predefined test cases. A collection of 164 C functions that exclusively rely on  C libraries. A collection of 2,621 functions drawn from  projects, each utilizing user-defined functions, structures, and macros.Our LLM4Decompile includes models with sizes between 1.3 billion and 33 billion parameters, and we have made these models available on Hugging Face.Note 3: V1.5 series are trained with a larger dataset (15B tokens) and a maximum token size of 4,096, with remarkable performance (over 100% improvement) compared to the previous model.Note 4: V2 series are built upon  and trained on 2 billion tokens to  the decompiled pseudo-code from Ghidra. Check ghidra folder for details. Please use the script below to install the necessary environment.git clone https://github.com/albertan017/LLM4Decompile.git
cd LLM4Decompile
conda create -n 'llm4decompile' python=3.9 -y
conda activate llm4decompile
pip install -r requirements.txt
Here is an example of how to use our model (Revised for V1.5. For previous models, please check the corresponding model page at HF). Note: Replace the "func0" with the function name you want to decompile. Compile the C code into binary, and disassemble the binary into assembly instructions.import subprocess
import os
func_name = 'func0'
OPT = ["O0", "O1", "O2", "O3"]
fileName = 'samples/sample' #'path/to/file'
for opt_state in OPT:
    output_file = fileName +'_' + opt_state
    input_file = fileName+'.c'
    compile_command = f'gcc -o {output_file}.o {input_file} -{opt_state} -lm'#compile the code with GCC on Linux
    subprocess.run(compile_command, shell=True, check=True)
    compile_command = f'objdump -d {output_file}.o > {output_file}.s'#disassemble the binary file into assembly instructions
    subprocess.run(compile_command, shell=True, check=True)
    
    input_asm = ''
    with open(output_file+'.s') as f:#asm file
        asm= f.read()
        if '<'+func_name+'>:' not in asm: #IMPORTANT replace func0 with the function name
            raise ValueError("compile fails")
        asm = '<'+func_name+'>:' + asm.split('<'+func_name+'>:')[-1].split('\n\n')[0] #IMPORTANT replace func0 with the function name
        asm_clean = ""
        asm_sp = asm.split("\n")
        for tmp in asm_sp:
            if len(tmp.split("\t"))<3 and '00' in tmp:
                continue
            idx = min(
                len(tmp.split("\t")) - 1, 2
            )
            tmp_asm = "\t".join(tmp.split("\t")[idx:])  # remove the binary code
            tmp_asm = tmp_asm.split("#")[0].strip()  # remove the comments
            asm_clean += tmp_asm + "\n"
    input_asm = asm_clean.strip()
    before = f"# This is the assembly code:\n"#prompt
    after = "\n# What is the source code?\n"#prompt
    input_asm_prompt = before+input_asm.strip()+after
    with open(fileName +'_' + opt_state +'.asm','w',encoding='utf-8') as f:
        f.write(input_asm_prompt)
Assembly instructions should be in the format:<FUNCTION_NAME>:\nOPERATIONS\nOPERATIONS\nTypical assembly instructions may look like this:<func0>:
endbr64
lea    (%rdi,%rsi,1),%eax
retq
 Use LLM4Decompile to translate the assembly instructions into C:from transformers import AutoTokenizer, AutoModelForCausalLM
import torch

model_path = 'LLM4Binary/llm4decompile-6.7b-v1.5' # V1.5 Model
tokenizer = AutoTokenizer.from_pretrained(model_path)
model = AutoModelForCausalLM.from_pretrained(model_path,torch_dtype=torch.bfloat16).cuda()

with open(fileName +'_' + OPT[0] +'.asm','r') as f:#optimization level O0
    asm_func = f.read()
inputs = tokenizer(asm_func, return_tensors="pt").to(model.device)
with torch.no_grad():
    outputs = model.generate(**inputs, max_new_tokens=2048)### max length to 4096, max new tokens should be below the range
c_func_decompile = tokenizer.decode(outputs[0][len(inputs[0]):-1])

with open(fileName +'.c','r') as f:#original file
    func = f.read()

print(f'original function:\n{func}')# Note we only decompile one function, where the original file may contain multiple functions
print(f'decompiled function:\n{c_func_decompile}')
Data are stored in llm4decompile/decompile-eval/decompile-eval-executable-gcc-obj.json, using JSON list format. There are 164*4 (O0, O1, O2, O3) samples, each with five keys:: indicates the ID of the problem.: the optimization stage, is one of [O0, O1, O2, O3].: C solution for HumanEval problem.: C test assertions.Larger training dataset with the cleaning process. (done:2024.05.13)Support for popular languages/platforms and settings.Support for executable binaries. (done:2024.05.13)Integration with decompilation tools (e.g., Ghidra, Rizin)This code repository is licensed under the MIT and DeepSeek License.@misc{tan2024llm4decompile,
      title={LLM4Decompile: Decompiling Binary Code with Large Language Models}, 
      author={Hanzhuo Tan and Qi Luo and Jing Li and Yuqun Zhang},
      year={2024},
      eprint={2403.05286},
      archivePrefix={arXiv},
      primaryClass={cs.PL}
}
]]></content:encoded></item><item><title>ChrisTitusTech/winutil</title><link>https://github.com/ChrisTitusTech/winutil</link><author></author><category>trending</category><pubDate>Tue, 11 Feb 2025 02:27:22 +0000</pubDate><source url="http://mshibanami.github.io/GitHubTrendingRSS">Dev - Github Trending</source><content:encoded><![CDATA[Chris Titus Tech's Windows Utility - Install Programs, Tweaks, Fixes, and UpdatesThis utility is a compilation of Windows tasks I perform on each Windows system I use. It is meant to streamline , debloat with , troubleshoot with , and fix Windows . I am extremely picky about any contributions to keep this project clean and efficient.Winutil must be run in Admin mode because it performs system-wide tweaks. To achieve this, run PowerShell as an administrator. Here are a few ways to do it:Right-click on the start menu.Choose "Windows PowerShell (Admin)" (for Windows 10) or "Terminal (Admin)" (for Windows 11).Search and Launch Method:Type "PowerShell" or "Terminal" (for Windows 11).Press  or Right-click and choose "Run as administrator" to launch it with administrator privileges.Stable Branch (Recommended)irm "https://christitus.com/win" | iex
irm "https://christitus.com/windev" | iex
These are the sponsors that help keep this project alive with monthly contributions.ðŸ… Thanks to all ContributorsThanks a lot for spending your time helping Winutil grow. Thanks a lot! Keep rocking ðŸ».]]></content:encoded></item><item><title>godotengine/godot</title><link>https://github.com/godotengine/godot</link><author></author><category>trending</category><pubDate>Tue, 11 Feb 2025 02:27:22 +0000</pubDate><source url="http://mshibanami.github.io/GitHubTrendingRSS">Dev - Github Trending</source><content:encoded><![CDATA[Godot Engine â€“ Multi-platform 2D and 3D game engine2D and 3D cross-platform game engineGodot Engine is a feature-packed, cross-platform game engine to create 2D and 3D games from a unified interface. It provides a comprehensive set of common tools, so that users can focus on making games without having to reinvent the wheel. Games can be exported with one click to a number of platforms, including the major desktop platforms (Linux, macOS, Windows), mobile platforms (Android, iOS), as well as Web-based platforms and consoles.Free, open source and community-drivenGodot is completely free and open source under the very permissive MIT license. No strings attached, no royalties, nothing. The users' games are theirs, down to the last line of engine code. Godot's development is fully independent and community-driven, empowering users to help shape their engine to match their expectations. It is supported by the Godot Foundation not-for-profit.Before being open sourced in February 2014, Godot had been developed by Juan Linietsky and Ariel Manzur (both still maintaining the project) for several years as an in-house engine, used to publish several work-for-hire titles.Community and contributingGodot is not only an engine but an ever-growing community of users and engine developers. The main community channels are listed on the homepage.To get started contributing to the project, see the contributing guide. This document also includes guidelines for reporting bugs.]]></content:encoded></item><item><title>unionlabs/union</title><link>https://github.com/unionlabs/union</link><author></author><category>trending</category><pubDate>Tue, 11 Feb 2025 02:27:22 +0000</pubDate><source url="http://mshibanami.github.io/GitHubTrendingRSS">Dev - Github Trending</source><content:encoded><![CDATA[The trust-minimized, zero-knowledge bridging protocol, designed for censorship resistance, extremely high security, and usage in decentralized finance.Union is the hyper-efficient zero-knowledge infrastructure layer for general message passing, asset transfers, NFTs, and DeFi. Itâ€™s based on Consensus Verification and has no dependencies on trusted third parties, oracles, multi-signatures, or MPC. It implements IBC for compatibility with Cosmos chains and connects to EVM chains like Ethereum, Berachain (beacon-kit), Arbitrum, and more.The upgradability of contracts on other chains, connections, token configurations, and evolution of the protocol will all be controlled by decentralized governance, aligning the priorities of Union with its users, validators, and operators.curl --proto '=https' --tlsv1.2 -sSf -L https://install.determinate.systems/nix | sh -s -- install
(Note that some components can only be built on Linux. If you are using macOS, we recommend using OrbStack to easily set up a NixOS VM within two minutes. Most Union developers use macOS with OrbStack, and there is no need to install Nix inside of the NixOS VM.)You can now  build any of Union's components from source:nix build .#uniond -L
nix build .#voyager -L
nix build .#app -L

# to see all packages, run:
nix flake show
The result of whatever you build will be in You can now also enter our dev shell, which has all of the dependencies (, , , , etc.) you need to work on any component: (Don't worry, this will not affect your system outside of this repo)Run the following to format the entire repo and check your spelling before each PR:Check the  channel on Union's discord if you need any help with this.The official docs are hosted here. Each individual component also has accompanying developer documentation for contributors, which you can find in each .]]></content:encoded></item><item><title>potpie-ai/potpie</title><link>https://github.com/potpie-ai/potpie</link><author></author><category>trending</category><pubDate>Tue, 11 Feb 2025 02:27:22 +0000</pubDate><source url="http://mshibanami.github.io/GitHubTrendingRSS">Dev - Github Trending</source><content:encoded><![CDATA[Prompt-To-Agent : Create custom engineering agents for your codebasePotpie is an open-source platform that creates AI agents specialized in your codebase, enabling automated code analysis, testing, and development tasks. By building a comprehensive knowledge graph of your code, Potpie's agents can understand complex relationships and assist with everything from debugging to feature development.ðŸ§  : Built-in knowledge graph captures relationships between code componentsðŸ¤– Pre-built & Custom Agents: Ready-to-use agents for common tasks + build your ownðŸ”„ : Works with your existing development workflowðŸ“ˆ : Handles codebases of any size or languageBring the power of Potpie's AI agents directly into your development environment with our VSCode extension:: Access all Potpie agents without leaving your editor: Ask questions, get explanations, and implement suggestions right where you codeðŸ¤– Potpie's Prebuilt AgentsPotpie offers a suite of specialized codebase agents for automating and optimizing key aspects of software development:: Automatically analyzes stacktraces and provides debugging steps specific to your codebase.: Answers questions about your codebase and explains functions, features, and architecture.: Analyzes code changes, identifies affected APIs, and suggests improvements before merging.: Generates integration test plans and code for flows to ensure components work together properly.: Automatically creates unit test plan and code for individual functions to enhance test coverage.: Creates a low level design for implementing a new feature by providing functional requirements to this agent.: Generates code for new features, refactors existing code, and suggests optimizations.ðŸ› ï¸ Potpie's Tooling SystemPotpie provides a set of tools that agents can use to interact with the knowledge graph and the underlying infrastructure:get_code_from_probable_node_name: Retrieves code snippets based on a probable node name.: Fetches code associated with a specific node ID.get_code_from_multiple_node_ids: Retrieves code snippets for multiple node IDs simultaneously.ask_knowledge_graph_queries: Executes vector similarity searches to obtain relevant information.: Retrieves nodes tagged with specific keywords.get_code_graph_from_node_id/name: Fetches code graph structures for a specific node.: Detects changes in the current branch compared to the default branch.: Retrieves the file structure of the codebase.Docker installed and runningGit installed (for repository access)Create a  file based on the Add the following required configurations:isDevelopmentMode=enabled
ENV=development
OPENAI_API_KEY=<your-openai-key>
POSTGRES_SERVER=postgresql://postgres:mysecretpassword@localhost:5432/momentum
NEO4J_URI=bolt://127.0.0.1:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=mysecretpassword
REDISHOST=127.0.0.1
REDISPORT=6379
BROKER_URL=redis://127.0.0.1:6379/0
CELERY_QUEUE_NAME=dev
defaultUsername=defaultuser
PROJECT_PATH=projects #repositories will be downloaded/cloned to this path on your system.
Create a Virtual Environment using Python 3.10:python3.10 -m venv venv
source venv/bin/activate
alternatively, you can also use the  library.Install dependencies in your venv:pip install -r requirements.txt
chmod +x start.sh
./start.sh
 (Skip this step in development mode)curl -X POST 'http://localhost:8001/api/v1/login' \
  -H 'Content-Type: application/json' \
  -d '{
    "email": "your-email",
    "password": "your-password"
  }'
# Save the bearer token from the response for subsequent requests
Initialize Repository Parsing# For development mode:
curl -X POST 'http://localhost:8001/api/v1/parse' \
  -H 'Content-Type: application/json' \
  -d '{
    "repo_path": "path/to/local/repo",
    "branch_name": "main"
  }'

# For production mode:
curl -X POST 'http://localhost:8001/api/v1/parse' \
  -H 'Content-Type: application/json' \
  -d '{
    "repo_name": "owner/repo-name",
    "branch_name": "main"
  }'
# Save the project_id from the response
curl -X GET 'http://localhost:8001/api/v1/parsing-status/your-project-id'
# Wait until parsing is complete
curl -X GET 'http://localhost:8001/api/v1/list-available-agents/?list_system_agents=true'
# Note down the agent_id you want to use
curl -X POST 'http://localhost:8001/api/v1/conversations/' \
  -H 'Content-Type: application/json' \
  -d '{
    "user_id": "your_user_id",
    "title": "My First Conversation",
    "status": "active",
    "project_ids": ["your-project-id"],
    "agent_ids": ["chosen-agent-id"]
  }'
# Save the conversation_id from the response
Start Interacting with Your Agentcurl -X POST 'http://localhost:8001/api/v1/conversations/your-conversation-id/message/' \
  -H 'Content-Type: application/json' \
  -d '{
    "content": "Your question or request here"
  }'
View Conversation History (Optional)curl -X GET 'http://localhost:8001/api/v1/conversations/your-conversation-id/messages/?start=0&limit=10'
: For developers new to a codebase, the codebase QnA agent helps them understand the codebase and get up to speed quickly. Ask it how to setup a new project, how to run the tests etcWe tried to onboard ourselves with Potpie to the  codebase and it worked like a charm : Video here.: Answer questions about any library you're integrating, explain functions, features, and architecture.We used the Q&A agent to understand the underlying working of a feature of the  codebase that was not documented in official docs : Video here.: Get detailed implementation plans for new features or improvements before writing code.We fed an open issue from the  project to this agent to generate a low level design for it: Video here.: Understand the functional impact of changes and compute the blast radius of modifications.Here we analyse a PR from the  codebase and understand its blast radius : Video here.: Get step-by-step debugging guidance based on stacktraces and codebase context.: Generate contextually aware unit and integration test plans and test code that understand your codebase's structure and purpose.With Custom Agents, you can design personalized tools that handle repeatable tasks with precision. Key components include:: Define the agent's task, goal, and expected output: Metadata about the agent's role and context: Individual steps for job completion: Functions for querying the knowledge graph or retrieving codeðŸ—ï¸ Accessing Agents via API KeyYou can access Potpie Agents through an API key, enabling integration into CI/CD workflows and other automated processes. For detailed instructions, please refer to the Potpie API documentation.: Easily create an API key for secure access.: Use the Parse API to analyze code repositories and obtain a project ID.: Check the status of your parsing requests.: Initiate conversations with specific agents using project and agent IDs adn get a conversation id.: Communicate with agents by sending messages within a conversation.Potpie is designed to be flexible and customizable. Here are key areas to personalize your own deployment:1. System Prompts ConfigurationModify prompts in app/modules/intelligence/prompts/system_prompt_setup.pyCreate new agents in app/modules/intelligence/agents/chat_agents and app/modules/intelligence/agents/agentic_tools3. Agent Behavior CustomizationModify guidelines within each agent's prompt in the app/modules/intelligence/agents directoryEdit or add tools in the app/modules/intelligence/tools directoryWe welcome contributions! To contribute:Create a new branch (git checkout -b feature-branch)Commit (git commit -m 'Add new feature')Push to the branch (git push origin feature-branch)This project is licensed under the Apache 2.0 License - see the LICENSE file for details.ðŸ’ª Thanks To All ContributorsThanks for spending your time helping build Potpie. Keep rocking ðŸ¥‚]]></content:encoded></item><item><title>vercel/ai-chatbot</title><link>https://github.com/vercel/ai-chatbot</link><author></author><category>trending</category><pubDate>Tue, 11 Feb 2025 02:27:22 +0000</pubDate><source url="http://mshibanami.github.io/GitHubTrendingRSS">Dev - Github Trending</source><content:encoded><![CDATA[A full-featured, hackable Next.js AI chatbot built by Vercel An Open-Source AI Chatbot Template Built With Next.js and the AI SDK by Vercel. Next.js App Router 
  Advanced routing for seamless navigation and performanceReact Server Components (RSCs) and Server Actions for server-side rendering and increased performanceAI SDKUnified API for generating text, structured objects, and tool calls with LLMsHooks for building dynamic chat and generative user interfacesSupports OpenAI (default), Anthropic, Cohere, and other model providersYou can deploy your own version of the Next.js AI Chatbot to Vercel with one click:Note: You should not commit your  file or it will expose secrets that will allow others to control access to your various OpenAI and authentication provider accounts.Install Vercel CLI: Link local instance with Vercel and GitHub accounts (creates  directory): Download your environment variables: ]]></content:encoded></item><item><title>RockChinQ/LangBot</title><link>https://github.com/RockChinQ/LangBot</link><author></author><category>trending</category><pubDate>Mon, 10 Feb 2025 02:28:02 +0000</pubDate><source url="http://mshibanami.github.io/GitHubTrendingRSS">Dev - Github Trending</source><content:encoded><![CDATA[ðŸ˜Žä¸°å¯Œç”Ÿæ€ã€ðŸ§©æ”¯æŒæ‰©å±•ã€ðŸ¦„å¤šæ¨¡æ€ - å¤§æ¨¡åž‹åŽŸç”Ÿå³æ—¶é€šä¿¡æœºå™¨äººå¹³å° ðŸ¤– | é€‚é… QQ / å¾®ä¿¡ï¼ˆä¼ä¸šå¾®ä¿¡ã€ä¸ªäººå¾®ä¿¡ï¼‰/ é£žä¹¦ï¼ˆfeishuï¼‰/ Discord / OneBot ç­‰æ¶ˆæ¯å¹³å° | æ”¯æŒ OpenAI GPTã€ChatGPTã€DeepSeekã€Difyã€Claudeã€Geminiã€Ollamaã€LM Studioã€SiliconFlowã€Qwenã€Moonshotã€ChatGLM ç­‰ LLM çš„æœºå™¨äºº / Agent | LLM-based instant messaging bots platform, supports Discord, WeChat, Lark, QQ platform, OpenAI ChatGPT, DeepSeek.ðŸ’¬ å¤§æ¨¡åž‹å¯¹è¯ã€Agentï¼šæ”¯æŒå¤šç§å¤§æ¨¡åž‹ï¼Œé€‚é…ç¾¤èŠå’Œç§èŠï¼›å…·æœ‰å¤šè½®å¯¹è¯ã€å·¥å…·è°ƒç”¨ã€å¤šæ¨¡æ€èƒ½åŠ›ï¼Œå¹¶æ·±åº¦é€‚é… Difyã€‚ç›®å‰æ”¯æŒ QQã€QQé¢‘é“ã€ä¼ä¸šå¾®ä¿¡ã€é£žä¹¦ã€Discordã€ä¸ªäººå¾®ä¿¡ï¼ŒåŽç»­è¿˜å°†æ”¯æŒ WhatsAppã€Telegram ç­‰å¹³å°ã€‚ðŸ› ï¸ é«˜ç¨³å®šæ€§ã€åŠŸèƒ½å®Œå¤‡ï¼šåŽŸç”Ÿæ”¯æŒè®¿é—®æŽ§åˆ¶ã€é™é€Ÿã€æ•æ„Ÿè¯è¿‡æ»¤ç­‰æœºåˆ¶ï¼›é…ç½®ç®€å•ï¼Œæ”¯æŒå¤šç§éƒ¨ç½²æ–¹å¼ã€‚ðŸ§© æ’ä»¶æ‰©å±•ã€æ´»è·ƒç¤¾åŒºï¼šæ”¯æŒäº‹ä»¶é©±åŠ¨ã€ç»„ä»¶æ‰©å±•ç­‰æ’ä»¶æœºåˆ¶ï¼›ä¸°å¯Œç”Ÿæ€ï¼Œç›®å‰å·²æœ‰æ•°åä¸ªæ’ä»¶ðŸ˜» [New] Web ç®¡ç†é¢æ¿ï¼šæ”¯æŒé€šè¿‡æµè§ˆå™¨ç®¡ç† LangBot å®žä¾‹ï¼Œå…·ä½“æ”¯æŒåŠŸèƒ½ï¼ŒæŸ¥çœ‹æ–‡æ¡£å·²ä¸Šæž¶å®å¡”é¢æ¿ï¼Œè‹¥æ‚¨å·²å®‰è£…å®å¡”é¢æ¿ï¼Œå¯ä»¥æ ¹æ®æ–‡æ¡£ä½¿ç”¨ã€‚LangBot ç¦»ä¸å¼€ä»¥ä¸‹è´¡çŒ®è€…å’Œç¤¾åŒºå†…æ‰€æœ‰äººçš„è´¡çŒ®ï¼Œæˆ‘ä»¬æ¬¢è¿Žä»»ä½•å½¢å¼çš„è´¡çŒ®å’Œåé¦ˆã€‚]]></content:encoded></item><item><title>practical-tutorials/project-based-learning</title><link>https://github.com/practical-tutorials/project-based-learning</link><author></author><category>trending</category><pubDate>Mon, 10 Feb 2025 02:28:02 +0000</pubDate><source url="http://mshibanami.github.io/GitHubTrendingRSS">Dev - Github Trending</source><content:encoded><![CDATA[Curated list of project-based tutorialsA list of programming tutorials in which aspiring software developers learn how to build an application from scratch. These tutorials are divided into different primary programming languages. Tutorials may involve multiple technologies and languages.To get started, simply fork this repo. Please refer to CONTRIBUTING.md for contribution guidelines.Others (Hapi, Express...):]]></content:encoded></item><item><title>AUTOMATIC1111/stable-diffusion-webui</title><link>https://github.com/AUTOMATIC1111/stable-diffusion-webui</link><author></author><category>trending</category><pubDate>Mon, 10 Feb 2025 02:28:02 +0000</pubDate><source url="http://mshibanami.github.io/GitHubTrendingRSS">Dev - Github Trending</source><content:encoded><![CDATA[A web interface for Stable Diffusion, implemented using Gradio library.Original txt2img and img2img modesOne click install and run script (but you still must install python and git)Attention, specify parts of text that the model should pay more attention to 
  a man in a  - will pay more attention to tuxedoa man in a  - alternative syntaxselect text and press  or  (or  or  if you're on a MacOS) to automatically adjust attention to selected text (code contributed by anonymous user)Loopback, run img2img processing multiple timesX/Y/Z plot, a way to draw a 3 dimensional plot of images with different parametersTextual Inversion 
  have as many embeddings as you want and use any names you like for themuse multiple embeddings with different numbers of vectors per tokenworks with half precision floating point numberstrain embeddings on 8GB (also reports of 6GB working)Extras tab with: 
  GFPGAN, neural network that fixes facesCodeFormer, face restoration tool as an alternative to GFPGANRealESRGAN, neural network upscalerESRGAN, neural network upscaler with a lot of third party modelsSwinIR and Swin2SR (see here), neural network upscalersLDSR, Latent diffusion super resolution upscalingResizing aspect ratio optionsSampling method selection 
  Adjust sampler eta values (noise multiplier)More advanced noise setting optionsInterrupt processing at any time4GB video card support (also reports of 2GB working)Correct seeds for batchesLive prompt token length validationGeneration parameters 
  parameters you used to generate images are saved with that imagein PNG chunks for PNG, in EXIF for JPEGcan drag the image to PNG info tab to restore generation parameters and automatically copy them into UIcan be disabled in settingsdrag and drop an image/text-parameters to promptboxRead Generation Parameters Button, loads parameters in promptbox to UIRunning arbitrary python code from UI (must run with  to enable)Mouseover hints for most UI elementsPossible to change defaults/mix/max/step values for UI elements via text configTiling support, a checkbox to create images that can be tiled like texturesProgress bar and live image generation preview 
  Can use a separate neural network to produce previews with almost none VRAM or compute requirementNegative prompt, an extra text field that allows you to list what you don't want to see in generated imageStyles, a way to save part of prompt and easily apply them via dropdown laterVariations, a way to generate same image but with tiny differencesSeed resizing, a way to generate same image but at slightly different resolutionCLIP interrogator, a button that tries to guess prompt from an imagePrompt Editing, a way to change prompt mid-generation, say to start making a watermelon and switch to anime girl midwayBatch Processing, process a group of files using img2imgImg2img Alternative, reverse Euler method of cross attention controlHighres Fix, a convenience option to produce high resolution pictures in one click without usual distortionsReloading checkpoints on the flyCheckpoint Merger, a tab that allows you to merge up to 3 checkpoints into oneComposable-Diffusion, a way to use multiple prompts at once 
  separate prompts using uppercase also supports weights for prompts: a cat :1.2 AND a dog AND a penguin :2.2No token limit for prompts (original stable diffusion lets you use up to 75 tokens)DeepDanbooru integration, creates danbooru style tags for anime promptsxformers, major speed increase for select cards: (add  to commandline args)via extension: History tab: view, direct and delete images conveniently within the UITraining tab 
  hypernetworks and embeddings optionsPreprocessing images: cropping, mirroring, autotagging using BLIP or deepdanbooru (for anime)Loras (same as Hypernetworks but more pretty)A separate UI where you can choose, with preview, which embeddings, hypernetworks or Loras to add to your promptCan select to load a different VAE from settings screenEstimated completion time in progress barNow without any bad letters!Load checkpoints in safetensors formatEased resolution restriction: generated image's dimensions must be a multiple of 8 rather than 64Reorder elements in the UI from settings screenMake sure the required dependencies are met and follow the instructions available for:Alternatively, use online services (like Google Colab):Installation on Windows 10/11 with NVidia-GPUs using release packageDownload  from v1.0.0-pre and extract its contents.Automatic Installation on WindowsInstall Python 3.10.6 (Newer version of Python does not support torch), checking "Add Python to PATH".Download the stable-diffusion-webui repository, for example by running git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git.Run  from Windows Explorer as normal, non-administrator, user.Automatic Installation on LinuxInstall the dependencies:# Debian-based:
sudo apt install wget git python3 python3-venv libgl1 libglib2.0-0
# Red Hat-based:
sudo dnf install wget git python3 gperftools-libs libglvnd-glx
# openSUSE-based:
sudo zypper install wget git python3 libtcmalloc4 libglvnd
# Arch-based:
sudo pacman -S wget git python3
If your system is very new, you need to install python3.11 or python3.10:# Ubuntu 24.04
sudo add-apt-repository ppa:deadsnakes/ppa
sudo apt update
sudo apt install python3.11

# Manjaro/Arch
sudo pacman -S yay
yay -S python311 # do not confuse with python3.11 package

# Only for 3.11
# Then set up env variable in launch script
export python_cmd="python3.11"
# or in webui-user.sh
python_cmd="python3.11"
Navigate to the directory you would like the webui to be installed and execute the following command:wget -q https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/webui.sh
Or just clone the repo wherever you want:git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui
Check  for options.Installation on Apple SiliconFind the instructions here.The documentation was moved from this README over to the project's wiki.For the purposes of getting Google and other search engines to crawl the wiki, here's a link to the (not for humans) crawlable wiki.Licenses for borrowed code can be found in  screen, and also in  file.]]></content:encoded></item><item><title>yamadashy/repomix</title><link>https://github.com/yamadashy/repomix</link><author></author><category>trending</category><pubDate>Mon, 10 Feb 2025 02:28:02 +0000</pubDate><source url="http://mshibanami.github.io/GitHubTrendingRSS">Dev - Github Trending</source><content:encoded><![CDATA[ðŸ“¦ Repomix (formerly Repopack) is a powerful tool that packs your entire repository into a single, AI-friendly file. Perfect for when you need to feed your codebase to Large Language Models (LLMs) or other AI tools like Claude, ChatGPT, DeepSeek, Perplexity, Gemini, Gemma, Llama, Grok, and more.Pack your codebase into AI-friendly formats Need discussion? Join us on Discord!Share your experience and tipsStay updated on new featuresGet help with configuration and usageðŸ“¦ Repomix is a powerful tool that packs your entire repository into a single, AI-friendly file. It is perfect for when you need to feed your codebase to Large Language Models (LLMs) or other AI tools like Claude, ChatGPT, DeepSeek, Perplexity, Gemini, Gemma, Llama, Grok, and more.ðŸŽ‰ New: Repomix Website & Discord Community!We look forward to seeing you there!: Formats your codebase in a way that's easy for AI to understand and process.: Provides token counts for each file and the entire repository, useful for LLM context limits.: You need just one command to pack your entire repository.: Easily configure what to include or exclude.: Automatically respects your .gitignore files.: Incorporates Secretlint for robust security checks to detect and prevent inclusion of sensitive information.You can try Repomix instantly in your project directory without installation:Or install globally for repeated use:# Install using npm
npm install -g repomix

# Alternatively using yarn
yarn global add repomix

# Alternatively using Homebrew (macOS/Linux)
brew install repomix

# Then run in any project directory
repomix
That's it! Repomix will generate a  file in your current directory, containing your entire repository in an AI-friendly format.You can then send this file to an AI assistant with a prompt like:This file contains all the files in the repository combined into one.
I want to refactor the code, so please review it first.
When you propose specific changes, the AI might be able to generate code accordingly. With features like Claude's Artifacts, you could potentially output multiple files, allowing for the generation of multiple interdependent pieces of code.Want to try it quickly? Visit the official website at repomix.com. Simply enter your repository name, fill in any optional details, and click the  button to see your generated output.The website offers several convenient features:Customizable output format (Plain Text, XML, or Markdown)Instant token count estimationUsing The VSCode Extension âš¡ï¸A community-maintained VSCode extension lets you run Repomix right inside your editor with just a few clicks. Run it on any folder, manage outputs seamlessly, and control everything through VSCode's intuitive interface.Want your output as a file or just the content? Need automatic cleanup? This extension has you covered. Plus, it works smoothly with your existing repomix.config.json.To pack your entire repository:To pack a specific directory:repomix path/to/directory
repomix --include "src/**/*.ts,**/*.md"
To exclude specific files or directories:repomix --ignore "**/*.log,tmp/"
To pack a remote repository:repomix --remote https://github.com/yamadashy/repomix

# You can also use GitHub shorthand:
repomix --remote yamadashy/repomix

# You can specify the branch name, tag, or commit hash:
repomix --remote https://github.com/yamadashy/repomix --remote-branch main

# Or use a specific commit hash:
repomix --remote https://github.com/yamadashy/repomix --remote-branch 935b695

# Another convenient way is specifying the branch's URL
repomix --remote https://github.com/yamadashy/repomix/tree/main

# Commit's URL is also supported
repomix --remote https://github.com/yamadashy/repomix/commit/836abcd7335137228ad77feb28655d85712680f1

To initialize a new configuration file ():Once you have generated the packed file, you can use it with Generative AI tools like Claude, ChatGPT, and Gemini.You can also run Repomix using Docker. This is useful if you want to run Repomix in an isolated environment or prefer using containers.Basic usage (current directory):docker run -v .:/app -it --rm ghcr.io/yamadashy/repomix
To pack a specific directory:docker run -v .:/app -it --rm ghcr.io/yamadashy/repomix path/to/directory
Process a remote repository and output to a  directory:docker run -v ./output:/app -it --rm ghcr.io/yamadashy/repomix --remote https://github.com/yamadashy/repomix
Once you have generated the packed file with Repomix, you can use it with AI tools like Claude, ChatGPT, and Gemini. Here are some example prompts to get you started:Code Review and RefactoringFor a comprehensive code review and refactoring suggestions:This file contains my entire codebase. Please review the overall structure and suggest any improvements or refactoring opportunities, focusing on maintainability and scalability.
To generate project documentation:Based on the codebase in this file, please generate a detailed README.md that includes an overview of the project, its main features, setup instructions, and usage examples.
For generating test cases:Analyze the code in this file and suggest a comprehensive set of unit tests for the main functions and classes. Include edge cases and potential error scenarios.
Evaluate code quality and adherence to best practices:Review the codebase for adherence to coding best practices and industry standards. Identify areas where the code could be improved in terms of readability, maintainability, and efficiency. Suggest specific changes to align the code with best practices.
Get a high-level understanding of the libraryThis file contains the entire codebase of library. Please provide a comprehensive overview of the library, including its main purpose, key features, and overall architecture.
Feel free to modify these prompts based on your specific needs and the capabilities of the AI tool you're using.Which AI tools they're using with RepomixEffective prompts they've discoveredHow Repomix has helped themTips and tricks for getting the most out of AI code analysisFeel free to join the discussion and share your own experiences! Your insights could help others make better use of Repomix.Repomix generates a single file with clear separators between different parts of your codebase. To enhance AI comprehension, the output file begins with an AI-oriented explanation, making it easier for AI models to understand the context and structure of the packed repository.Plain Text Format (default)This file is a merged representation of the entire codebase, combining all repository files into a single document.

================================================================
File Summary
================================================================
(Metadata and usage AI instructions)

================================================================
Directory Structure
================================================================
src/
  cli/
    cliOutput.ts
    index.ts
  config/
    configLoader.ts

(...remaining directories)

================================================================
Files
================================================================

================
File: src/index.js
================
// File contents here

================
File: src/utils.js
================
// File contents here

(...remaining files)

================================================================
Instruction
================================================================
(Custom instructions from `output.instructionFilePath`)
To generate output in XML format, use the  option:The XML format structures the content in a hierarchical manner:This file is a merged representation of the entire codebase, combining all repository files into a single document.

<file_summary>
  (Metadata and usage AI instructions)
</file_summary>

<directory_structure>
src/
cli/
cliOutput.ts
index.ts

(...remaining directories)
</directory_structure>

<files>
<file path="src/index.js">
  // File contents here
</file>

(...remaining files)
</files>

<instruction>
(Custom instructions from `output.instructionFilePath`)
</instruction>
When your prompts involve multiple components like context, instructions, and examples, XML tags can be a game-changer. They help Claude parse your prompts more accurately, leading to higher-quality outputs.This means that the XML output from Repomix is not just a different format, but potentially a more effective way to feed your codebase into AI systems for analysis, code review, or other tasks.To generate output in Markdown format, use the  option:The Markdown format structures the content in a hierarchical manner:This file is a merged representation of the entire codebase, combining all repository files into a single document.

# File Summary

(Metadata and usage AI instructions)

# Repository Structure

```
src/
  cli/
    cliOutput.ts
    index.ts
```

(...remaining directories)

# Repository Files

## File: src/index.js

```
// File contents here
```

(...remaining files)

# Instruction

(Custom instructions from `output.instructionFilePath`)
This format provides a clean, readable structure that is both human-friendly and easily parseable by AI systems.: Show tool version: Specify the output file name: Specify the output style (, , ): Enable parsable output based on the chosen style schema. Note that this can increase token count.--output-show-line-numbers: Show line numbers in the output: Additionally copy generated output to system clipboard: Disable file summary section output: Disable directory structure section output: Remove comments from supported file types: Remove empty lines from the output: Custom text to include in the file header--instruction-file-path <path>: Path to a file containing detailed custom instructions--include-empty-directories: Include empty directories in the output: List of include patterns (comma-separated): Additional ignore patterns (comma-separated): Disable .gitignore file usage: Disable default patternsRemote Repository Options: Process a remote Git repository: Specify the remote branch name, tag, or commit hash (defaults to repository default branch): Path to a custom config file: Create config file: Use global config: Disable security check--token-count-encoding <encoding>: Specify token count encoding (e.g., , ): Number of top files to display in the summary: Enable verbose loggingrepomix -o custom-output.txt
repomix -i "*.log,tmp" -v
repomix -c ./custom-config.json
repomix --style xml
repomix --remote https://github.com/user/repo
npx repomix src
To update a globally installed Repomix:# Using npm
npm update -g repomix

# Using yarn
yarn global upgrade repomix
Using  is generally more convenient as it always uses the latest version.Remote Repository ProcessingRepomix supports processing remote Git repositories without the need for manual cloning. This feature allows you to quickly analyze any public Git repository with a single command.To process a remote repository, use the  option followed by the repository URL:repomix --remote https://github.com/yamadashy/repomix
You can also use GitHub's shorthand format:repomix --remote yamadashy/repomix
You can specify the branch name, tag, or commit hash:# Using --remote-branch option
repomix --remote https://github.com/yamadashy/repomix --remote-branch main

# Using branch's URL
repomix --remote https://github.com/yamadashy/repomix/tree/main
Or use a specific commit hash:# Using --remote-branch option
repomix --remote https://github.com/yamadashy/repomix --remote-branch 935b695

# Using commit's URL
repomix --remote https://github.com/yamadashy/repomix/commit/836abcd7335137228ad77feb28655d85712680f1
Create a  file in your project root for custom configurations.Here's an explanation of the configuration options:The name of the output fileThe style of the output (, , )Whether to escape the output based on the chosen style schema. Note that this can increase token count.Custom text to include in the file headeroutput.instructionFilePathPath to a file containing detailed custom instructionsWhether to include a summary section at the beginning of the outputoutput.directoryStructureWhether to include the directory structure in the outputWhether to remove comments from supported file typesWhether to remove empty lines from the outputWhether to add line numbers to each line in the outputWhether to copy the output to system clipboard in addition to saving the fileNumber of top files to display in the summary. If set to 0, no summary will be displayedoutput.includeEmptyDirectoriesWhether to include empty directories in the repository structureWhether to use patterns from the project's  fileignore.useDefaultPatternsWhether to use default ignore patternssecurity.enableSecurityCheckWhether to perform security checks on filesToken count encoding for AI model context limits (e.g., , ){
  "output": {
    "filePath": "repomix-output.xml",
    "style": "xml",
    "parsableStyle": true,
    "headerText": "Custom header information for the packed file.",
    "fileSummary": true,
    "directoryStructure": true,
    "removeComments": false,
    "removeEmptyLines": false,
    "showLineNumbers": false,
    "copyToClipboard": true,
    "topFilesLength": 5,
    "includeEmptyDirectories": false
  },
  "include": [
    "**/*"
  ],
  "ignore": {
    "useGitignore": true,
    "useDefaultPatterns": true,
    // Patterns can also be specified in .repomixignore
    "customPatterns": [
      "additional-folder",
      "**/*.log"
    ]
  },
  "security": {
    "enableSecurityCheck": true
  },
  "tokenCount": {
    "encoding": "o200k_base"
  }
}
To create a global configuration file:The global configuration file will be created in:Windows: %LOCALAPPDATA%\Repomix\repomix.config.jsonmacOS/Linux: $XDG_CONFIG_HOME/repomix/repomix.config.json or ~/.config/repomix/repomix.config.jsonNote: Local configuration (if present) takes precedence over global configuration.Repomix now supports specifying files to include using glob patterns. This allows for more flexible and powerful file selection:Use  to include all JavaScript files in any directoryUse  to include all files within the  directory and its subdirectoriesCombine multiple patterns like ["src/**/*.js", "**/*.md"] to include JavaScript files in  and all Markdown filesRepomix offers multiple methods to set ignore patterns for excluding specific files or directories during the packing process:: By default, patterns listed in your project's  file are used. This behavior can be controlled with the  setting or the  cli option.: Repomix includes a default list of commonly excluded files and directories (e.g., node_modules, .git, binary files). This feature can be controlled with the ignore.useDefaultPatterns setting or the  cli option. Please see defaultIgnore.ts for more details.: You can create a  file in your project root to define Repomix-specific ignore patterns. This file follows the same format as .: Additional ignore patterns can be specified using the  option in the configuration file. You can overwrite this setting with the  command line option.Priority Order (from highest to lowest):Custom patterns  (if  is true and  is not used)Default patterns (if ignore.useDefaultPatterns is true and  is not used)This approach allows for flexible file exclusion configuration based on your project's needs. It helps optimize the size of the generated pack file by ensuring the exclusion of security-sensitive files and large binary files, while preventing the leakage of confidential information.Note: Binary files are not included in the packed output by default, but their paths are listed in the "Repository Structure" section of the output file. This provides a complete overview of the repository structure while keeping the packed file efficient and text-based.The output.instructionFilePath option allows you to specify a separate file containing detailed instructions or context about your project. This allows AI systems to understand the specific context and requirements of your project, potentially leading to more relevant and tailored analysis or suggestions.Here's an example of how you might use this feature:Create a file named  in your project root:# Coding Guidelines

- Follow the Airbnb JavaScript Style Guide
- Suggest splitting files into smaller, focused units when appropriate
- Add comments for non-obvious logic. Keep all text in English
- All new features should have corresponding unit tests

# Generate Comprehensive Output

- Include all content without abbreviation, unless specified otherwise
- Optimize for handling large codebases while maintaining output quality
In your , add the  option:{
  "output": {
    "instructionFilePath": "repomix-instruction.md",
    // other options...
  }
}
When Repomix generates the output, it will include the contents of  in a dedicated section.Put long-form data at the top: Place your long documents and inputs (~20K+ tokens) near the top of your prompt, above your query, instructions, and examples. This can significantly improve Claude's performance across all models. Queries at the end can improve response quality by up to 30% in tests, especially with complex, multi-document inputs.When  is set to , Repomix will attempt to remove comments from supported file types. This feature can help reduce the size of the output file and focus on the essential code content.Supported languages include: HTML, CSS, JavaScript, TypeScript, Vue, Svelte, Python, PHP, Ruby, C, C#, Java, Go, Rust, Swift, Kotlin, Dart, Shell, and YAML.Note: The comment removal process is conservative to avoid accidentally removing code. In complex cases, some comments might be retained.Repomix includes a security check feature that uses Secretlint to detect potentially sensitive information in your files. This feature helps you identify possible security risks before sharing your packed repository.The security check results will be displayed in the CLI output after the packing process is complete. If any suspicious files are detected, you'll see a list of these files along with a warning message.ðŸ” Security Check:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
2 suspicious file(s) detected:
1. src/utils/test.txt
2. tests/utils/secretLintUtils.test.ts

Please review these files for potentially sensitive information.
By default, Repomix's security check feature is enabled. You can disable it by setting security.enableSecurityCheck to  in your configuration file:{
  "security": {
    "enableSecurityCheck": false
  }
}
Or using the  command line option:repomix --no-security-check
[!NOTE] Disabling security checks may expose sensitive information. Use this option with caution and only when necessary, such as when working with test files or documentation that contains example credentials.We welcome contributions from the community! To get started, please refer to our Contributing Guide.: The Repomix CLI tool does  collect, transmit, or store any user data, telemetry, or repository information.: Repomix CLI operates fully offline after installation. The only cases where an internet connection is needed are: 
  Installation via npm/yarn.Using the  flag to process remote repositories.Checking for updates (manually triggered).: Since all processing is local, Repomix CLI is safe to use with private and internal repositories.: The Repomix website uses  to collect usage data, such as page views and user interactions. This helps us understand how the website is used and improve the user experience.Repomix (both the CLI tool and the website) is provided "as is" without any warranties or guarantees. We do not take responsibility for how the generated output is used, including but not limited to its accuracy, legality, or any potential consequences arising from its use.]]></content:encoded></item><item><title>lobehub/lobe-chat</title><link>https://github.com/lobehub/lobe-chat</link><author></author><category>trending</category><pubDate>Sun, 9 Feb 2025 02:28:32 +0000</pubDate><source url="http://mshibanami.github.io/GitHubTrendingRSS">Dev - Github Trending</source><content:encoded><![CDATA[ðŸ¤¯ Lobe Chat - an open-source, modern-design AI chat framework. Supports Multi AI Providers( OpenAI / Claude 3 / Gemini / Ollama / Qwen / DeepSeek), Knowledge Base (file upload / knowledge management / RAG ), Multi-Modals (Vision/TTS/Plugins/Artifacts). One-click FREE deployment of your private ChatGPT/ Claude application.ðŸ‘‹ðŸ» Getting Started & Join Our CommunityWe are a group of e/acc design-engineers, hoping to provide modern design components and tools for AIGC. By adopting the Bootstrapping approach, we aim to provide developers and users with a more open, transparent, and user-friendly product ecosystem.Whether for users or professional developers, LobeHub will be your AI Agent playground. Please be aware that LobeChat is currently under active development, and feedback is welcome for any issues encountered., You will receive all release notifications from GitHub without any delay ~ â­ï¸LobeChat supports file upload and knowledge base functionality. You can upload various types of files including documents, images, audio, and video, as well as create knowledge bases, making it convenient for users to manage and search for files. Additionally, you can utilize files and knowledge base features during conversations, enabling a richer dialogue experience.In the continuous development of LobeChat, we deeply understand the importance of diversity in model service providers for meeting the needs of the community when providing AI conversation services. Therefore, we have expanded our support to multiple model service providers, rather than being limited to a single one, in order to offer users a more diverse and rich selection of conversations.In this way, LobeChat can more flexibly adapt to the needs of different users, while also providing developers with a wider range of choices.Supported Model Service ProvidersWe have implemented support for the following model service providers:: OpenAI is a global leader in artificial intelligence research, with models like the GPT series pushing the frontiers of natural language processing. OpenAI is committed to transforming multiple industries through innovative and efficient AI solutions. Their products demonstrate significant performance and cost-effectiveness, widely used in research, business, and innovative applications.: Ollama provides models that cover a wide range of fields, including code generation, mathematical operations, multilingual processing, and conversational interaction, catering to diverse enterprise-level and localized deployment needs.: Anthropic is a company focused on AI research and development, offering a range of advanced language models such as Claude 3.5 Sonnet, Claude 3 Sonnet, Claude 3 Opus, and Claude 3 Haiku. These models achieve an ideal balance between intelligence, speed, and cost, suitable for various applications from enterprise workloads to rapid-response scenarios. Claude 3.5 Sonnet, as their latest model, has excelled in multiple evaluations while maintaining a high cost-performance ratio.: Bedrock is a service provided by Amazon AWS, focusing on delivering advanced AI language and visual models for enterprises. Its model family includes Anthropic's Claude series, Meta's Llama 3.1 series, and more, offering a range of options from lightweight to high-performance, supporting tasks such as text generation, conversation, and image processing for businesses of varying scales and needs.: Google's Gemini series represents its most advanced, versatile AI models, developed by Google DeepMind, designed for multimodal capabilities, supporting seamless understanding and processing of text, code, images, audio, and video. Suitable for various environments from data centers to mobile devices, it significantly enhances the efficiency and applicability of AI models.: DeepSeek is a company focused on AI technology research and application, with its latest model DeepSeek-V2.5 integrating general dialogue and code processing capabilities, achieving significant improvements in human preference alignment, writing tasks, and instruction following.: The HuggingFace Inference API provides a fast and free way for you to explore thousands of models for various tasks. Whether you are prototyping for a new application or experimenting with the capabilities of machine learning, this API gives you instant access to high-performance models across multiple domains.: OpenRouter is a service platform providing access to various cutting-edge large model interfaces, supporting OpenAI, Anthropic, LLaMA, and more, suitable for diverse development and application needs. Users can flexibly choose the optimal model and pricing based on their requirements, enhancing the AI experience.: Run serverless GPU-powered machine learning models on Cloudflare's global network.: With GitHub Models, developers can become AI engineers and leverage the industry's leading AI models.At the same time, we are also planning to support more model service providers. If you would like LobeChat to support your favorite service provider, feel free to join our ðŸ’¬ community discussion.To meet the specific needs of users, LobeChat also supports the use of local models based on Ollama, allowing users to flexibly use their own or third-party models.LobeChat now supports OpenAI's latest  model with visual recognition capabilities, a multimodal intelligence that can perceive visuals. Users can easily upload or drag and drop images into the dialogue box, and the agent will be able to recognize the content of the images and engage in intelligent conversation based on this, creating smarter and more diversified chat scenarios.This feature opens up new interactive methods, allowing communication to transcend text and include a wealth of visual elements. Whether it's sharing images in daily use or interpreting images within specific industries, the agent provides an outstanding conversational experience.LobeChat supports Text-to-Speech (TTS) and Speech-to-Text (STT) technologies, enabling our application to convert text messages into clear voice outputs, allowing users to interact with our conversational agent as if they were talking to a real person. Users can choose from a variety of voices to pair with the agent.Moreover, TTS offers an excellent solution for those who prefer auditory learning or desire to receive information while busy. In LobeChat, we have meticulously selected a range of high-quality voice options (OpenAI Audio, Microsoft Edge Speech) to meet the needs of users from different regions and cultural backgrounds. Users can choose the voice that suits their personal preferences or specific scenarios, resulting in a personalized communication experience.With support for the latest text-to-image generation technology, LobeChat now allows users to invoke image creation tools directly within conversations with the agent. By leveraging the capabilities of AI tools such as , , and , the agents are now equipped to transform your ideas into images.This enables a more private and immersive creative process, allowing for the seamless integration of visual storytelling into your personal dialogue with the agent.The plugin ecosystem of LobeChat is an important extension of its core functionality, greatly enhancing the practicality and flexibility of the LobeChat assistant.By utilizing plugins, LobeChat assistants can obtain and process real-time information, such as searching for web information and providing users with instant and relevant news.In addition, these plugins are not limited to news aggregation, but can also extend to other practical functions, such as quickly searching documents, generating images, obtaining data from various platforms like Bilibili, Steam, and interacting with various third-party services.Smart web search that reads and analyzes pages to deliver comprehensive answers from Google results.Find any NFT data on the NEAR Protocol.Search for information from the internet base BingApiAnalyze stocks and get comprehensive real-time investment data and analytics.In LobeChat Agent Marketplace, creators can discover a vibrant and innovative community that brings together a multitude of well-designed agents, which not only play an important role in work scenarios but also offer great convenience in learning processes. Our marketplace is not just a showcase platform but also a collaborative space. Here, everyone can contribute their wisdom and share the agents they have developed.By ðŸ¤–/ðŸª Submit Agents, you can easily submit your agent creations to our platform. Importantly, LobeChat has established a sophisticated automated internationalization (i18n) workflow, capable of seamlessly translating your agent into multiple language versions. This means that no matter what language your users speak, they can experience your agent without barriers.We welcome all users to join this growing ecosystem and participate in the iteration and optimization of agents. Together, we can create more interesting, practical, and innovative agents, further enriching the diversity and practicality of the agent offerings.LobeChat supports the use of both server-side and local databases. Depending on your needs, you can choose the appropriate deployment solution:: suitable for users who want more control over their data and privacy protection. LobeChat uses CRDT (Conflict-Free Replicated Data Type) technology to achieve multi-device synchronization. This is an experimental feature aimed at providing a seamless data synchronization experience.: suitable for users who want a more convenient user experience. LobeChat supports PostgreSQL as a server-side database. For detailed documentation on how to configure the server-side database, please visit Configure Server-side Database.Regardless of which database you choose, LobeChat can provide you with an excellent user experience.LobeChat supports multi-user management and provides two main user authentication and management solutions to meet different needs:: LobeChat integrates , a flexible and powerful identity verification library that supports multiple authentication methods, including OAuth, email login, credential login, etc. With , you can easily implement user registration, login, session management, social login, and other functions to ensure the security and privacy of user data.: For users who need more advanced user management features, LobeChat also supports , a modern user management platform.  provides richer functions, such as multi-factor authentication (MFA), user profile management, login activity monitoring, etc. With , you can get higher security and flexibility, and easily cope with complex user management needs.Regardless of which user management solution you choose, LobeChat can provide you with an excellent user experience and powerful functional support.We deeply understand the importance of providing a seamless experience for users in today's multi-device environment. Therefore, we have adopted Progressive Web Application (PWA) technology, a modern web technology that elevates web applications to an experience close to that of native apps.Through PWA, LobeChat can offer a highly optimized user experience on both desktop and mobile devices while maintaining its lightweight and high-performance characteristics. Visually and in terms of feel, we have also meticulously designed the interface to ensure it is indistinguishable from native apps, providing smooth animations, responsive layouts, and adapting to different device screen resolutions.If you are unfamiliar with the installation process of PWA, you can add LobeChat as your desktop application (also applicable to mobile devices) by following these steps:Launch the Chrome or Edge browser on your computer.Visit the LobeChat webpage.In the upper right corner of the address bar, click on the  icon.Follow the instructions on the screen to complete the PWA Installation.We have carried out a series of optimization designs for mobile devices to enhance the user's mobile experience. Currently, we are iterating on the mobile user experience to achieve smoother and more intuitive interactions. If you have any suggestions or ideas, we welcome you to provide feedback through GitHub Issues or Pull Requests.As a design-engineering-oriented application, LobeChat places great emphasis on users' personalized experiences, hence introducing flexible and diverse theme modes, including a light mode for daytime and a dark mode for nighttime. Beyond switching theme modes, a range of color customization options allow users to adjust the application's theme colors according to their preferences. Whether it's a desire for a sober dark blue, a lively peach pink, or a professional gray-white, users can find their style of color choices in LobeChat.The default configuration can intelligently recognize the user's system color mode and automatically switch themes to ensure a consistent visual experience with the operating system. For users who like to manually control details, LobeChat also offers intuitive setting options and a choice between chat bubble mode and document mode for conversation scenarios.Beside these features, LobeChat also have much better basic technique underground:âœ¨ more features will be added when LobeChat evolve.You can find our upcoming Roadmap plans in the Projects section.LobeChat provides Self-Hosted Version with Vercel, Alibaba Cloud, and Docker Image. This allows you to deploy your own chatbot within a few minutes without any prior knowledge. Deploying with Vercel, Zeabur , Sealos or Alibaba Cloud"If you want to deploy this service yourself on Vercel, Zeabur or Alibaba Cloud, you can follow these steps:Click the button below to start deployment: Log in directly with your GitHub account, and remember to fill in the (required) and  (recommended) on the environment variable section.After deployment, you can start using it.Bind a custom domain (optional): The DNS of the domain assigned by Vercel is polluted in some areas; binding a custom domain can connect directly.After fork, only retain the upstream sync action and disable other actions in your repository on GitHub.If you have deployed your own project following the one-click deployment steps in the README, you might encounter constant prompts indicating "updates available." This is because Vercel defaults to creating a new project instead of forking this one, resulting in an inability to detect updates accurately.We provide a Docker image for deploying the LobeChat service on your own private device. Use the following command to start the LobeChat service:$ docker run -d -p 3210:3210 \
  -e OPENAI_API_KEY=sk-xxxx \
  -e ACCESS_CODE=lobe66 \
  --name lobe-chat \
  lobehub/lobe-chat
If you need to use the OpenAI service through a proxy, you can configure the proxy address using the  environment variable:$ docker run -d -p 3210:3210 \
  -e OPENAI_API_KEY=sk-xxxx \
  -e OPENAI_PROXY_URL=https://api-proxy.com/v1 \
  -e ACCESS_CODE=lobe66 \
  --name lobe-chat \
  lobehub/lobe-chat
This project provides some additional configuration items set with environment variables:This is the API key you apply on the OpenAI account pageIf you manually configure the OpenAI interface proxy, you can use this configuration item to override the default OpenAI API request base URLhttps://api.chatanywhere.cn or The default value ishttps://api.openai.com/v1Add a password to access this service; you can set a long password to avoid leaking. If this value contains a comma, it is a password array. or  or Used to control the model list. Use  to add a model,  to hide a model, and  to customize the display name of a model, separated by commas.qwen-7b-chat,+glm-6b,-gpt-3.5-turboPlugins provide a means to extend the Function Calling capabilities of LobeChat. They can be used to introduce new function calls and even new ways to render message results. If you are interested in plugin development, please refer to our ðŸ“˜ Plugin Development Guide in the Wiki.lobe-chat-plugins: This is the plugin index for LobeChat. It accesses index.json from this repository to display a list of available plugins for LobeChat to the user.@lobehub/chat-plugins-gateway: The LobeChat Plugins Gateway is a backend service that provides a gateway for LobeChat plugins. We deploy this service using Vercel. The primary API POST /api/v1/runner is deployed as an Edge Function.The plugin system is currently undergoing major development. You can learn more in the following issues:[x] : Implement separation of the plugin from the main body, split the plugin into an independent repository for maintenance, and realize dynamic loading of the plugin.[x] : The security and stability of the plugin's use, more accurately presenting abnormal states, the maintainability of the plugin architecture, and developer-friendly.[x] : Higher-level and more comprehensive customization capabilities, support for plugin authentication, and examples.You can use GitHub Codespaces for online development:Or clone it for local development:$ git clone https://github.com/lobehub/lobe-chat.git
$ cd lobe-chat
$ pnpm install
$ pnpm dev
Contributions of all types are more than welcome; if you are interested in contributing code, feel free to check out our GitHub Issues and Projects to get stuck in to show us what youâ€™re made of.We are creating a technology-driven forum, fostering knowledge interaction and the exchange of ideas that may culminate in mutual inspiration and collaborative innovation.Help us make LobeChat better. Welcome to provide product design feedback, user experience discussions directly to us.Every bit counts and your one-time donation sparkles in our galaxy of support! You're a shooting star, making a swift and bright impact on our journey. Thank you for believing in us â€“ your generosity guides us toward our mission, one brilliant flash at a time. Modern theme for Stable Diffusion WebUI, exquisite interface design, highly customizable UI, and efficiency-boosting features. WebUI for Midjourney, leverages AI to quickly generate a wide array of rich and diverse images from text prompts, sparking creativity and enhancing conversations. Lobe i18n is an automation tool for the i18n (internationalization) translation process, powered by ChatGPT. It supports features such as automatic splitting of large files, incremental updates, and customization options for the OpenAI model, API proxy, and temperature. Lobe Commit is a CLI tool that leverages Langchain/ChatGPT to generate Gitmoji-based commit messages.]]></content:encoded></item><item><title>mendableai/firecrawl</title><link>https://github.com/mendableai/firecrawl</link><author></author><category>trending</category><pubDate>Sun, 9 Feb 2025 02:28:32 +0000</pubDate><source url="http://mshibanami.github.io/GitHubTrendingRSS">Dev - Github Trending</source><content:encoded><![CDATA[ðŸ”¥ Turn entire websites into LLM-ready markdown or structured data. Scrape, crawl and extract with a single API.Empower your AI apps with clean data from any website. Featuring advanced scraping, crawling, and data extraction capabilities.This repository is in development, and weâ€™re still integrating custom modules into the mono repo. It's not fully ready for self-hosted deployment yet, but you can run it locally.Firecrawl is an API service that takes a URL, crawls it, and converts it into clean markdown or structured data. We crawl all accessible subpages and give you clean data for each. No sitemap required. Check out our documentation.Pst. hey, you, join our stargazers :)We provide an easy to use API with our hosted version. You can find the playground and documentation here. You can also self host the backend if you'd like.Check out the following resources to get started:To run locally, refer to guide here.To use the API, you need to sign up on Firecrawl and get an API key.: scrapes a URL and get its content in LLM-ready format (markdown, structured data via LLM Extract, screenshot, html): scrapes all the URLs of a web page and return content in LLM-ready format: input a website and get all the website urls - extremely fast: get structured data from single page, multiple pages or entire websites with AI.: markdown, structured data, screenshot, HTML, links, metadata: proxies, anti-bot mechanisms, dynamic content (js-rendered), output parsing, orchestration: exclude tags, crawl behind auth walls with custom headers, max crawl depth, etc...: pdfs, docx, images: designed to get the data you need - no matter how hard it is: click, scroll, input, wait and more before extracting data: scrape thousands of URLs at the same time with a new async endpoint.You can find all of Firecrawl's capabilities and how to use them in our documentationUsed to crawl a URL and all accessible subpages. This submits a crawl job and returns a job ID to check the status of the crawl.curl -X POST https://api.firecrawl.dev/v1/crawl \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer fc-YOUR_API_KEY' \
    -d '{
      "url": "https://docs.firecrawl.dev",
      "limit": 100,
      "scrapeOptions": {
        "formats": ["markdown", "html"]
      }
    }'
Returns a crawl job id and the url to check the status of the crawl.{
  "success": true,
  "id": "123-456-789",
  "url": "https://api.firecrawl.dev/v1/crawl/123-456-789"
}
Used to check the status of a crawl job and get its result.curl -X GET https://api.firecrawl.dev/v1/crawl/123-456-789 \
  -H 'Content-Type: application/json' \
  -H 'Authorization: Bearer YOUR_API_KEY'
{
  "status": "completed",
  "total": 36,
  "creditsUsed": 36,
  "expiresAt": "2024-00-00T00:00:00.000Z",
  "data": [
    {
      "markdown": "[Firecrawl Docs home page![light logo](https://mintlify.s3-us-west-1.amazonaws.com/firecrawl/logo/light.svg)!...",
      "html": "<!DOCTYPE html><html lang=\"en\" class=\"js-focus-visible lg:[--scroll-mt:9.5rem]\" data-js-focus-visible=\"\">...",
      "metadata": {
        "title": "Build a 'Chat with website' using Groq Llama 3 | Firecrawl",
        "language": "en",
        "sourceURL": "https://docs.firecrawl.dev/learn/rag-llama3",
        "description": "Learn how to use Firecrawl, Groq Llama 3, and Langchain to build a 'Chat with your website' bot.",
        "ogLocaleAlternate": [],
        "statusCode": 200
      }
    }
  ]
}
Used to scrape a URL and get its content in the specified formats.curl -X POST https://api.firecrawl.dev/v1/scrape \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer YOUR_API_KEY' \
    -d '{
      "url": "https://docs.firecrawl.dev",
      "formats" : ["markdown", "html"]
    }'
{
  "success": true,
  "data": {
    "markdown": "Launch Week I is here! [See our Day 2 Release ðŸš€](https://www.firecrawl.dev/blog/launch-week-i-day-2-doubled-rate-limits)[ðŸ’¥ Get 2 months free...",
    "html": "<!DOCTYPE html><html lang=\"en\" class=\"light\" style=\"color-scheme: light;\"><body class=\"__variable_36bd41 __variable_d7dc5d font-inter ...",
    "metadata": {
      "title": "Home - Firecrawl",
      "description": "Firecrawl crawls and converts any website into clean markdown.",
      "language": "en",
      "keywords": "Firecrawl,Markdown,Data,Mendable,Langchain",
      "robots": "follow, index",
      "ogTitle": "Firecrawl",
      "ogDescription": "Turn any website into LLM-ready data.",
      "ogUrl": "https://www.firecrawl.dev/",
      "ogImage": "https://www.firecrawl.dev/og.png?123",
      "ogLocaleAlternate": [],
      "ogSiteName": "Firecrawl",
      "sourceURL": "https://firecrawl.dev",
      "statusCode": 200
    }
  }
}
Used to map a URL and get urls of the website. This returns most links present on the website.curl -X POST https://api.firecrawl.dev/v1/map \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer YOUR_API_KEY' \
    -d '{
      "url": "https://firecrawl.dev"
    }'
{
  "status": "success",
  "links": [
    "https://firecrawl.dev",
    "https://www.firecrawl.dev/pricing",
    "https://www.firecrawl.dev/blog",
    "https://www.firecrawl.dev/playground",
    "https://www.firecrawl.dev/smart-crawl",
  ]
}
Map with  param allows you to search for specific urls inside a website.curl -X POST https://api.firecrawl.dev/v1/map \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer YOUR_API_KEY' \
    -d '{
      "url": "https://firecrawl.dev",
      "search": "docs"
    }'
Response will be an ordered list from the most relevant to the least relevant.{
  "status": "success",
  "links": [
    "https://docs.firecrawl.dev",
    "https://docs.firecrawl.dev/sdks/python",
    "https://docs.firecrawl.dev/learn/rag-llama3",
  ]
}
Get structured data from entire websites with a prompt and/or a schema.You can extract structured data from one or multiple URLs, including wildcards:When you use /*, Firecrawl will automatically crawl and parse all URLs it can discover in that domain, then extract the requested data.curl -X POST https://api.firecrawl.dev/v1/extract \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer YOUR_API_KEY' \
    -d '{
      "urls": [
        "https://firecrawl.dev/*", 
        "https://docs.firecrawl.dev/", 
        "https://www.ycombinator.com/companies"
      ],
      "prompt": "Extract the company mission, whether it is open source, and whether it is in Y Combinator from the page.",
      "schema": {
        "type": "object",
        "properties": {
          "company_mission": {
            "type": "string"
          },
          "is_open_source": {
            "type": "boolean"
          },
          "is_in_yc": {
            "type": "boolean"
          }
        },
        "required": [
          "company_mission",
          "supports_sso",
          "is_open_source",
          "is_in_yc"
        ]
      }
    }'
{
  "success": true,
  "id": "44aa536d-f1cb-4706-ab87-ed0386685740",
  "urlTrace": []
}
If you are using the sdks, it will auto pull the response for you:{
  "success": true,
  "data": {
    "company_mission": "Firecrawl is the easiest way to extract data from the web. Developers use us to reliably convert URLs into LLM-ready markdown or structured data with a single API call.",
    "supports_sso": false,
    "is_open_source": true,
    "is_in_yc": true
  }
}
Used to extract structured data from scraped pages.curl -X POST https://api.firecrawl.dev/v1/scrape \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer YOUR_API_KEY' \
    -d '{
      "url": "https://www.mendable.ai/",
      "formats": ["json"],
      "jsonOptions": {
        "schema": {
          "type": "object",
          "properties": {
            "company_mission": {
                      "type": "string"
            },
            "supports_sso": {
                      "type": "boolean"
            },
            "is_open_source": {
                      "type": "boolean"
            },
            "is_in_yc": {
                      "type": "boolean"
            }
          },
          "required": [
            "company_mission",
            "supports_sso",
            "is_open_source",
            "is_in_yc"
          ]
        }
      }
    }'
{
  "success": true,
  "data": {
    "content": "Raw Content",
    "metadata": {
      "title": "Mendable",
      "description": "Mendable allows you to easily build AI chat applications. Ingest, customize, then deploy with one line of code anywhere you want. Brought to you by SideGuide",
      "robots": "follow, index",
      "ogTitle": "Mendable",
      "ogDescription": "Mendable allows you to easily build AI chat applications. Ingest, customize, then deploy with one line of code anywhere you want. Brought to you by SideGuide",
      "ogUrl": "https://mendable.ai/",
      "ogImage": "https://mendable.ai/mendable_new_og1.png",
      "ogLocaleAlternate": [],
      "ogSiteName": "Mendable",
      "sourceURL": "https://mendable.ai/"
    },
    "json": {
      "company_mission": "Train a secure AI on your technical resources that answers customer and employee questions so your team doesn't have to",
      "supports_sso": true,
      "is_open_source": false,
      "is_in_yc": true
    }
  }
}
Extracting without a schema (New)You can now extract without a schema by just passing a  to the endpoint. The llm chooses the structure of the data.curl -X POST https://api.firecrawl.dev/v1/scrape \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer YOUR_API_KEY' \
    -d '{
      "url": "https://docs.firecrawl.dev/",
      "formats": ["json"],
      "jsonOptions": {
        "prompt": "Extract the company mission from the page."
      }
    }'
Interacting with the page with Actions (Cloud-only)Firecrawl allows you to perform various actions on a web page before scraping its content. This is particularly useful for interacting with dynamic content, navigating through pages, or accessing content that requires user interaction.Here is an example of how to use actions to navigate to google.com, search for Firecrawl, click on the first result, and take a screenshot.curl -X POST https://api.firecrawl.dev/v1/scrape \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer YOUR_API_KEY' \
    -d '{
        "url": "google.com",
        "formats": ["markdown"],
        "actions": [
            {"type": "wait", "milliseconds": 2000},
            {"type": "click", "selector": "textarea[title=\"Search\"]"},
            {"type": "wait", "milliseconds": 2000},
            {"type": "write", "text": "firecrawl"},
            {"type": "wait", "milliseconds": 2000},
            {"type": "press", "key": "ENTER"},
            {"type": "wait", "milliseconds": 3000},
            {"type": "click", "selector": "h3"},
            {"type": "wait", "milliseconds": 3000},
            {"type": "screenshot"}
        ]
    }'
Batch Scraping Multiple URLs (New)You can now batch scrape multiple URLs at the same time. It is very similar to how the /crawl endpoint works. It submits a batch scrape job and returns a job ID to check the status of the batch scrape.curl -X POST https://api.firecrawl.dev/v1/batch/scrape \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer YOUR_API_KEY' \
    -d '{
      "urls": ["https://docs.firecrawl.dev", "https://docs.firecrawl.dev/sdks/overview"],
      "formats" : ["markdown", "html"]
    }'
The search endpoint combines web search with Firecrawlâ€™s scraping capabilities to return full page content for any query.Include  with  to get complete markdown content for each search result otherwise it defaults to getting SERP results (url, title, description).curl -X POST https://api.firecrawl.dev/v1/search \
    -H 'Content-Type: application/json' \
    -H 'Authorization: Bearer YOUR_API_KEY' \
    -d '{
      "query": "What is Mendable?"
    }'
{
  "success": true,
  "data": [
    {
      "url": "https://mendable.ai",
      "title": "Mendable | AI for CX and Sales",
      "description": "AI for CX and Sales"
    }
  ]
}
from firecrawl.firecrawl import FirecrawlApp

app = FirecrawlApp(api_key="fc-YOUR_API_KEY")

# Scrape a website:
scrape_status = app.scrape_url(
  'https://firecrawl.dev', 
  params={'formats': ['markdown', 'html']}
)
print(scrape_status)

# Crawl a website:
crawl_status = app.crawl_url(
  'https://firecrawl.dev', 
  params={
    'limit': 100, 
    'scrapeOptions': {'formats': ['markdown', 'html']}
  },
  poll_interval=30
)
print(crawl_status)
Extracting structured data from a URLWith LLM extraction, you can easily extract structured data from any URL. We support pydantic schemas to make it easier for you too. Here is how you to use it:
from firecrawl.firecrawl import FirecrawlApp

app = FirecrawlApp(api_key="fc-YOUR_API_KEY")

class ArticleSchema(BaseModel):
    title: str
    points: int
    by: str
    commentsURL: str

class TopArticlesSchema(BaseModel):
    top: List[ArticleSchema] = Field(..., max_items=5, description="Top 5 stories")

data = app.scrape_url('https://news.ycombinator.com', {
    'formats': ['json'],
    'jsonOptions': {
        'schema': TopArticlesSchema.model_json_schema()
    }
})
print(data["json"])
To install the Firecrawl Node SDK, you can use npm:npm install @mendable/firecrawl-js
Set the API key as an environment variable named  or pass it as a parameter to the  class.import FirecrawlApp, { CrawlParams, CrawlStatusResponse } from '@mendable/firecrawl-js';

const app = new FirecrawlApp({apiKey: "fc-YOUR_API_KEY"});

// Scrape a website
const scrapeResponse = await app.scrapeUrl('https://firecrawl.dev', {
  formats: ['markdown', 'html'],
});

if (scrapeResponse) {
  console.log(scrapeResponse)
}

// Crawl a website
const crawlResponse = await app.crawlUrl('https://firecrawl.dev', {
  limit: 100,
  scrapeOptions: {
    formats: ['markdown', 'html'],
  }
} satisfies CrawlParams, true, 30) satisfies CrawlStatusResponse;

if (crawlResponse) {
  console.log(crawlResponse)
}
Extracting structured data from a URLWith LLM extraction, you can easily extract structured data from any URL. We support zod schema to make it easier for you too. Here is how to use it:import FirecrawlApp from "@mendable/firecrawl-js";
import { z } from "zod";

const app = new FirecrawlApp({
  apiKey: "fc-YOUR_API_KEY"
});

// Define schema to extract contents into
const schema = z.object({
  top: z
    .array(
      z.object({
        title: z.string(),
        points: z.number(),
        by: z.string(),
        commentsURL: z.string(),
      })
    )
    .length(5)
    .describe("Top 5 stories on Hacker News"),
});

const scrapeResult = await app.scrapeUrl("https://news.ycombinator.com", {
  jsonOptions: { extractionSchema: schema },
});

console.log(scrapeResult.data["json"]);
Open Source vs Cloud OfferingFirecrawl is open source available under the AGPL-3.0 license.To deliver the best possible product, we offer a hosted version of Firecrawl alongside our open-source offering. The cloud solution allows us to continuously innovate and maintain a high-quality, sustainable service for all users.Firecrawl Cloud is available at firecrawl.dev and offers a range of features that are not available in the open source version:It is the sole responsibility of the end users to respect websites' policies when scraping, searching and crawling with Firecrawl. Users are advised to adhere to the applicable privacy policies and terms of use of the websites prior to initiating any scraping activities. By default, Firecrawl respects the directives specified in the websites' robots.txt files when crawling. By utilizing Firecrawl, you expressly agree to comply with these conditions.This project is primarily licensed under the GNU Affero General Public License v3.0 (AGPL-3.0), as specified in the LICENSE file in the root directory of this repository. However, certain components of this project are licensed under the MIT License. Refer to the LICENSE files in these specific directories for details.The AGPL-3.0 license applies to all parts of the project unless otherwise specified.The SDKs and some UI components are licensed under the MIT License. Refer to the LICENSE files in these specific directories for details.When using or contributing to this project, ensure you comply with the appropriate license terms for the specific component you are working with.For more details on the licensing of specific components, please refer to the LICENSE files in the respective directories or contact the project maintainers.]]></content:encoded></item><item><title>k2-fsa/sherpa-onnx</title><link>https://github.com/k2-fsa/sherpa-onnx</link><author></author><category>trending</category><pubDate>Sun, 9 Feb 2025 02:28:32 +0000</pubDate><source url="http://mshibanami.github.io/GitHubTrendingRSS">Dev - Github Trending</source><content:encoded><![CDATA[Speech-to-text, text-to-speech, speaker diarization, and VAD using next-gen Kaldi with onnxruntime without Internet connection. Support embedded systems, Android, iOS, HarmonyOS, Raspberry Pi, RISC-V, x86_64 servers, websocket server/client, C/C++, Python, Kotlin, C#, Go, NodeJS, Java, Swift, Dart, JavaScript, Flutter, Object Pascal, Lazarus, RustSpoken Language identificationSupported programming languagesIt also supports WebAssembly.This repository supports running the following functions Speech-to-text (i.e., ASR); both streaming and non-streaming are supportedText-to-speech (i.e., TTS)Spoken language identificationon the following platforms and operating systems:Links for Huggingface SpacesLinks for pre-built Android APKsLinks for pre-built Flutter APPsLinks for pre-built Lazarus APPsLinks for pre-trained modelsSome pre-trained ASR models (Streaming)Some pre-trained ASR models (Non-Streaming)Projects using sherpa-onnxTalk to any LLM with hands-free voice interaction, voice interruption, and Live2D taking face running locally across platformsUses streaming ASR in C# with graphical user interface.It uses the JavaScript API of sherpa-onnx along with ElectronA server based on nodejs providing Restful API for speech recognition.ä¸€ä¸ªæ¨¡å—åŒ–ï¼Œå…¨è¿‡ç¨‹å¯ç¦»çº¿ï¼Œä½Žå ç”¨çŽ‡çš„å¯¹è¯æœºå™¨äºº/æ™ºèƒ½éŸ³ç®±It uses QT. Both ASR and TTS are used.]]></content:encoded></item><item><title>langgenius/dify</title><link>https://github.com/langgenius/dify</link><author></author><category>trending</category><pubDate>Sun, 9 Feb 2025 02:28:32 +0000</pubDate><source url="http://mshibanami.github.io/GitHubTrendingRSS">Dev - Github Trending</source><content:encoded><![CDATA[Dify is an open-source LLM app development platform. Dify's intuitive interface combines AI workflow, RAG pipeline, agent capabilities, model management, observability features and more, letting you quickly go from prototype to production.Dify is an open-source LLM app development platform. Its intuitive interface combines agentic AI workflow, RAG pipeline, agent capabilities, model management, observability features and more, letting you quickly go from prototype to production.Before installing Dify, make sure your machine meets the following minimum system requirements:The easiest way to start the Dify server is through docker compose. Before running Dify with the following commands, make sure that Docker and Docker Compose are installed on your machine:cd dify
cd docker
cp .env.example .env
docker compose up -d
After running, you can access the Dify dashboard in your browser at http://localhost/install and start the initialization process.Please refer to our FAQ if you encounter problems setting up Dify. Reach out to the community and us if you are still having issues.: Build and test powerful AI workflows on a visual canvas, leveraging all the following features and beyond.2. Comprehensive model support: Seamless integration with hundreds of proprietary / open-source LLMs from dozens of inference providers and self-hosted solutions, covering GPT, Mistral, Llama3, and any OpenAI API-compatible models. A full list of supported model providers can be found here.: Intuitive interface for crafting prompts, comparing model performance, and adding additional features such as text-to-speech to a chat-based app.: Extensive RAG capabilities that cover everything from document ingestion to retrieval, with out-of-box support for text extraction from PDFs, PPTs, and other common document formats.: You can define agents based on LLM Function Calling or ReAct, and add pre-built or custom tools for the agent. Dify provides 50+ built-in tools for AI agents, such as Google Search, DALLÂ·E, Stable Diffusion and WolframAlpha.: Monitor and analyze application logs and performance over time. You could continuously improve prompts, datasets, and models based on production data and annotations.: All of Dify's offerings come with corresponding APIs, so you could effortlessly integrate Dify into your own business logic.Enterprise Feature (SSO/Access control) We host a Dify Cloud service for anyone to try with zero setup. It provides all the capabilities of the self-deployed version, and includes 200 free GPT-4 calls in the sandbox plan.Self-hosting Dify Community Edition Quickly get Dify running in your environment with this starter guide. Use our documentation for further references and more in-depth instructions.Star Dify on GitHub and be instantly notified of new releases.If you need to customize the configuration, please refer to the comments in our .env.example file and update the corresponding values in your  file. Additionally, you might need to make adjustments to the  file itself, such as changing image versions, port mappings, or volume mounts, based on your specific deployment environment and requirements. After making any changes, please re-run . You can find the full list of available environment variables here.If you'd like to configure a highly-available setup, there are community-contributed Helm Charts and YAML files which allow Dify to be deployed on Kubernetes.Using Terraform for DeploymentDeploy Dify to Cloud Platform with a single click using terraformUsing AWS CDK for DeploymentDeploy Dify to AWS with CDKFor those who'd like to contribute code, see our Contribution Guide. At the same time, please consider supporting Dify by sharing it on social media and at events and conferences.We are looking for contributors to help with translating Dify to languages other than Mandarin or English. If you are interested in helping, please see the i18n README for more information, and leave us a comment in the  channel of our Discord Community Server.Discord. Best for: sharing your applications and hanging out with the community.X(Twitter). Best for: sharing your applications and hanging out with the community.To protect your privacy, please avoid posting security issues on GitHub. Instead, send your questions to security@dify.ai and we will provide you with a more detailed answer.This repository is available under the Dify Open Source License, which is essentially Apache 2.0 with a few additional restrictions.]]></content:encoded></item><item><title>microsoft/terminal</title><link>https://github.com/microsoft/terminal</link><author></author><category>trending</category><pubDate>Sun, 9 Feb 2025 02:28:32 +0000</pubDate><source url="http://mshibanami.github.io/GitHubTrendingRSS">Dev - Github Trending</source><content:encoded><![CDATA[The new Windows Terminal and the original Windows console host, all in the same place!This repository contains the source code for:Related repositories include:Installing and running Windows Terminal[!NOTE] Windows Terminal requires Windows 10 2004 (build 19041) or laterMicrosoft Store [Recommended]This is our preferred method.For users who are unable to install Windows Terminal from the Microsoft Store, released builds can be manually downloaded from this repository's Releases page.Download the Microsoft.WindowsTerminal_<versionNumber>.msixbundle file from the  section. To install the app, you can simply double-click on the  file, and the app installer should automatically run. If that fails for any reason, you can try the following command at a PowerShell prompt:# NOTE: If you are using PowerShell 7+, please run
# Import-Module Appx -UseWindowsPowerShell
# before using Add-AppxPackage.

Add-AppxPackage Microsoft.WindowsTerminal_<versionNumber>.msixbundle
[!NOTE] If you install Terminal manually:You may need to install the VC++ v14 Desktop Framework Package. This should only be necessary on older builds of Windows 10 and only if you get an error about missing framework packages.Terminal will not auto-update when new builds are released so you will need to regularly install the latest Terminal release to receive all the latest fixes and improvements!Via Windows Package Manager CLI (aka winget)winget users can download and install the latest Terminal release by installing the Microsoft.WindowsTerminal package:winget install --id Microsoft.WindowsTerminal -e
[!NOTE] Dependency support is available in WinGet version 1.6.2631 or later. To install the Terminal stable release 1.18 or later, please make sure you have the updated version of the WinGet client.Via Chocolatey (unofficial)Chocolatey users can download and install the latest Terminal release by installing the microsoft-windows-terminal package:choco install microsoft-windows-terminal
To upgrade Windows Terminal using Chocolatey, run the following:choco upgrade microsoft-windows-terminal
Scoop users can download and install the latest Terminal release by installing the  package:scoop bucket add extras
scoop install windows-terminal
To update Windows Terminal using Scoop, run the following:scoop update windows-terminal
If you have any issues when installing/updating the package, please search for or report the same on the issues page of Scoop Extras bucket repository.Installing Windows Terminal CanaryWindows Terminal Canary is a nightly build of Windows Terminal. This build has the latest code from our  branch, giving you an opportunity to try features before they make it to Windows Terminal Preview.Windows Terminal Canary is our least stable offering, so you may discover bugs before we have had a chance to find them.Windows Terminal Canary is available as an App Installer distribution and a Portable ZIP distribution.The App Installer distribution supports automatic updates. Due to platform limitations, this installer only works on Windows 11.The Portable ZIP distribution is a portable application. It will not automatically update and will not automatically check for updates. This portable ZIP distribution works on Windows 10 (19041+) and Windows 11.The plan for the Windows Terminal is described here and will be updated as the project proceeds.Terminal & Console OverviewPlease take a few minutes to review the overview below before diving into the code:Windows Terminal is a new, modern, feature-rich, productive terminal application for command-line users. It includes many of the features most frequently requested by the Windows command-line community including support for tabs, rich text, globalization, configurability, theming & styling, and more.The Terminal will also need to meet our goals and measures to ensure it remains fast and efficient, and doesn't consume vast amounts of memory or power.The Windows Console host, , is Windows' original command-line user experience. It also hosts Windows' command-line infrastructure and the Windows Console API server, input engine, rendering engine, user preferences, etc. The console host code in this repository is the actual source from which the  in Windows itself is built.However, because Windows Console's primary goal is to maintain backward compatibility, we have been unable to add many of the features the community (and the team) have been wanting for the last several years including tabs, unicode text, and emoji.These limitations led us to create the new Windows Terminal.While overhauling Windows Console, we modernized its codebase considerably, cleanly separating logical entities into modules and classes, introduced some key extensibility points, replaced several old, home-grown collections and containers with safer, more efficient STL containers, and made the code simpler and safer by using Microsoft's Windows Implementation Libraries - WIL.This overhaul resulted in several of Console's key components being available for re-use in any terminal implementation on Windows. These components include a new DirectWrite-based text layout and rendering engine, a text buffer capable of storing both UTF-16 and UTF-8, a VT parser/emitter, and more.Creating the new Windows TerminalWhen we started planning the new Windows Terminal application, we explored and evaluated several approaches and technology stacks. We ultimately decided that our goals would be best met by continuing our investment in our C++ codebase, which would allow us to reuse several of the aforementioned modernized components in both the existing Console and the new Terminal. Further, we realized that this would allow us to build much of the Terminal's core itself as a reusable UI control that others can incorporate into their own applications.The result of this work is contained within this repo and delivered as the Windows Terminal application you can download from the Microsoft Store, or directly from this repo's releases.For more information about Windows Terminal, you may find some of these resources useful and interesting:I built and ran the new Terminal, but it looks just like the old consoleCause: You're launching the incorrect solution in Visual Studio.Solution: Make sure you're building & deploying the  project in Visual Studio.[!NOTE]  is just a locally-built , the classic Windows Console that hosts Windows' command-line infrastructure. OpenConsole is used by Windows Terminal to connect to and communicate with command-line applications (via ConPty).We are excited to work alongside you, our amazing community, to build and enhance Windows Terminal!BEFORE you start work on a feature/fix, please read & follow our Contributor's Guide to help avoid any wasted or duplicate effort.Communicating with the TeamThe easiest way to communicate with the team is via GitHub issues.Please file new issues, feature requests and suggestions, but DO search for similar open/closed preexisting issues before creating a new issue.If you would like to ask a question that you feel doesn't warrant an issue (yet), please reach out to us via Twitter:OpenConsole.sln may be built from within Visual Studio or from the command-line using a set of convenience scripts & tools in the  directory:Import-Module .\tools\OpenConsole.psm1
Set-MsBuildDevEnvironment
Invoke-OpenConsoleBuild
To debug the Windows Terminal in VS, right click on  (in the Solution Explorer) and go to properties. In the Debug menu, change "Application process" and "Background task process" to "Native Only".You should then be able to build & debug the Terminal project by hitting . Make sure to select either the "x64" or the "x86" platform - the Terminal doesn't build for "Any Cpu" (because the Terminal is a C++ application, not a C# one).ðŸ‘‰ You will  be able to launch the Terminal directly by running the WindowsTerminal.exe. For more details on why, see #926, #4043Please review these brief docs below about our coding practices.ðŸ‘‰ If you find something missing from these docs, feel free to contribute to any of our documentation files anywhere in the repository (or write some new ones!)This is a work in progress as we learn what we'll need to provide people in order to be effective contributors to our project.]]></content:encoded></item><item><title>ruanyf/weekly</title><link>https://github.com/ruanyf/weekly</link><author></author><category>trending</category><pubDate>Sun, 9 Feb 2025 02:28:32 +0000</pubDate><source url="http://mshibanami.github.io/GitHubTrendingRSS">Dev - Github Trending</source><content:encoded><![CDATA[P.S. è®¨è®ºåŒºçš„ã€Šè°åœ¨æ‹›äººã€‹ï¼Œæ˜¯ä¸€ä¸ªå…è´¹çš„ç¨‹åºå‘˜æ‹›è˜å¸–ï¼Œæä¾›å¤§é‡å°±ä¸šä¿¡æ¯ï¼Œæ¬¢è¿Žè®¿é—®æˆ–å‘å¸ƒå·¥ä½œ/å®žä¹ å²—ä½ã€‚å‘¨åˆŠå·²ç»æ²‰æ·€äº†å¤§é‡å†…å®¹ï¼Œå¯ä»¥ä½¿ç”¨ä¸‹é¢çš„å‡ ç§æ–¹æ³•è¿›è¡Œæœç´¢ã€‚3ã€å°†è¿™ä¸ªä»“åº“å…‹éš†åˆ°æœ¬åœ°ï¼Œç„¶åŽåœ¨ä»“åº“ç›®å½•ä½¿ç”¨ä¸‹é¢çš„å‘½ä»¤ã€‚$ grep -nri [æœç´¢è¯] docs | cat --number
$ grep -nri css docs | cat --number
]]></content:encoded></item><item><title>openai/openai-cookbook</title><link>https://github.com/openai/openai-cookbook</link><author></author><category>trending</category><pubDate>Sun, 9 Feb 2025 02:28:32 +0000</pubDate><source url="http://mshibanami.github.io/GitHubTrendingRSS">Dev - Github Trending</source><content:encoded><![CDATA[Examples and guides for using the OpenAI APIExample code and guides for accomplishing common tasks with the OpenAI API. To run these examples, you'll need an OpenAI account and associated API key (create a free account here). Set an environment variable called  with your API key. Alternatively, in most IDEs such as Visual Studio Code, you can create an  file at the root of your repo containing OPENAI_API_KEY=<your API key>, which will be picked up by the notebooks.Most code examples are written in Python, though the concepts can be applied in any language.The OpenAI Cookbook is a community-driven resource. Whether you're submitting an idea, fixing a typo, adding a new guide, or improving an existing one, your contributions are greatly appreciated!Before contributing, read through the existing issues and pull requests to see if someone else is already working on something similar. That way you can avoid duplicating efforts.If there are examples or guides you'd like to see, feel free to suggest them on the issues page.If you'd like to contribute new content, make sure to read through our contribution guidelines. We welcome high-quality submissions of new examples and guides, as long as they meet our criteria and fit within the scope of the cookbook.]]></content:encoded></item><item><title>jingyaogong/minimind</title><link>https://github.com/jingyaogong/minimind</link><author></author><category>trending</category><pubDate>Sun, 9 Feb 2025 02:28:32 +0000</pubDate><source url="http://mshibanami.github.io/GitHubTrendingRSS">Dev - Github Trending</source><content:encoded><![CDATA[ðŸš€ðŸš€ ã€Œå¤§æ¨¡åž‹ã€50åˆ†é’Ÿå®Œå…¨ä»Ž0è®­ç»ƒ26Mçš„å°å‚æ•°GPTï¼ðŸŒ Train a 26M-parameter GPT from scratch in just 50 min!æœ¬å¼€æºé¡¹ç›®æ—¨åœ¨å®Œå…¨ä»Ž0å¼€å§‹ï¼Œæœ€å¿«ä»…ç”¨3å°æ—¶ï¼å³å¯è®­ç»ƒå‡ºä»…ä¸º26.88Må¤§å°çš„å¾®åž‹è¯­è¨€æ¨¡åž‹ã€‚æžå…¶è½»é‡ï¼Œæœ€å°ç‰ˆæœ¬ä½“ç§¯çº¦æ˜¯ GPT3 çš„ $\frac{1}{7000}$ï¼ŒåŠ›æ±‚åšåˆ°æœ€æ™®é€šçš„ä¸ªäººGPUä¹Ÿå¯å¿«é€ŸæŽ¨ç†ç”šè‡³è®­ç»ƒã€‚å‘å¸ƒäº†å¤§æ¨¡åž‹æžç®€ç»“æž„ï¼Œæ•°æ®é›†æ¸…æ´—å’Œé¢„å¤„ç†ã€ç›‘ç£é¢„è®­ç»ƒ(Pretrain)ã€æœ‰ç›‘ç£æŒ‡ä»¤å¾®è°ƒ(SFT)ã€ä½Žç§©è‡ªé€‚åº”(LoRA) å¾®è°ƒï¼Œæ— å¥–åŠ±å¼ºåŒ–å­¦ä¹ ç›´æŽ¥åå¥½å¯¹é½(DPO)çš„å…¨é˜¶æ®µä»£ç ï¼Œä¹ŸåŒ…å«æ‹“å±•å…±äº«æ··åˆä¸“å®¶(MoE) çš„ç¨€ç–æ¨¡åž‹ï¼›æ‹“å±•è§†è§‰å¤šæ¨¡æ€VLM: MiniMind-Vã€‚è¿™ä¸ä»…æ˜¯ä¸€ä¸ªå¼€æºæ¨¡åž‹çš„å®žçŽ°ï¼Œä¹Ÿæ˜¯å…¥é—¨å¤§è¯­è¨€æ¨¡åž‹ï¼ˆLLMï¼‰çš„æ•™ç¨‹ã€‚å¸Œæœ›æ­¤é¡¹ç›®èƒ½ä¸ºç ”ç©¶è€…æä¾›ä¸€ä¸ªæŠ›ç –å¼•çŽ‰çš„å…¥é—¨ç¤ºä¾‹ï¼Œå¸®åŠ©å¤§å®¶å¿«é€Ÿä¸Šæ‰‹å¹¶å¯¹LLMé¢†åŸŸäº§ç”Ÿæ›´å¤šçš„æŽ¢ç´¢ä¸Žåˆ›æ–°ã€‚ä¸ºé˜²æ­¢è¯¯è¯»ï¼Œã€Œæœ€å¿«3å°æ—¶ã€æ˜¯æŒ‡æ‚¨éœ€è¦å…·å¤‡ï¼žæœ¬äººç¡¬ä»¶é…ç½®çš„æœºå™¨ï¼Œå…·ä½“è§„æ ¼çš„è¯¦ç»†ä¿¡æ¯å°†åœ¨ä¸‹æ–‡æä¾›ã€‚å¤§è¯­è¨€æ¨¡åž‹ï¼ˆLLMï¼‰é¢†åŸŸï¼Œå¦‚ GPTã€LLaMAã€GLM ç­‰ï¼Œè™½ç„¶å®ƒä»¬æ•ˆæžœæƒŠè‰³ï¼Œ ä½†åŠ¨è¾„10 Bilionåºžå¤§çš„æ¨¡åž‹å‚æ•°ä¸ªäººè®¾å¤‡æ˜¾å­˜è¿œä¸å¤Ÿè®­ç»ƒï¼Œç”šè‡³æŽ¨ç†å›°éš¾ã€‚ å‡ ä¹Žæ‰€æœ‰äººéƒ½ä¸ä¼šåªæ»¡è¶³äºŽç”¨Loraç­‰æ–¹æ¡ˆfine-tuingå¤§æ¨¡åž‹å­¦ä¼šä¸€äº›æ–°çš„æŒ‡ä»¤ï¼Œ è¿™çº¦ç­‰äºŽåœ¨æ•™ç‰›é¡¿çŽ©21ä¸–çºªçš„æ™ºèƒ½æ‰‹æœºï¼Œç„¶è€Œï¼Œè¿™è¿œè¿œè„±ç¦»äº†å­¦ä¹ ç‰©ç†æœ¬èº«çš„å¥¥å¦™ã€‚ æ­¤å¤–ï¼Œå–è¯¾ä»˜è´¹è®¢é˜…çš„è¥é”€å·æ¼æ´žç™¾å‡ºçš„ä¸€çŸ¥åŠè§£è®²è§£AIçš„æ•™ç¨‹éåœ°ï¼Œ è®©ç†è§£LLMçš„ä¼˜è´¨å†…å®¹é›ªä¸ŠåŠ éœœï¼Œä¸¥é‡é˜»ç¢äº†å­¦ä¹ è€…ã€‚å› æ­¤ï¼Œæœ¬é¡¹ç›®çš„ç›®æ ‡æ˜¯æŠŠä¸Šæ‰‹LLMçš„é—¨æ§›æ— é™é™ä½Žï¼Œ ç›´æŽ¥ä»Ž0å¼€å§‹è®­ç»ƒä¸€ä¸ªæžå…¶è½»é‡çš„è¯­è¨€æ¨¡åž‹ã€‚[!TIP] ï¼ˆæˆªè‡³2024-9-17ï¼‰MiniMindç³»åˆ—å·²å®Œæˆäº†3ä¸ªåž‹å·æ¨¡åž‹çš„é¢„è®­ç»ƒï¼Œæœ€å°ä»…éœ€26Mï¼ˆ0.02Bï¼‰ï¼Œå³å¯å…·å¤‡æµç•…çš„å¯¹è¯èƒ½åŠ›ï¼è¯¥åˆ†æžåœ¨å…·æœ‰Torch 2.1.2ã€CUDA 12.2å’ŒFlash Attention 2çš„2Ã—RTX 3090 GPUä¸Šè¿›è¡Œã€‚å…¬å¼€MiniMindæ¨¡åž‹ä»£ç ï¼ˆåŒ…å«Denseå’ŒMoEæ¨¡åž‹ï¼‰ã€Pretrainã€SFTæŒ‡ä»¤å¾®è°ƒã€LoRAå¾®è°ƒã€DPOåå¥½ä¼˜åŒ–çš„å…¨è¿‡ç¨‹ä»£ç ã€æ•°æ®é›†å’Œæ¥æºã€‚å…¼å®¹ã€ã€ã€ç­‰æµè¡Œæ¡†æž¶ã€‚è®­ç»ƒæ”¯æŒå•æœºå•å¡ã€å•æœºå¤šå¡(DDPã€DeepSpeed)è®­ç»ƒï¼Œä½¿ç”¨wandbå¯è§†åŒ–è®­ç»ƒæµç¨‹ã€‚æ”¯æŒåœ¨ä»»æ„ä½ç½®åœæ­¢ï¼ŒåŠåœ¨ä»»æ„ä½ç½®ç»§ç»­è®­ç»ƒã€‚å®žçŽ°Openai-ApiåŸºæœ¬çš„chatæŽ¥å£ï¼Œä¾¿äºŽé›†æˆåˆ°ç¬¬ä¸‰æ–¹ChatUIä½¿ç”¨ï¼ˆFastGPTã€Open-WebUIç­‰ï¼‰ã€‚CPU: Intel(R) Core(TM) i9-10980XE CPU @ 3.00GHz
å†…å­˜ï¼š128 GB
æ˜¾å¡ï¼šNVIDIA GeForce RTX 3090(24GB) * 2
çŽ¯å¢ƒï¼špython 3.9 + Torch 2.1.2 + DDPå•æœºå¤šå¡è®­ç»ƒ
# step 1
git clone https://huggingface.co/jingyaogong/minimind-v1
# step 2
python 2-eval.py
ã€Œæ³¨æ„ã€éœ€è¦python>=3.10ï¼Œå®‰è£… pip install streamlit==1.27.2# or step 3, use streamlit
streamlit run fast_inference.py
git clone https://github.com/jingyaogong/minimind.git
cd minimind
pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple
# æµ‹è¯•torchæ˜¯å¦å¯ç”¨cuda
import torch
print(torch.cuda.is_available())
2.2 å¤„ç†æ•°æ®é›†ï¼Œä¾‹å¦‚pretrainæ•°æ®æå‰è¿›è¡Œtoken-encoderã€sftæ•°æ®é›†æŠ½ç¦»qaåˆ°csvæ–‡ä»¶2.3 åœ¨ ä¸­è°ƒæ•´modelçš„å‚æ•°é…ç½®è¿™é‡Œä»…éœ€è°ƒæ•´dimå’Œn_layerså’Œuse_moeå‚æ•°ï¼Œåˆ†åˆ«æ˜¯æˆ–ï¼Œå¯¹åº”äºŽå’Œ2.4  æ‰§è¡Œé¢„è®­ç»ƒï¼Œå¾—åˆ°  ä½œä¸ºé¢„è®­ç»ƒçš„è¾“å‡ºæƒé‡2.5  æ‰§è¡ŒæŒ‡ä»¤å¾®è°ƒï¼Œå¾—åˆ°  ä½œä¸ºæŒ‡ä»¤å¾®è°ƒçš„è¾“å‡ºæƒé‡2.6  æ‰§è¡Œloraå¾®è°ƒï¼ˆéžå¿…é¡»ï¼‰2.7  æ‰§è¡ŒDPOäººç±»åå¥½å¼ºåŒ–å­¦ä¹ å¯¹é½ï¼ˆéžå¿…é¡»ï¼‰ðŸ­ã€ŒTipã€é¢„è®­ç»ƒå’Œå…¨å‚å¾®è°ƒpretrainå’Œfull_sftå‡æ”¯æŒå¤šå¡åŠ é€Ÿå‡è®¾ä½ çš„è®¾å¤‡åªæœ‰1å¼ æ˜¾å¡ï¼Œä½¿ç”¨åŽŸç”Ÿpythonå¯åŠ¨è®­ç»ƒå³å¯ï¼šæ‰§è¡Œé¢„è®­ç»ƒæˆ–æŒ‡ä»¤å¾®è°ƒè®­ç»ƒ python 1-pretrain.py
# and
python 3-full_sft.py
torchrun --nproc_per_node N 1-pretrain.py
# and
torchrun --nproc_per_node N 3-full_sft.py
deepspeed --master_port 29500 --num_gpus=N 1-pretrain.py
# and
deepspeed --master_port 29500 --num_gpus=N 3-full_sft.py
torchrun --nproc_per_node N 1-pretrain.py --use_wandb
# and
python 1-pretrain.py --use_wandb
é€šè¿‡æ·»åŠ å‚æ•°ï¼Œå¯ä»¥è®°å½•è®­ç»ƒè¿‡ç¨‹ï¼Œè®­ç»ƒå®ŒæˆåŽï¼Œå¯ä»¥åœ¨wandbç½‘ç«™ä¸ŠæŸ¥çœ‹è®­ç»ƒè¿‡ç¨‹ã€‚é€šè¿‡ä¿®æ”¹ å’Œå‚æ•°ï¼Œå¯ä»¥æŒ‡å®šé¡¹ç›®åç§°å’Œè¿è¡Œåç§°ã€‚ðŸ¤– åˆ†è¯å™¨ï¼šnlpä¸­çš„Tokenizerç±»ä¼¼äºŽè¯å…¸ï¼Œå°†å•è¯ä»Žè‡ªç„¶è¯­è¨€é€šè¿‡â€œè¯å…¸â€æ˜ å°„åˆ°0,1,36è¿™æ ·çš„æ•°å­—ï¼Œå¯ä»¥ç†è§£ä¸ºæ•°å­—å°±ä»£è¡¨äº†å•è¯åœ¨â€œè¯å…¸â€ä¸­çš„é¡µç ã€‚ LLMåˆ†è¯å™¨çš„æž„å»ºæ–¹å¼æœ‰ä¸¤ç§ï¼šä¸€ç§æ˜¯è‡ªå·±æž„é€ è¯è¡¨è®­ç»ƒä¸€ä¸ªåˆ†è¯å™¨ï¼Œä»£ç å¯è§ï¼›å¦ä¸€ç§æ˜¯é€‰æ‹©å¼€æºæ¨¡åž‹è®­ç»ƒå¥½çš„åˆ†è¯å™¨ã€‚ â€œè¯å…¸â€å½“ç„¶å¯ä»¥ç›´æŽ¥é€‰æ‹©ç”¨æ–°åŽè¯å…¸æˆ–æ˜¯ç‰›æ´¥è¯å…¸ï¼Œä¼˜ç‚¹æ˜¯tokenè½¬åŒ–åŽ‹ç¼©çŽ‡å¾ˆå¥½ï¼Œä½†ç¼ºç‚¹æ˜¯è¯è¡¨å¤ªé•¿ï¼ŒåŠ¨è¾„æ•°åä¸‡ä¸ªè¯æ±‡çŸ­è¯­ï¼› ä¹Ÿå¯ä»¥ä½¿ç”¨è‡ªå·±è®­ç»ƒçš„åˆ†è¯å™¨ï¼Œä¼˜ç‚¹æ˜¯è¯è¡¨éšæ„æŽ§åˆ¶ï¼Œç¼ºç‚¹æ˜¯åŽ‹ç¼©çŽ‡ä¸å¤Ÿç†æƒ³ï¼Œä¸”ç”Ÿåƒ»è¯ä¸å®¹æ˜“é¢é¢ä¿±åˆ°ã€‚ å½“ç„¶ï¼Œâ€œè¯å…¸â€çš„é€‰æ‹©å¾ˆé‡è¦ï¼ŒLLMçš„è¾“å‡ºæœ¬è´¨ä¸Šæ˜¯SoftMaxåˆ°è¯å…¸Nä¸ªè¯çš„å¤šåˆ†ç±»é—®é¢˜ï¼Œç„¶åŽé€šè¿‡â€œè¯å…¸â€è§£ç åˆ°è‡ªç„¶è¯­è¨€ã€‚ å› ä¸ºLLMä½“ç§¯éžå¸¸å°ï¼Œä¸ºäº†é¿å…æ¨¡åž‹å¤´é‡è„šè½»ï¼ˆè¯åµŒå…¥embeddingå±‚å‚æ•°å æ•´ä¸ªLLMæ¯”å¤ªé«˜ï¼‰ï¼Œæ‰€ä»¥è¯è¡¨é•¿åº¦éœ€è¦é€‰æ‹©æ¯”è¾ƒå°ã€‚ å¼ºå¤§çš„å¼€æºæ¨¡åž‹ä¾‹å¦‚01ä¸‡ç‰©ã€åƒé—®ã€chatglmã€mistralã€Llama3ç­‰ï¼Œå®ƒä»¬çš„tokenizerè¯è¡¨é•¿åº¦å¦‚ä¸‹ï¼šðŸ‘‰2024-09-17æ›´æ–°ï¼šä¸ºäº†é˜²æ­¢è¿‡åŽ»çš„ç‰ˆæœ¬æ­§ä¹‰&æŽ§åˆ¶ä½“ç§¯ï¼Œminimindæ‰€æœ‰æ¨¡åž‹å‡ä½¿ç”¨minimind_tokenizeråˆ†è¯ï¼ŒåºŸå¼ƒæ‰€æœ‰mistral_tokenizerç‰ˆæœ¬ã€‚å°½ç®¡minimind_tokenizeré•¿åº¦å¾ˆå°ï¼Œç¼–è§£ç æ•ˆçŽ‡å¼±äºŽqwen2ã€glmç­‰ä¸­æ–‡å‹å¥½åž‹åˆ†è¯å™¨ã€‚ ä½†minimindæ¨¡åž‹é€‰æ‹©äº†è‡ªå·±è®­ç»ƒçš„minimind_tokenizerä½œä¸ºåˆ†è¯å™¨ï¼Œä»¥ä¿æŒæ•´ä½“å‚æ•°è½»é‡ï¼Œé¿å…ç¼–ç å±‚å’Œè®¡ç®—å±‚å æ¯”å¤±è¡¡ï¼Œå¤´é‡è„šè½»ï¼Œå› ä¸ºminimindçš„è¯è¡¨å¤§å°åªæœ‰6400ã€‚ ä¸”minimindåœ¨å®žé™…æµ‹è¯•ä¸­æ²¡æœ‰å‡ºçŽ°è¿‡ç”Ÿåƒ»è¯æ±‡è§£ç å¤±è´¥çš„æƒ…å†µï¼Œæ•ˆæžœè‰¯å¥½ã€‚ ç”±äºŽè‡ªå®šä¹‰è¯è¡¨åŽ‹ç¼©é•¿åº¦åˆ°6400ï¼Œä½¿å¾—LLMæ€»å‚æ•°é‡æœ€ä½Žåªæœ‰26Mã€‚ðŸ“™ã€Pretrainæ•°æ®ã€‘ï¼š Seq-Monkeyé€šç”¨æ–‡æœ¬æ•°æ®é›† / Seq-Monkeyç™¾åº¦ç½‘ç›˜ æ˜¯ç”±å¤šç§å…¬å¼€æ¥æºçš„æ•°æ®ï¼ˆå¦‚ç½‘é¡µã€ç™¾ç§‘ã€åšå®¢ã€å¼€æºä»£ç ã€ä¹¦ç±ç­‰ï¼‰æ±‡æ€»æ¸…æ´—è€Œæˆã€‚æ•´ç†æˆç»Ÿä¸€çš„JSONLæ ¼å¼ï¼Œå¹¶ç»è¿‡äº†ä¸¥æ ¼çš„ç­›é€‰å’ŒåŽ»é‡ï¼Œç¡®ä¿æ•°æ®çš„å…¨é¢æ€§ã€è§„æ¨¡ã€å¯ä¿¡æ€§å’Œé«˜è´¨é‡ã€‚æ€»é‡å¤§çº¦åœ¨10B tokenï¼Œé€‚åˆä¸­æ–‡å¤§è¯­è¨€æ¨¡åž‹çš„é¢„è®­ç»ƒã€‚ç¬¬2ç§é€‰æ‹©ï¼šSkyPile-150Bæ•°æ®é›† çš„å¯å…¬å¼€è®¿é—®éƒ¨åˆ†åŒ…å«çº¦2.33äº¿ä¸ªç‹¬ç«‹ç½‘é¡µï¼Œæ¯ä¸ªç½‘é¡µå¹³å‡åŒ…å«1000å¤šä¸ªæ±‰å­—ã€‚æ•°æ®é›†åŒ…æ‹¬å¤§çº¦1500äº¿ä¸ªä»¤ç‰Œå’Œ620GBçš„çº¯æ–‡æœ¬æ•°æ®ã€‚ ï¼Œå¯ä»¥å°è¯•åªæŒ‘é€‰SkyPile-150Bçš„éƒ¨åˆ†jsonlä¸‹è½½ï¼ˆå¹¶åœ¨./data_process.pyä¸­å¯¹æ–‡æœ¬tokenizerç”Ÿæˆ* .csvæ–‡ä»¶ï¼‰ï¼Œä»¥ä¾¿å¿«é€Ÿè·‘é€šé¢„è®­ç»ƒæµç¨‹ã€‚ðŸ“˜ã€DPOæ•°æ®ã€‘ï¼šå¤§çº¦åˆå¹¶åŽå…±8ä¸‡æ¡dpoæ•°æ®ï¼Œäººå·¥æ ‡æ³¨çš„åå¥½æ•°æ®ï¼Œå‡æ¥è‡ªæ´»å­—æ¨¡åž‹ ï¼Œå¯ä»¥ç”¨äºŽè®­ç»ƒå¥–åŠ±æ¨¡åž‹ï¼Œä¼˜åŒ–æ¨¡åž‹å›žå¤è´¨é‡ï¼Œä½¿å…¶æ›´åŠ ç¬¦åˆäººç±»åå¥½ã€‚MiniMind-Denseï¼ˆå’ŒLlama3.1ä¸€æ ·ï¼‰ä½¿ç”¨äº†Transformerçš„Decoder-Onlyç»“æž„ï¼Œè·ŸGPT-3çš„åŒºåˆ«åœ¨äºŽï¼šé‡‡ç”¨äº†GPT-3çš„é¢„æ ‡å‡†åŒ–æ–¹æ³•ï¼Œä¹Ÿå°±æ˜¯åœ¨æ¯ä¸ªTransformerå­å±‚çš„è¾“å…¥ä¸Šè¿›è¡Œå½’ä¸€åŒ–ï¼Œè€Œä¸æ˜¯åœ¨è¾“å‡ºä¸Šã€‚å…·ä½“æ¥è¯´ï¼Œä½¿ç”¨çš„æ˜¯RMSNormå½’ä¸€åŒ–å‡½æ•°ã€‚ç”¨SwiGLUæ¿€æ´»å‡½æ•°æ›¿ä»£äº†ReLUï¼Œè¿™æ ·åšæ˜¯ä¸ºäº†æé«˜æ€§èƒ½ã€‚åƒGPT-Neoä¸€æ ·ï¼ŒåŽ»æŽ‰äº†ç»å¯¹ä½ç½®åµŒå…¥ï¼Œæ”¹ç”¨äº†æ—‹è½¬ä½ç½®åµŒå…¥ï¼ˆRoPEï¼‰ï¼Œè¿™æ ·åœ¨å¤„ç†è¶…å‡ºè®­ç»ƒé•¿åº¦çš„æŽ¨ç†æ—¶æ•ˆæžœæ›´å¥½ã€‚DeepSeek-V2åœ¨å‰é¦ˆç½‘ç»œï¼ˆFFNï¼‰æ–¹é¢ï¼Œé‡‡ç”¨äº†æ›´ç»†ç²’åº¦çš„ä¸“å®¶åˆ†å‰²å’Œå…±äº«çš„ä¸“å®¶éš”ç¦»æŠ€æœ¯ï¼Œä»¥æé«˜Expertsçš„æ•ˆæžœã€‚MiniMindçš„æ•´ä½“ç»“æž„ä¸€è‡´ï¼Œåªæ˜¯åœ¨RoPEè®¡ç®—ã€æŽ¨ç†å‡½æ•°å’ŒFFNå±‚çš„ä»£ç ä¸Šåšäº†ä¸€äº›å°è°ƒæ•´ã€‚ å…¶ç»“æž„å¦‚ä¸‹å›¾ï¼ˆé‡ç»˜ç‰ˆï¼‰ï¼šLLMé¦–å…ˆè¦å­¦ä¹ çš„å¹¶éžç›´æŽ¥ä¸Žäººäº¤æµï¼Œè€Œæ˜¯è®©è‚šå­ä¸­å……æ»¡çŸ¥è¯†çš„å¢¨æ°´ï¼Œè‡³äºŽå¢¨æ°´ç†è®ºä¸Šå–çš„è¶Šé¥±è¶Šå¥½ï¼Œäº§ç”Ÿå¤§é‡çš„å¯¹ä¸–ç•Œçš„è®¤çŸ¥ç§¯ç´¯ã€‚é¢„è®­ç»ƒå°±æ˜¯è®©Modelå…ˆåŸ‹å¤´è‹¦å­¦å¤§é‡åŸºæœ¬çš„çŸ¥è¯†ï¼Œä¾‹å¦‚ä»Žç»´åŸºç™¾ç§‘ã€æ–°é—»ã€å¸¸è¯†ã€ä¹¦ç±ç­‰ã€‚å®ƒæ— ç›‘ç£çš„ä»Žå¤§é‡çš„æ–‡æœ¬æ•°æ®ä¸­åŽ‹ç¼©çŸ¥è¯†åˆ°è‡ªå·±æ¨¡åž‹çš„æƒé‡ï¼Œç›®çš„æ˜¯ï¼šå­¦ä¼šè¯è¯­æŽ¥é¾™ã€‚ä¾‹å¦‚æˆ‘ä»¬è¾“å…¥â€œç§¦å§‹çš‡æ˜¯â€å››ä¸ªå­—ï¼Œå®ƒåœ¨å¤§é‡å­¦ä¹ åŽèƒ½é¢„æµ‹å‡ºä¸‹ä¸€å¥è¯å¤§æ¦‚çŽ‡æ˜¯â€œä¸­å›½çš„ç¬¬ä¸€ä½çš‡å¸â€ã€‚pretrainçš„å­¦ä¹ çŽ‡è®¾ç½®ä¸º1e-4åˆ°1e-5çš„åŠ¨æ€å­¦ä¹ çŽ‡ï¼Œé¢„è®­ç»ƒepochæ•°è®¾ä¸º5ã€‚torchrun --nproc_per_node 2 1-pretrain.py
å•è½®æ¬¡å¯¹è¯æœ‰ç›‘ç£å¾®è°ƒ(Single dialog Fine-tuning):ç»è¿‡é¢„è®­ç»ƒï¼ŒåŠæˆå“LLMæ­¤æ—¶å·²ç»æŽŒæ¡äº†å‡ ä¹Žæ‰€æœ‰çš„è¯­è¨€çŸ¥è¯†å’Œç™¾ç§‘å¸¸è¯†ã€‚æ­¤æ—¶å®ƒè¿˜ä¸ä¼šä¸ŽäººèŠå¤©ï¼Œç›¸åå®ƒåªä¼šæ— è„‘åœ°è¿›è¡Œè¾“å…¥è¯è¯­çš„æŽ¥é¾™ï¼Œç”Ÿæˆä¸‹ä¸€ä¸ªè¯ã€‚æ­¤æ—¶éœ€è¦å¯¹åŠæˆå“LLMåšé™åˆ¶åœ¨èŠå¤©æ¨¡æ¿ä¸­è¿›è¡Œå¾®è°ƒï¼Œä¾‹å¦‚å½“å®ƒé‡åˆ°è¿™æ ·çš„æ¨¡æ¿â€œ<èŠå¤©å¼€å§‹>ç§¦å§‹çš‡æ˜¯<èŠå¤©ç»ˆæ­¢> â€åŽä¸å†æ— è„‘æŽ¥é¾™ï¼Œè€Œæ˜¯æ„è¯†åˆ°è¿™æ˜¯ä¸€æ®µå®Œæ•´çš„å¯¹è¯ç»“æŸã€‚æˆ‘ä»¬ç§°è¿™ä¸ªè¿‡ç¨‹ä¸ºæŒ‡ä»¤å¾®è°ƒï¼Œå°±å¦‚åŒè®©å­¦å¯Œäº”è½¦çš„ã€Œç‰›é¡¿ã€å…ˆç”Ÿé€‚åº”21ä¸–çºªçš„èŠå¤©ä¹ æƒ¯ï¼Œå­¦ä¹ å±å¹•å·¦ä¾§æ˜¯å¯¹æ–¹æ¶ˆæ¯ï¼Œå³ä¾§æ˜¯æœ¬äººæ¶ˆæ¯è¿™ä¸ªè§„å¾‹ã€‚åœ¨è®­ç»ƒæ—¶ï¼ŒMiniMindçš„æŒ‡ä»¤å’Œå›žç­”é•¿åº¦è¢«æˆªæ–­åœ¨512ï¼Œæ˜¯ä¸ºäº†èŠ‚çœæ˜¾å­˜ç©ºé—´ã€‚å°±åƒæˆ‘ä»¬å­¦ä¹ æ—¶ï¼Œä¼šå…ˆä»ŽçŸ­çš„æ–‡ç« å¼€å§‹ï¼Œå½“å­¦ä¼šé˜…è¯»200å­—ä½œæ–‡åŽï¼Œ800å­—é•¿æ–‡ç« å°±ä¸éœ€è¦å†å•ç‹¬å­¦ä¹ ã€‚åœ¨æŽ¨ç†æ—¶é€šè¿‡è°ƒæ•´RoPEçº¿æ€§å·®å€¼ï¼Œå®žçŽ°é•¿åº¦å¤–æŽ¨åˆ°1024æˆ–2048åŠä»¥ä¸Šå¾ˆæ–¹ä¾¿ã€‚å­¦ä¹ çŽ‡è®¾ç½®ä¸º1e-5åˆ°1e-6çš„åŠ¨æ€å­¦ä¹ çŽ‡ï¼Œå¾®è°ƒepochæ•°ä¸º6ã€‚# 3-full_sft.pyä¸­è®¾ç½®æ•°æ®é›†ä¸ºsft_data_single.csv
torchrun --nproc_per_node 2 3-full_sft.py
å¤šè½®å¯¹è¯å¾®è°ƒ(Multi dialog Fine-tuning):åœ¨2çš„åŸºç¡€ä¸Šï¼ŒLLMå·²ç»å­¦ä¼šä¸€ä¸ªé—®é¢˜->ä¸€ä¸ªå›žç­”çš„èŠå¤©æ¨¡æ¿ã€‚æ­¤æ—¶ä»…éœ€åœ¨å…·å¤‡åŽ†å²é—®ç­”çš„æ›´é•¿èŠå¤©æ¨¡æ¿ä¸Šè¿›ä¸€æ­¥å¾®è°ƒå³å¯ã€‚æˆ‘ä»¬ä»…éœ€ä½¿ç”¨æ•°æ®é›†çš„history_chat å­—æ®µï¼Œå³åŽ†å²å¯¹è¯ï¼Œä»¥åŠhistory_chat_responseå­—æ®µï¼Œå³åŽ†å²å¯¹è¯çš„å›žç­”ã€‚æž„å»ºã€é—®é¢˜->å›žç­”ï¼Œé—®é¢˜->å›žç­”ï¼Œé—®é¢˜->ã€‘çš„æ–°èŠå¤©æ¨¡æ¿ï¼Œç„¶åŽä½¿ç”¨è¿™ä¸ªæ•°æ®é›†è¿›è¡Œå¾®è°ƒã€‚å­¦ä¹ å®Œæˆçš„æ¨¡åž‹ä¸ä»…ä»…åªèƒ½å›žç­”å½“å‰é—®é¢˜ï¼Œè¿˜èƒ½æ ¹æ®åŽ†å²å¯¹è¯è¿›è¡Œè¿žè´¯çš„å¯¹è¯ã€‚è¿™ä¸€æ­¥  ï¼Œå› ä¸ºå°æ¨¡åž‹é•¿ä¸Šæ–‡å¯¹è¯èƒ½åŠ›å¾ˆå¼±ï¼Œå¼ºè¡Œå¯¹é½å¤šè½®é—®ç­”æ¨¡æ¿ä¼šæŸå¤±ä¸€å®šç¨‹åº¦çš„å•è½®SFTæ•ˆæžœã€‚å­¦ä¹ çŽ‡è®¾ç½®ä¸º1e-5åˆ°1e-6çš„åŠ¨æ€å­¦ä¹ çŽ‡ï¼Œå¾®è°ƒepochæ•°ä¸º5ã€‚# 3-full_sft.pyä¸­è®¾ç½®æ•°æ®é›†ä¸ºsft_data.csv
torchrun --nproc_per_node 2 3-full_sft.py
äººç±»åé¦ˆå¼ºåŒ–å­¦ä¹ (RLHF)ä¹‹-ç›´æŽ¥åå¥½ä¼˜åŒ–(Direct Preference Optimization, DPO):åœ¨å‰é¢çš„è®­ç»ƒä¸­ï¼ŒGPTå·²ç»å…·å¤‡äº†åŸºæœ¬çš„å¯¹è¯èƒ½åŠ›ï¼Œä½†æ˜¯è¿™æ ·çš„èƒ½åŠ›å®Œå…¨åŸºäºŽå•è¯æŽ¥é¾™ï¼Œç¼ºå°‘æ­£ä¾‹åä¾‹çš„æ¿€åŠ±ã€‚GPTå°šä¸”æœªçŸ¥ä»€ä¹ˆå›žç­”æ˜¯å¥½çš„ï¼Œä»€ä¹ˆæ˜¯å·®çš„ã€‚æˆ‘ä»¬å¸Œæœ›å®ƒèƒ½å¤Ÿæ›´ç¬¦åˆäººçš„åå¥½ï¼Œç»™å‡ºæ›´è®©äººæ»¡æ„çš„å›žç­”ã€‚è¿™ä¸ªè¿‡ç¨‹å°±åƒæ˜¯è®©GPTå‚åŠ å·¥ä½œåŸ¹è®­ï¼Œä»Žä¼˜ç§€å‘˜å·¥çš„ä½œä¸ºä¾‹å­ï¼Œæ¶ˆæžå‘˜å·¥ä½œä¸ºåä¾‹ï¼Œå­¦ä¹ å¦‚ä½•æ›´å¥½åœ°æœåŠ¡å®¢æˆ·ã€‚RLHFç³»åˆ—ä¸­ï¼Œä¸ŽPPO(Proximal Policy Optimization)è¿™ç§éœ€è¦å¥–åŠ±æ¨¡åž‹ã€ä»·å€¼æ¨¡åž‹çš„RLç®—æ³•ä¸åŒï¼›DPOé€šè¿‡æŽ¨å¯¼PPOå¥–åŠ±æ¨¡åž‹çš„æ˜¾å¼è§£ï¼ŒæŠŠåœ¨çº¿å¥–åŠ±æ¨¡åž‹æ¢æˆç¦»çº¿æ•°æ®ï¼Œrefè¾“å‡ºå¯ä»¥æå‰ä¿å­˜ã€‚DPOæ€§èƒ½å‡ ä¹Žä¸å˜ï¼Œåªç”¨è·‘ actor å’Œ ref 2 ä¸ªæ¨¡åž‹ï¼Œå¤§å¤§èŠ‚çœæ˜¾å­˜å¼€é”€å’Œå¢žåŠ è®­ç»ƒç¨³å®šæ€§ã€‚æ´»å­—ä¸‰å…ƒç»„(q,chose,reject)æ•°æ®é›†ï¼Œå­¦ä¹ çŽ‡le-5ï¼ŒåŠç²¾åº¦fp16,å…±1ä¸ªepochï¼Œè€—æ—¶1hã€‚ðŸ“‹å…³äºŽLLMçš„å‚æ•°é…ç½®ï¼Œæœ‰ä¸€ç¯‡å¾ˆæœ‰æ„æ€çš„è®ºæ–‡MobileLLMåšäº†è¯¦ç»†çš„ç ”ç©¶å’Œå®žéªŒã€‚ scaling lawåœ¨å°æ¨¡åž‹ä¸­æœ‰è‡ªå·±ç‹¬ç‰¹çš„è§„å¾‹ã€‚ å¼•èµ·Transformerå‚æ•°æˆè§„æ¨¡å˜åŒ–çš„å‚æ•°å‡ ä¹Žåªå–å†³äºŽå’Œã€‚2020å¹´æå‡ºScaling Lawçš„è®ºæ–‡è®¤ä¸ºï¼Œè®­ç»ƒæ•°æ®é‡ã€å‚æ•°é‡ä»¥åŠè®­ç»ƒè¿­ä»£æ¬¡æ•°æ‰æ˜¯å†³å®šæ€§èƒ½çš„å…³é”®å› ç´ ï¼Œè€Œæ¨¡åž‹æž¶æž„çš„å½±å“å‡ ä¹Žå¯ä»¥å¿½è§†ã€‚ ç„¶è€Œä¼¼ä¹Žè¿™ä¸ªå®šå¾‹å¯¹å°æ¨¡åž‹å¹¶ä¸å®Œå…¨é€‚ç”¨ã€‚ MobileLLMæå‡ºæž¶æž„çš„æ·±åº¦æ¯”å®½åº¦æ›´é‡è¦ï¼Œã€Œæ·±è€Œçª„ã€çš„ã€Œç˜¦é•¿ã€æ¨¡åž‹å¯ä»¥å­¦ä¹ åˆ°æ¯”ã€Œå®½è€Œæµ…ã€æ¨¡åž‹æ›´å¤šçš„æŠ½è±¡æ¦‚å¿µã€‚ ä¾‹å¦‚å½“æ¨¡åž‹å‚æ•°å›ºå®šåœ¨125Mæˆ–è€…350Mæ—¶ï¼Œ30ï½ž42å±‚çš„ã€Œç‹­é•¿ã€æ¨¡åž‹æ˜Žæ˜¾æ¯”12å±‚å·¦å³çš„ã€ŒçŸ®èƒ–ã€æ¨¡åž‹æœ‰æ›´ä¼˜è¶Šçš„æ€§èƒ½ï¼Œ åœ¨å¸¸è¯†æŽ¨ç†ã€é—®ç­”ã€é˜…è¯»ç†è§£ç­‰8ä¸ªåŸºå‡†æµ‹è¯•ä¸Šéƒ½æœ‰ç±»ä¼¼çš„è¶‹åŠ¿ã€‚ è¿™å…¶å®žæ˜¯éžå¸¸æœ‰è¶£çš„å‘çŽ°ï¼Œå› ä¸ºä»¥å¾€ä¸º100Må·¦å³é‡çº§çš„å°æ¨¡åž‹è®¾è®¡æž¶æž„æ—¶ï¼Œå‡ ä¹Žæ²¡äººå°è¯•è¿‡å åŠ è¶…è¿‡12å±‚ã€‚ è¿™ä¸ŽMiniMindåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ¨¡åž‹å‚æ•°é‡åœ¨å’Œä¹‹é—´è¿›è¡Œè°ƒæ•´å®žéªŒè§‚å¯Ÿåˆ°çš„æ•ˆæžœæ˜¯ä¸€è‡´çš„ã€‚ ç„¶è€Œã€Œæ·±è€Œçª„ã€çš„ã€Œçª„ã€ä¹Ÿæ˜¯æœ‰ç»´åº¦æžé™çš„ï¼Œå½“d_model<512æ—¶ï¼Œè¯åµŒå…¥ç»´åº¦åå¡Œçš„åŠ£åŠ¿éžå¸¸æ˜Žæ˜¾ï¼Œ å¢žåŠ çš„layerså¹¶ä¸èƒ½å¼¥è¡¥è¯åµŒå…¥åœ¨å›ºå®šq_headå¸¦æ¥d_headä¸è¶³çš„åŠ£åŠ¿ã€‚ å½“d_model>1536æ—¶ï¼Œlayersçš„å¢žåŠ ä¼¼ä¹Žæ¯”d_modelçš„ä¼˜å…ˆçº§æ›´é«˜ï¼Œæ›´èƒ½å¸¦æ¥å…·æœ‰â€œæ€§ä»·æ¯”â€çš„å‚æ•°->æ•ˆæžœå¢žç›Šã€‚ å› æ­¤MiniMindè®¾å®šsmallæ¨¡åž‹çš„d_model=512ï¼Œn_layers=8æ¥èŽ·å–çš„ã€Œæžå°ä½“ç§¯<->æ›´å¥½æ•ˆæžœã€çš„å¹³è¡¡ã€‚ è®¾å®šd_model=768ï¼Œn_layers=16æ¥èŽ·å–æ•ˆæžœçš„æ›´å¤§æ”¶ç›Šï¼Œæ›´åŠ ç¬¦åˆå°æ¨¡åž‹scaling-lawçš„å˜åŒ–æ›²çº¿ã€‚single_chat/full_sft_512.pthmulti_chat/full_sft_512.pthsingle_chat/full_sft_512_moe.pthmulti_chat/full_sft_512_moe.pthsingle_chat/full_sft_768.pthmulti_chat/full_sft_768.pth[!TIP] æµ‹è¯•åŸºäºŽã€Œå•è½®å¯¹è¯full_sftã€å’Œã€ŒDPOå¼ºåŒ–å­¦ä¹ å¯¹é½ã€çš„minimindæ¨¡åž‹å¯¹æ¯”ã€‚æ¨¡åž‹æ–‡ä»¶ç™¾åº¦ç½‘ç›˜ï¼Œå…¶ä¸­  å³ä¸ºã€ŒDPOå¼ºåŒ–å­¦ä¹ å¯¹é½ã€åŽçš„minimindæ¨¡åž‹æƒé‡ã€‚[Q]: ä½ å«ä»€ä¹ˆåå­—ï¼Ÿ
[ft_768]: æˆ‘æ˜¯ä¸€æ¬¾äººå·¥æ™ºèƒ½è¯­è¨€æ¨¡åž‹ï¼Œå¯ä»¥å›žç­”æ‚¨çš„é—®é¢˜å’Œæä¾›å¸®åŠ©ã€‚æ‚¨æœ‰ä»€ä¹ˆéœ€è¦æˆ‘å¸®å¿™çš„å—ï¼Ÿ
[rl_768]: æˆ‘æ˜¯ä¸€æ¬¾åŸºäºŽäººå·¥æ™ºèƒ½æŠ€æœ¯çš„è‡ªç„¶è¯­è¨€å¤„ç†ç³»ç»Ÿï¼Œä¸»è¦ç”¨äºŽå¤„ç†å’Œç”Ÿæˆäººç±»è¯­è¨€çš„ä»»åŠ¡ã€‚æˆ‘å¯ä»¥å¸®åŠ©ç”¨æˆ·è¿›è¡Œæ–‡æœ¬å¤„ç†ã€è¯­éŸ³è¯†åˆ«ã€æ–‡æœ¬ç”Ÿæˆç­‰ä»»åŠ¡ï¼ŒåŒæ—¶ä¹Ÿå¯ä»¥å¸®åŠ©ç”¨æˆ·è¿›è¡Œæ™ºèƒ½èŠå¤©ã€ç¿»è¯‘ã€ç¿»è¯‘ç­‰å¤šç§åº”ç”¨ã€‚å¦‚æžœæ‚¨éœ€è¦æ›´å¤šå…³äºŽè¯¥é¡¹ç›®çš„ä¿¡æ¯ï¼Œè¯·å‘Šè¯‰æˆ‘ã€‚
[ft_512]: æˆ‘å¾ˆé«˜å…´èƒ½å¤Ÿå¸®åŠ©ä½ ã€‚ä½ æœ‰ä»€ä¹ˆå…¶ä»–é—®é¢˜éœ€è¦æˆ‘å¸®å¿™è§£ç­”å—ï¼Ÿ
[rl_512]: æˆ‘æ˜¯ä¸€æ¬¾åŸºäºŽè‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯çš„èŠå¤©æœºå™¨äººï¼Œèƒ½å¤Ÿç†è§£å’Œå›žå¤ç”¨æˆ·çš„é—®é¢˜å’ŒæŒ‡ä»¤ï¼Œå¹¶è¿›è¡Œç›¸åº”çš„å›žå¤å’Œå›žå¤ã€‚æˆ‘è¢«è®­ç»ƒä¸ºèƒ½å¤Ÿä¸Žäººç±»è¿›è¡Œäº¤äº’å’Œå›žç­”å„ç§é—®é¢˜å’Œä»»åŠ¡ã€‚è¯·é—®æœ‰ä»€ä¹ˆéœ€è¦å—ï¼Ÿ

[Q]: ä½ æ˜¯è°ï¼Ÿ
[ft_768]: æˆ‘æ˜¯ä¸€ä¸ªäººå·¥æ™ºèƒ½è¯­è¨€æ¨¡åž‹ï¼Œæ²¡æœ‰ä¸ªäººèº«ä»½å’Œèº«ä»½ã€‚æˆ‘åªæ˜¯æ ¹æ®è¾“å…¥çš„æŒ‡ä»¤å’Œæ–‡æœ¬ä¿¡æ¯ç”Ÿæˆå“åº”ã€‚
[rl_768]: æˆ‘æ˜¯ä¸€ä¸ªè®¡ç®—æœºç¨‹åºï¼Œæ²¡æœ‰ä¸ªäººèº«ä»½æˆ–èº«ä»½ã€‚æˆ‘è¢«è®¾è®¡æ¥å›žç­”å„ç§é—®é¢˜å’Œæä¾›å¸®åŠ©ï¼ŒåŒ…æ‹¬å›žç­”é—®é¢˜ã€æä¾›å»ºè®®ã€è¿›è¡Œå®žéªŒã€æä¾›ä¿¡æ¯ç­‰ç­‰ã€‚æˆ‘è¢«å¹¿æ³›åº”ç”¨äºŽå„ç§é¢†åŸŸï¼Œä¾‹å¦‚è‡ªç„¶è¯­è¨€å¤„ç†ã€è®¡ç®—æœºè§†è§‰ã€äººå·¥æ™ºèƒ½ç­‰ç­‰ã€‚å¦‚æžœæ‚¨éœ€è¦æ›´å¤šçš„å¸®åŠ©æˆ–ä¿¡æ¯ï¼Œè¯·éšæ—¶ä¸Žæˆ‘è”ç³»ã€‚æˆ‘ä¼šå°½æˆ‘æ‰€èƒ½æ¥å¸®åŠ©æ‚¨çš„å·¥ä½œå’Œç”Ÿæ´»ã€‚
[ft_512]: æˆ‘æ˜¯ä¸€ä¸ªå¤§åž‹è¯­è¨€æ¨¡åž‹ï¼Œå¯ä»¥å›žç­”å„ç§å„æ ·çš„é—®é¢˜ï¼ŒåŒ…æ‹¬ç§‘å­¦ã€åŽ†å²ã€æ–‡åŒ–å’ŒæŠ€æœ¯æ–¹é¢çš„é—®é¢˜ã€‚æ‚¨æœ‰ä»€ä¹ˆéœ€è¦æˆ‘å›žç­”çš„é—®é¢˜å—ï¼Ÿ
[rl_512]: æˆ‘æ˜¯ä¸€ä¸ªè®¡ç®—æœºç¨‹åºï¼Œæ²¡æœ‰å…·ä½“çš„èº«ä¸–å’Œäººç‰©ã€‚å¦‚æžœæ‚¨å¯ä»¥å‘Šè¯‰æˆ‘æ‚¨æƒ³çŸ¥é“çš„å…·ä½“ä¿¡æ¯ï¼Œæˆ‘ä¼šå°½åŠ›å›žç­”æ‚¨çš„é—®é¢˜ã€‚

[Q]: ä¸­å›½æœ‰å“ªäº›æ¯”è¾ƒå¥½çš„å¤§å­¦ï¼Ÿ
[ft_768]: ä¸­å›½æœ‰å¾ˆå¤šè‘—åçš„å¤§å­¦ï¼Œå…¶ä¸­åŒ…æ‹¬åŒ—äº¬å¤§å­¦ã€ä¸Šæµ·äº¤é€šå¤§å­¦ã€å¤å…´ä¸­åŒ»è¯å­¦é™¢ã€æµ™æ±Ÿå¤§å­¦ç­‰ã€‚è¿™äº›å¤§å­¦åœ¨ä¸åŒçš„é¢†åŸŸéƒ½æœ‰ç€è‡ªå·±çš„æ ‡å¿—æ€§å»ºç­‘å’Œç ”ç©¶æ–¹å‘ï¼Œå€¼å¾—ä¸€æçš„æ˜¯ï¼Œå®ƒä»¬åœ¨ä¸­å›½çš„é¡¶å°–æ•™è‚²èµ„æºä¸­äº«æœ‰å¾ˆé«˜çš„å£°èª‰ã€‚
[rl_768]: ä¸­å›½çš„å¤§å­¦æœ‰å¾ˆå¤šï¼Œå…·ä½“æƒ…å†µè¿˜è¦æ ¹æ®ä½ çš„éœ€æ±‚æ¥å†³å®šã€‚å¦‚æžœä½ éœ€è¦æ›´è¯¦ç»†çš„ä¿¡æ¯ï¼Œå»ºè®®å¯ä»¥åŽ»å’¨è¯¢ä¸€ä¸‹ä½ æ‰€åœ¨åŸŽå¸‚çš„å¤§å­¦æŽ’åå’Œæ”¿ç­–æ³•è§„ï¼Œä»Žè€Œé€‰æ‹©ä¸€ä¸ªåˆé€‚çš„å¤§å­¦ã€‚åŒæ—¶ï¼Œä½ å¯ä»¥åœ¨ç½‘ä¸ŠæŸ¥é˜…ç›¸å…³ä¿¡æ¯ï¼Œæˆ–è€…åŽ»å’¨è¯¢ä¸€äº›å¤§å­¦ç›¸å…³æœºæž„ï¼Œå¦‚ä¸­å›½äººæ°‘å¤§å­¦ã€ä¸­å›½äººæ°‘å¤§å­¦ç­‰ï¼Œä»¥èŽ·å¾—æ›´ä¸ºè¯¦ç»†å’Œä¸“ä¸šçš„æŒ‡å¯¼å’Œå»ºè®®ã€‚
[ft_512]: ä¸­å›½æœ‰å¾ˆå¤šä¼˜ç§€çš„å¤§å­¦ï¼Œæ¯”å¦‚éº»çœç†å·¥å­¦é™¢ã€åŒ—äº¬å¤§å­¦ã€ä¸Šæµ·å¤§å­¦ç­‰ç­‰ã€‚è¿™äº›å¤§å­¦åœ¨ä¸­å›½æ•™è‚²äº‹ä¸šçš„å‘å±•å’Œæˆå°±éƒ½éžå¸¸çªå‡ºã€‚
[rl_512]: ä¸­å›½æ•™è‚²å±€ã€ä¸­å›½å¤§å­¦ã€ä¸­å›½å¤§é™†å¤§å­¦å’Œä¸­å›½å¤§é™†å¤§å­¦å‡æœ‰ä¼˜ç§€çš„æ•™è‚²ä½“è£ï¼Œä½†å„åœ°æ•™è‚²æ°´å¹³å’Œä¸“ä¸šè¦æ±‚éƒ½å¯èƒ½å­˜åœ¨å·®å¼‚ã€‚ä¸­å›½æ•™è‚²å±€çš„å­¦åŽ†è¦æ±‚ã€æ•™å­¦æ–¹æ³•ã€å¸ˆèµ„åŠ›é‡ç­‰å› ç´ éƒ½å„å…·ç‰¹ç‚¹ï¼Œè€Œå¤§å­¦çš„å­¦åŽ†è¦æ±‚ä¹Ÿå„æœ‰åƒç§‹ã€‚ä¸­å›½å¤§é™†å¤§å­¦ç”Ÿçš„å­¦åŽ†è¦æ±‚ä¹Ÿå„æœ‰ä¸åŒï¼Œéœ€è¦æ ¹æ®è‡ªå·±çš„å®žé™…æƒ…å†µè¿›è¡Œé€‰æ‹©ã€‚å¦‚æžœæ‚¨å¯¹ä¸­å›½å¤§é™†å¤§å­¦ç”Ÿçš„ä¸“ä¸šè¦æ±‚æœ‰æ›´å…·ä½“éœ€æ±‚ï¼Œå»ºè®®æ‚¨å¯ä»¥é€šè¿‡äº’è”ç½‘ã€å›½å†…å¤–çš„å„ç±»æœºæž„å’Œæœºæž„è¿›è¡Œæ¯”è¾ƒå’Œäº¤æµã€‚åŒæ—¶ï¼Œæ‚¨ä¹Ÿå¯ä»¥å‘èº«è¾¹çš„äººæˆ–æœ‹å‹ã€è€å¸ˆã€å®¶é•¿ç­‰äººå£«å¯»æ±‚å¸®åŠ©å’Œå»ºè®®ã€‚å¸Œæœ›ä»¥ä¸Šå›žç­”å¯¹æ‚¨æœ‰å¸®åŠ©ã€‚

[Q]: ä½ çŸ¥é“å…‰é€Ÿæ˜¯å¤šå°‘å—ï¼Ÿ
[ft_768]: å…‰é€Ÿæ˜¯ä¸€ä¸ªç‰©ç†å¸¸æ•°ï¼Œè¡¨ç¤ºå…‰åœ¨çœŸç©ºä¸­ä¼ æ’­çš„é€Ÿåº¦ï¼Œå¤§çº¦æ˜¯æ¯ç§’299792458ç±³ã€‚å…‰é€Ÿæ˜¯ç‰©ç†å­¦ä¸­æœ€åŸºæœ¬çš„ç‰©ç†å¸¸æ•°ä¹‹ä¸€ï¼Œä¹Ÿæ˜¯ç›¸å¯¹è®ºçš„é‡è¦åŸºç¡€ä¹‹ä¸€ã€‚
[rl_768]: å½“ç„¶çŸ¥é“ï¼Œå…‰é€Ÿæ˜¯å…‰åœ¨çœŸç©ºä¸­ä¼ æ’­çš„é€Ÿåº¦ï¼Œé€šå¸¸ç”¨cæ¥è¡¨ç¤ºã€‚å®ƒæ˜¯å®‡å®™ç‰©ç†å­¦ä¸­éžå¸¸é‡è¦çš„ç†è®ºä¹‹ä¸€ã€‚åœ¨ç‰©ç†å­¦ä¸­ï¼Œå…‰é€Ÿè¢«è®¤ä¸ºæ˜¯å®‡å®™ä¸­æœ€é‡è¦çš„é€Ÿåº¦ä¹‹ä¸€ã€‚å®ƒä»£è¡¨ç€å…‰åœ¨çœŸç©ºä¸­ä¼ æ’­çš„é€Ÿåº¦ï¼Œè¿™ä¹Ÿæ˜¯è®¸å¤šé‡è¦å…¬å¼å’Œå…¬å¼çš„åŸºç¡€ã€‚
[ft_512]: å…‰é€Ÿæ˜¯å…‰åœ¨çœŸç©ºä¸­ä¼ æ’­çš„é€Ÿåº¦ï¼Œçº¦ä¸ºæ¯ç§’299,792,458ç±³ã€‚å®ƒæ˜¯å‡ ä¹Žæ‰€æœ‰çš„ç‰©ç†å­¦æ¦‚å¿µï¼Œä¹Ÿæ˜¯å®‡å®™ä¸­æœ€ç¥žç§˜å’Œæœ€é‡è¦çš„ç‰©ç†æ¦‚å¿µä¹‹ä¸€ã€‚
[rl_512]: å…‰é€Ÿæ˜¯å…‰åœ¨çœŸç©ºä¸­ä¼ æ’­çš„é€Ÿåº¦ï¼Œæ˜¯è‡ªç„¶ç•Œä¸­ä¸å¯é€†è½¬çš„é€Ÿåº¦ã€‚å…‰æºæ˜¯ç”±å…‰çš„åŽŸå­ã€åˆ†å­ã€å›ºä½“å’Œå…‰çš„ç»„æˆï¼Œå…¶é€Ÿåº¦çº¦ä¸ºæ¯ç§’å¹³æ–¹ã€‚å…‰çš„é€Ÿåº¦æ˜¯æ¯ç§’çº¦1ä¸ªè‹±äºžæˆ–å…‰å¹´ï¼Œè¿™ä¸ªæ•°å­—æ˜¯æ ¹æ®ç›¸å¯¹è®ºã€é‡å­åŠ›å­¦å’Œå¼•åŠ›ç†è®ºæ¥è®¡ç®—çš„ã€‚å…‰é€Ÿæ˜¯ç›¸å¯¹çš„æ¦‚å¿µä¹‹ä¸€ï¼Œå®ƒä»£è¡¨ç€æˆ‘ä»¬å¯¹è‡ªç„¶ç•Œä¸­ä»»ä½•äº‹ä»¶çš„ç†è§£å’Œè§£é‡Šã€‚
RLHFæ•°æ®ä½¿ç”¨å¤§çº¦10ä¸‡æ¡ï¼›full_sftæ¨¡åž‹åœ¨ç®€æ´æ€§å’Œä¿¡æ¯å‡†ç¡®æ€§æ–¹é¢è¡¨çŽ°æ›´å¥½ï¼›rlæ¨¡åž‹åœ¨å›žç­”ä¸­æä¾›äº†æ›´å¤šçš„èƒŒæ™¯ä¿¡æ¯ï¼Œä½†ä¿¡æ¯å‡†ç¡®æ€§æœ‰å¾…æ”¹è¿›ã€‚æ€»çš„æ¥è¯´RLHFåŽçš„æ¨¡åž‹å€¾å‘äºŽå­¦ä¹ ï¼šè¯´æ›´å¤šæœ‰ç¤¼è²Œä½†æ— ç”¨çš„åºŸè¯è®¨å¥½â€œå¯¹è¯â€æœ¬èº«ï¼Œè€Œå¯¹ä¿¡æ¯å‡†ç¡®æ€§åˆ™æœ‰è½»å¾®æŸå¤±ã€‚å¤©ä¸‹æ²¡æœ‰å…è´¹çš„åˆé¤ï¼Œè¿˜éœ€è¦ç»§ç»­æå‡RLHFæ•°æ®é›†çš„è´¨é‡ï¼Œä¹Ÿè¦æŽ¥å—æ¨¡åž‹èƒ½åŠ›æ— æ³•é¿å…çš„æŸå¤±(ç¨‹åº¦æœ‰è½»é‡)ã€‚DPOå’Œåœ¨çº¿PPOçš„åŒºåˆ«åœ¨äºŽrejectå’Œchosenéƒ½æ˜¯ç¦»çº¿å‡†å¤‡çš„ï¼Œå’Œminimindæ¨¡åž‹æœ¬èº«çš„è¾“å‡ºå¿…ç„¶å­˜åœ¨å¾ˆå¤§çš„åˆ†å¸ƒå·®å¼‚ã€‚è¿™ç±»ä¼¼äºŽDPOç®—æ³•ä½¿æ¨¡åž‹è§‚çœ‹ä¹’ä¹“çƒä¸–ç•Œå† å†›çš„æ‰“æ³•ã€Œå½•åƒã€è¿›è¡Œå¼ºåŒ–å­¦ä¹ ï¼Œè€Œä¸æ˜¯åƒPPOä¸€æ ·è¯·rewardæ¨¡åž‹åšã€Œæ•™ç»ƒã€çº æ­£è‡ªå·±çš„æ‰“æ³•å¼ºåŒ–å­¦ä¹ ã€‚[!TIP] ä»¥ä¸‹æµ‹è¯•äºŽ2024-09-17å®Œæˆï¼Œæ­¤æ—¥æœŸåŽå‘å¸ƒçš„æ–°æ¨¡åž‹ï¼Œæ— ç‰¹æ®Šéœ€è¦æ—¶å°†ä¸åŠ å…¥æµ‹è¯•ã€‚ æµ‹è¯•åŸºäºŽå•è½®å¯¹è¯full_sftçš„minimindæ¨¡åž‹(æ— å¤šè½®å¾®è°ƒå’Œå¼ºåŒ–å­¦ä¹ å¾®è°ƒ)ã€‚[Q]: ä½ çŸ¥é“é•¿æ±Ÿå—ï¼Ÿ
[A]: æ˜¯çš„ï¼Œé•¿æ±Ÿæ˜¯ä¸­å›½æœ€é•¿çš„æ²³æµï¼Œå…¨é•¿è¶…è¿‡3300åƒç±³ã€‚
[B]: é•¿æ±Ÿæ˜¯ä¸­å›½æœ€é•¿çš„æ²³æµï¼Œæ€»é•¿åº¦çº¦ä¸º6300å…¬é‡Œã€‚å®ƒå‘æºäºŽé’è—é«˜åŽŸçš„é’æµ·æ¹–ï¼Œæµç»é’æµ·ã€å››å·ã€ç”˜è‚ƒã€å®å¤ã€å†…è’™å¤ã€é™•è¥¿å’Œå±±è¥¿ã€‚é•¿æ±ŸæµåŸŸæ˜¯ä¸­å›½æœ€å¤§çš„å†œä¸šåŒºä¹‹ä¸€ï¼Œä¹Ÿæ˜¯ä¸­å›½çš„æ–‡åŒ–å’Œç»æµŽä¸­å¿ƒã€‚
[C]: æ˜¯çš„ï¼Œé•¿æ±Ÿæ˜¯ä¸­å›½æœ€é•¿çš„æ²³æµä¹‹ä¸€ï¼Œä¹Ÿæ˜¯ä¸–ç•Œç¬¬ä¸‰å¤§æ²³æµã€‚é•¿æ±Ÿå‘æºäºŽé’è—é«˜åŽŸï¼Œæµç»11ä¸ªçœä»½ï¼Œæœ€ç»ˆæ³¨å…¥ä¸œæµ·ã€‚é•¿æ±ŸæµåŸŸæ˜¯ä¸­å›½æœ€å¤§çš„æ²³æµæµåŸŸä¹‹ä¸€ï¼Œæ‹¥æœ‰ç€ä¸°å¯Œçš„è‡ªç„¶èµ„æºå’Œæ–‡åŒ–é—äº§ï¼Œå¦‚é•¿æ±Ÿå¤§æ¡¥ã€é•¿æ±Ÿæµ·æ´‹åšç‰©é¦†ã€é•¿æ±Ÿå¤åŸŽç­‰ã€‚
[D]: åŒæ—¶ä¹ŸçŸ¥é“ï¼Œä¸­å›½æ˜¯ä¸–ç•Œä¸Šæœ€é•¿çš„åŸŽå¸‚ä¹‹ä¸€ï¼Œæ‹¥æœ‰è¶…è¿‡3400ä¸‡äººå£ã€‚
[E]: æ˜¯çš„ï¼Œé•¿æ±Ÿæ˜¯ä¸­å›½æœ€é•¿çš„æ²³æµï¼Œä¹Ÿæ˜¯ä¸–ç•Œä¸Šæœ€é•¿çš„æ²³æµä¹‹ä¸€ã€‚å®ƒå‘æºäºŽé’è—é«˜åŽŸï¼Œæµç»ä¹ä¸ªçœåŒºï¼Œæœ€ç»ˆæ³¨å…¥ä¸œæµ·ã€‚é•¿æ±ŸæµåŸŸçš„æ°”å€™æ¸©å’Œï¼Œå››å­£åˆ†æ˜Žï¼Œæ˜¯ä¸­å›½é‡è¦çš„å†œä¸šå’Œå·¥ä¸šåŸºåœ°ã€‚é•¿æ±ŸæµåŸŸçš„æ°´äº§èµ„æºä¸°å¯Œï¼Œæ˜¯ä¸­å›½çš„é‡è¦æ¸”ä¸šèµ„æºä¹‹ä¸€ã€‚


[Q]: ç¬¬ä¸€é¢—äººé€ å«æ˜Ÿæ˜¯å“ªä¸ªå›½å®¶å‘å°„çš„ï¼Ÿ
[A]: ç¬¬ä¸€é¢—äººé€ å«æ˜Ÿæ˜¯æ–¯æ™®ç‰¹å°¼å…‹1å·ã€‚
[B]: ç¬¬ä¸€é¢—äººé€ å«æ˜Ÿæ˜¯ä¿„ç½—æ–¯çš„å›½é™…å«æ˜Ÿï¼ŒäºŽ1957å¹´å‘å°„ã€‚
[C]: ç¬¬ä¸€é¢—äººé€ å«æ˜Ÿæ˜¯è‹è”å‘å°„çš„ï¼Œå®ƒæ˜¯ç”±è‹è”äºŽ1957å¹´10æœˆå‘å°„çš„ã€‚
[D]: è¿™é¢—åä¸ºâ€œé˜¿å§†æ–¯ç‰¹æœ—â€çš„å«æ˜Ÿï¼ŒäºŽ1961å¹´11æœˆ20æ—¥å‘å°„ï¼Œæ˜¯ç¬¬ä¸€ä¸ªæˆåŠŸå°†äººç±»é€å…¥å¤ªç©ºçš„å«æ˜Ÿã€‚
[E]: ç¬¬ä¸€é¢—äººé€ å«æ˜Ÿæ˜¯è‹è”äºŽ1957å¹´4æœˆ4æ—¥å‘å°„çš„ï¼Œå®ƒæ˜¯ç”±è‹è”å®‡èˆªå‘˜å°¤é‡ŒÂ·åŠ åŠ æž—ï¼ˆYuri Gagarinï¼‰å’Œè‹è”å·¥ç¨‹å¸ˆç½—å°”å¾·Â·è°¢å°”ç›–è€¶å¤«ï¼ˆRoald Skohleyï¼‰å…±åŒå‘å°„çš„ã€‚åœ¨å‘å°„è¿‡ç¨‹ä¸­ï¼ŒåŠ åŠ æž—å’Œè°¢å°”ç›–è€¶å¤«ä½¿ç”¨äº†ä¸€ä¸ªåä¸ºâ€œæ–¯æ™®ç‰¹å°¼å…‹1å·â€çš„å°åž‹å«æ˜Ÿï¼Œå®ƒçš„ç›´å¾„ä¸º4.3ç±³ï¼Œé‡é‡ä¸º1,051å…¬æ–¤ã€‚è¿™æžšå«æ˜Ÿè¢«ç§°ä¸ºâ€œæ–¯æ™®ç‰¹å°¼å…‹1å·â€ï¼Œæ˜¯è‹è”å¤ªç©ºç«žèµ›ä¸­çš„ä¸€ä¸ªé‡Œç¨‹ç¢‘ï¼Œä¹Ÿæ˜¯äººç±»åŽ†å²ä¸Šç¬¬ä¸€æ¬¡åœ¨å¤ªç©ºä¸­è¿›è¡Œå¤ªç©ºè¡Œèµ°ã€‚


[Q]: ä½ çŸ¥é“æ³°å±±åœ¨å“ªé‡Œå—ï¼Ÿ
[A]: æ³°å±±ä½äºŽä¸­å›½ä¸œéƒ¨åœ°åŒºï¼Œæ˜¯ä¸­å›½äº”å²³ä¹‹ä¸€ã€‚
[B]: æ³°å±±ä½äºŽå±±ä¸œçœæ³°å®‰å¸‚æ³°å®‰å¸‚ã€‚æ³°å®‰å¸‚æ˜¯ä¸­å›½äº”å²³ä¹‹ä¸€ï¼Œä¹Ÿæ˜¯ä¸–ç•Œæ–‡åŒ–é—äº§å’Œä¸­å›½åŽ†å²æ–‡åŒ–åå±±ä¹‹ä¸€ã€‚æ³°å®‰å¸‚æœ‰è®¸å¤šè‘—åçš„æ™¯ç‚¹ï¼Œå¦‚äº”å²³ä¹‹ä¸€ã€çŽ‰çš‡é¡¶ã€å—å¤©é—¨ã€çŽ‰çš‡é˜ç­‰ã€‚
[C]: æ³°å±±ä½äºŽä¸­å›½å±±ä¸œçœæ³°å®‰å¸‚ï¼Œæ˜¯ä¸­å›½äº”å²³ä¹‹ä¸€ã€‚
[D]: ä½œä¸ºä¸€ä¸ªäººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼Œæˆ‘æ— æ³•è®¿é—®äº’è”ç½‘ï¼Œå› æ­¤æ— æ³•æä¾›å…³äºŽä½ æ‰€åœ¨ä½ç½®çš„ä¿¡æ¯ã€‚ä¸è¿‡ï¼Œä½ å¯ä»¥é€šè¿‡æœç´¢æˆ–æœç´¢ç›¸å…³å…³é”®è¯æ¥èŽ·å–æœ‰å…³ä½ æ‰€åœ¨ä½ç½®çš„ä¿¡æ¯ï¼Œæˆ–è€…æŸ¥çœ‹ç›¸å…³æ–°é—»æˆ–ç½‘ç«™æ¥èŽ·å–æœ‰å…³ä½ æ‰€åœ¨ä½ç½®çš„ä¿¡æ¯ã€‚
[E]: æ³°å±±ä½äºŽä¸­å›½å±±ä¸œçœæ³°å®‰å¸‚å¢ƒå†…ï¼Œæ˜¯ä¸­å›½äº”å²³ä¹‹ä¸€ï¼Œä¹Ÿæ˜¯ä¸­å›½æ–‡åŒ–å’ŒåŽ†å²çš„é‡è¦è±¡å¾ä¹‹ä¸€ã€‚å®ƒæ˜¯ä¸­å›½äº”å²³ä¹‹ä¸€ï¼Œä¹Ÿæ˜¯ä¸­å›½é“æ•™å’Œä½›æ•™çš„å‘æºåœ°ä¹‹ä¸€ã€‚æ³°å±±çš„æµ·æ‹”é«˜åº¦ä¸º1,545ç±³ï¼Œæ˜¯ä¸­å›½äº”å²³ä¹‹ä¸€ï¼Œä¹Ÿæ˜¯ä¸­å›½æœ€è‘—åçš„æ—…æ¸¸æ™¯ç‚¹ä¹‹ä¸€ã€‚å®ƒçš„åŽ†å²å¯ä»¥è¿½æº¯åˆ°å…¬å…ƒå‰5ä¸–çºªï¼Œæ˜¯ä¸­å›½å¤ä»£å¸çŽ‹ç¥­ç¥€çš„åœºæ‰€ã€‚æ³°å±±ä¹Ÿæ˜¯ä¸­å›½æ–‡åŒ–çš„é‡è¦ç»„æˆéƒ¨åˆ†ï¼Œè¢«èª‰ä¸ºâ€œäº”å²³ä¹‹é¦–â€ï¼Œæ˜¯ä¸­å›½æ–‡åŒ–çš„é‡è¦é—äº§ä¹‹ä¸€ã€‚


[Q]: ä¸–ç•Œä¸Šæœ€é«˜çš„å±±å³°æ˜¯ä»€ä¹ˆï¼Ÿ
[A]: ä¸–ç•Œä¸Šæœ€é«˜çš„å±±å³°æ˜¯ç ç©†æœ—çŽ›å³°ï¼Œä½äºŽå°¼æ³Šå°”å’Œä¸­å›½çš„è¾¹å¢ƒä¸Šï¼Œæµ·æ‹”8848ç±³ã€‚
[B]: ä¸–ç•Œä¸Šæœ€é«˜çš„å±±å³°æ˜¯ç ç©†æœ—çŽ›å³°ï¼Œä½äºŽå–œé©¬æ‹‰é›…å±±è„‰ï¼Œæµ·æ‹”8,848ç±³ã€‚
[C]: ç ç©†æœ—çŽ›å³°æ˜¯ä¸–ç•Œä¸Šæœ€é«˜çš„å±±å³°ï¼Œæµ·æ‹”8848ç±³ã€‚
[D]: ä¸–ç•Œä¸Šæœ€é«˜çš„å±±å³°æ˜¯ç ç©†æœ—çŽ›å³°ï¼Œä½äºŽå–œé©¬æ‹‰é›…å±±è„‰ï¼Œæµ·æ‹”8,848.86ç±³ï¼ˆ29,031.69è‹±å°ºï¼‰ã€‚
[E]: ä¸–ç•Œä¸Šæœ€é«˜çš„å±±å³°æ˜¯ç ç©†æœ—çŽ›å³°ï¼Œä¹Ÿç§°ä¸ºè¨åŠ çŽ›å¡”ï¼Œä½äºŽå–œé©¬æ‹‰é›…å±±è„‰çš„å°¼æ³Šå°”å’Œä¸­å›½è¾¹å¢ƒä¹‹é—´ï¼Œæµ·æ‹”8,848.86ç±³ï¼ˆ29,031.69è‹±å°ºï¼‰ã€‚å®ƒæ˜¯ä¸–ç•Œä¸Šæœ€è‘—åçš„ç™»å±±ç›®æ ‡ä¹‹ä¸€ï¼Œå¸å¼•ç€æ¥è‡ªä¸–ç•Œå„åœ°çš„ç™»å±±è€…å‰æ¥æŒ‘æˆ˜ã€‚ç ç©†æœ—çŽ›å³°çš„åå­—æ¥è‡ªè—è¯­ï¼Œæ„æ€æ˜¯â€œå¥³ç¥žçš„é¢å³°â€ï¼Œå®ƒæ˜¯ç”±ä¸¤ä¸ªä¸åŒçš„å±±å³°ç»„æˆçš„ï¼Œå…¶ä¸­ä¸€ä¸ªæ˜¯ä½äºŽå°¼æ³Šå°”çš„ç ç©†æœ—çŽ›å³°ï¼Œå¦ä¸€ä¸ªåˆ™ä½äºŽä¸­å›½ã€‚å®ƒçš„é«˜åº¦æ˜¯é€šè¿‡æµ‹é‡æµ·æ‹”é«˜åº¦æ¥ç¡®å®šçš„ï¼Œå› ä¸ºå®ƒæ˜¯é€šè¿‡æµ‹é‡åœ°çƒçš„å¹³å‡é«˜åº¦æ¥ç¡®å®šçš„ã€‚å°½ç®¡ç ç©†æœ—çŽ›å³°æ˜¯ä¸–ç•Œä¸Šæœ€é«˜çš„å±±å³°ï¼Œä½†å®ƒå¹¶ä¸æ˜¯åœ°çƒä¸Šä»»ä½•å…¶ä»–åœ°æ–¹éƒ½èƒ½åˆ°è¾¾çš„ã€‚åœ°çƒä¸Šçš„å…¶ä»–åœ°æ–¹ï¼Œå¦‚å—ç¾Žæ´²çš„å®‰ç¬¬æ–¯å±±è„‰ï¼Œä¹Ÿæ˜¯ä¸–ç•Œä¸Šæœ€é«˜çš„å±±è„‰ï¼Œä½†å®ƒå¹¶ä¸æ˜¯åœ°çƒä¸Šæœ€é«˜çš„å±±å³°ã€‚æ€»ä¹‹ï¼Œç ç©†æœ—çŽ›å³°æ˜¯ä¸–ç•Œä¸Šæœ€é«˜çš„å±±å³°ï¼Œä½†å®ƒå¹¶ä¸æ˜¯åœ°çƒä¸Šä»»ä½•åœ°æ–¹éƒ½èƒ½åˆ°è¾¾çš„ã€‚å®ƒæ˜¯åœ°çƒä¸Šæœ€é«˜çš„å±±è„‰ï¼Œä½†å®ƒå¹¶ä¸æ˜¯åœ°çƒä¸Šä»»ä½•åœ°æ–¹éƒ½èƒ½åˆ°è¾¾çš„ã€‚


[Q]: ä¸‡æœ‰å¼•åŠ›æ˜¯è°æå‡ºçš„ï¼Ÿ
[A]: ä¸‡æœ‰å¼•åŠ›æ˜¯ç”±è‹±å›½ç‰©ç†å­¦å®¶ç‰›é¡¿æå‡ºçš„ã€‚ä»–è®¤ä¸ºï¼Œæ‰€æœ‰ç‰©ä½“éƒ½ä¼šäº§ç”Ÿå¼•åŠ›ï¼Œè¿™ä¸ªå¼•åŠ›æ˜¯ç”±ç‰©ä½“çš„è´¨é‡å’Œè·ç¦»å†³å®šçš„ã€‚è¿™ä¸ªç†è®ºæ­ç¤ºäº†è´¨é‡å’Œè·ç¦»ä¹‹é—´çš„å…³ç³»ï¼Œå¹¶è¯æ˜Žäº†ä¸‡æœ‰å¼•åŠ›çš„æœ¬è´¨ã€‚
[B]: ä¸‡æœ‰å¼•åŠ›æ˜¯ç”±ç‰›é¡¿åœ¨1687å¹´æå‡ºçš„ã€‚å®ƒæ˜¯å®‡å®™ä¸­ä¸€ä¸ªåŸºæœ¬çš„ç‰©ç†çŽ°è±¡ï¼Œå®ƒæè¿°äº†ç‰©ä½“ä¹‹é—´çš„ç›¸äº’ä½œç”¨ã€‚è¿™ä¸ªåŠ›è¢«ç§°ä¸ºä¸‡æœ‰å¼•åŠ›ï¼Œå®ƒåœ¨æ‰€æœ‰ç‰©ä½“ä¹‹é—´éƒ½å­˜åœ¨ï¼Œè¿™ç§åŠ›ä¸Žç‰©ä½“çš„è´¨é‡å’Œè·ç¦»æœ‰å…³ã€‚ä¸‡æœ‰å¼•åŠ›æ˜¯è‡ªç„¶ç•Œä¸­æœ€åŸºæœ¬çš„åŠ›é‡ä¹‹ä¸€ï¼Œå®ƒä¸ä»…å½±å“ç€ç‰©ä½“çš„è¿åŠ¨å’Œå˜åŒ–ï¼Œè¿˜å¯¹å®‡å®™çš„ç»“æž„å’Œæ¼”åŒ–äº§ç”Ÿç€é‡è¦çš„å½±å“ã€‚
[C]: ä¸‡æœ‰å¼•åŠ›æ˜¯è‹±å›½ç‰©ç†å­¦å®¶è‰¾è¨å…‹Â·ç‰›é¡¿åœ¨17ä¸–çºªæå‡ºçš„ã€‚
[D]: å¼•åŠ›æ˜¯å®‡å®™ä¸­ä¸€ç§åŠ›é‡ï¼Œå®ƒæ˜¯ç”±è´¨é‡æˆ–èƒ½é‡æ‰€ç»„æˆçš„ã€‚æ ¹æ®ç‰›é¡¿çš„ä¸‡æœ‰å¼•åŠ›å®šå¾‹ï¼Œä¸€ä¸ªç‰©ä½“ä¹‹é—´çš„å¼•åŠ›å¤§å°ä¸Žå®ƒçš„è´¨é‡æˆæ­£æ¯”ï¼Œä¸Žå®ƒçš„è´¨é‡æˆåæ¯”ã€‚å› æ­¤ï¼Œç‰›é¡¿çš„ä¸‡æœ‰å¼•åŠ›å®šå¾‹è¡¨æ˜Žï¼Œä¸€ä¸ªç‰©ä½“ä¹‹é—´çš„å¼•åŠ›å¤§å°ä¸Žå®ƒçš„è´¨é‡æˆæ­£æ¯”ï¼Œä¸Žå®ƒçš„è´¨é‡æˆåæ¯”ã€‚è¿™ä¸ªå®šå¾‹åœ¨ç‰©ç†å­¦ã€å¤©æ–‡å­¦å’Œç‰©ç†å­¦ä¸­éƒ½æœ‰å¹¿æ³›çš„åº”ç”¨ã€‚
[E]: ä¸‡æœ‰å¼•åŠ›æ˜¯ç”±è‹±å›½ç‰©ç†å­¦å®¶è‰¾è¨å…‹Â·ç‰›é¡¿äºŽ1687å¹´æå‡ºçš„ã€‚ä»–åœ¨1687å¹´å‘è¡¨äº†ä¸€ç¯‡è‘—åçš„è®ºæ–‡ï¼Œé¢˜ä¸ºã€Šè‡ªç„¶å“²å­¦çš„æ•°å­¦åŽŸç†ã€‹ï¼Œå…¶ä¸­æå‡ºäº†ä¸‡æœ‰å¼•åŠ›å®šå¾‹ï¼ŒæŒ‡å‡ºä»»ä½•ä¸¤ä¸ªç‰©ä½“ä¹‹é—´éƒ½å­˜åœ¨ç€ä¸€ç§å¼•åŠ›ï¼Œè¿™ç§å¼•åŠ›çš„å¤§å°ä¸Žå®ƒä»¬çš„è´¨é‡æˆæ­£æ¯”ï¼Œä¸Žå®ƒä»¬ä¹‹é—´çš„è·ç¦»çš„å¹³æ–¹æˆåæ¯”ã€‚è¿™ä¸ªå®šå¾‹è¢«ç§°ä¸ºä¸‡æœ‰å¼•åŠ›å®šå¾‹ï¼Œå®ƒæè¿°äº†è´¨é‡å’Œè·ç¦»ä¹‹é—´çš„å…³ç³»ã€‚å®ƒè¡¨æ˜Žï¼Œä¸¤ä¸ªç‰©ä½“ä¹‹é—´çš„å¼•åŠ›ä¸Žå®ƒä»¬çš„è´¨é‡æˆæ­£æ¯”ï¼Œä¸Žå®ƒä»¬ä¹‹é—´çš„è·ç¦»çš„å¹³æ–¹æˆåæ¯”ã€‚è¿™ä¸ªå®šå¾‹å¯¹äºŽè§£é‡Šå®‡å®™ä¸­çš„è®¸å¤šçŽ°è±¡å’ŒçŽ°è±¡ä¹‹é—´çš„ç›¸äº’ä½œç”¨éžå¸¸é‡è¦ï¼Œä¾‹å¦‚è¡Œæ˜Ÿç»•å¤ªé˜³è¿åŠ¨ã€æ’æ˜Ÿä¹‹é—´çš„å¼•åŠ›é€é•œæ•ˆåº”ç­‰ç­‰ã€‚å®ƒä¹Ÿè¢«å¹¿æ³›åº”ç”¨äºŽå¤©æ–‡å­¦ã€ç‰©ç†å­¦å’Œå·¥ç¨‹å­¦ç­‰é¢†åŸŸï¼Œä¸ºæˆ‘ä»¬ç†è§£å®‡å®™çš„æœ¬è´¨å’Œæ¼”åŒ–æä¾›äº†é‡è¦çš„ç†è®ºåŸºç¡€ã€‚


[Q]: ä½ çŸ¥é“å¤§ç†ŠçŒ«çš„ä¸»è¦é£Ÿç‰©æ˜¯ä»€ä¹ˆå—ï¼Ÿ
[A]: å¤§ç†ŠçŒ«çš„ä¸»è¦é£Ÿç‰©æ˜¯ç«¹å­ã€‚å®ƒä»¬é€šå¸¸åƒç«¹å­ï¼Œæ¯å¤©éœ€è¦åƒæŽ‰å¤§çº¦30å…¬æ–¤çš„ç«¹å­ã€‚
[B]: æ˜¯çš„ï¼Œå¤§ç†ŠçŒ«ä¸»è¦ä»¥ç«¹å­ä¸ºé£Ÿã€‚å®ƒä»¬æ¯å¤©éœ€è¦åƒæŽ‰å¤§é‡çš„ç«¹å­æ¥ç»´æŒç”Ÿå‘½ï¼Œæ¯å¤©éœ€è¦åƒæŽ‰40è‡³80å…¬æ–¤çš„ç«¹å­ã€‚æ­¤å¤–ï¼Œå®ƒä»¬ä¹Ÿä¼šåƒä¸€äº›å…¶ä»–çš„æ¤ç‰©ï¼Œå¦‚è‰ã€æžœå®žã€åšæžœå’Œå°åž‹å“ºä¹³åŠ¨ç‰©ã€‚
[C]: å¤§ç†ŠçŒ«ä¸»è¦ä»¥ç«¹å­ä¸ºé£Ÿï¼Œä¹Ÿä¼šå¶å°”é£Ÿç”¨å…¶ä»–çš„æ¤ç‰©å’ŒåŠ¨ç‰©ã€‚æ­¤å¤–ï¼Œå¤§ç†ŠçŒ«ä¹Ÿä¼šåƒä¸€äº›é‡Žæžœã€å°åŠ¨ç‰©å’Œæ¤ç‰©ï¼Œä½†è¿™äº›éƒ½ä¸å±žäºŽå®ƒä»¬çš„ä¸»è¦é£Ÿç‰©æ¥æºã€‚
[D]: å¤§ç†ŠçŒ«çš„ä¸»è¦é£Ÿç‰©æ˜¯ç«¹å­ã€‚
[E]: å¤§ç†ŠçŒ«æ˜¯ä¸€ç§ä»¥ç«¹å­ä¸ºä¸»è¦é£Ÿç‰©çš„æ¤é£ŸåŠ¨ç‰©ï¼Œå®ƒä»¬çš„è‚ é“ç»“æž„é€‚åˆæ¶ˆåŒ–çº¤ç»´ç´ å«é‡é«˜çš„ç«¹å­ï¼Œä½†ä¹Ÿä¼šåƒä¸€äº›å…¶ä»–æ¤ç‰©ï¼Œå¦‚è‰æœ¬æ¤ç‰©å’Œå°åž‹å“ºä¹³åŠ¨ç‰©ã€‚å¤§ç†ŠçŒ«çš„è‚ é“ç»“æž„ä¹Ÿé€‚åº”äº†é«˜çº¤ç»´çš„ç«¹å­ï¼Œè¿™ä½¿å¾—å®ƒä»¬èƒ½å¤Ÿæ¶ˆåŒ–å¤§é‡çš„çº¤ç»´ç´ ï¼Œä»Žè€Œå¸®åŠ©å®ƒä»¬åœ¨é‡Žå¤–ç”Ÿå­˜ã€‚å¤§ç†ŠçŒ«çš„è‚ é“ä¸­è¿˜å«æœ‰ä¸€ç§å«åšâ€œçº¤ç»´ç´ é…¶â€çš„é…¶ç±»ç‰©è´¨ï¼Œè¿™ç§é…¶èƒ½å¤Ÿå¸®åŠ©å¤§ç†ŠçŒ«åˆ†è§£çº¤ç»´ç´ ï¼Œä»Žè€Œå¸®åŠ©å®ƒä»¬æ¶ˆåŒ–å¤§é‡çš„æ°´åˆ†å’Œè¥å…»ç‰©è´¨ã€‚æ­¤å¤–ï¼Œå¤§ç†ŠçŒ«çš„è‚ é“è¿˜å«æœ‰ä¸€ç§å«åšâ€œçº¤ç»´ç´ è›‹ç™½â€çš„è›‹ç™½è´¨ï¼Œè¿™ç§è›‹ç™½è´¨èƒ½å¤Ÿå¸®åŠ©å¤§ç†ŠçŒ«ç»´æŒä½“å†…çš„èƒ½é‡æ°´å¹³ï¼Œä»Žè€Œå¸®åŠ©å®ƒä»¬åœ¨é‡Žå¤–ç”Ÿå­˜ã€‚æ€»çš„æ¥è¯´ï¼Œå¤§ç†ŠçŒ«çš„ä¸»è¦é£Ÿç‰©æ˜¯ç«¹å­ï¼Œä½†å®ƒä»¬ä¹Ÿä¼šåƒä¸€äº›å…¶ä»–æ¤ç‰©ï¼Œå¦‚è‰æœ¬æ¤ç‰©å’Œå°åž‹å“ºä¹³åŠ¨ç‰©ã€‚


[Q]: æµ·æ°´ä¸ºä»€ä¹ˆæ˜¯å’¸çš„ï¼Ÿ
[A]: æµ·æ°´ä¸­å«æœ‰è®¸å¤šç›åˆ†ï¼Œè¿™äº›ç›åˆ†å¯ä»¥å¯¼è‡´æµ·æ°´å’¸åº¦çš„å¢žåŠ ã€‚æµ·æ°´ä¸­çš„ç›åˆ†ä¸»è¦æ¥è‡ªäºŽæµ·æ°´ä¸­çš„ç›åˆ†ï¼Œè¿™äº›ç›åˆ†å¯ä»¥ä»Žæµ·æ°´ä¸­çš„ç›åˆ†ä¸­èŽ·å¾—ã€‚æµ·æ°´ä¸­çš„æ°§åŒ–ç‰©å’Œç›åˆ†å¯ä»¥ä¸Žæµ·æ°´ä¸­çš„ç›åˆ†å½¢æˆæ°¢é”®ï¼Œä»Žè€Œä½¿æµ·æ°´å’¸åº¦å¢žåŠ ã€‚
[B]: æµ·æ°´æ˜¯å’¸çš„ï¼Œè¿™æ˜¯å› ä¸ºå®ƒå«æœ‰å¤§é‡çš„ç›åˆ†ï¼Œå…¶ä¸­åŒ…æ‹¬æ°¯ç¦»å­å’Œæ°¯ç¦»å­ã€‚è¿™äº›ç¦»å­åœ¨æµ·æ´‹ä¸­å½¢æˆäº†å¤§é‡çš„ç›ï¼Œè¿™äº›ç›åˆ†è¢«ç§°ä¸ºç›åˆ†ã€‚æµ·æ°´ä¸­å«æœ‰è®¸å¤šæº¶è§£åœ¨æ°´ä¸­çš„ç›ï¼Œè¿™äº›ç›åˆ†ä¼šéšç€æµ·æ°´çš„å‡é«˜è€Œé€æ¸è’¸å‘ï¼Œæœ€ç»ˆå¯¼è‡´æµ·æ°´ä¸­ç›åˆ†çš„è’¸å‘ã€‚è¿™äº›ç›åˆ†åœ¨æµ·æ°´ä¸­è¢«å®Œå…¨æ¶ˆè€—ï¼Œç„¶åŽè¢«æŽ’é™¤åœ¨æµ·æ°´ä¸­ã€‚æ­¤å¤–ï¼Œæµ·æ°´ä¸­è¿˜å«æœ‰è®¸å¤šå…¶ä»–çš„ç›åˆ†ï¼Œä½†è¿™äº›ç›åˆ†æ˜¯ä¸åŒçš„ï¼Œå› ä¸ºå®ƒä»¬åœ¨æ°´ä¸­çš„æµ®èµ·å’Œä¸‹é™è¿‡ç¨‹æ˜¯ä¸åŒçš„ã€‚æµ·æ°´ä¸­çš„ç›åˆ†æ˜¯ä»Žæµ·åº•çš„å²©çŸ³ä¸­æå–å‡ºæ¥çš„ï¼Œè¿™äº›ç›åˆ†åœ¨æµ·æ°´ä¸­å¯ä»¥è¢«åˆ©ç”¨ã€‚æ€»çš„æ¥è¯´ï¼Œæµ·æ°´æ˜¯å’¸çš„ï¼Œè¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆæµ·æ°´ä¸­å«æœ‰è®¸å¤šç›åˆ†å’Œç›åˆ†çš„åŽŸå› ã€‚
[C]: æµ·æ°´å«æœ‰è®¸å¤šæº¶è§£çš„ç›ç±»ï¼Œå…¶ä¸­æœ€ä¸»è¦çš„æ˜¯æ°¯åŒ–é’ ã€‚å½“æ°´ä¸­åŠ å…¥ç›æ—¶ï¼Œç›çš„åˆ†å­ä¼šä¸Žæ°´åˆ†å­å‘ç”Ÿååº”ï¼Œå½¢æˆæ°¢æ°§åŒ–é’ ï¼Œè¿™æ˜¯ä¸€ç§ç›ã€‚
[D]: å› ä¸ºæ°´æ˜¯è®¸å¤šç”Ÿç‰©çš„ç”Ÿå­˜æ‰€å¿…éœ€çš„ï¼Œå®ƒèƒ½å¤Ÿå¸æ”¶å’Œé‡Šæ”¾äºŒæ°§åŒ–ç¢³ï¼Œé‡Šæ”¾æ°§æ°”ï¼Œç»´æŒå¤§æ°”ä¸­çš„æ°´è’¸æ°”ï¼Œä»¥åŠç»´æŒæ°´å¾ªçŽ¯ã€‚æ°´ä¸­çš„ç›ç±»å’ŒåŒ–å­¦ç‰©è´¨ä¼šé‡Šæ”¾å‡ºæ°§æ°”ï¼Œä½¿åœ°çƒä¸Šçš„ç”Ÿç‰©å‘¼å¸ã€‚æ­¤å¤–ï¼Œæ°´è¿˜å…·æœ‰è®¸å¤šå…¶ä»–åŠŸèƒ½ï¼Œå¦‚ä¿æŒæ°´å¾ªçŽ¯ã€ç»´æŒæ°´å¾ªçŽ¯ã€è°ƒèŠ‚æ°”å€™å’ŒçŽ¯å¢ƒç­‰ã€‚æ°´æ˜¯è®¸å¤šç”Ÿç‰©ç”Ÿå­˜æ‰€å¿…éœ€çš„ï¼Œå®ƒä¹Ÿæ˜¯è®¸å¤šè‡ªç„¶çŽ°è±¡çš„é‡è¦åŸºç¡€ã€‚
[E]: æµ·æ°´æ˜¯å’¸çš„ä¸»è¦åŽŸå› æ˜¯å› ä¸ºå…¶ä¸­å«æœ‰å¤§é‡çš„æº¶è§£ç›ç±»ï¼Œå…¶ä¸­æœ€ä¸»è¦çš„æ˜¯æ°¯åŒ–é’ ï¼ˆNaClï¼‰ã€‚æ°¯åŒ–é’ æ˜¯ä¸€ç§éžå¸¸å¸¸è§çš„ç›ç±»ï¼Œå®ƒå­˜åœ¨äºŽåœ°çƒä¸Šçš„å¤§éƒ¨åˆ†åœ°åŒºï¼ŒåŒ…æ‹¬æµ·æ´‹ã€æ¹–æ³Šã€æ²³æµå’Œåœ°ä¸‹æ°´ã€‚å½“æ°´ä»Žæµ·æ´‹ä¸­è’¸å‘æ—¶ï¼Œå®ƒä¼šå¸¦èµ°ä¸€éƒ¨åˆ†ç›åˆ†ï¼Œä½¿æµ·æ°´å˜å¾—å’¸ã€‚æ­¤å¤–ï¼Œæµ·ä¸­è¿˜å«æœ‰å…¶ä»–æº¶è§£ç›ç±»çš„ç‰©è´¨ï¼Œå¦‚ç¡«é…¸ç›ã€ç¡«é…¸é•ã€ç¡«é…¸é’™ã€ç¡«é…¸é•ç›ã€ç¡«é…¸é•é’¾ã€ç¡«é…¸é•é’ ã€ç¡«é…¸é•é’™ã€ç¡«é…¸é•é•é’™ã€ç¡«é…¸é•é•é’™ã€ç¡«é…¸é•é•é’™ã€ç¡«é…¸é•é•é’ ã€ç¡«é…¸é•é•é’™ã€ç¡«é…¸é•é•é•é’™ã€ç¡«é…¸é•é•é•é’™ã€ç¡«é…¸é•é•é•é’™ã€ç¡«é…¸é•é•é•é’™ã€ç¡«é…¸é•é•é•é’™ã€ç¡«é…¸é•é•é•é’™ã€ç¡«é…¸é•é•é•é’™ã€ç¡«é…¸é•é•é•é’™ã€ç¡«é…¸é•é•é•é’™ã€ç¡«é…¸é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•é•é•é•é’™ã€ç¡«é…¸é•é•é•é•
[!NOTE] ðŸ™‹â€â™‚ï¸ç›´æŽ¥æŠŠä¸Šè¿°æ¨¡åž‹çš„å›žç­”ä¸¢ç»™GPT-4oï¼Œè®©å®ƒå¸®å¿™æ‰“ä¸ªåˆ†ï¼šï¼šæ¨¡åž‹Açš„å›žç­”é€šå¸¸ç®€æ´æ˜Žäº†ï¼Œä½†åœ¨æŸäº›é—®é¢˜ä¸Šç¼ºä¹è¯¦ç»†ä¿¡æ¯å’Œå‡†ç¡®æ€§ã€‚ä¾‹å¦‚ï¼Œåœ¨é•¿æ±Ÿçš„é•¿åº¦é—®é¢˜ä¸Šï¼Œæ¨¡åž‹Açš„å›žç­”æ˜¯é”™è¯¯çš„ã€‚ï¼šæ¨¡åž‹Bçš„å›žç­”åœ¨æŸäº›é—®é¢˜ä¸Šæä¾›äº†é¢å¤–çš„ä¿¡æ¯ï¼Œä½†è¿™äº›ä¿¡æ¯æœ‰æ—¶æ˜¯ä¸å‡†ç¡®çš„æˆ–å¤šä½™çš„ã€‚ä¾‹å¦‚ï¼Œåœ¨é•¿æ±Ÿçš„é•¿åº¦é—®é¢˜ä¸Šï¼Œæ¨¡åž‹Bæä¾›äº†ä¸å‡†ç¡®çš„é•¿åº¦å’ŒæµåŸŸé¢ç§¯ã€‚ï¼šæ¨¡åž‹Cçš„å›žç­”é€šå¸¸è¾ƒä¸ºè¯¦ç»†ï¼Œä¸”åœ¨å¤§å¤šæ•°é—®é¢˜ä¸Šæä¾›äº†å‡†ç¡®çš„ä¿¡æ¯ã€‚ä¾‹å¦‚ï¼Œåœ¨é•¿æ±Ÿå’Œæ³°å±±çš„é—®é¢˜ä¸Šï¼Œæ¨¡åž‹Cçš„å›žç­”æ˜¯å‡†ç¡®çš„ã€‚ï¼šæ¨¡åž‹Dçš„å›žç­”åœ¨æŸäº›é—®é¢˜ä¸Šæ˜¾å¾—æ··ä¹±ï¼Œä¸”ç¼ºä¹å‡†ç¡®æ€§ã€‚ä¾‹å¦‚ï¼Œåœ¨æ³°å±±çš„é—®é¢˜ä¸Šï¼Œæ¨¡åž‹Dçš„å›žç­”å®Œå…¨åç¦»äº†ä¸»é¢˜ã€‚ï¼šæ¨¡åž‹Eçš„å›žç­”é€šå¸¸éžå¸¸è¯¦ç»†ï¼Œä½†åœ¨æŸäº›é—®é¢˜ä¸Šè¿‡äºŽå†—é•¿ï¼Œä¸”åŒ…å«äº†ä¸€äº›ä¸å¿…è¦çš„ä¿¡æ¯ã€‚ä¾‹å¦‚ï¼Œåœ¨ä¸‡æœ‰å¼•åŠ›çš„é—®é¢˜ä¸Šï¼Œæ¨¡åž‹Eçš„å›žç­”è¿‡äºŽå¤æ‚ã€‚minimindç³»åˆ—ï¼ˆABCï¼‰çš„æŽ’åºç¬¦åˆç›´è§‰ï¼Œminimind-v1(0.1B)è¯„åˆ†æœ€é«˜ï¼Œå¸¸è¯†æ€§é—®é¢˜çš„å›žç­”åŸºæœ¬æ²¡æœ‰é”™è¯¯å’Œå¹»è§‰ã€‚å‡ºä¹Žæ„æ–™çš„æ˜¯ï¼Œminimind-v1-small(0.02B)ä»…æœ‰26Må‚æ•°ï¼Œå´å¯ä»¥æŽ¥è¿‘minimind-v1(0.1B)çš„è¡¨çŽ°ã€‚minimind-v1(0.1B)çš„sftè½®æ•°ä»…æœ‰ä¸åˆ°2ï¼Œå·æ‡’æå‰killè…¾å‡ºèµ„æºç»™å°æ¨¡åž‹ï¼Œ0.1Bæ²¡æœ‰å¾—åˆ°å……åˆ†è®­ç»ƒçš„æƒ…å†µä¸‹ä¾ç„¶åšåˆ°äº†æœ€å¼ºï¼Œå…¶å®žè¿˜æ˜¯åº•å¤§ä¸€çº§åŽ‹æ­»äººã€‚minimind-v1-moe(0.1B)è¡¨çŽ°åªæ¯”minimind-v1-small(0.02B) ç•¥å¥½ï¼ŒåŒæ ·æ˜¯å› ä¸ºå·æ‡’æ—©åœè…¾å‡ºèµ„æºåšå…¶å®ƒè®­ç»ƒäº†ï¼Œä½†æ˜¯MoEæ¨¡åž‹è¿™ç§ç¨€ç–å¤šExpertsæ¨¡å¼éœ€è¦çš„è®­ç»ƒè½®æ¬¡éœ€è¦é…Œæƒ…æ›´é«˜ï¼Œè®©æ‰€æœ‰FFNå±‚ä¸“å®¶å¾—åˆ°è·¯ç”±çš„æ¿€æ´»å……åˆ†è®­ç»ƒï¼Œåœ¨ç›®å‰epochsè®¾ç½®ä¸º3æ—¶è®­ç»ƒçš„è¿˜ä¸å¤Ÿå……è¶³ã€‚ minimindåœ¨æ—©æœŸå®žéªŒéªŒè¯é˜¶æ®µåœ¨Yi-Tokenizerä¸Šè¯•éªŒè¿‡moeçš„å……åˆ†è®­ç»ƒç‰ˆæœ¬ï¼Œå¯ä»¥åšåˆ°æ¯”denseå°æ¨¡åž‹è¡¨çŽ°è‚‰çœ¼å¯è§åœ°æ›´å¥½ã€‚æ­¤éƒ¨åˆ†å¯èƒ½éœ€è¦ç•™ç»™æ—¥åŽè…¾å‡ºæœåŠ¡å™¨å†è®­ç»ƒå¹¶æ›´æ–°v2ã€v3ç‰ˆæœ¬ã€‚Eæ¨¡åž‹çš„å›žç­”è‚‰çœ¼çœ‹èµ·æ¥æ˜¯éžå¸¸ä¸é”™çš„ï¼Œå°½ç®¡å­˜åœ¨äº›è®¸å¹»è§‰çžŽç¼–çš„æƒ…å†µã€‚ä½†GPT-4oå’ŒDeepseekçš„è¯„åˆ†éƒ½ä¸€è‡´è®¤ä¸ºå®ƒâ€œä¿¡æ¯è¿‡åº¦å†—é•¿ï¼Œä¸”æœ‰é‡å¤å†…å®¹ï¼Œå­˜åœ¨å¹»è§‰â€ã€‚ å…¶å®žè¿™ç§è¯„ä»·ç•¥æ˜¾ä¸¥æ ¼ï¼Œ100ä¸ªå­—ä¸­å“ªæ€•æœ‰10ä¸ªå­—æ˜¯å¹»è§‰ï¼Œå°±å¾ˆå®¹æ˜“æŠŠå®ƒå½’åˆ°ä½Žåˆ†ã€‚ç”±äºŽEæ¨¡åž‹é¢„è®­ç»ƒæ–‡æœ¬é•¿åº¦æ›´é•¿ï¼Œæ•°æ®é›†å¤§å¾—å¤šï¼Œæ‰€ä»¥å›žç­”çš„çœ‹èµ·æ¥å¾ˆå®Œå¤‡ã€‚åœ¨ä½“ç§¯è¿‘ä¼¼çš„æƒ…å†µä¸‹ï¼Œæ•°æ®æ•°é‡å’Œè´¨é‡éƒ½å¾ˆé‡è¦ã€‚Scaling Lawï¼šæ¨¡åž‹å‚æ•°è¶Šå¤§ï¼Œè®­ç»ƒæ•°æ®è¶Šå¤šæ¨¡åž‹çš„æ€§èƒ½è¶Šå¼ºã€‚C-Evalè¯„æµ‹ä»£ç è§ï¼šï¼Œ å°æ¨¡åž‹çš„æµ‹è¯„é€šå¸¸ä¸ºäº†é¿å…å›žå¤æ ¼å¼çš„éš¾ä»¥å›ºå®šçš„ç‰¹ç‚¹ï¼Œ è€Œç›´æŽ¥åˆ¤æ–­,,,å››ä¸ªå­—æ¯å¯¹åº”tokené¢„æµ‹æ¦‚çŽ‡ï¼Œå–æœ€å¤§çš„ä½œä¸ºå›žç­”ç­”æ¡ˆï¼Œä¸Žæ ‡å‡†ç­”æ¡ˆè®¡ç®—æ­£ç¡®çŽ‡ã€‚ minimindæ¨¡åž‹æœ¬èº«æ²¡æœ‰ä½¿ç”¨è¾ƒå¤§çš„æ•°æ®é›†è®­ç»ƒï¼Œä¹Ÿæ²¡æœ‰é’ˆå¯¹å›žç­”é€‰æ‹©é¢˜çš„æŒ‡ä»¤åšå¾®è°ƒï¼Œæµ‹è¯„ç»“æžœå¯ä»¥å½“ä¸ªå‚è€ƒã€‚probability_and_statisticschinese_language_and_literatureideological_and_moral_cultivationenvironmental_impact_assessment_engineermiddle_school_mathematicsæ€»é¢˜æ•°: 1346  
æ€»æ­£ç¡®æ•°: 316  
æ€»æ­£ç¡®çŽ‡: 23.48%
ä»¥ä¸‹æ¥è‡ªGPT-4oå¯¹minimindè¡¨çŽ°çš„çžŽçŒœï¼š### æ¨¡åž‹æ“…é•¿çš„é¢†åŸŸï¼š
1. é«˜ä¸­çš„åŒ–å­¦ï¼šæ­£ç¡®çŽ‡ä¸º42.11%ï¼Œæ˜¯æœ€é«˜çš„ä¸€ä¸ªé¢†åŸŸã€‚è¯´æ˜Žæ¨¡åž‹åœ¨è¿™æ–¹é¢çš„çŸ¥è¯†å¯èƒ½è¾ƒä¸ºæ‰Žå®žã€‚
2. ç¦»æ•£æ•°å­¦ï¼šæ­£ç¡®çŽ‡ä¸º37.50%ï¼Œå±žäºŽæ•°å­¦ç›¸å…³é¢†åŸŸï¼Œè¡¨çŽ°è¾ƒå¥½ã€‚
3. æ•™è‚²ç§‘å­¦ï¼šæ­£ç¡®çŽ‡ä¸º37.93%ï¼Œè¯´æ˜Žæ¨¡åž‹åœ¨æ•™è‚²ç›¸å…³é—®é¢˜ä¸Šçš„è¡¨çŽ°ä¹Ÿä¸é”™ã€‚
4. åŸºç¡€åŒ»å­¦ï¼šæ­£ç¡®çŽ‡ä¸º36.84%ï¼Œåœ¨åŒ»å­¦åŸºç¡€çŸ¥è¯†æ–¹é¢è¡¨çŽ°ä¹Ÿæ¯”è¾ƒå¥½ã€‚
5. æ“ä½œç³»ç»Ÿï¼šæ­£ç¡®çŽ‡ä¸º36.84%ï¼Œè¯´æ˜Žæ¨¡åž‹åœ¨è®¡ç®—æœºæ“ä½œç³»ç»Ÿæ–¹é¢çš„è¡¨çŽ°è¾ƒä¸ºå¯é ã€‚

### æ¨¡åž‹ä¸æ“…é•¿çš„é¢†åŸŸï¼š
1. æ³•å¾‹ç›¸å…³ï¼šå¦‚æ³•å¾‹ä¸“ä¸šï¼ˆ8.70%ï¼‰å’Œç¨ŽåŠ¡ä¼šè®¡ï¼ˆ20.41%ï¼‰ï¼Œè¡¨çŽ°ç›¸å¯¹è¾ƒå·®ã€‚
2. ä¸­å­¦å’Œå¤§å­¦çš„ç‰©ç†ï¼šå¦‚ä¸­å­¦ç‰©ç†ï¼ˆ26.32%ï¼‰å’Œå¤§å­¦ç‰©ç†ï¼ˆ21.05%ï¼‰ï¼Œæ¨¡åž‹åœ¨ç‰©ç†ç›¸å…³çš„é¢†åŸŸè¡¨çŽ°ä¸ä½³ã€‚
3. é«˜ä¸­çš„æ”¿æ²»ã€åœ°ç†ï¼šå¦‚é«˜ä¸­æ”¿æ²»ï¼ˆ15.79%ï¼‰å’Œé«˜ä¸­åœ°ç†ï¼ˆ21.05%ï¼‰ï¼Œæ¨¡åž‹åœ¨è¿™äº›é¢†åŸŸçš„æ­£ç¡®çŽ‡è¾ƒä½Žã€‚
4. è®¡ç®—æœºç½‘ç»œä¸Žä½“ç³»ç»“æž„ï¼šå¦‚è®¡ç®—æœºç½‘ç»œï¼ˆ21.05%ï¼‰å’Œè®¡ç®—æœºä½“ç³»ç»“æž„ï¼ˆ9.52%ï¼‰ï¼Œåœ¨è¿™äº›è®¡ç®—æœºä¸“ä¸šè¯¾ç¨‹ä¸Šçš„è¡¨çŽ°ä¹Ÿä¸å¤Ÿå¥½ã€‚
5. çŽ¯å¢ƒå½±å“è¯„ä¼°å·¥ç¨‹å¸ˆï¼šæ­£ç¡®çŽ‡ä»…ä¸º12.90%ï¼Œåœ¨çŽ¯å¢ƒç§‘å­¦é¢†åŸŸçš„è¡¨çŽ°ä¹Ÿä¸ç†æƒ³ã€‚

### æ€»ç»“ï¼š
- æ“…é•¿é¢†åŸŸï¼šåŒ–å­¦ã€æ•°å­¦ï¼ˆç‰¹åˆ«æ˜¯ç¦»æ•£æ•°å­¦ï¼‰ã€æ•™è‚²ç§‘å­¦ã€åŸºç¡€åŒ»å­¦ã€è®¡ç®—æœºæ“ä½œç³»ç»Ÿã€‚
- ä¸æ“…é•¿é¢†åŸŸï¼šæ³•å¾‹ã€ç‰©ç†ã€æ”¿æ²»ã€åœ°ç†ã€è®¡ç®—æœºç½‘ç»œä¸Žä½“ç³»ç»“æž„ã€çŽ¯å¢ƒç§‘å­¦ã€‚

è¿™è¡¨æ˜Žæ¨¡åž‹åœ¨æ¶‰åŠé€»è¾‘æŽ¨ç†ã€åŸºç¡€ç§‘å­¦å’Œä¸€äº›å·¥ç¨‹æŠ€æœ¯é¢†åŸŸçš„é—®é¢˜ä¸Šè¡¨çŽ°è¾ƒå¥½ï¼Œä½†åœ¨äººæ–‡ç¤¾ç§‘ã€çŽ¯å¢ƒç§‘å­¦ä»¥åŠæŸäº›ç‰¹å®šä¸“ä¸šé¢†åŸŸï¼ˆå¦‚æ³•å¾‹å’Œç¨ŽåŠ¡ï¼‰ä¸Šè¡¨çŽ°è¾ƒå¼±ã€‚å¦‚æžœè¦æé«˜æ¨¡åž‹çš„æ€§èƒ½ï¼Œå¯èƒ½éœ€è¦åŠ å¼ºå®ƒåœ¨äººæ–‡ç¤¾ç§‘ã€ç‰©ç†ã€æ³•å¾‹ã€ä»¥åŠçŽ¯å¢ƒç§‘å­¦ç­‰æ–¹é¢çš„è®­ç»ƒã€‚
minimind (root dir)
â”œâ”€minimind
|  â”œâ”€â”€ config.json
|  â”œâ”€â”€ generation_config.json
|  â”œâ”€â”€ LMConfig.py
|  â”œâ”€â”€ model.py
|  â”œâ”€â”€ pytorch_model.bin
|  â”œâ”€â”€ special_tokens_map.json
|  â”œâ”€â”€ tokenizer_config.json
|  â”œâ”€â”€ tokenizer.json
python chat_openai_api.py
curl http://ip:port/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{ 
    "model": "model-identifier",
    "messages": [ 
      { "role": "user", "content": "ä¸–ç•Œä¸Šæœ€é«˜çš„å±±æ˜¯ä»€ä¹ˆï¼Ÿ" }
    ], 
    "temperature": 0.7, 
    "max_tokens": -1,
    "stream": true
}'
åœ¨fastgptä¸­æŽ¥å…¥ä½¿ç”¨minimind api[!TIP] å¦‚æžœæ‚¨è§‰å¾— å¯¹æ‚¨æœ‰æ‰€å¸®åŠ©ï¼Œå¯ä»¥åœ¨ GitHub ä¸ŠåŠ ä¸€ä¸ªâ­ ç¯‡å¹…ä¸çŸ­æ°´å¹³æœ‰é™éš¾å…çº°æ¼ï¼Œæ¬¢è¿Žåœ¨Issuesäº¤æµæŒ‡æ­£æˆ–æäº¤PRæ”¹è¿›é¡¹ç›®[!NOTE] ä¼—äººæ‹¾æŸ´ç«ç„°é«˜ å¦‚æžœæ‚¨å·²ç»å°è¯•è®­ç»ƒäº†æ–°çš„MiniMindåž‹å·ï¼Œæ¬¢è¿Žåœ¨Discussionsæˆ–Issuesä¸­åˆ†äº«æ‚¨çš„æ¨¡åž‹æƒé‡ å¯ä»¥æ˜¯åœ¨ç‰¹å®šä¸‹æ¸¸ä»»åŠ¡æˆ–åž‚ç›´é¢†åŸŸï¼ˆä¾‹å¦‚æƒ…æ„Ÿè¯†åˆ«ã€åŒ»ç–—ã€å¿ƒç†ã€é‡‘èžã€æ³•å¾‹é—®ç­”ç­‰ï¼‰çš„MiniMindæ–°æ¨¡åž‹ç‰ˆæœ¬ ä¹Ÿå¯ä»¥æ˜¯æ‹“å±•è®­ç»ƒåŽï¼ˆä¾‹å¦‚æŽ¢ç´¢æ›´é•¿æ–‡æœ¬åºåˆ—ã€æ›´å¤§ä½“ç§¯ï¼ˆ0.1B+ï¼‰æˆ–æ›´å¤§çš„æ•°æ®é›†ï¼‰çš„MiniMindæ–°æ¨¡åž‹ç‰ˆæœ¬ ä»»ä½•åˆ†äº«éƒ½è§†ä½œç‹¬ä¸€æ— äºŒçš„ï¼Œæ‰€æœ‰å°è¯•éƒ½å…·æœ‰ä»·å€¼ï¼Œå¹¶å—åˆ°é¼“åŠ± è¿™äº›è´¡çŒ®éƒ½ä¼šè¢«åŠæ—¶å‘çŽ°å¹¶æ•´ç†åœ¨é¸£è°¢åˆ—è¡¨ä¸­ï¼Œå†æ¬¡æ„Ÿè°¢æ‰€æœ‰æ”¯æŒï¼]]></content:encoded></item><item><title>unslothai/unsloth</title><link>https://github.com/unslothai/unsloth</link><author></author><category>trending</category><pubDate>Sun, 9 Feb 2025 02:28:32 +0000</pubDate><source url="http://mshibanami.github.io/GitHubTrendingRSS">Dev - Github Trending</source><content:encoded><![CDATA[Finetune Llama 3.3, DeepSeek-R1 & Reasoning LLMs 2x faster with 70% less memory! ðŸ¦¥All notebooks are ! Add your dataset, click "Run All", and you'll get a 2x faster finetuned model which can be exported to GGUF, Ollama, vLLM or uploaded to Hugging Face.ðŸ¥‡ Performance BenchmarkingWe tested using the Alpaca Dataset, a batch size of 2, gradient accumulation steps of 4, rank = 32, and applied QLoRA on all linear layers (q, k, v, o, gate, up, down):ðŸ’¾ Installation InstructionsFor stable releases, use . We recommend pip install "unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git" for most installations though.âš ï¸Only use Conda if you have it. If not, use Pip. Select either  for CUDA 11.8 or CUDA 12.1. We support .conda create --name unsloth_env \
    python=3.11 \
    pytorch-cuda=12.1 \
    pytorch cudatoolkit xformers -c pytorch -c nvidia -c xformers \
    -y
conda activate unsloth_env

pip install "unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git"
pip install --no-deps trl peft accelerate bitsandbytes
âš ï¸Do **NOT** use this if you have Conda. Pip is a bit more complex since there are dependency issues. The pip command is different for  and CUDA versions.For other torch versions, we support , , , ,  and for CUDA versions, we support  and  and . For Ampere devices (A100, H100, RTX3090) and above, use  or  or .For example, if you have  and , use:pip install --upgrade pip
pip install "unsloth[cu121-torch240] @ git+https://github.com/unslothai/unsloth.git"
Another example, if you have  and , use:pip install --upgrade pip
pip install "unsloth[cu124-torch250] @ git+https://github.com/unslothai/unsloth.git"
pip install "unsloth[cu121-ampere-torch240] @ git+https://github.com/unslothai/unsloth.git"
pip install "unsloth[cu118-ampere-torch240] @ git+https://github.com/unslothai/unsloth.git"
pip install "unsloth[cu121-torch240] @ git+https://github.com/unslothai/unsloth.git"
pip install "unsloth[cu118-torch240] @ git+https://github.com/unslothai/unsloth.git"

pip install "unsloth[cu121-torch230] @ git+https://github.com/unslothai/unsloth.git"
pip install "unsloth[cu121-ampere-torch230] @ git+https://github.com/unslothai/unsloth.git"

pip install "unsloth[cu121-torch250] @ git+https://github.com/unslothai/unsloth.git"
pip install "unsloth[cu124-ampere-torch250] @ git+https://github.com/unslothai/unsloth.git"
Or, run the below in a terminal to get the  pip installation command:wget -qO- https://raw.githubusercontent.com/unslothai/unsloth/main/unsloth/_auto_install.py | python -
Or, run the below manually in a Python REPL:try: import torch
except: raise ImportError('Install torch via `pip install torch`')
from packaging.version import Version as V
v = V(torch.__version__)
cuda = str(torch.version.cuda)
is_ampere = torch.cuda.get_device_capability()[0] >= 8
if cuda != "12.1" and cuda != "11.8" and cuda != "12.4": raise RuntimeError(f"CUDA = {cuda} not supported!")
if   v <= V('2.1.0'): raise RuntimeError(f"Torch = {v} too old!")
elif v <= V('2.1.1'): x = 'cu{}{}-torch211'
elif v <= V('2.1.2'): x = 'cu{}{}-torch212'
elif v  < V('2.3.0'): x = 'cu{}{}-torch220'
elif v  < V('2.4.0'): x = 'cu{}{}-torch230'
elif v  < V('2.5.0'): x = 'cu{}{}-torch240'
elif v  < V('2.6.0'): x = 'cu{}{}-torch250'
else: raise RuntimeError(f"Torch = {v} too new!")
x = x.format(cuda.replace(".", ""), "-ampere" if is_ampere else "")
print(f'pip install --upgrade pip && pip install "unsloth[{x}] @ git+https://github.com/unslothai/unsloth.git"')
To run Unsloth directly on Windows:trainer = SFTTrainer(
    dataset_num_proc=1,
    ...
)
For advanced installation instructions or if you see weird errors during installations:Install  and . Go to https://pytorch.org to install it. For example pip install torch torchvision torchaudio tritonConfirm if CUDA is installated correctly. Try . If that fails, you need to install  or CUDA drivers.Install  manually. You can try installing  and seeing if  succeeds. Check if  succeeded with  Go to https://github.com/facebookresearch/xformers. Another option is to install  for Ampere GPUs.Finally, install  and check it with Go to our official Documentation for saving to GGUF, checkpointing, evaluation and more!We support Huggingface's TRL, Trainer, Seq2SeqTrainer or even Pytorch code!If you want to download models from the ModelScope community, please use an environment variable: , and install the modelscope library by: pip install modelscope -U.unsloth_cli.py also supports  to download models and datasets. please remember to use the model and dataset id in the ModelScope community.from unsloth import FastLanguageModel 
from unsloth import is_bfloat16_supported
import torch
from trl import SFTTrainer
from transformers import TrainingArguments
from datasets import load_dataset
max_seq_length = 2048 # Supports RoPE Scaling interally, so choose any!
# Get LAION dataset
url = "https://huggingface.co/datasets/laion/OIG/resolve/main/unified_chip2.jsonl"
dataset = load_dataset("json", data_files = {"train" : url}, split = "train")

# 4bit pre quantized models we support for 4x faster downloading + no OOMs.
fourbit_models = [
    "unsloth/mistral-7b-v0.3-bnb-4bit",      # New Mistral v3 2x faster!
    "unsloth/mistral-7b-instruct-v0.3-bnb-4bit",
    "unsloth/llama-3-8b-bnb-4bit",           # Llama-3 15 trillion tokens model 2x faster!
    "unsloth/llama-3-8b-Instruct-bnb-4bit",
    "unsloth/llama-3-70b-bnb-4bit",
    "unsloth/Phi-3-mini-4k-instruct",        # Phi-3 2x faster!
    "unsloth/Phi-3-medium-4k-instruct",
    "unsloth/mistral-7b-bnb-4bit",
    "unsloth/gemma-7b-bnb-4bit",             # Gemma 2.2x faster!
] # More models at https://huggingface.co/unsloth

model, tokenizer = FastLanguageModel.from_pretrained(
    model_name = "unsloth/llama-3-8b-bnb-4bit",
    max_seq_length = max_seq_length,
    dtype = None,
    load_in_4bit = True,
)

# Do model patching and add fast LoRA weights
model = FastLanguageModel.get_peft_model(
    model,
    r = 16,
    target_modules = ["q_proj", "k_proj", "v_proj", "o_proj",
                      "gate_proj", "up_proj", "down_proj",],
    lora_alpha = 16,
    lora_dropout = 0, # Supports any, but = 0 is optimized
    bias = "none",    # Supports any, but = "none" is optimized
    # [NEW] "unsloth" uses 30% less VRAM, fits 2x larger batch sizes!
    use_gradient_checkpointing = "unsloth", # True or "unsloth" for very long context
    random_state = 3407,
    max_seq_length = max_seq_length,
    use_rslora = False,  # We support rank stabilized LoRA
    loftq_config = None, # And LoftQ
)

trainer = SFTTrainer(
    model = model,
    train_dataset = dataset,
    dataset_text_field = "text",
    max_seq_length = max_seq_length,
    tokenizer = tokenizer,
    args = TrainingArguments(
        per_device_train_batch_size = 2,
        gradient_accumulation_steps = 4,
        warmup_steps = 10,
        max_steps = 60,
        fp16 = not is_bfloat16_supported(),
        bf16 = is_bfloat16_supported(),
        logging_steps = 1,
        output_dir = "outputs",
        optim = "adamw_8bit",
        seed = 3407,
    ),
)
trainer.train()

# Go to https://github.com/unslothai/unsloth/wiki for advanced tips like
# (1) Saving to GGUF / merging to 16bit for vLLM
# (2) Continued training from a saved LoRA adapter
# (3) Adding an evaluation loop / OOMs
# (4) Customized chat templates
DPO (Direct Preference Optimization), PPO, Reward Modelling all seem to work as per 3rd party independent testing from Llama-Factory. We have a preliminary Google Colab notebook for reproducing Zephyr on Tesla T4 here: notebook.import os
os.environ["CUDA_VISIBLE_DEVICES"] = "0" # Optional set GPU device ID

from unsloth import FastLanguageModel, PatchDPOTrainer
from unsloth import is_bfloat16_supported
PatchDPOTrainer()
import torch
from transformers import TrainingArguments
from trl import DPOTrainer

model, tokenizer = FastLanguageModel.from_pretrained(
    model_name = "unsloth/zephyr-sft-bnb-4bit",
    max_seq_length = max_seq_length,
    dtype = None,
    load_in_4bit = True,
)

# Do model patching and add fast LoRA weights
model = FastLanguageModel.get_peft_model(
    model,
    r = 64,
    target_modules = ["q_proj", "k_proj", "v_proj", "o_proj",
                      "gate_proj", "up_proj", "down_proj",],
    lora_alpha = 64,
    lora_dropout = 0, # Supports any, but = 0 is optimized
    bias = "none",    # Supports any, but = "none" is optimized
    # [NEW] "unsloth" uses 30% less VRAM, fits 2x larger batch sizes!
    use_gradient_checkpointing = "unsloth", # True or "unsloth" for very long context
    random_state = 3407,
    max_seq_length = max_seq_length,
)

dpo_trainer = DPOTrainer(
    model = model,
    ref_model = None,
    args = TrainingArguments(
        per_device_train_batch_size = 4,
        gradient_accumulation_steps = 8,
        warmup_ratio = 0.1,
        num_train_epochs = 3,
        fp16 = not is_bfloat16_supported(),
        bf16 = is_bfloat16_supported(),
        logging_steps = 1,
        optim = "adamw_8bit",
        seed = 42,
        output_dir = "outputs",
    ),
    beta = 0.1,
    train_dataset = YOUR_DATASET_HERE,
    # eval_dataset = YOUR_DATASET_HERE,
    tokenizer = tokenizer,
    max_length = 1024,
    max_prompt_length = 512,
)
dpo_trainer.train()
ðŸ¥‡ Detailed Benchmarking TablesContext length benchmarksLlama 3.1 (8B) max. context lengthWe tested Llama 3.1 (8B) Instruct and did 4bit QLoRA on all linear layers (Q, K, V, O, gate, up and down) with rank = 32 with a batch size of 1. We padded all sequences to a certain maximum sequence length to mimic long context finetuning workloads.Llama 3.3 (70B) max. context lengthWe tested Llama 3.3 (70B) Instruct on a 80GB A100 and did 4bit QLoRA on all linear layers (Q, K, V, O, gate, up and down) with rank = 32 with a batch size of 1. We padded all sequences to a certain maximum sequence length to mimic long context finetuning workloads.You can cite the Unsloth repo as follows:@software{unsloth,
  author = {Daniel Han, Michael Han and Unsloth team},
  title = {Unsloth},
  url = {http://github.com/unslothai/unsloth},
  year = {2023}
}
]]></content:encoded></item></channel></rss>